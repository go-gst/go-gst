// Code generated by girgen. DO NOT EDIT.

package gstvideo

import (
	"fmt"
	"runtime"
	_ "runtime/cgo"
	"strings"
	"unsafe"

	"github.com/diamondburned/gotk4/pkg/core/gbox"
	"github.com/diamondburned/gotk4/pkg/core/gerror"
	"github.com/diamondburned/gotk4/pkg/core/gextras"
	coreglib "github.com/diamondburned/gotk4/pkg/core/glib"
	"github.com/diamondburned/gotk4/pkg/glib/v2"
	"github.com/go-gst/go-gst/pkg/gst"
	"github.com/go-gst/go-gst/pkg/gstbase"
)

// #cgo pkg-config: gstreamer-video-1.0
// #cgo CFLAGS: -Wno-deprecated-declarations
// #include <stdlib.h>
// #include <glib-object.h>
// #include <gst/video/video.h>
// extern void callbackDelete(gpointer);
// extern void _gotk4_gstvideo1_VideoConvertSampleCallback(GstSample*, GError*, gpointer);
// extern void _gotk4_gstvideo1_VideoAggregatorPadClass_update_conversion_info(GstVideoAggregatorPad*);
// extern void _gotk4_gstvideo1_VideoAggregatorPadClass_prepare_frame_start(GstVideoAggregatorPad*, GstVideoAggregator*, GstBuffer*, GstVideoFrame*);
// extern void _gotk4_gstvideo1_VideoAggregatorPadClass_prepare_frame_finish(GstVideoAggregatorPad*, GstVideoAggregator*, GstVideoFrame*);
// extern void _gotk4_gstvideo1_VideoAggregatorPadClass_clean_frame(GstVideoAggregatorPad*, GstVideoAggregator*, GstVideoFrame*);
// extern void _gotk4_gstvideo1_VideoAggregatorConvertPadClass_create_conversion_info(GstVideoAggregatorConvertPad*, GstVideoAggregator*, GstVideoInfo*);
// extern void _gotk4_gstvideo1_VideoAggregatorClass_find_best_format(GstVideoAggregator*, GstCaps*, GstVideoInfo*, gboolean*);
// extern void _gotk4_gstvideo1_ColorBalance_ConnectValueChanged(gpointer, GstColorBalanceChannel*, gint, guintptr);
// extern void _gotk4_gstvideo1_ColorBalanceChannel_ConnectValueChanged(gpointer, gint, guintptr);
// extern void _gotk4_gstvideo1_ColorBalanceChannelClass_value_changed(GstColorBalanceChannel*, gint);
// extern gboolean _gotk4_gstvideo1_VideoSinkClass_set_info(GstVideoSink*, GstCaps*, GstVideoInfo*);
// extern gboolean _gotk4_gstvideo1_VideoFilterClass_set_info(GstVideoFilter*, GstCaps*, GstVideoInfo*, GstCaps*, GstVideoInfo*);
// extern gboolean _gotk4_gstvideo1_VideoEncoderClass_transform_meta(GstVideoEncoder*, GstVideoCodecFrame*, GstMeta*);
// extern gboolean _gotk4_gstvideo1_VideoEncoderClass_stop(GstVideoEncoder*);
// extern gboolean _gotk4_gstvideo1_VideoEncoderClass_start(GstVideoEncoder*);
// extern gboolean _gotk4_gstvideo1_VideoEncoderClass_src_query(GstVideoEncoder*, GstQuery*);
// extern gboolean _gotk4_gstvideo1_VideoEncoderClass_src_event(GstVideoEncoder*, GstEvent*);
// extern gboolean _gotk4_gstvideo1_VideoEncoderClass_sink_query(GstVideoEncoder*, GstQuery*);
// extern gboolean _gotk4_gstvideo1_VideoEncoderClass_sink_event(GstVideoEncoder*, GstEvent*);
// extern gboolean _gotk4_gstvideo1_VideoEncoderClass_set_format(GstVideoEncoder*, GstVideoCodecState*);
// extern gboolean _gotk4_gstvideo1_VideoEncoderClass_reset(GstVideoEncoder*, gboolean);
// extern gboolean _gotk4_gstvideo1_VideoEncoderClass_propose_allocation(GstVideoEncoder*, GstQuery*);
// extern gboolean _gotk4_gstvideo1_VideoEncoderClass_open(GstVideoEncoder*);
// extern gboolean _gotk4_gstvideo1_VideoEncoderClass_negotiate(GstVideoEncoder*);
// extern gboolean _gotk4_gstvideo1_VideoEncoderClass_flush(GstVideoEncoder*);
// extern gboolean _gotk4_gstvideo1_VideoEncoderClass_decide_allocation(GstVideoEncoder*, GstQuery*);
// extern gboolean _gotk4_gstvideo1_VideoEncoderClass_close(GstVideoEncoder*);
// extern gboolean _gotk4_gstvideo1_VideoDecoderClass_transform_meta(GstVideoDecoder*, GstVideoCodecFrame*, GstMeta*);
// extern gboolean _gotk4_gstvideo1_VideoDecoderClass_stop(GstVideoDecoder*);
// extern gboolean _gotk4_gstvideo1_VideoDecoderClass_start(GstVideoDecoder*);
// extern gboolean _gotk4_gstvideo1_VideoDecoderClass_src_query(GstVideoDecoder*, GstQuery*);
// extern gboolean _gotk4_gstvideo1_VideoDecoderClass_src_event(GstVideoDecoder*, GstEvent*);
// extern gboolean _gotk4_gstvideo1_VideoDecoderClass_sink_query(GstVideoDecoder*, GstQuery*);
// extern gboolean _gotk4_gstvideo1_VideoDecoderClass_sink_event(GstVideoDecoder*, GstEvent*);
// extern gboolean _gotk4_gstvideo1_VideoDecoderClass_set_format(GstVideoDecoder*, GstVideoCodecState*);
// extern gboolean _gotk4_gstvideo1_VideoDecoderClass_reset(GstVideoDecoder*, gboolean);
// extern gboolean _gotk4_gstvideo1_VideoDecoderClass_propose_allocation(GstVideoDecoder*, GstQuery*);
// extern gboolean _gotk4_gstvideo1_VideoDecoderClass_open(GstVideoDecoder*);
// extern gboolean _gotk4_gstvideo1_VideoDecoderClass_negotiate(GstVideoDecoder*);
// extern gboolean _gotk4_gstvideo1_VideoDecoderClass_handle_missing_data(GstVideoDecoder*, GstClockTime, GstClockTime);
// extern gboolean _gotk4_gstvideo1_VideoDecoderClass_flush(GstVideoDecoder*);
// extern gboolean _gotk4_gstvideo1_VideoDecoderClass_decide_allocation(GstVideoDecoder*, GstQuery*);
// extern gboolean _gotk4_gstvideo1_VideoDecoderClass_close(GstVideoDecoder*);
// extern gboolean _gotk4_gstvideo1_VideoAggregatorPadClass_prepare_frame(GstVideoAggregatorPad*, GstVideoAggregator*, GstBuffer*, GstVideoFrame*);
// extern GstFlowReturn _gotk4_gstvideo1_VideoSinkClass_show_frame(GstVideoSink*, GstBuffer*);
// extern GstFlowReturn _gotk4_gstvideo1_VideoFilterClass_transform_frame_ip(GstVideoFilter*, GstVideoFrame*);
// extern GstFlowReturn _gotk4_gstvideo1_VideoFilterClass_transform_frame(GstVideoFilter*, GstVideoFrame*, GstVideoFrame*);
// extern GstFlowReturn _gotk4_gstvideo1_VideoEncoderClass_pre_push(GstVideoEncoder*, GstVideoCodecFrame*);
// extern GstFlowReturn _gotk4_gstvideo1_VideoEncoderClass_handle_frame(GstVideoEncoder*, GstVideoCodecFrame*);
// extern GstFlowReturn _gotk4_gstvideo1_VideoEncoderClass_finish(GstVideoEncoder*);
// extern GstFlowReturn _gotk4_gstvideo1_VideoDecoderClass_parse(GstVideoDecoder*, GstVideoCodecFrame*, GstAdapter*, gboolean);
// extern GstFlowReturn _gotk4_gstvideo1_VideoDecoderClass_handle_frame(GstVideoDecoder*, GstVideoCodecFrame*);
// extern GstFlowReturn _gotk4_gstvideo1_VideoDecoderClass_finish(GstVideoDecoder*);
// extern GstFlowReturn _gotk4_gstvideo1_VideoDecoderClass_drain(GstVideoDecoder*);
// extern GstFlowReturn _gotk4_gstvideo1_VideoAggregatorClass_aggregate_frames(GstVideoAggregator*, GstBuffer*);
// extern GstCaps* _gotk4_gstvideo1_VideoEncoderClass_getcaps(GstVideoEncoder*, GstCaps*);
// extern GstCaps* _gotk4_gstvideo1_VideoDecoderClass_getcaps(GstVideoDecoder*, GstCaps*);
// extern GstCaps* _gotk4_gstvideo1_VideoAggregatorClass_update_caps(GstVideoAggregator*, GstCaps*);
// GList* _gotk4_gstvideo1_ColorBalance_virtual_list_channels(void* fnptr, GstColorBalance* arg0) {
//   return ((GList* (*)(GstColorBalance*))(fnptr))(arg0);
// };
// GstCaps* _gotk4_gstvideo1_VideoAggregator_virtual_update_caps(void* fnptr, GstVideoAggregator* arg0, GstCaps* arg1) {
//   return ((GstCaps* (*)(GstVideoAggregator*, GstCaps*))(fnptr))(arg0, arg1);
// };
// GstCaps* _gotk4_gstvideo1_VideoDecoder_virtual_getcaps(void* fnptr, GstVideoDecoder* arg0, GstCaps* arg1) {
//   return ((GstCaps* (*)(GstVideoDecoder*, GstCaps*))(fnptr))(arg0, arg1);
// };
// GstCaps* _gotk4_gstvideo1_VideoEncoder_virtual_getcaps(void* fnptr, GstVideoEncoder* arg0, GstCaps* arg1) {
//   return ((GstCaps* (*)(GstVideoEncoder*, GstCaps*))(fnptr))(arg0, arg1);
// };
// GstColorBalanceType _gotk4_gstvideo1_ColorBalance_virtual_get_balance_type(void* fnptr, GstColorBalance* arg0) {
//   return ((GstColorBalanceType (*)(GstColorBalance*))(fnptr))(arg0);
// };
// GstFlowReturn _gotk4_gstvideo1_VideoAggregator_virtual_aggregate_frames(void* fnptr, GstVideoAggregator* arg0, GstBuffer* arg1) {
//   return ((GstFlowReturn (*)(GstVideoAggregator*, GstBuffer*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstvideo1_VideoDecoder_virtual_drain(void* fnptr, GstVideoDecoder* arg0) {
//   return ((GstFlowReturn (*)(GstVideoDecoder*))(fnptr))(arg0);
// };
// GstFlowReturn _gotk4_gstvideo1_VideoDecoder_virtual_finish(void* fnptr, GstVideoDecoder* arg0) {
//   return ((GstFlowReturn (*)(GstVideoDecoder*))(fnptr))(arg0);
// };
// GstFlowReturn _gotk4_gstvideo1_VideoDecoder_virtual_handle_frame(void* fnptr, GstVideoDecoder* arg0, GstVideoCodecFrame* arg1) {
//   return ((GstFlowReturn (*)(GstVideoDecoder*, GstVideoCodecFrame*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstvideo1_VideoDecoder_virtual_parse(void* fnptr, GstVideoDecoder* arg0, GstVideoCodecFrame* arg1, GstAdapter* arg2, gboolean arg3) {
//   return ((GstFlowReturn (*)(GstVideoDecoder*, GstVideoCodecFrame*, GstAdapter*, gboolean))(fnptr))(arg0, arg1, arg2, arg3);
// };
// GstFlowReturn _gotk4_gstvideo1_VideoEncoder_virtual_finish(void* fnptr, GstVideoEncoder* arg0) {
//   return ((GstFlowReturn (*)(GstVideoEncoder*))(fnptr))(arg0);
// };
// GstFlowReturn _gotk4_gstvideo1_VideoEncoder_virtual_handle_frame(void* fnptr, GstVideoEncoder* arg0, GstVideoCodecFrame* arg1) {
//   return ((GstFlowReturn (*)(GstVideoEncoder*, GstVideoCodecFrame*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstvideo1_VideoEncoder_virtual_pre_push(void* fnptr, GstVideoEncoder* arg0, GstVideoCodecFrame* arg1) {
//   return ((GstFlowReturn (*)(GstVideoEncoder*, GstVideoCodecFrame*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstvideo1_VideoFilter_virtual_transform_frame(void* fnptr, GstVideoFilter* arg0, GstVideoFrame* arg1, GstVideoFrame* arg2) {
//   return ((GstFlowReturn (*)(GstVideoFilter*, GstVideoFrame*, GstVideoFrame*))(fnptr))(arg0, arg1, arg2);
// };
// GstFlowReturn _gotk4_gstvideo1_VideoFilter_virtual_transform_frame_ip(void* fnptr, GstVideoFilter* arg0, GstVideoFrame* arg1) {
//   return ((GstFlowReturn (*)(GstVideoFilter*, GstVideoFrame*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstvideo1_VideoSink_virtual_show_frame(void* fnptr, GstVideoSink* arg0, GstBuffer* arg1) {
//   return ((GstFlowReturn (*)(GstVideoSink*, GstBuffer*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoAggregatorPad_virtual_prepare_frame(void* fnptr, GstVideoAggregatorPad* arg0, GstVideoAggregator* arg1, GstBuffer* arg2, GstVideoFrame* arg3) {
//   return ((gboolean (*)(GstVideoAggregatorPad*, GstVideoAggregator*, GstBuffer*, GstVideoFrame*))(fnptr))(arg0, arg1, arg2, arg3);
// };
// gboolean _gotk4_gstvideo1_VideoDecoder_virtual_close(void* fnptr, GstVideoDecoder* arg0) {
//   return ((gboolean (*)(GstVideoDecoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstvideo1_VideoDecoder_virtual_decide_allocation(void* fnptr, GstVideoDecoder* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstVideoDecoder*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoDecoder_virtual_flush(void* fnptr, GstVideoDecoder* arg0) {
//   return ((gboolean (*)(GstVideoDecoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstvideo1_VideoDecoder_virtual_handle_missing_data(void* fnptr, GstVideoDecoder* arg0, GstClockTime arg1, GstClockTime arg2) {
//   return ((gboolean (*)(GstVideoDecoder*, GstClockTime, GstClockTime))(fnptr))(arg0, arg1, arg2);
// };
// gboolean _gotk4_gstvideo1_VideoDecoder_virtual_negotiate(void* fnptr, GstVideoDecoder* arg0) {
//   return ((gboolean (*)(GstVideoDecoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstvideo1_VideoDecoder_virtual_open(void* fnptr, GstVideoDecoder* arg0) {
//   return ((gboolean (*)(GstVideoDecoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstvideo1_VideoDecoder_virtual_propose_allocation(void* fnptr, GstVideoDecoder* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstVideoDecoder*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoDecoder_virtual_reset(void* fnptr, GstVideoDecoder* arg0, gboolean arg1) {
//   return ((gboolean (*)(GstVideoDecoder*, gboolean))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoDecoder_virtual_set_format(void* fnptr, GstVideoDecoder* arg0, GstVideoCodecState* arg1) {
//   return ((gboolean (*)(GstVideoDecoder*, GstVideoCodecState*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoDecoder_virtual_sink_event(void* fnptr, GstVideoDecoder* arg0, GstEvent* arg1) {
//   return ((gboolean (*)(GstVideoDecoder*, GstEvent*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoDecoder_virtual_sink_query(void* fnptr, GstVideoDecoder* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstVideoDecoder*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoDecoder_virtual_src_event(void* fnptr, GstVideoDecoder* arg0, GstEvent* arg1) {
//   return ((gboolean (*)(GstVideoDecoder*, GstEvent*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoDecoder_virtual_src_query(void* fnptr, GstVideoDecoder* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstVideoDecoder*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoDecoder_virtual_start(void* fnptr, GstVideoDecoder* arg0) {
//   return ((gboolean (*)(GstVideoDecoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstvideo1_VideoDecoder_virtual_stop(void* fnptr, GstVideoDecoder* arg0) {
//   return ((gboolean (*)(GstVideoDecoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstvideo1_VideoDecoder_virtual_transform_meta(void* fnptr, GstVideoDecoder* arg0, GstVideoCodecFrame* arg1, GstMeta* arg2) {
//   return ((gboolean (*)(GstVideoDecoder*, GstVideoCodecFrame*, GstMeta*))(fnptr))(arg0, arg1, arg2);
// };
// gboolean _gotk4_gstvideo1_VideoEncoder_virtual_close(void* fnptr, GstVideoEncoder* arg0) {
//   return ((gboolean (*)(GstVideoEncoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstvideo1_VideoEncoder_virtual_decide_allocation(void* fnptr, GstVideoEncoder* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstVideoEncoder*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoEncoder_virtual_flush(void* fnptr, GstVideoEncoder* arg0) {
//   return ((gboolean (*)(GstVideoEncoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstvideo1_VideoEncoder_virtual_negotiate(void* fnptr, GstVideoEncoder* arg0) {
//   return ((gboolean (*)(GstVideoEncoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstvideo1_VideoEncoder_virtual_open(void* fnptr, GstVideoEncoder* arg0) {
//   return ((gboolean (*)(GstVideoEncoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstvideo1_VideoEncoder_virtual_propose_allocation(void* fnptr, GstVideoEncoder* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstVideoEncoder*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoEncoder_virtual_reset(void* fnptr, GstVideoEncoder* arg0, gboolean arg1) {
//   return ((gboolean (*)(GstVideoEncoder*, gboolean))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoEncoder_virtual_set_format(void* fnptr, GstVideoEncoder* arg0, GstVideoCodecState* arg1) {
//   return ((gboolean (*)(GstVideoEncoder*, GstVideoCodecState*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoEncoder_virtual_sink_event(void* fnptr, GstVideoEncoder* arg0, GstEvent* arg1) {
//   return ((gboolean (*)(GstVideoEncoder*, GstEvent*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoEncoder_virtual_sink_query(void* fnptr, GstVideoEncoder* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstVideoEncoder*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoEncoder_virtual_src_event(void* fnptr, GstVideoEncoder* arg0, GstEvent* arg1) {
//   return ((gboolean (*)(GstVideoEncoder*, GstEvent*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoEncoder_virtual_src_query(void* fnptr, GstVideoEncoder* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstVideoEncoder*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoEncoder_virtual_start(void* fnptr, GstVideoEncoder* arg0) {
//   return ((gboolean (*)(GstVideoEncoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstvideo1_VideoEncoder_virtual_stop(void* fnptr, GstVideoEncoder* arg0) {
//   return ((gboolean (*)(GstVideoEncoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstvideo1_VideoEncoder_virtual_transform_meta(void* fnptr, GstVideoEncoder* arg0, GstVideoCodecFrame* arg1, GstMeta* arg2) {
//   return ((gboolean (*)(GstVideoEncoder*, GstVideoCodecFrame*, GstMeta*))(fnptr))(arg0, arg1, arg2);
// };
// gboolean _gotk4_gstvideo1_VideoFilter_virtual_set_info(void* fnptr, GstVideoFilter* arg0, GstCaps* arg1, GstVideoInfo* arg2, GstCaps* arg3, GstVideoInfo* arg4) {
//   return ((gboolean (*)(GstVideoFilter*, GstCaps*, GstVideoInfo*, GstCaps*, GstVideoInfo*))(fnptr))(arg0, arg1, arg2, arg3, arg4);
// };
// gboolean _gotk4_gstvideo1_VideoOrientation_virtual_get_hcenter(void* fnptr, GstVideoOrientation* arg0, gint* arg1) {
//   return ((gboolean (*)(GstVideoOrientation*, gint*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoOrientation_virtual_get_hflip(void* fnptr, GstVideoOrientation* arg0, gboolean* arg1) {
//   return ((gboolean (*)(GstVideoOrientation*, gboolean*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoOrientation_virtual_get_vcenter(void* fnptr, GstVideoOrientation* arg0, gint* arg1) {
//   return ((gboolean (*)(GstVideoOrientation*, gint*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoOrientation_virtual_get_vflip(void* fnptr, GstVideoOrientation* arg0, gboolean* arg1) {
//   return ((gboolean (*)(GstVideoOrientation*, gboolean*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoOrientation_virtual_set_hcenter(void* fnptr, GstVideoOrientation* arg0, gint arg1) {
//   return ((gboolean (*)(GstVideoOrientation*, gint))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoOrientation_virtual_set_hflip(void* fnptr, GstVideoOrientation* arg0, gboolean arg1) {
//   return ((gboolean (*)(GstVideoOrientation*, gboolean))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoOrientation_virtual_set_vcenter(void* fnptr, GstVideoOrientation* arg0, gint arg1) {
//   return ((gboolean (*)(GstVideoOrientation*, gint))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoOrientation_virtual_set_vflip(void* fnptr, GstVideoOrientation* arg0, gboolean arg1) {
//   return ((gboolean (*)(GstVideoOrientation*, gboolean))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstvideo1_VideoSink_virtual_set_info(void* fnptr, GstVideoSink* arg0, GstCaps* arg1, GstVideoInfo* arg2) {
//   return ((gboolean (*)(GstVideoSink*, GstCaps*, GstVideoInfo*))(fnptr))(arg0, arg1, arg2);
// };
// gint _gotk4_gstvideo1_ColorBalance_virtual_get_value(void* fnptr, GstColorBalance* arg0, GstColorBalanceChannel* arg1) {
//   return ((gint (*)(GstColorBalance*, GstColorBalanceChannel*))(fnptr))(arg0, arg1);
// };
// void _gotk4_gstvideo1_ColorBalanceChannel_virtual_value_changed(void* fnptr, GstColorBalanceChannel* arg0, gint arg1) {
//   ((void (*)(GstColorBalanceChannel*, gint))(fnptr))(arg0, arg1);
// };
// void _gotk4_gstvideo1_ColorBalance_virtual_set_value(void* fnptr, GstColorBalance* arg0, GstColorBalanceChannel* arg1, gint arg2) {
//   ((void (*)(GstColorBalance*, GstColorBalanceChannel*, gint))(fnptr))(arg0, arg1, arg2);
// };
// void _gotk4_gstvideo1_ColorBalance_virtual_value_changed(void* fnptr, GstColorBalance* arg0, GstColorBalanceChannel* arg1, gint arg2) {
//   ((void (*)(GstColorBalance*, GstColorBalanceChannel*, gint))(fnptr))(arg0, arg1, arg2);
// };
// void _gotk4_gstvideo1_Navigation_virtual_send_event(void* fnptr, GstNavigation* arg0, GstStructure* arg1) {
//   ((void (*)(GstNavigation*, GstStructure*))(fnptr))(arg0, arg1);
// };
// void _gotk4_gstvideo1_Navigation_virtual_send_event_simple(void* fnptr, GstNavigation* arg0, GstEvent* arg1) {
//   ((void (*)(GstNavigation*, GstEvent*))(fnptr))(arg0, arg1);
// };
// void _gotk4_gstvideo1_VideoAggregatorConvertPad_virtual_create_conversion_info(void* fnptr, GstVideoAggregatorConvertPad* arg0, GstVideoAggregator* arg1, GstVideoInfo* arg2) {
//   ((void (*)(GstVideoAggregatorConvertPad*, GstVideoAggregator*, GstVideoInfo*))(fnptr))(arg0, arg1, arg2);
// };
// void _gotk4_gstvideo1_VideoAggregatorPad_virtual_clean_frame(void* fnptr, GstVideoAggregatorPad* arg0, GstVideoAggregator* arg1, GstVideoFrame* arg2) {
//   ((void (*)(GstVideoAggregatorPad*, GstVideoAggregator*, GstVideoFrame*))(fnptr))(arg0, arg1, arg2);
// };
// void _gotk4_gstvideo1_VideoAggregatorPad_virtual_prepare_frame_finish(void* fnptr, GstVideoAggregatorPad* arg0, GstVideoAggregator* arg1, GstVideoFrame* arg2) {
//   ((void (*)(GstVideoAggregatorPad*, GstVideoAggregator*, GstVideoFrame*))(fnptr))(arg0, arg1, arg2);
// };
// void _gotk4_gstvideo1_VideoAggregatorPad_virtual_prepare_frame_start(void* fnptr, GstVideoAggregatorPad* arg0, GstVideoAggregator* arg1, GstBuffer* arg2, GstVideoFrame* arg3) {
//   ((void (*)(GstVideoAggregatorPad*, GstVideoAggregator*, GstBuffer*, GstVideoFrame*))(fnptr))(arg0, arg1, arg2, arg3);
// };
// void _gotk4_gstvideo1_VideoAggregatorPad_virtual_update_conversion_info(void* fnptr, GstVideoAggregatorPad* arg0) {
//   ((void (*)(GstVideoAggregatorPad*))(fnptr))(arg0);
// };
// void _gotk4_gstvideo1_VideoAggregator_virtual_find_best_format(void* fnptr, GstVideoAggregator* arg0, GstCaps* arg1, GstVideoInfo* arg2, gboolean* arg3) {
//   ((void (*)(GstVideoAggregator*, GstCaps*, GstVideoInfo*, gboolean*))(fnptr))(arg0, arg1, arg2, arg3);
// };
// void _gotk4_gstvideo1_VideoOverlay_virtual_expose(void* fnptr, GstVideoOverlay* arg0) {
//   ((void (*)(GstVideoOverlay*))(fnptr))(arg0);
// };
// void _gotk4_gstvideo1_VideoOverlay_virtual_handle_events(void* fnptr, GstVideoOverlay* arg0, gboolean arg1) {
//   ((void (*)(GstVideoOverlay*, gboolean))(fnptr))(arg0, arg1);
// };
// void _gotk4_gstvideo1_VideoOverlay_virtual_set_render_rectangle(void* fnptr, GstVideoOverlay* arg0, gint arg1, gint arg2, gint arg3, gint arg4) {
//   ((void (*)(GstVideoOverlay*, gint, gint, gint, gint))(fnptr))(arg0, arg1, arg2, arg3, arg4);
// };
// void _gotk4_gstvideo1_VideoOverlay_virtual_set_window_handle(void* fnptr, GstVideoOverlay* arg0, guintptr arg1) {
//   ((void (*)(GstVideoOverlay*, guintptr))(fnptr))(arg0, arg1);
// };
import "C"

// GType values.
var (
	GTypeAncillaryMetaField                = coreglib.Type(C.gst_ancillary_meta_field_get_type())
	GTypeColorBalanceType                  = coreglib.Type(C.gst_color_balance_type_get_type())
	GTypeNavigationCommand                 = coreglib.Type(C.gst_navigation_command_get_type())
	GTypeNavigationEventType               = coreglib.Type(C.gst_navigation_event_type_get_type())
	GTypeNavigationMessageType             = coreglib.Type(C.gst_navigation_message_type_get_type())
	GTypeNavigationQueryType               = coreglib.Type(C.gst_navigation_query_type_get_type())
	GTypeVideoAFDSpec                      = coreglib.Type(C.gst_video_afd_spec_get_type())
	GTypeVideoAFDValue                     = coreglib.Type(C.gst_video_afd_value_get_type())
	GTypeVideoAlphaMode                    = coreglib.Type(C.gst_video_alpha_mode_get_type())
	GTypeVideoAncillaryDID                 = coreglib.Type(C.gst_video_ancillary_did_get_type())
	GTypeVideoAncillaryDID16               = coreglib.Type(C.gst_video_ancillary_di_d16_get_type())
	GTypeVideoCaptionType                  = coreglib.Type(C.gst_video_caption_type_get_type())
	GTypeVideoChromaMethod                 = coreglib.Type(C.gst_video_chroma_method_get_type())
	GTypeVideoChromaMode                   = coreglib.Type(C.gst_video_chroma_mode_get_type())
	GTypeVideoColorMatrix                  = coreglib.Type(C.gst_video_color_matrix_get_type())
	GTypeVideoColorPrimaries               = coreglib.Type(C.gst_video_color_primaries_get_type())
	GTypeVideoColorRange                   = coreglib.Type(C.gst_video_color_range_get_type())
	GTypeVideoDitherMethod                 = coreglib.Type(C.gst_video_dither_method_get_type())
	GTypeVideoFieldOrder                   = coreglib.Type(C.gst_video_field_order_get_type())
	GTypeVideoFormat                       = coreglib.Type(C.gst_video_format_get_type())
	GTypeVideoGLTextureOrientation         = coreglib.Type(C.gst_video_gl_texture_orientation_get_type())
	GTypeVideoGLTextureType                = coreglib.Type(C.gst_video_gl_texture_type_get_type())
	GTypeVideoGammaMode                    = coreglib.Type(C.gst_video_gamma_mode_get_type())
	GTypeVideoInterlaceMode                = coreglib.Type(C.gst_video_interlace_mode_get_type())
	GTypeVideoMatrixMode                   = coreglib.Type(C.gst_video_matrix_mode_get_type())
	GTypeVideoMultiviewFramePacking        = coreglib.Type(C.gst_video_multiview_frame_packing_get_type())
	GTypeVideoMultiviewMode                = coreglib.Type(C.gst_video_multiview_mode_get_type())
	GTypeVideoOrientationMethod            = coreglib.Type(C.gst_video_orientation_method_get_type())
	GTypeVideoPrimariesMode                = coreglib.Type(C.gst_video_primaries_mode_get_type())
	GTypeVideoResamplerMethod              = coreglib.Type(C.gst_video_resampler_method_get_type())
	GTypeVideoTileMode                     = coreglib.Type(C.gst_video_tile_mode_get_type())
	GTypeVideoTileType                     = coreglib.Type(C.gst_video_tile_type_get_type())
	GTypeVideoTransferFunction             = coreglib.Type(C.gst_video_transfer_function_get_type())
	GTypeVideoVBIParserResult              = coreglib.Type(C.gst_video_vbi_parser_result_get_type())
	GTypeNavigationModifierType            = coreglib.Type(C.gst_navigation_modifier_type_get_type())
	GTypeVideoBufferFlags                  = coreglib.Type(C.gst_video_buffer_flags_get_type())
	GTypeVideoChromaFlags                  = coreglib.Type(C.gst_video_chroma_flags_get_type())
	GTypeVideoChromaSite                   = coreglib.Type(C.gst_video_chroma_site_get_type())
	GTypeVideoCodecFrameFlags              = coreglib.Type(C.gst_video_codec_frame_flags_get_type())
	GTypeVideoDecoderRequestSyncPointFlags = coreglib.Type(C.gst_video_decoder_request_sync_point_flags_get_type())
	GTypeVideoDitherFlags                  = coreglib.Type(C.gst_video_dither_flags_get_type())
	GTypeVideoFlags                        = coreglib.Type(C.gst_video_flags_get_type())
	GTypeVideoFormatFlags                  = coreglib.Type(C.gst_video_format_flags_get_type())
	GTypeVideoFrameFlags                   = coreglib.Type(C.gst_video_frame_flags_get_type())
	GTypeVideoFrameMapFlags                = coreglib.Type(C.gst_video_frame_map_flags_get_type())
	GTypeVideoMultiviewFlags               = coreglib.Type(C.gst_video_multiview_flags_get_type())
	GTypeVideoOverlayFormatFlags           = coreglib.Type(C.gst_video_overlay_format_flags_get_type())
	GTypeVideoPackFlags                    = coreglib.Type(C.gst_video_pack_flags_get_type())
	GTypeVideoResamplerFlags               = coreglib.Type(C.gst_video_resampler_flags_get_type())
	GTypeVideoScalerFlags                  = coreglib.Type(C.gst_video_scaler_flags_get_type())
	GTypeVideoTimeCodeFlags                = coreglib.Type(C.gst_video_time_code_flags_get_type())
	GTypeColorBalance                      = coreglib.Type(C.gst_color_balance_get_type())
	GTypeNavigation                        = coreglib.Type(C.gst_navigation_get_type())
	GTypeVideoDirection                    = coreglib.Type(C.gst_video_direction_get_type())
	GTypeVideoOrientation                  = coreglib.Type(C.gst_video_orientation_get_type())
	GTypeVideoOverlay                      = coreglib.Type(C.gst_video_overlay_get_type())
	GTypeColorBalanceChannel               = coreglib.Type(C.gst_color_balance_channel_get_type())
	GTypeVideoAggregator                   = coreglib.Type(C.gst_video_aggregator_get_type())
	GTypeVideoAggregatorConvertPad         = coreglib.Type(C.gst_video_aggregator_convert_pad_get_type())
	GTypeVideoAggregatorPad                = coreglib.Type(C.gst_video_aggregator_pad_get_type())
	GTypeVideoAggregatorParallelConvertPad = coreglib.Type(C.gst_video_aggregator_parallel_convert_pad_get_type())
	GTypeVideoBufferPool                   = coreglib.Type(C.gst_video_buffer_pool_get_type())
	GTypeVideoDecoder                      = coreglib.Type(C.gst_video_decoder_get_type())
	GTypeVideoEncoder                      = coreglib.Type(C.gst_video_encoder_get_type())
	GTypeVideoFilter                       = coreglib.Type(C.gst_video_filter_get_type())
	GTypeVideoMultiviewFlagsSet            = coreglib.Type(C.gst_video_multiview_flagset_get_type())
	GTypeVideoSink                         = coreglib.Type(C.gst_video_sink_get_type())
	GTypeVideoCodecFrame                   = coreglib.Type(C.gst_video_codec_frame_get_type())
	GTypeVideoCodecState                   = coreglib.Type(C.gst_video_codec_state_get_type())
	GTypeVideoInfo                         = coreglib.Type(C.gst_video_info_get_type())
	GTypeVideoInfoDmaDRM                   = coreglib.Type(C.gst_video_info_dma_drm_get_type())
	GTypeVideoOverlayComposition           = coreglib.Type(C.gst_video_overlay_composition_get_type())
	GTypeVideoOverlayRectangle             = coreglib.Type(C.gst_video_overlay_rectangle_get_type())
	GTypeVideoTimeCode                     = coreglib.Type(C.gst_video_time_code_get_type())
	GTypeVideoTimeCodeInterval             = coreglib.Type(C.gst_video_time_code_interval_get_type())
	GTypeVideoVBIEncoder                   = coreglib.Type(C.gst_video_vbi_encoder_get_type())
	GTypeVideoVBIParser                    = coreglib.Type(C.gst_video_vbi_parser_get_type())
)

func init() {
	coreglib.RegisterGValueMarshalers([]coreglib.TypeMarshaler{
		coreglib.TypeMarshaler{T: GTypeAncillaryMetaField, F: marshalAncillaryMetaField},
		coreglib.TypeMarshaler{T: GTypeColorBalanceType, F: marshalColorBalanceType},
		coreglib.TypeMarshaler{T: GTypeNavigationCommand, F: marshalNavigationCommand},
		coreglib.TypeMarshaler{T: GTypeNavigationEventType, F: marshalNavigationEventType},
		coreglib.TypeMarshaler{T: GTypeNavigationMessageType, F: marshalNavigationMessageType},
		coreglib.TypeMarshaler{T: GTypeNavigationQueryType, F: marshalNavigationQueryType},
		coreglib.TypeMarshaler{T: GTypeVideoAFDSpec, F: marshalVideoAFDSpec},
		coreglib.TypeMarshaler{T: GTypeVideoAFDValue, F: marshalVideoAFDValue},
		coreglib.TypeMarshaler{T: GTypeVideoAlphaMode, F: marshalVideoAlphaMode},
		coreglib.TypeMarshaler{T: GTypeVideoAncillaryDID, F: marshalVideoAncillaryDID},
		coreglib.TypeMarshaler{T: GTypeVideoAncillaryDID16, F: marshalVideoAncillaryDID16},
		coreglib.TypeMarshaler{T: GTypeVideoCaptionType, F: marshalVideoCaptionType},
		coreglib.TypeMarshaler{T: GTypeVideoChromaMethod, F: marshalVideoChromaMethod},
		coreglib.TypeMarshaler{T: GTypeVideoChromaMode, F: marshalVideoChromaMode},
		coreglib.TypeMarshaler{T: GTypeVideoColorMatrix, F: marshalVideoColorMatrix},
		coreglib.TypeMarshaler{T: GTypeVideoColorPrimaries, F: marshalVideoColorPrimaries},
		coreglib.TypeMarshaler{T: GTypeVideoColorRange, F: marshalVideoColorRange},
		coreglib.TypeMarshaler{T: GTypeVideoDitherMethod, F: marshalVideoDitherMethod},
		coreglib.TypeMarshaler{T: GTypeVideoFieldOrder, F: marshalVideoFieldOrder},
		coreglib.TypeMarshaler{T: GTypeVideoFormat, F: marshalVideoFormat},
		coreglib.TypeMarshaler{T: GTypeVideoGLTextureOrientation, F: marshalVideoGLTextureOrientation},
		coreglib.TypeMarshaler{T: GTypeVideoGLTextureType, F: marshalVideoGLTextureType},
		coreglib.TypeMarshaler{T: GTypeVideoGammaMode, F: marshalVideoGammaMode},
		coreglib.TypeMarshaler{T: GTypeVideoInterlaceMode, F: marshalVideoInterlaceMode},
		coreglib.TypeMarshaler{T: GTypeVideoMatrixMode, F: marshalVideoMatrixMode},
		coreglib.TypeMarshaler{T: GTypeVideoMultiviewFramePacking, F: marshalVideoMultiviewFramePacking},
		coreglib.TypeMarshaler{T: GTypeVideoMultiviewMode, F: marshalVideoMultiviewMode},
		coreglib.TypeMarshaler{T: GTypeVideoOrientationMethod, F: marshalVideoOrientationMethod},
		coreglib.TypeMarshaler{T: GTypeVideoPrimariesMode, F: marshalVideoPrimariesMode},
		coreglib.TypeMarshaler{T: GTypeVideoResamplerMethod, F: marshalVideoResamplerMethod},
		coreglib.TypeMarshaler{T: GTypeVideoTileMode, F: marshalVideoTileMode},
		coreglib.TypeMarshaler{T: GTypeVideoTileType, F: marshalVideoTileType},
		coreglib.TypeMarshaler{T: GTypeVideoTransferFunction, F: marshalVideoTransferFunction},
		coreglib.TypeMarshaler{T: GTypeVideoVBIParserResult, F: marshalVideoVBIParserResult},
		coreglib.TypeMarshaler{T: GTypeNavigationModifierType, F: marshalNavigationModifierType},
		coreglib.TypeMarshaler{T: GTypeVideoBufferFlags, F: marshalVideoBufferFlags},
		coreglib.TypeMarshaler{T: GTypeVideoChromaFlags, F: marshalVideoChromaFlags},
		coreglib.TypeMarshaler{T: GTypeVideoChromaSite, F: marshalVideoChromaSite},
		coreglib.TypeMarshaler{T: GTypeVideoCodecFrameFlags, F: marshalVideoCodecFrameFlags},
		coreglib.TypeMarshaler{T: GTypeVideoDecoderRequestSyncPointFlags, F: marshalVideoDecoderRequestSyncPointFlags},
		coreglib.TypeMarshaler{T: GTypeVideoDitherFlags, F: marshalVideoDitherFlags},
		coreglib.TypeMarshaler{T: GTypeVideoFlags, F: marshalVideoFlags},
		coreglib.TypeMarshaler{T: GTypeVideoFormatFlags, F: marshalVideoFormatFlags},
		coreglib.TypeMarshaler{T: GTypeVideoFrameFlags, F: marshalVideoFrameFlags},
		coreglib.TypeMarshaler{T: GTypeVideoFrameMapFlags, F: marshalVideoFrameMapFlags},
		coreglib.TypeMarshaler{T: GTypeVideoMultiviewFlags, F: marshalVideoMultiviewFlags},
		coreglib.TypeMarshaler{T: GTypeVideoOverlayFormatFlags, F: marshalVideoOverlayFormatFlags},
		coreglib.TypeMarshaler{T: GTypeVideoPackFlags, F: marshalVideoPackFlags},
		coreglib.TypeMarshaler{T: GTypeVideoResamplerFlags, F: marshalVideoResamplerFlags},
		coreglib.TypeMarshaler{T: GTypeVideoScalerFlags, F: marshalVideoScalerFlags},
		coreglib.TypeMarshaler{T: GTypeVideoTimeCodeFlags, F: marshalVideoTimeCodeFlags},
		coreglib.TypeMarshaler{T: GTypeColorBalance, F: marshalColorBalance},
		coreglib.TypeMarshaler{T: GTypeNavigation, F: marshalNavigation},
		coreglib.TypeMarshaler{T: GTypeVideoDirection, F: marshalVideoDirection},
		coreglib.TypeMarshaler{T: GTypeVideoOrientation, F: marshalVideoOrientation},
		coreglib.TypeMarshaler{T: GTypeVideoOverlay, F: marshalVideoOverlay},
		coreglib.TypeMarshaler{T: GTypeColorBalanceChannel, F: marshalColorBalanceChannel},
		coreglib.TypeMarshaler{T: GTypeVideoAggregator, F: marshalVideoAggregator},
		coreglib.TypeMarshaler{T: GTypeVideoAggregatorConvertPad, F: marshalVideoAggregatorConvertPad},
		coreglib.TypeMarshaler{T: GTypeVideoAggregatorPad, F: marshalVideoAggregatorPad},
		coreglib.TypeMarshaler{T: GTypeVideoAggregatorParallelConvertPad, F: marshalVideoAggregatorParallelConvertPad},
		coreglib.TypeMarshaler{T: GTypeVideoBufferPool, F: marshalVideoBufferPool},
		coreglib.TypeMarshaler{T: GTypeVideoDecoder, F: marshalVideoDecoder},
		coreglib.TypeMarshaler{T: GTypeVideoEncoder, F: marshalVideoEncoder},
		coreglib.TypeMarshaler{T: GTypeVideoFilter, F: marshalVideoFilter},
		coreglib.TypeMarshaler{T: GTypeVideoMultiviewFlagsSet, F: marshalVideoMultiviewFlagsSet},
		coreglib.TypeMarshaler{T: GTypeVideoSink, F: marshalVideoSink},
		coreglib.TypeMarshaler{T: GTypeVideoCodecFrame, F: marshalVideoCodecFrame},
		coreglib.TypeMarshaler{T: GTypeVideoCodecState, F: marshalVideoCodecState},
		coreglib.TypeMarshaler{T: GTypeVideoInfo, F: marshalVideoInfo},
		coreglib.TypeMarshaler{T: GTypeVideoInfoDmaDRM, F: marshalVideoInfoDmaDRM},
		coreglib.TypeMarshaler{T: GTypeVideoOverlayComposition, F: marshalVideoOverlayComposition},
		coreglib.TypeMarshaler{T: GTypeVideoOverlayRectangle, F: marshalVideoOverlayRectangle},
		coreglib.TypeMarshaler{T: GTypeVideoTimeCode, F: marshalVideoTimeCode},
		coreglib.TypeMarshaler{T: GTypeVideoTimeCodeInterval, F: marshalVideoTimeCodeInterval},
		coreglib.TypeMarshaler{T: GTypeVideoVBIEncoder, F: marshalVideoVBIEncoder},
		coreglib.TypeMarshaler{T: GTypeVideoVBIParser, F: marshalVideoVBIParser},
	})
}

const BUFFER_POOL_OPTION_VIDEO_AFFINE_TRANSFORMATION_META = "GstBufferPoolOptionVideoAffineTransformation"

// BUFFER_POOL_OPTION_VIDEO_ALIGNMENT: bufferpool option to
// enable extra padding. When a bufferpool supports this option,
// gst_buffer_pool_config_set_video_alignment() can be called.
//
// When this option is enabled on the bufferpool,
// T_BUFFER_POOL_OPTION_VIDEO_META should also be enabled.
const BUFFER_POOL_OPTION_VIDEO_ALIGNMENT = "GstBufferPoolOptionVideoAlignment"

// BUFFER_POOL_OPTION_VIDEO_GL_TEXTURE_UPLOAD_META: option that can be activated
// on a bufferpool to request gl texture upload meta on buffers from the pool.
//
// When this option is enabled on the bufferpool,
// GST_BUFFER_POOL_OPTION_VIDEO_META should also be enabled.
const BUFFER_POOL_OPTION_VIDEO_GL_TEXTURE_UPLOAD_META = "GstBufferPoolOptionVideoGLTextureUploadMeta"

// BUFFER_POOL_OPTION_VIDEO_META: option that can be activated on bufferpool to
// request video metadata on buffers from the pool.
const BUFFER_POOL_OPTION_VIDEO_META = "GstBufferPoolOptionVideoMeta"

// CAPS_FEATURE_FORMAT_INTERLACED: name of the caps feature indicating that the
// stream is interlaced.
//
// Currently it is only used for video with 'interlace-mode=alternate' to ensure
// backwards compatibility for this new mode. In this mode each buffer carries
// a single field of interlaced video. GST_VIDEO_BUFFER_FLAG_TOP_FIELD and
// GST_VIDEO_BUFFER_FLAG_BOTTOM_FIELD indicate whether the buffer carries a top
// or bottom field. The order of buffers/fields in the stream and the timestamps
// on the buffers indicate the temporal order of the fields. Top and bottom
// fields are expected to alternate in this mode. The frame rate in the caps
// still signals the frame rate, so the notional field rate will be twice the
// frame rate from the caps (see GST_VIDEO_INFO_FIELD_RATE_N).
const CAPS_FEATURE_FORMAT_INTERLACED = "format:Interlaced"
const CAPS_FEATURE_META_GST_VIDEO_AFFINE_TRANSFORMATION_META = "meta:GstVideoAffineTransformation"
const CAPS_FEATURE_META_GST_VIDEO_GL_TEXTURE_UPLOAD_META = "meta:GstVideoGLTextureUploadMeta"
const CAPS_FEATURE_META_GST_VIDEO_META = "meta:GstVideoMeta"
const CAPS_FEATURE_META_GST_VIDEO_OVERLAY_COMPOSITION = "meta:GstVideoOverlayComposition"

// META_TAG_VIDEO_COLORSPACE_STR: this metadata stays relevant as long as video
// colorspace is unchanged.
const META_TAG_VIDEO_COLORSPACE_STR = "colorspace"

// META_TAG_VIDEO_ORIENTATION_STR: this metadata stays relevant as long as video
// orientation is unchanged.
const META_TAG_VIDEO_ORIENTATION_STR = "orientation"

// META_TAG_VIDEO_SIZE_STR: this metadata stays relevant as long as video size
// is unchanged.
const META_TAG_VIDEO_SIZE_STR = "size"

// META_TAG_VIDEO_STR: this metadata is relevant for video streams.
const META_TAG_VIDEO_STR = "video"
const VIDEO_COLORIMETRY_BT2020 = "bt2020"
const VIDEO_COLORIMETRY_BT2020_10 = "bt2020-10"
const VIDEO_COLORIMETRY_BT2100_HLG = "bt2100-hlg"
const VIDEO_COLORIMETRY_BT2100_PQ = "bt2100-pq"
const VIDEO_COLORIMETRY_BT601 = "bt601"
const VIDEO_COLORIMETRY_BT709 = "bt709"
const VIDEO_COLORIMETRY_SMPTE240M = "smpte240m"
const VIDEO_COLORIMETRY_SRGB = "sRGB"
const VIDEO_COMP_A = 3
const VIDEO_COMP_B = 2
const VIDEO_COMP_G = 1
const VIDEO_COMP_INDEX = 0
const VIDEO_COMP_PALETTE = 1
const VIDEO_COMP_R = 0
const VIDEO_COMP_U = 1
const VIDEO_COMP_V = 2
const VIDEO_COMP_Y = 0

// VIDEO_CONVERTER_OPT_ALPHA_MODE the alpha mode to use. Default is
// T_VIDEO_ALPHA_MODE_COPY.
const VIDEO_CONVERTER_OPT_ALPHA_MODE = "GstVideoConverter.alpha-mode"

// VIDEO_CONVERTER_OPT_ALPHA_VALUE the alpha color value to use. Default to 1.0.
const VIDEO_CONVERTER_OPT_ALPHA_VALUE = "GstVideoConverter.alpha-value"

// VIDEO_CONVERTER_OPT_ASYNC_TASKS whether gst_video_converter_frame()
// will return immediately without waiting for the conversion to complete.
// A subsequent gst_video_converter_frame_finish() must be performed to ensure
// completion of the conversion before subsequent use. Default FALSE.
const VIDEO_CONVERTER_OPT_ASYNC_TASKS = "GstVideoConverter.async-tasks"

// VIDEO_CONVERTER_OPT_BORDER_ARGB the border color to use if
// T_VIDEO_CONVERTER_OPT_FILL_BORDER is set to TRUE. The color is in ARGB
// format. Default 0xff000000.
const VIDEO_CONVERTER_OPT_BORDER_ARGB = "GstVideoConverter.border-argb"

// VIDEO_CONVERTER_OPT_CHROMA_MODE set the chroma resample mode subsampled
// formats. Default is T_VIDEO_CHROMA_MODE_FULL.
const VIDEO_CONVERTER_OPT_CHROMA_MODE = "GstVideoConverter.chroma-mode"

// VIDEO_CONVERTER_OPT_CHROMA_RESAMPLER_METHOD The resampler method to use
// for chroma resampling. Other options for the resampler can be used, see the
// VideoResampler. Default is T_VIDEO_RESAMPLER_METHOD_LINEAR.
const VIDEO_CONVERTER_OPT_CHROMA_RESAMPLER_METHOD = "GstVideoConverter.chroma-resampler-method"

// VIDEO_CONVERTER_OPT_DEST_HEIGHT height in the destination frame, default
// destination height.
const VIDEO_CONVERTER_OPT_DEST_HEIGHT = "GstVideoConverter.dest-height"

// VIDEO_CONVERTER_OPT_DEST_WIDTH width in the destination frame, default
// destination width.
const VIDEO_CONVERTER_OPT_DEST_WIDTH = "GstVideoConverter.dest-width"

// VIDEO_CONVERTER_OPT_DEST_X x position in the destination frame, default 0.
const VIDEO_CONVERTER_OPT_DEST_X = "GstVideoConverter.dest-x"

// VIDEO_CONVERTER_OPT_DEST_Y y position in the destination frame, default 0.
const VIDEO_CONVERTER_OPT_DEST_Y = "GstVideoConverter.dest-y"

// VIDEO_CONVERTER_OPT_DITHER_METHOD The dither method to use when changing bit
// depth. Default is T_VIDEO_DITHER_BAYER.
const VIDEO_CONVERTER_OPT_DITHER_METHOD = "GstVideoConverter.dither-method"

// VIDEO_CONVERTER_OPT_DITHER_QUANTIZATION The quantization amount to dither to.
// Components will be quantized to multiples of this value. Default is 1.
const VIDEO_CONVERTER_OPT_DITHER_QUANTIZATION = "GstVideoConverter.dither-quantization"

// VIDEO_CONVERTER_OPT_FILL_BORDER if the destination rectangle does
// not fill the complete destination image, render a border with
// T_VIDEO_CONVERTER_OPT_BORDER_ARGB. Otherwise the unusded pixels in the
// destination are untouched. Default TRUE.
const VIDEO_CONVERTER_OPT_FILL_BORDER = "GstVideoConverter.fill-border"

// VIDEO_CONVERTER_OPT_GAMMA_MODE set the gamma mode. Default is
// T_VIDEO_GAMMA_MODE_NONE.
const VIDEO_CONVERTER_OPT_GAMMA_MODE = "GstVideoConverter.gamma-mode"

// VIDEO_CONVERTER_OPT_MATRIX_MODE set the color matrix conversion mode
// for converting between Y'PbPr and non-linear RGB (R'G'B'). Default is
// T_VIDEO_MATRIX_MODE_FULL.
const VIDEO_CONVERTER_OPT_MATRIX_MODE = "GstVideoConverter.matrix-mode"

// VIDEO_CONVERTER_OPT_PRIMARIES_MODE set the primaries conversion mode. Default
// is T_VIDEO_PRIMARIES_MODE_NONE.
const VIDEO_CONVERTER_OPT_PRIMARIES_MODE = "GstVideoConverter.primaries-mode"

// VIDEO_CONVERTER_OPT_RESAMPLER_METHOD The resampler method to use
// for resampling. Other options for the resampler can be used, see the
// VideoResampler. Default is T_VIDEO_RESAMPLER_METHOD_CUBIC.
const VIDEO_CONVERTER_OPT_RESAMPLER_METHOD = "GstVideoConverter.resampler-method"

// VIDEO_CONVERTER_OPT_RESAMPLER_TAPS The number of taps for the resampler.
// Default is 0: let the resampler choose a good value.
const VIDEO_CONVERTER_OPT_RESAMPLER_TAPS = "GstVideoConverter.resampler-taps"

// VIDEO_CONVERTER_OPT_SRC_HEIGHT source height to convert, default source
// height.
const VIDEO_CONVERTER_OPT_SRC_HEIGHT = "GstVideoConverter.src-height"

// VIDEO_CONVERTER_OPT_SRC_WIDTH source width to convert, default source width.
const VIDEO_CONVERTER_OPT_SRC_WIDTH = "GstVideoConverter.src-width"

// VIDEO_CONVERTER_OPT_SRC_X source x position to start conversion, default 0.
const VIDEO_CONVERTER_OPT_SRC_X = "GstVideoConverter.src-x"

// VIDEO_CONVERTER_OPT_SRC_Y source y position to start conversion, default 0.
const VIDEO_CONVERTER_OPT_SRC_Y = "GstVideoConverter.src-y"

// VIDEO_CONVERTER_OPT_THREADS maximum number of threads to use. Default 1,
// 0 for the number of cores.
const VIDEO_CONVERTER_OPT_THREADS = "GstVideoConverter.threads"

// VIDEO_DECODER_MAX_ERRORS: default maximum number of errors tolerated before
// signaling error.
const VIDEO_DECODER_MAX_ERRORS = -1

// VIDEO_DECODER_SINK_NAME: name of the templates for the sink pad.
const VIDEO_DECODER_SINK_NAME = "sink"

// VIDEO_DECODER_SRC_NAME: name of the templates for the source pad.
const VIDEO_DECODER_SRC_NAME = "src"

// VIDEO_DMA_DRM_CAPS_MAKE: generic caps string for video wit
// DMABuf(GST_CAPS_FEATURE_MEMORY_DMABUF) feature, for use in pad templates.
// As drm-format is supposed to be defined at run-time it's not predefined here.
const VIDEO_DMA_DRM_CAPS_MAKE = "video/x-raw(memory:DMABuf), format = (string) DMA_DRM, width = "

// VIDEO_ENCODER_SINK_NAME: name of the templates for the sink pad.
const VIDEO_ENCODER_SINK_NAME = "sink"

// VIDEO_ENCODER_SRC_NAME: name of the templates for the source pad.
const VIDEO_ENCODER_SRC_NAME = "src"

// VIDEO_FORMATS_ALL: list of all video formats, for use in template caps
// strings.
//
// Formats are sorted by decreasing "quality", using these criteria by priority:
// - number of components - depth - subsampling factor of the width -
// subsampling factor of the height - number of planes - native endianness
// preferred - pixel stride - poffset - prefer non-complex formats - prefer YUV
// formats over RGB ones - prefer I420 over YV12 - format name.
const VIDEO_FORMATS_ALL = "{ "

// VIDEO_FORMATS_ALL_STR: declare all video formats as a string.
//
// Formats are sorted by decreasing "quality", using these criteria by priority:
// - number of components - depth - subsampling factor of the width -
// subsampling factor of the height - number of planes - native endianness
// preferred - pixel stride - poffset - prefer non-complex formats - prefer YUV
// formats over RGB ones - prefer I420 over YV12 - format name.
const VIDEO_FORMATS_ALL_STR = "A444_16BE, A444_16LE, AYUV64, ARGB64, RGBA64_BE, ARGB64_BE, BGRA64_BE, ABGR64_BE, RGBA64_LE, ARGB64_LE, BGRA64_LE, ABGR64_LE, A422_16BE, A422_16LE, A420_16BE, A420_16LE, A444_12BE, GBRA_12BE, A444_12LE, GBRA_12LE, Y412_BE, Y412_LE, A422_12BE, A422_12LE, A420_12BE, A420_12LE, A444_10BE, GBRA_10BE, A444_10LE, GBRA_10LE, A422_10BE, A422_10LE, A420_10BE, A420_10LE, Y410, BGR10A2_LE, RGB10A2_LE, A444, GBRA, AYUV, VUYA, RGBA, RBGA, ARGB, BGRA, ABGR, A422, A420, AV12, Y444_16BE, GBR_16BE, Y444_16LE, GBR_16LE, v216, P016_BE, P016_LE, Y444_12BE, GBR_12BE, Y444_12LE, GBR_12LE, I422_12BE, I422_12LE, Y212_BE, Y212_LE, I420_12BE, I420_12LE, P012_BE, P012_LE, Y444_10BE, GBR_10BE, Y444_10LE, GBR_10LE, r210, I422_10BE, I422_10LE, NV16_10LE32, Y210, UYVP, v210, I420_10BE, I420_10LE, P010_10BE, MT2110R, MT2110T, NV12_10BE_8L128, NV12_10LE40_4L4, P010_10LE, NV12_10LE40, NV12_10LE32, Y444, BGRP, GBR, RGBP, NV24, v308, IYU2, RGBx, xRGB, BGRx, xBGR, RGB, BGR, Y42B, NV16, NV61, YUY2, YVYU, UYVY, VYUY, I420, YV12, NV12, NV21, NV12_16L32S, NV12_32L32, NV12_4L4, NV12_64Z32, NV12_8L128, Y41B, IYU1, YUV9, YVU9, BGR16, RGB16, BGR15, RGB15, RGB8P, GRAY16_BE, GRAY16_LE, GRAY10_LE32, GRAY8"

// VIDEO_FORMATS_ANY: this is similar to GST_VIDEO_FORMATS_ALL but includes
// formats like DMA_DRM that do not have a software converter. This should be
// used for passthrough template caps.
const VIDEO_FORMATS_ANY = "{ "

// VIDEO_FORMATS_ANY_STR: this is similar to GST_VIDEO_FORMATS_ALL_STR but
// includes formats like DMA_DRM for which no software converter exists.
// This should be used for passthrough template caps.
const VIDEO_FORMATS_ANY_STR = "DMA_DRM, "
const VIDEO_FPS_RANGE = "(fraction) [ 0, max ]"
const VIDEO_MAX_COMPONENTS = 4
const VIDEO_MAX_PLANES = 4

// VIDEO_RESAMPLER_OPT_CUBIC_B: g_TYPE_DOUBLE, B parameter of the cubic filter.
// The B parameter controls the bluriness. Values between 0.0 and 2.0 are
// accepted. 1/3 is the default.
//
// Below are some values of popular filters: B C Hermite 0.0 0.0 Spline 1.0 0.0
// Catmull-Rom 0.0 1/2 Mitchell 1/3 1/3 Robidoux 0.3782 0.3109 Robidoux Sharp
// 0.2620 0.3690 Robidoux Soft 0.6796 0.1602.
const VIDEO_RESAMPLER_OPT_CUBIC_B = "GstVideoResampler.cubic-b"

// VIDEO_RESAMPLER_OPT_CUBIC_C: g_TYPE_DOUBLE, C parameter of the cubic filter.
// The C parameter controls the Keys alpha value. Values between 0.0 and 2.0 are
// accepted. 1/3 is the default.
//
// See T_VIDEO_RESAMPLER_OPT_CUBIC_B for some more common values.
const VIDEO_RESAMPLER_OPT_CUBIC_C = "GstVideoResampler.cubic-c"

// VIDEO_RESAMPLER_OPT_ENVELOPE: g_TYPE_DOUBLE, specifies the size of filter
// envelope for GST_VIDEO_RESAMPLER_METHOD_LANCZOS. values are clamped between
// 1.0 and 5.0. 2.0 is the default.
const VIDEO_RESAMPLER_OPT_ENVELOPE = "GstVideoResampler.envelope"

// VIDEO_RESAMPLER_OPT_MAX_TAPS: g_TYPE_INT, limits the maximum number of taps
// to use. 16 is the default.
const VIDEO_RESAMPLER_OPT_MAX_TAPS = "GstVideoResampler.max-taps"

// VIDEO_RESAMPLER_OPT_SHARPEN: g_TYPE_DOUBLE, specifies sharpening of the
// filter for GST_VIDEO_RESAMPLER_METHOD_LANCZOS. values are clamped between 0.0
// and 1.0. 0.0 is the default.
const VIDEO_RESAMPLER_OPT_SHARPEN = "GstVideoResampler.sharpen"

// VIDEO_RESAMPLER_OPT_SHARPNESS: g_TYPE_DOUBLE, specifies sharpness of the
// filter for GST_VIDEO_RESAMPLER_METHOD_LANCZOS. values are clamped between 0.5
// and 1.5. 1.0 is the default.
const VIDEO_RESAMPLER_OPT_SHARPNESS = "GstVideoResampler.sharpness"

// VIDEO_SCALER_OPT_DITHER_METHOD The dither method to use for propagating
// quatization errors.
const VIDEO_SCALER_OPT_DITHER_METHOD = "GstVideoScaler.dither-method"
const VIDEO_SIZE_RANGE = "(int) [ 1, max ]"
const VIDEO_TILE_TYPE_MASK = 65535
const VIDEO_TILE_TYPE_SHIFT = 16
const VIDEO_TILE_X_TILES_MASK = 65535
const VIDEO_TILE_Y_TILES_SHIFT = 16

// AncillaryMetaField: location of a GstAncillaryMeta.
type AncillaryMetaField C.gint

const (
	// AncillaryMetaFieldProgressive: progressive or no field specified
	// (default).
	AncillaryMetaFieldProgressive AncillaryMetaField = 0
	// AncillaryMetaFieldInterlacedFirst: interlaced first field.
	AncillaryMetaFieldInterlacedFirst AncillaryMetaField = 16
	// AncillaryMetaFieldInterlacedSecond: interlaced second field.
	AncillaryMetaFieldInterlacedSecond AncillaryMetaField = 17
)

func marshalAncillaryMetaField(p uintptr) (interface{}, error) {
	return AncillaryMetaField(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for AncillaryMetaField.
func (a AncillaryMetaField) String() string {
	switch a {
	case AncillaryMetaFieldProgressive:
		return "Progressive"
	case AncillaryMetaFieldInterlacedFirst:
		return "InterlacedFirst"
	case AncillaryMetaFieldInterlacedSecond:
		return "InterlacedSecond"
	default:
		return fmt.Sprintf("AncillaryMetaField(%d)", a)
	}
}

// ColorBalanceType: enumeration indicating whether an element implements
// color balancing operations in software or in dedicated hardware. In general,
// dedicated hardware implementations (such as those provided by xvimagesink)
// are preferred.
type ColorBalanceType C.gint

const (
	// ColorBalanceHardware: color balance is implemented with dedicated
	// hardware.
	ColorBalanceHardware ColorBalanceType = iota
	// ColorBalanceSoftware: color balance is implemented via software
	// processing.
	ColorBalanceSoftware
)

func marshalColorBalanceType(p uintptr) (interface{}, error) {
	return ColorBalanceType(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for ColorBalanceType.
func (c ColorBalanceType) String() string {
	switch c {
	case ColorBalanceHardware:
		return "Hardware"
	case ColorBalanceSoftware:
		return "Software"
	default:
		return fmt.Sprintf("ColorBalanceType(%d)", c)
	}
}

// NavigationCommand: set of commands that may be issued to an element providing
// the Navigation interface. The available commands can be queried via the
// gst_navigation_query_new_commands() query.
//
// For convenience in handling DVD navigation, the MENU commands are aliased
// as: GST_NAVIGATION_COMMAND_DVD_MENU = GST_NAVIGATION_COMMAND_MENU1
// GST_NAVIGATION_COMMAND_DVD_TITLE_MENU = GST_NAVIGATION_COMMAND_MENU2
// GST_NAVIGATION_COMMAND_DVD_ROOT_MENU = GST_NAVIGATION_COMMAND_MENU3
// GST_NAVIGATION_COMMAND_DVD_SUBPICTURE_MENU = GST_NAVIGATION_COMMAND_MENU4
// GST_NAVIGATION_COMMAND_DVD_AUDIO_MENU = GST_NAVIGATION_COMMAND_MENU5
// GST_NAVIGATION_COMMAND_DVD_ANGLE_MENU = GST_NAVIGATION_COMMAND_MENU6
// GST_NAVIGATION_COMMAND_DVD_CHAPTER_MENU = GST_NAVIGATION_COMMAND_MENU7.
type NavigationCommand C.gint

const (
	// NavigationCommandInvalid: invalid command entry.
	NavigationCommandInvalid NavigationCommand = 0
	// NavigationCommandMenu1: execute navigation menu command 1. For DVD,
	// this enters the DVD root menu, or exits back to the title from the menu.
	NavigationCommandMenu1 NavigationCommand = 1
	// NavigationCommandMenu2: execute navigation menu command 2. For DVD,
	// this jumps to the DVD title menu.
	NavigationCommandMenu2 NavigationCommand = 2
	// NavigationCommandMenu3: execute navigation menu command 3. For DVD,
	// this jumps into the DVD root menu.
	NavigationCommandMenu3 NavigationCommand = 3
	// NavigationCommandMenu4: execute navigation menu command 4. For DVD,
	// this jumps to the Subpicture menu.
	NavigationCommandMenu4 NavigationCommand = 4
	// NavigationCommandMenu5: execute navigation menu command 5. For DVD,
	// the jumps to the audio menu.
	NavigationCommandMenu5 NavigationCommand = 5
	// NavigationCommandMenu6: execute navigation menu command 6. For DVD,
	// this jumps to the angles menu.
	NavigationCommandMenu6 NavigationCommand = 6
	// NavigationCommandMenu7: execute navigation menu command 7. For DVD,
	// this jumps to the chapter menu.
	NavigationCommandMenu7 NavigationCommand = 7
	// NavigationCommandLeft: select the next button to the left in a menu,
	// if such a button exists.
	NavigationCommandLeft NavigationCommand = 20
	// NavigationCommandRight: select the next button to the right in a menu,
	// if such a button exists.
	NavigationCommandRight NavigationCommand = 21
	// NavigationCommandUp: select the button above the current one in a menu,
	// if such a button exists.
	NavigationCommandUp NavigationCommand = 22
	// NavigationCommandDown: select the button below the current one in a menu,
	// if such a button exists.
	NavigationCommandDown NavigationCommand = 23
	// NavigationCommandActivate: activate (click) the currently selected button
	// in a menu, if such a button exists.
	NavigationCommandActivate NavigationCommand = 24
	// NavigationCommandPrevAngle: switch to the previous angle in a multiangle
	// feature.
	NavigationCommandPrevAngle NavigationCommand = 30
	// NavigationCommandNextAngle: switch to the next angle in a multiangle
	// feature.
	NavigationCommandNextAngle NavigationCommand = 31
)

func marshalNavigationCommand(p uintptr) (interface{}, error) {
	return NavigationCommand(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for NavigationCommand.
func (n NavigationCommand) String() string {
	switch n {
	case NavigationCommandInvalid:
		return "Invalid"
	case NavigationCommandMenu1:
		return "Menu1"
	case NavigationCommandMenu2:
		return "Menu2"
	case NavigationCommandMenu3:
		return "Menu3"
	case NavigationCommandMenu4:
		return "Menu4"
	case NavigationCommandMenu5:
		return "Menu5"
	case NavigationCommandMenu6:
		return "Menu6"
	case NavigationCommandMenu7:
		return "Menu7"
	case NavigationCommandLeft:
		return "Left"
	case NavigationCommandRight:
		return "Right"
	case NavigationCommandUp:
		return "Up"
	case NavigationCommandDown:
		return "Down"
	case NavigationCommandActivate:
		return "Activate"
	case NavigationCommandPrevAngle:
		return "PrevAngle"
	case NavigationCommandNextAngle:
		return "NextAngle"
	default:
		return fmt.Sprintf("NavigationCommand(%d)", n)
	}
}

// NavigationEventType: enum values for the various events that an element
// implementing the GstNavigation interface might send up the pipeline. Touch
// events have been inspired by the libinput API, and have the same meaning
// here.
type NavigationEventType C.gint

const (
	// NavigationEventInvalid: returned from gst_navigation_event_get_type()
	// when the passed event is not a navigation event.
	NavigationEventInvalid NavigationEventType = iota
	// NavigationEventKeyPress: key press event. Use
	// gst_navigation_event_parse_key_event() to extract the details from the
	// event.
	NavigationEventKeyPress
	// NavigationEventKeyRelease: key release event. Use
	// gst_navigation_event_parse_key_event() to extract the details from the
	// event.
	NavigationEventKeyRelease
	// NavigationEventMouseButtonPress: mouse button press event. Use
	// gst_navigation_event_parse_mouse_button_event() to extract the details
	// from the event.
	NavigationEventMouseButtonPress
	// NavigationEventMouseButtonRelease: mouse button release event. Use
	// gst_navigation_event_parse_mouse_button_event() to extract the details
	// from the event.
	NavigationEventMouseButtonRelease
	// NavigationEventMouseMove: mouse movement event. Use
	// gst_navigation_event_parse_mouse_move_event() to extract the details from
	// the event.
	NavigationEventMouseMove
	// NavigationEventCommand: navigation command event. Use
	// gst_navigation_event_parse_command() to extract the details from the
	// event.
	NavigationEventCommand
	// NavigationEventMouseScroll: mouse scroll event. Use
	// gst_navigation_event_parse_mouse_scroll_event() to extract the details
	// from the event.
	NavigationEventMouseScroll
	// NavigationEventTouchDown: event describing a new touch point, which will
	// be assigned an identifier that is unique to it for the duration of its
	// movement on the screen. Use gst_navigation_event_parse_touch_event() to
	// extract the details from the event.
	NavigationEventTouchDown
	// NavigationEventTouchMotion: event describing the
	// movement of an active touch point across the screen. Use
	// gst_navigation_event_parse_touch_event() to extract the details from the
	// event.
	NavigationEventTouchMotion
	// NavigationEventTouchUp: event describing a removed touch point.
	// After this event, its identifier may be reused for any new touch points.
	// Use gst_navigation_event_parse_touch_up_event() to extract the details
	// from the event.
	NavigationEventTouchUp
	// NavigationEventTouchFrame: event signaling the end of a sequence of
	// simultaneous touch events.
	NavigationEventTouchFrame
	// NavigationEventTouchCancel: event cancelling all currently active touch
	// points.
	NavigationEventTouchCancel
)

func marshalNavigationEventType(p uintptr) (interface{}, error) {
	return NavigationEventType(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for NavigationEventType.
func (n NavigationEventType) String() string {
	switch n {
	case NavigationEventInvalid:
		return "Invalid"
	case NavigationEventKeyPress:
		return "KeyPress"
	case NavigationEventKeyRelease:
		return "KeyRelease"
	case NavigationEventMouseButtonPress:
		return "MouseButtonPress"
	case NavigationEventMouseButtonRelease:
		return "MouseButtonRelease"
	case NavigationEventMouseMove:
		return "MouseMove"
	case NavigationEventCommand:
		return "Command"
	case NavigationEventMouseScroll:
		return "MouseScroll"
	case NavigationEventTouchDown:
		return "TouchDown"
	case NavigationEventTouchMotion:
		return "TouchMotion"
	case NavigationEventTouchUp:
		return "TouchUp"
	case NavigationEventTouchFrame:
		return "TouchFrame"
	case NavigationEventTouchCancel:
		return "TouchCancel"
	default:
		return fmt.Sprintf("NavigationEventType(%d)", n)
	}
}

// NavigationMessageType: set of notifications that may be received on the bus
// when navigation related status changes.
type NavigationMessageType C.gint

const (
	// NavigationMessageInvalid: returned from gst_navigation_message_get_type()
	// when the passed message is not a navigation message.
	NavigationMessageInvalid NavigationMessageType = iota
	// NavigationMessageMouseOver: sent when the mouse moves over or leaves a
	// clickable region of the output, such as a DVD menu button.
	NavigationMessageMouseOver
	// NavigationMessageCommandsChanged: sent when the set of available commands
	// changes and should re-queried by interested applications.
	NavigationMessageCommandsChanged
	// NavigationMessageAnglesChanged: sent when display angles in a multi-angle
	// feature (such as a multiangle DVD) change - either angles have appeared
	// or disappeared.
	NavigationMessageAnglesChanged
	// NavigationMessageEvent: sent when a navigation event was not handled by
	// any element in the pipeline (Since: 1.6).
	NavigationMessageEvent
)

func marshalNavigationMessageType(p uintptr) (interface{}, error) {
	return NavigationMessageType(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for NavigationMessageType.
func (n NavigationMessageType) String() string {
	switch n {
	case NavigationMessageInvalid:
		return "Invalid"
	case NavigationMessageMouseOver:
		return "MouseOver"
	case NavigationMessageCommandsChanged:
		return "CommandsChanged"
	case NavigationMessageAnglesChanged:
		return "AnglesChanged"
	case NavigationMessageEvent:
		return "Event"
	default:
		return fmt.Sprintf("NavigationMessageType(%d)", n)
	}
}

// NavigationQueryType types of navigation interface queries.
type NavigationQueryType C.gint

const (
	// NavigationQueryInvalid: invalid query.
	NavigationQueryInvalid NavigationQueryType = iota
	// NavigationQueryCommands: command query.
	NavigationQueryCommands
	// NavigationQueryAngles: viewing angle query.
	NavigationQueryAngles
)

func marshalNavigationQueryType(p uintptr) (interface{}, error) {
	return NavigationQueryType(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for NavigationQueryType.
func (n NavigationQueryType) String() string {
	switch n {
	case NavigationQueryInvalid:
		return "Invalid"
	case NavigationQueryCommands:
		return "Commands"
	case NavigationQueryAngles:
		return "Angles"
	default:
		return fmt.Sprintf("NavigationQueryType(%d)", n)
	}
}

// VideoAFDSpec: enumeration of the different standards that may apply to AFD
// data:
//
// 0) ETSI/DVB:
// https://www.etsi.org/deliver/etsi_ts/101100_101199/101154/02.01.01_60/ts_101154v020101p.pdf
//
// 1) ATSC A/53:
// https://www.atsc.org/wp-content/uploads/2015/03/a_53-Part-4-2009.pdf
//
// 2) SMPTE ST2016-1:.
type VideoAFDSpec C.gint

const (
	// VideoAfdSpecDvbEtsi: AFD value is from DVB/ETSI standard.
	VideoAfdSpecDvbEtsi VideoAFDSpec = iota
	// VideoAfdSpecAtscA53: AFD value is from ATSC A/53 standard.
	VideoAfdSpecAtscA53
	VideoAfdSpecSmpteSt20161
)

func marshalVideoAFDSpec(p uintptr) (interface{}, error) {
	return VideoAFDSpec(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoAFDSpec.
func (v VideoAFDSpec) String() string {
	switch v {
	case VideoAfdSpecDvbEtsi:
		return "DvbEtsi"
	case VideoAfdSpecAtscA53:
		return "AtscA53"
	case VideoAfdSpecSmpteSt20161:
		return "SmpteSt20161"
	default:
		return fmt.Sprintf("VideoAFDSpec(%d)", v)
	}
}

// VideoAFDValue: enumeration of the various values for Active Format
// Description (AFD)
//
// AFD should be included in video user data whenever the rectangular picture
// area containing useful information does not extend to the full height or
// width of the coded frame. AFD data may also be included in user data when the
// rectangular picture area containing useful information extends to the full
// height and width of the coded frame.
//
// For details, see Table 6.14 Active Format in:
//
// ATSC Digital Television Standard: Part 4 – MPEG-2 Video System
// Characteristics
//
// https://www.atsc.org/wp-content/uploads/2015/03/a_53-Part-4-2009.pdf
//
// and Active Format Description in Complete list of AFD codes
//
// https://en.wikipedia.org/wiki/Active_Format_DescriptionAFD_codes
//
// and SMPTE ST2016-1
//
// Notes:
//
// 1) AFD 0 is undefined for ATSC and SMPTE ST2016-1, indicating that AFD data
// is not available: If Bar Data is not present, AFD '0000' indicates that
// exact information is not available and the active image should be assumed
// to be the same as the coded frame. AFD '0000'. AFD '0000' accompanied by Bar
// Data signals that the active image’s aspect ratio is narrower than 16:9,
// but is not 4:3 or 14:9. As the exact aspect ratio cannot be conveyed by
// AFD alone, wherever possible, AFD ‘0000’ should be accompanied by Bar Data
// to define the exact vertical or horizontal extent of the active image.
// 2) AFD 0 is reserved for DVB/ETSI 3) values 1, 5, 6, 7, and 12 are reserved
// for both ATSC and DVB/ETSI 4) values 2 and 3 are not recommended for ATSC,
// but are valid for DVB/ETSI.
type VideoAFDValue C.gint

const (
	// VideoAfdUnavailable: unavailable (see note 0 below).
	VideoAfdUnavailable VideoAFDValue = 0
	// VideoAfd169_TopAligned: for 4:3 coded frame, letterbox 16:9 image,
	// at top of the coded frame. For 16:9 coded frame, full frame 16:9 image,
	// the same as the coded frame.
	VideoAfd169_TopAligned VideoAFDValue = 2
	// VideoAfd149_TopAligned: for 4:3 coded frame, letterbox 14:9 image,
	// at top of the coded frame. For 16:9 coded frame, pillarbox 14:9 image,
	// horizontally centered in the coded frame.
	VideoAfd149_TopAligned VideoAFDValue = 3
	// VideoAfdGreaterThan169: for 4:3 coded frame, letterbox image with an
	// aspect ratio greater than 16:9, vertically centered in the coded frame.
	// For 16:9 coded frame, letterbox image with an aspect ratio greater than
	// 16:9.
	VideoAfdGreaterThan169 VideoAFDValue = 4
	// VideoAfd43_Full169_Full: for 4:3 coded frame, full frame 4:3 image,
	// the same as the coded frame. For 16:9 coded frame, full frame 16:9 image,
	// the same as the coded frame.
	VideoAfd43_Full169_Full VideoAFDValue = 8
	// VideoAfd43_Full43_Pillar: for 4:3 coded frame, full frame 4:3 image,
	// the same as the coded frame. For 16:9 coded frame, pillarbox 4:3 image,
	// horizontally centered in the coded frame.
	VideoAfd43_Full43_Pillar VideoAFDValue = 9
	// VideoAfd169_Letter169_Full: for 4:3 coded frame, letterbox 16:9 image,
	// vertically centered in the coded frame with all image areas protected.
	// For 16:9 coded frame, full frame 16:9 image, with all image areas
	// protected.
	VideoAfd169_Letter169_Full VideoAFDValue = 10
	// VideoAfd149_Letter149_Pillar: for 4:3 coded frame, letterbox 14:9 image,
	// vertically centered in the coded frame. For 16:9 coded frame, pillarbox
	// 14:9 image, horizontally centered in the coded frame.
	VideoAfd149_Letter149_Pillar VideoAFDValue = 11
	// VideoAfd43_Full149_Center: for 4:3 coded frame, full frame 4:3 image,
	// with alternative 14:9 center. For 16:9 coded frame, pillarbox 4:3 image,
	// with alternative 14:9 center.
	VideoAfd43_Full149_Center VideoAFDValue = 13
	// VideoAfd169_Letter149_Center: for 4:3 coded frame, letterbox 16:9 image,
	// with alternative 14:9 center. For 16:9 coded frame, full frame 16:9
	// image, with alternative 14:9 center.
	VideoAfd169_Letter149_Center VideoAFDValue = 14
	// VideoAfd169_Letter43_Center: for 4:3 coded frame, letterbox 16:9 image,
	// with alternative 4:3 center. For 16:9 coded frame, full frame 16:9 image,
	// with alternative 4:3 center.
	VideoAfd169_Letter43_Center VideoAFDValue = 15
)

func marshalVideoAFDValue(p uintptr) (interface{}, error) {
	return VideoAFDValue(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoAFDValue.
func (v VideoAFDValue) String() string {
	switch v {
	case VideoAfdUnavailable:
		return "Unavailable"
	case VideoAfd169_TopAligned:
		return "169_TopAligned"
	case VideoAfd149_TopAligned:
		return "149_TopAligned"
	case VideoAfdGreaterThan169:
		return "GreaterThan169"
	case VideoAfd43_Full169_Full:
		return "43_Full169_Full"
	case VideoAfd43_Full43_Pillar:
		return "43_Full43_Pillar"
	case VideoAfd169_Letter169_Full:
		return "169_Letter169_Full"
	case VideoAfd149_Letter149_Pillar:
		return "149_Letter149_Pillar"
	case VideoAfd43_Full149_Center:
		return "43_Full149_Center"
	case VideoAfd169_Letter149_Center:
		return "169_Letter149_Center"
	case VideoAfd169_Letter43_Center:
		return "169_Letter43_Center"
	default:
		return fmt.Sprintf("VideoAFDValue(%d)", v)
	}
}

// VideoAlphaMode: different alpha modes.
type VideoAlphaMode C.gint

const (
	// VideoAlphaModeCopy: when input and output have alpha, it will
	// be copied. When the input has no alpha, alpha will be set to
	// T_VIDEO_CONVERTER_OPT_ALPHA_VALUE.
	VideoAlphaModeCopy VideoAlphaMode = iota
	// VideoAlphaModeSet: set all alpha to T_VIDEO_CONVERTER_OPT_ALPHA_VALUE.
	VideoAlphaModeSet
	// VideoAlphaModeMult: multiply all alpha with
	// T_VIDEO_CONVERTER_OPT_ALPHA_VALUE. When the input format has no
	// alpha but the output format has, the alpha value will be set to
	// T_VIDEO_CONVERTER_OPT_ALPHA_VALUE.
	VideoAlphaModeMult
)

func marshalVideoAlphaMode(p uintptr) (interface{}, error) {
	return VideoAlphaMode(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoAlphaMode.
func (v VideoAlphaMode) String() string {
	switch v {
	case VideoAlphaModeCopy:
		return "Copy"
	case VideoAlphaModeSet:
		return "Set"
	case VideoAlphaModeMult:
		return "Mult"
	default:
		return fmt.Sprintf("VideoAlphaMode(%d)", v)
	}
}

type VideoAncillaryDID C.gint

const (
	VideoAncillaryDidUndefined               VideoAncillaryDID = 0
	VideoAncillaryDidDeletion                VideoAncillaryDID = 128
	VideoAncillaryDidHanc3GAudioDataFirst    VideoAncillaryDID = 160
	VideoAncillaryDidHanc3GAudioDataLast     VideoAncillaryDID = 167
	VideoAncillaryDidHancHdtvAudioDataFirst  VideoAncillaryDID = 224
	VideoAncillaryDidHancHdtvAudioDataLast   VideoAncillaryDID = 231
	VideoAncillaryDidHancSdtvAudioData1First VideoAncillaryDID = 236
	VideoAncillaryDidHancSdtvAudioData1Last  VideoAncillaryDID = 239
	VideoAncillaryDidCameraPosition          VideoAncillaryDID = 240
	VideoAncillaryDidHancErrorDetection      VideoAncillaryDID = 244
	VideoAncillaryDidHancSdtvAudioData2First VideoAncillaryDID = 248
	VideoAncillaryDidHancSdtvAudioData2Last  VideoAncillaryDID = 255
)

func marshalVideoAncillaryDID(p uintptr) (interface{}, error) {
	return VideoAncillaryDID(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoAncillaryDID.
func (v VideoAncillaryDID) String() string {
	switch v {
	case VideoAncillaryDidUndefined:
		return "Undefined"
	case VideoAncillaryDidDeletion:
		return "Deletion"
	case VideoAncillaryDidHanc3GAudioDataFirst:
		return "Hanc3GAudioDataFirst"
	case VideoAncillaryDidHanc3GAudioDataLast:
		return "Hanc3GAudioDataLast"
	case VideoAncillaryDidHancHdtvAudioDataFirst:
		return "HancHdtvAudioDataFirst"
	case VideoAncillaryDidHancHdtvAudioDataLast:
		return "HancHdtvAudioDataLast"
	case VideoAncillaryDidHancSdtvAudioData1First:
		return "HancSdtvAudioData1First"
	case VideoAncillaryDidHancSdtvAudioData1Last:
		return "HancSdtvAudioData1Last"
	case VideoAncillaryDidCameraPosition:
		return "CameraPosition"
	case VideoAncillaryDidHancErrorDetection:
		return "HancErrorDetection"
	case VideoAncillaryDidHancSdtvAudioData2First:
		return "HancSdtvAudioData2First"
	case VideoAncillaryDidHancSdtvAudioData2Last:
		return "HancSdtvAudioData2Last"
	default:
		return fmt.Sprintf("VideoAncillaryDID(%d)", v)
	}
}

// VideoAncillaryDID16: some know types of Ancillary Data identifiers.
type VideoAncillaryDID16 C.gint

const (
	// VideoAncillaryDid16S334Eia708: CEA 708 Ancillary data according to SMPTE
	// 334.
	VideoAncillaryDid16S334Eia708 VideoAncillaryDID16 = 24833
	// VideoAncillaryDid16S334Eia608: CEA 608 Ancillary data according to SMPTE
	// 334.
	VideoAncillaryDid16S334Eia608 VideoAncillaryDID16 = 24834
	// VideoAncillaryDid16S20163AfdBar: AFD/Bar Ancillary data according to
	// SMPTE 2016-3 (Since: 1.18).
	VideoAncillaryDid16S20163AfdBar VideoAncillaryDID16 = 16645
)

func marshalVideoAncillaryDID16(p uintptr) (interface{}, error) {
	return VideoAncillaryDID16(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoAncillaryDID16.
func (v VideoAncillaryDID16) String() string {
	switch v {
	case VideoAncillaryDid16S334Eia708:
		return "S334Eia708"
	case VideoAncillaryDid16S334Eia608:
		return "S334Eia608"
	case VideoAncillaryDid16S20163AfdBar:
		return "S20163AfdBar"
	default:
		return fmt.Sprintf("VideoAncillaryDID16(%d)", v)
	}
}

// VideoCaptionType various known types of Closed Caption (CC).
type VideoCaptionType C.gint

const (
	// VideoCaptionTypeUnknown: unknown type of CC.
	VideoCaptionTypeUnknown VideoCaptionType = iota
	// VideoCaptionTypeCea608Raw: CEA-608 as byte pairs. Note that this
	// format is not recommended since is does not specify to which field
	// the caption comes from and therefore assumes it comes from the first
	// field (and that there is no information on the second field). Use
	// GST_VIDEO_CAPTION_TYPE_CEA708_RAW if you wish to store CEA-608 from two
	// fields and prefix each byte pair with 0xFC for the first field and 0xFD
	// for the second field.
	VideoCaptionTypeCea608Raw
	// VideoCaptionTypeCea608S3341A: CEA-608 as byte triplets as defined in
	// SMPTE S334-1 Annex A. The second and third byte of the byte triplet
	// is the raw CEA608 data, the first byte is a bitfield: The top/7th bit
	// is 0 for the second field, 1 for the first field, bit 6 and 5 are 0
	// and bits 4 to 0 are a 5 bit unsigned integer that represents the line
	// offset relative to the base-line of the original image format (line 9
	// for 525-line field 1, line 272 for 525-line field 2, line 5 for 625-line
	// field 1 and line 318 for 625-line field 2).
	VideoCaptionTypeCea608S3341A
	// VideoCaptionTypeCea708Raw: CEA-708 as cc_data byte triplets. They can
	// also contain 608-in-708 and the first byte of each triplet has to be
	// inspected for detecting the type.
	VideoCaptionTypeCea708Raw
	// VideoCaptionTypeCea708Cdp: CEA-708 (and optionally CEA-608) in a CDP
	// (Caption Distribution Packet) defined by SMPTE S-334-2. Contains the
	// whole CDP (starting with 0x9669).
	VideoCaptionTypeCea708Cdp
)

func marshalVideoCaptionType(p uintptr) (interface{}, error) {
	return VideoCaptionType(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoCaptionType.
func (v VideoCaptionType) String() string {
	switch v {
	case VideoCaptionTypeUnknown:
		return "Unknown"
	case VideoCaptionTypeCea608Raw:
		return "Cea608Raw"
	case VideoCaptionTypeCea608S3341A:
		return "Cea608S3341A"
	case VideoCaptionTypeCea708Raw:
		return "Cea708Raw"
	case VideoCaptionTypeCea708Cdp:
		return "Cea708Cdp"
	default:
		return fmt.Sprintf("VideoCaptionType(%d)", v)
	}
}

// VideoCaptionTypeFromCaps parses fixed Closed Caption Caps and returns the
// corresponding caption type, or GST_VIDEO_CAPTION_TYPE_UNKNOWN.
//
// The function takes the following parameters:
//
//   - caps: fixed Caps to parse.
//
// The function returns the following values:
//
//   - videoCaptionType: VideoCaptionType.
func VideoCaptionTypeFromCaps(caps *gst.Caps) VideoCaptionType {
	var _arg1 *C.GstCaps            // out
	var _cret C.GstVideoCaptionType // in

	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C.gst_video_caption_type_from_caps(_arg1)
	runtime.KeepAlive(caps)

	var _videoCaptionType VideoCaptionType // out

	_videoCaptionType = VideoCaptionType(_cret)

	return _videoCaptionType
}

// VideoCaptionTypeToCaps creates new caps corresponding to type.
//
// The function takes the following parameters:
//
//   - typ: VideoCaptionType.
//
// The function returns the following values:
//
//   - caps: new Caps.
func VideoCaptionTypeToCaps(typ VideoCaptionType) *gst.Caps {
	var _arg1 C.GstVideoCaptionType // out
	var _cret *C.GstCaps            // in

	_arg1 = C.GstVideoCaptionType(typ)

	_cret = C.gst_video_caption_type_to_caps(_arg1)
	runtime.KeepAlive(typ)

	var _caps *gst.Caps // out

	_caps = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_caps)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _caps
}

// VideoChromaMethod: different subsampling and upsampling methods.
type VideoChromaMethod C.gint

const (
	// VideoChromaMethodNearest duplicates the chroma samples when upsampling
	// and drops when subsampling.
	VideoChromaMethodNearest VideoChromaMethod = iota
	// VideoChromaMethodLinear uses linear interpolation to reconstruct missing
	// chroma and averaging to subsample.
	VideoChromaMethodLinear
)

func marshalVideoChromaMethod(p uintptr) (interface{}, error) {
	return VideoChromaMethod(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoChromaMethod.
func (v VideoChromaMethod) String() string {
	switch v {
	case VideoChromaMethodNearest:
		return "Nearest"
	case VideoChromaMethodLinear:
		return "Linear"
	default:
		return fmt.Sprintf("VideoChromaMethod(%d)", v)
	}
}

// VideoChromaMode: different chroma downsampling and upsampling modes.
type VideoChromaMode C.gint

const (
	// VideoChromaModeFull: do full chroma up and down sampling.
	VideoChromaModeFull VideoChromaMode = iota
	// VideoChromaModeUpsampleOnly: only perform chroma upsampling.
	VideoChromaModeUpsampleOnly
	// VideoChromaModeDownsampleOnly: only perform chroma downsampling.
	VideoChromaModeDownsampleOnly
	// VideoChromaModeNone: disable chroma resampling.
	VideoChromaModeNone
)

func marshalVideoChromaMode(p uintptr) (interface{}, error) {
	return VideoChromaMode(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoChromaMode.
func (v VideoChromaMode) String() string {
	switch v {
	case VideoChromaModeFull:
		return "Full"
	case VideoChromaModeUpsampleOnly:
		return "UpsampleOnly"
	case VideoChromaModeDownsampleOnly:
		return "DownsampleOnly"
	case VideoChromaModeNone:
		return "None"
	default:
		return fmt.Sprintf("VideoChromaMode(%d)", v)
	}
}

// VideoColorMatrix: color matrix is used to convert between Y'PbPr and
// non-linear RGB (R'G'B').
type VideoColorMatrix C.gint

const (
	// VideoColorMatrixUnknown: unknown matrix.
	VideoColorMatrixUnknown VideoColorMatrix = iota
	// VideoColorMatrixRGB: identity matrix. Order of coefficients is actually
	// GBR, also IEC 61966-2-1 (sRGB).
	VideoColorMatrixRGB
	// VideoColorMatrixFcc: FCC Title 47 Code of Federal Regulations 73.682
	// (a)(20).
	VideoColorMatrixFcc
	// VideoColorMatrixBt709: ITU-R BT.709 color matrix, also ITU-R BT1361 / IEC
	// 61966-2-4 xvYCC709 / SMPTE RP177 Annex B.
	VideoColorMatrixBt709
	// VideoColorMatrixBt601: ITU-R BT.601 color matrix, also SMPTE170M / ITU-R
	// BT1358 525 / ITU-R BT1700 NTSC.
	VideoColorMatrixBt601
	// VideoColorMatrixSmpte240M: SMPTE 240M color matrix.
	VideoColorMatrixSmpte240M
	// VideoColorMatrixBt2020: ITU-R BT.2020 color matrix. Since: 1.6.
	VideoColorMatrixBt2020
)

func marshalVideoColorMatrix(p uintptr) (interface{}, error) {
	return VideoColorMatrix(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoColorMatrix.
func (v VideoColorMatrix) String() string {
	switch v {
	case VideoColorMatrixUnknown:
		return "Unknown"
	case VideoColorMatrixRGB:
		return "RGB"
	case VideoColorMatrixFcc:
		return "Fcc"
	case VideoColorMatrixBt709:
		return "Bt709"
	case VideoColorMatrixBt601:
		return "Bt601"
	case VideoColorMatrixSmpte240M:
		return "Smpte240M"
	case VideoColorMatrixBt2020:
		return "Bt2020"
	default:
		return fmt.Sprintf("VideoColorMatrix(%d)", v)
	}
}

// VideoColorMatrixFromISO converts the value to the VideoColorMatrix The
// matrix coefficients (MatrixCoefficients) value is defined by "ISO/IEC 23001-8
// Section 7.3 Table 4" and "ITU-T H.273 Table 4". "H.264 Table E-5" and "H.265
// Table E.5" share the identical values.
//
// The function takes the following parameters:
//
//   - value: ITU-T H.273 matrix coefficients value.
//
// The function returns the following values:
//
//   - videoColorMatrix: matched VideoColorMatrix.
func VideoColorMatrixFromISO(value uint) VideoColorMatrix {
	var _arg1 C.guint               // out
	var _cret C.GstVideoColorMatrix // in

	_arg1 = C.guint(value)

	_cret = C.gst_video_color_matrix_from_iso(_arg1)
	runtime.KeepAlive(value)

	var _videoColorMatrix VideoColorMatrix // out

	_videoColorMatrix = VideoColorMatrix(_cret)

	return _videoColorMatrix
}

// VideoColorMatrixGetKrKb: get the coefficients used to convert between Y'PbPr
// and R'G'B' using matrix.
//
// When:
//
//	0.0 <= [Y',R',G',B'] <= 1.0)
//	(-0.5 <= [Pb,Pr] <= 0.5)
//
// the general conversion is given by:
//
//	Y' = Kr*R' + (1-Kr-Kb)*G' + Kb*B'
//	Pb = (B'-Y')/(2*(1-Kb))
//	Pr = (R'-Y')/(2*(1-Kr))
//
// and the other way around:
//
//	R' = Y' + Cr*2*(1-Kr)
//	G' = Y' - Cb*2*(1-Kb)*Kb/(1-Kr-Kb) - Cr*2*(1-Kr)*Kr/(1-Kr-Kb)
//	B' = Y' + Cb*2*(1-Kb).
//
// The function takes the following parameters:
//
//   - matrix: VideoColorMatrix.
//
// The function returns the following values:
//
//   - Kr: result red channel coefficient.
//   - Kb: result blue channel coefficient.
//   - ok: TRUE if matrix was a YUV color format and Kr and Kb contain valid
//     values.
func VideoColorMatrixGetKrKb(matrix VideoColorMatrix) (Kr, Kb float64, ok bool) {
	var _arg1 C.GstVideoColorMatrix // out
	var _arg2 C.gdouble             // in
	var _arg3 C.gdouble             // in
	var _cret C.gboolean            // in

	_arg1 = C.GstVideoColorMatrix(matrix)

	_cret = C.gst_video_color_matrix_get_Kr_Kb(_arg1, &_arg2, &_arg3)
	runtime.KeepAlive(matrix)

	var _Kr float64 // out
	var _Kb float64 // out
	var _ok bool    // out

	_Kr = float64(_arg2)
	_Kb = float64(_arg3)
	if _cret != 0 {
		_ok = true
	}

	return _Kr, _Kb, _ok
}

// VideoColorMatrixToISO converts VideoColorMatrix to the "matrix coefficients"
// (MatrixCoefficients) value defined by "ISO/IEC 23001-8 Section 7.3 Table 4"
// and "ITU-T H.273 Table 4". "H.264 Table E-5" and "H.265 Table E.5" share the
// identical values.
//
// The function takes the following parameters:
//
//   - matrix: VideoColorMatrix.
//
// The function returns the following values:
//
//   - guint: value of ISO/IEC 23001-8 matrix coefficients.
func VideoColorMatrixToISO(matrix VideoColorMatrix) uint {
	var _arg1 C.GstVideoColorMatrix // out
	var _cret C.guint               // in

	_arg1 = C.GstVideoColorMatrix(matrix)

	_cret = C.gst_video_color_matrix_to_iso(_arg1)
	runtime.KeepAlive(matrix)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// VideoColorPrimaries: color primaries define the how to transform linear RGB
// values to and from the CIE XYZ colorspace.
type VideoColorPrimaries C.gint

const (
	// VideoColorPrimariesUnknown: unknown color primaries.
	VideoColorPrimariesUnknown VideoColorPrimaries = iota
	// VideoColorPrimariesBt709: BT709 primaries, also ITU-R BT1361 / IEC
	// 61966-2-4 / SMPTE RP177 Annex B.
	VideoColorPrimariesBt709
	// VideoColorPrimariesBt470M: BT470M primaries, also FCC Title 47 Code of
	// Federal Regulations 73.682 (a)(20).
	VideoColorPrimariesBt470M
	// VideoColorPrimariesBt470Bg: BT470BG primaries, also ITU-R BT601-6 625 /
	// ITU-R BT1358 625 / ITU-R BT1700 625 PAL & SECAM.
	VideoColorPrimariesBt470Bg
	// VideoColorPrimariesSmpte170M: SMPTE170M primaries, also ITU-R BT601-6 525
	// / ITU-R BT1358 525 / ITU-R BT1700 NTSC.
	VideoColorPrimariesSmpte170M
	// VideoColorPrimariesSmpte240M: SMPTE240M primaries.
	VideoColorPrimariesSmpte240M
	// VideoColorPrimariesFilm: generic film (colour filters using Illuminant
	// C).
	VideoColorPrimariesFilm
	// VideoColorPrimariesBt2020: ITU-R BT2020 primaries. Since: 1.6.
	VideoColorPrimariesBt2020
	// VideoColorPrimariesAdobergb: adobe RGB primaries. Since: 1.8.
	VideoColorPrimariesAdobergb
	// VideoColorPrimariesSmptest428: SMPTE ST 428 primaries (CIE 1931 XYZ).
	// Since: 1.16.
	VideoColorPrimariesSmptest428
	// VideoColorPrimariesSmpterp431: SMPTE RP 431 primaries (ST 431-2 (2011) /
	// DCI P3). Since: 1.16.
	VideoColorPrimariesSmpterp431
	// VideoColorPrimariesSmpteeg432: SMPTE EG 432 primaries (ST 432-1 (2010) /
	// P3 D65). Since: 1.16.
	VideoColorPrimariesSmpteeg432
	// VideoColorPrimariesEbu3213: EBU 3213 primaries (JEDEC P22 phosphors).
	// Since: 1.16.
	VideoColorPrimariesEbu3213
)

func marshalVideoColorPrimaries(p uintptr) (interface{}, error) {
	return VideoColorPrimaries(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoColorPrimaries.
func (v VideoColorPrimaries) String() string {
	switch v {
	case VideoColorPrimariesUnknown:
		return "Unknown"
	case VideoColorPrimariesBt709:
		return "Bt709"
	case VideoColorPrimariesBt470M:
		return "Bt470M"
	case VideoColorPrimariesBt470Bg:
		return "Bt470Bg"
	case VideoColorPrimariesSmpte170M:
		return "Smpte170M"
	case VideoColorPrimariesSmpte240M:
		return "Smpte240M"
	case VideoColorPrimariesFilm:
		return "Film"
	case VideoColorPrimariesBt2020:
		return "Bt2020"
	case VideoColorPrimariesAdobergb:
		return "Adobergb"
	case VideoColorPrimariesSmptest428:
		return "Smptest428"
	case VideoColorPrimariesSmpterp431:
		return "Smpterp431"
	case VideoColorPrimariesSmpteeg432:
		return "Smpteeg432"
	case VideoColorPrimariesEbu3213:
		return "Ebu3213"
	default:
		return fmt.Sprintf("VideoColorPrimaries(%d)", v)
	}
}

// VideoColorPrimariesFromISO converts the value to the VideoColorPrimaries
// The colour primaries (ColourPrimaries) value is defined by "ISO/IEC 23001-8
// Section 7.1 Table 2" and "ITU-T H.273 Table 2". "H.264 Table E-3" and "H.265
// Table E.3" share the identical values.
//
// The function takes the following parameters:
//
//   - value: ITU-T H.273 colour primaries value.
//
// The function returns the following values:
//
//   - videoColorPrimaries: matched VideoColorPrimaries.
func VideoColorPrimariesFromISO(value uint) VideoColorPrimaries {
	var _arg1 C.guint                  // out
	var _cret C.GstVideoColorPrimaries // in

	_arg1 = C.guint(value)

	_cret = C.gst_video_color_primaries_from_iso(_arg1)
	runtime.KeepAlive(value)

	var _videoColorPrimaries VideoColorPrimaries // out

	_videoColorPrimaries = VideoColorPrimaries(_cret)

	return _videoColorPrimaries
}

// VideoColorPrimariesGetInfo: get information about the chromaticity
// coordinates of primaries.
//
// The function takes the following parameters:
//
//   - primaries: VideoColorPrimaries.
//
// The function returns the following values:
//
//   - videoColorPrimariesInfo for primaries.
func VideoColorPrimariesGetInfo(primaries VideoColorPrimaries) *VideoColorPrimariesInfo {
	var _arg1 C.GstVideoColorPrimaries      // out
	var _cret *C.GstVideoColorPrimariesInfo // in

	_arg1 = C.GstVideoColorPrimaries(primaries)

	_cret = C.gst_video_color_primaries_get_info(_arg1)
	runtime.KeepAlive(primaries)

	var _videoColorPrimariesInfo *VideoColorPrimariesInfo // out

	_videoColorPrimariesInfo = (*VideoColorPrimariesInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _videoColorPrimariesInfo
}

// VideoColorPrimariesIsEquivalent checks whether primaries and other are
// functionally equivalent.
//
// The function takes the following parameters:
//
//   - primaries: VideoColorPrimaries.
//   - other VideoColorPrimaries.
//
// The function returns the following values:
//
//   - ok: TRUE if primaries and other can be considered equivalent.
func VideoColorPrimariesIsEquivalent(primaries, other VideoColorPrimaries) bool {
	var _arg1 C.GstVideoColorPrimaries // out
	var _arg2 C.GstVideoColorPrimaries // out
	var _cret C.gboolean               // in

	_arg1 = C.GstVideoColorPrimaries(primaries)
	_arg2 = C.GstVideoColorPrimaries(other)

	_cret = C.gst_video_color_primaries_is_equivalent(_arg1, _arg2)
	runtime.KeepAlive(primaries)
	runtime.KeepAlive(other)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// VideoColorPrimariesToISO converts VideoColorPrimaries to the "colour
// primaries" (ColourPrimaries) value defined by "ISO/IEC 23001-8 Section 7.1
// Table 2" and "ITU-T H.273 Table 2". "H.264 Table E-3" and "H.265 Table E.3"
// share the identical values.
//
// The function takes the following parameters:
//
//   - primaries: VideoColorPrimaries.
//
// The function returns the following values:
//
//   - guint: value of ISO/IEC 23001-8 colour primaries.
func VideoColorPrimariesToISO(primaries VideoColorPrimaries) uint {
	var _arg1 C.GstVideoColorPrimaries // out
	var _cret C.guint                  // in

	_arg1 = C.GstVideoColorPrimaries(primaries)

	_cret = C.gst_video_color_primaries_to_iso(_arg1)
	runtime.KeepAlive(primaries)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// VideoColorRange: possible color range values. These constants are defined for
// 8 bit color values and can be scaled for other bit depths.
type VideoColorRange C.gint

const (
	// VideoColorRangeUnknown: unknown range.
	VideoColorRangeUnknown VideoColorRange = iota
	// VideoColorRange0255: [0..255] for 8 bit components.
	VideoColorRange0255
	// VideoColorRange16235: [16..235] for 8 bit components. Chroma has
	// [16..240] range.
	VideoColorRange16235
)

func marshalVideoColorRange(p uintptr) (interface{}, error) {
	return VideoColorRange(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoColorRange.
func (v VideoColorRange) String() string {
	switch v {
	case VideoColorRangeUnknown:
		return "Unknown"
	case VideoColorRange0255:
		return "0255"
	case VideoColorRange16235:
		return "16235"
	default:
		return fmt.Sprintf("VideoColorRange(%d)", v)
	}
}

// VideoColorRangeOffsets: compute the offset and scale values for each
// component of info. For each component, (c[i] - offset[i]) / scale[i] will
// scale the component c[i] to the range [0.0 .. 1.0].
//
// The reverse operation (c[i] * scale[i]) + offset[i] can be used to convert
// the component values in range [0.0 .. 1.0] back to their representation in
// info and range.
//
// The function takes the following parameters:
//
//   - range: VideoColorRange.
//   - info: VideoFormatInfo.
//
// The function returns the following values:
//
//   - offset: output offsets.
//   - scale: output scale.
func VideoColorRangeOffsets(_range VideoColorRange, info *VideoFormatInfo) (offset, scale [4]int) {
	var _arg1 C.GstVideoColorRange  // out
	var _arg2 *C.GstVideoFormatInfo // out
	var _arg3 [4]C.gint             // in
	var _arg4 [4]C.gint             // in

	_arg1 = C.GstVideoColorRange(_range)
	_arg2 = (*C.GstVideoFormatInfo)(gextras.StructNative(unsafe.Pointer(info)))

	C.gst_video_color_range_offsets(_arg1, _arg2, &_arg3[0], &_arg4[0])
	runtime.KeepAlive(_range)
	runtime.KeepAlive(info)

	var _offset [4]int // out
	var _scale [4]int  // out

	{
		src := &_arg3
		for i := 0; i < 4; i++ {
			_offset[i] = int(src[i])
		}
	}
	{
		src := &_arg4
		for i := 0; i < 4; i++ {
			_scale[i] = int(src[i])
		}
	}

	return _offset, _scale
}

// VideoDitherMethod: different dithering methods to use.
type VideoDitherMethod C.gint

const (
	// VideoDitherNone: no dithering.
	VideoDitherNone VideoDitherMethod = iota
	// VideoDitherVerterr: propagate rounding errors downwards.
	VideoDitherVerterr
	// VideoDitherFloydSteinberg: dither with floyd-steinberg error diffusion.
	VideoDitherFloydSteinberg
	// VideoDitherSierraLite: dither with Sierra Lite error diffusion.
	VideoDitherSierraLite
	// VideoDitherBayer: ordered dither using a bayer pattern.
	VideoDitherBayer
)

func marshalVideoDitherMethod(p uintptr) (interface{}, error) {
	return VideoDitherMethod(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoDitherMethod.
func (v VideoDitherMethod) String() string {
	switch v {
	case VideoDitherNone:
		return "None"
	case VideoDitherVerterr:
		return "Verterr"
	case VideoDitherFloydSteinberg:
		return "FloydSteinberg"
	case VideoDitherSierraLite:
		return "SierraLite"
	case VideoDitherBayer:
		return "Bayer"
	default:
		return fmt.Sprintf("VideoDitherMethod(%d)", v)
	}
}

// VideoFieldOrder: field order of interlaced content. This is only valid for
// interlace-mode=interleaved and not interlace-mode=mixed. In the case of mixed
// or GST_VIDEO_FIELD_ORDER_UNKOWN, the field order is signalled via buffer
// flags.
type VideoFieldOrder C.gint

const (
	// VideoFieldOrderUnknown: unknown field order for interlaced content.
	// The actual field order is signalled via buffer flags.
	VideoFieldOrderUnknown VideoFieldOrder = iota
	// VideoFieldOrderTopFieldFirst: top field is first.
	VideoFieldOrderTopFieldFirst
	// VideoFieldOrderBottomFieldFirst: bottom field is first.
	VideoFieldOrderBottomFieldFirst
)

func marshalVideoFieldOrder(p uintptr) (interface{}, error) {
	return VideoFieldOrder(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoFieldOrder.
func (v VideoFieldOrder) String() string {
	switch v {
	case VideoFieldOrderUnknown:
		return "Unknown"
	case VideoFieldOrderTopFieldFirst:
		return "TopFieldFirst"
	case VideoFieldOrderBottomFieldFirst:
		return "BottomFieldFirst"
	default:
		return fmt.Sprintf("VideoFieldOrder(%d)", v)
	}
}

// VideoFieldOrderFromString: convert order to a VideoFieldOrder.
//
// The function takes the following parameters:
//
//   - order: field order.
//
// The function returns the following values:
//
//   - videoFieldOrder of order or T_VIDEO_FIELD_ORDER_UNKNOWN when order is not
//     a valid string representation for a VideoFieldOrder.
func VideoFieldOrderFromString(order string) VideoFieldOrder {
	var _arg1 *C.gchar             // out
	var _cret C.GstVideoFieldOrder // in

	_arg1 = (*C.gchar)(unsafe.Pointer(C.CString(order)))
	defer C.free(unsafe.Pointer(_arg1))

	_cret = C.gst_video_field_order_from_string(_arg1)
	runtime.KeepAlive(order)

	var _videoFieldOrder VideoFieldOrder // out

	_videoFieldOrder = VideoFieldOrder(_cret)

	return _videoFieldOrder
}

// VideoFieldOrderToString: convert order to its string representation.
//
// The function takes the following parameters:
//
//   - order: VideoFieldOrder.
//
// The function returns the following values:
//
//   - utf8: order as a string.
func VideoFieldOrderToString(order VideoFieldOrder) string {
	var _arg1 C.GstVideoFieldOrder // out
	var _cret *C.gchar             // in

	_arg1 = C.GstVideoFieldOrder(order)

	_cret = C.gst_video_field_order_to_string(_arg1)
	runtime.KeepAlive(order)

	var _utf8 string // out

	_utf8 = C.GoString((*C.gchar)(unsafe.Pointer(_cret)))

	return _utf8
}

// VideoFormat: enum value describing the most common video formats.
//
// See the GStreamer raw video format design document
// (https://gstreamer.freedesktop.org/documentation/additional/design/mediatype-video-raw.html#formats)
// for details about the layout and packing of these formats in memory.
type VideoFormat C.gint

const (
	// VideoFormatUnknown: unknown or unset video format id.
	VideoFormatUnknown VideoFormat = iota
	// VideoFormatEncoded: encoded video format. Only ever use that in
	// caps for special video formats in combination with non-system memory
	// GstCapsFeatures where it does not make sense to specify a real video
	// format.
	VideoFormatEncoded
	// VideoFormatI420: planar 4:2:0 YUV.
	VideoFormatI420
	// VideoFormatYV12: planar 4:2:0 YVU (like I420 but UV planes swapped).
	VideoFormatYV12
	// VideoFormatYuy2: packed 4:2:2 YUV (Y0-U0-Y1-V0 Y2-U2-Y3-V2 Y4 ...).
	VideoFormatYuy2
	// VideoFormatUyvy: packed 4:2:2 YUV (U0-Y0-V0-Y1 U2-Y2-V2-Y3 U4 ...).
	VideoFormatUyvy
	// VideoFormatAyuv: packed 4:4:4 YUV with alpha channel (A0-Y0-U0-V0 ...).
	VideoFormatAyuv
	// VideoFormatRgbx: sparse rgb packed into 32 bit, space last.
	VideoFormatRgbx
	// VideoFormatBgrx: sparse reverse rgb packed into 32 bit, space last.
	VideoFormatBgrx
	// VideoFormatXrgb: sparse rgb packed into 32 bit, space first.
	VideoFormatXrgb
	// VideoFormatXbgr: sparse reverse rgb packed into 32 bit, space first.
	VideoFormatXbgr
	// VideoFormatRGBA: rgb with alpha channel last.
	VideoFormatRGBA
	// VideoFormatBgra: reverse rgb with alpha channel last.
	VideoFormatBgra
	// VideoFormatARGB: rgb with alpha channel first.
	VideoFormatARGB
	// VideoFormatAbgr: reverse rgb with alpha channel first.
	VideoFormatAbgr
	// VideoFormatRGB: RGB packed into 24 bits without padding (R-G-B-R-G-B).
	VideoFormatRGB
	// VideoFormatBGR: reverse RGB packed into 24 bits without padding
	// (B-G-R-B-G-R).
	VideoFormatBGR
	// VideoFormatY41B: planar 4:1:1 YUV.
	VideoFormatY41B
	// VideoFormatY42B: planar 4:2:2 YUV.
	VideoFormatY42B
	// VideoFormatYvyu: packed 4:2:2 YUV (Y0-V0-Y1-U0 Y2-V2-Y3-U2 Y4 ...).
	VideoFormatYvyu
	// VideoFormatY444: planar 4:4:4 YUV.
	VideoFormatY444
	// VideoFormatV210: packed 4:2:2 10-bit YUV, complex format.
	VideoFormatV210
	// VideoFormatV216: packed 4:2:2 16-bit YUV, Y0-U0-Y1-V1 order.
	VideoFormatV216
	// VideoFormatNv12: planar 4:2:0 YUV with interleaved UV plane.
	VideoFormatNv12
	// VideoFormatNv21: planar 4:2:0 YUV with interleaved VU plane.
	VideoFormatNv21
	// VideoFormatGray8: 8-bit grayscale.
	VideoFormatGray8
	// VideoFormatGray16Be: 16-bit grayscale, most significant byte first.
	VideoFormatGray16Be
	// VideoFormatGray16LE: 16-bit grayscale, least significant byte first.
	VideoFormatGray16LE
	// VideoFormatV308: packed 4:4:4 YUV (Y-U-V ...).
	VideoFormatV308
	// VideoFormatRGB16: rgb 5-6-5 bits per component.
	VideoFormatRGB16
	// VideoFormatBGR16: reverse rgb 5-6-5 bits per component.
	VideoFormatBGR16
	// VideoFormatRGB15: rgb 5-5-5 bits per component.
	VideoFormatRGB15
	// VideoFormatBGR15: reverse rgb 5-5-5 bits per component.
	VideoFormatBGR15
	// VideoFormatUyvp: packed 10-bit 4:2:2 YUV (U0-Y0-V0-Y1 U2-Y2-V2-Y3 U4
	// ...).
	VideoFormatUyvp
	// VideoFormatA420: planar 4:4:2:0 AYUV.
	VideoFormatA420
	// VideoFormatRGB8P: 8-bit paletted RGB.
	VideoFormatRGB8P
	// VideoFormatYuv9: planar 4:1:0 YUV.
	VideoFormatYuv9
	// VideoFormatYvu9: planar 4:1:0 YUV (like YUV9 but UV planes swapped).
	VideoFormatYvu9
	// VideoFormatIyu1: packed 4:1:1 YUV (Cb-Y0-Y1-Cr-Y2-Y3 ...).
	VideoFormatIyu1
	// VideoFormatARGB64: rgb with alpha channel first, 16 bits (native
	// endianness) per channel.
	VideoFormatARGB64
	// VideoFormatAyuv64: packed 4:4:4 YUV with alpha channel, 16 bits (native
	// endianness) per channel (A0-Y0-U0-V0 ...).
	VideoFormatAyuv64
	// VideoFormatR210: packed 4:4:4 RGB, 10 bits per channel.
	VideoFormatR210
	// VideoFormatI42010Be: planar 4:2:0 YUV, 10 bits per channel.
	VideoFormatI42010Be
	// VideoFormatI42010LE: planar 4:2:0 YUV, 10 bits per channel.
	VideoFormatI42010LE
	// VideoFormatI42210Be: planar 4:2:2 YUV, 10 bits per channel.
	VideoFormatI42210Be
	// VideoFormatI42210LE: planar 4:2:2 YUV, 10 bits per channel.
	VideoFormatI42210LE
	// VideoFormatY44410Be: planar 4:4:4 YUV, 10 bits per channel (Since: 1.2).
	VideoFormatY44410Be
	// VideoFormatY44410LE: planar 4:4:4 YUV, 10 bits per channel (Since: 1.2).
	VideoFormatY44410LE
	// VideoFormatGbr: planar 4:4:4 RGB, 8 bits per channel (Since: 1.2).
	VideoFormatGbr
	// VideoFormatGbr10Be: planar 4:4:4 RGB, 10 bits per channel (Since: 1.2).
	VideoFormatGbr10Be
	// VideoFormatGbr10LE: planar 4:4:4 RGB, 10 bits per channel (Since: 1.2).
	VideoFormatGbr10LE
	// VideoFormatNv16: planar 4:2:2 YUV with interleaved UV plane (Since: 1.2).
	VideoFormatNv16
	// VideoFormatNv24: planar 4:4:4 YUV with interleaved UV plane (Since: 1.2).
	VideoFormatNv24
	// VideoFormatNv1264Z32: NV12 with 64x32 tiling in zigzag pattern (Since:
	// 1.4).
	VideoFormatNv1264Z32
	// VideoFormatA42010Be: planar 4:4:2:0 YUV, 10 bits per channel (Since:
	// 1.6).
	VideoFormatA42010Be
	// VideoFormatA42010LE: planar 4:4:2:0 YUV, 10 bits per channel (Since:
	// 1.6).
	VideoFormatA42010LE
	// VideoFormatA42210Be: planar 4:4:2:2 YUV, 10 bits per channel (Since:
	// 1.6).
	VideoFormatA42210Be
	// VideoFormatA42210LE: planar 4:4:2:2 YUV, 10 bits per channel (Since:
	// 1.6).
	VideoFormatA42210LE
	// VideoFormatA44410Be: planar 4:4:4:4 YUV, 10 bits per channel (Since:
	// 1.6).
	VideoFormatA44410Be
	// VideoFormatA44410LE: planar 4:4:4:4 YUV, 10 bits per channel (Since:
	// 1.6).
	VideoFormatA44410LE
	// VideoFormatNv61: planar 4:2:2 YUV with interleaved VU plane (Since: 1.6).
	VideoFormatNv61
	// VideoFormatP01010Be: planar 4:2:0 YUV with interleaved UV plane, 10 bits
	// per channel (Since: 1.10).
	VideoFormatP01010Be
	// VideoFormatP01010LE: planar 4:2:0 YUV with interleaved UV plane, 10 bits
	// per channel (Since: 1.10).
	VideoFormatP01010LE
	// VideoFormatIyu2: packed 4:4:4 YUV (U-Y-V ...) (Since: 1.10).
	VideoFormatIyu2
	// VideoFormatVyuy: packed 4:2:2 YUV (V0-Y0-U0-Y1 V2-Y2-U2-Y3 V4 ...).
	VideoFormatVyuy
	// VideoFormatGbra: planar 4:4:4:4 ARGB, 8 bits per channel (Since: 1.12).
	VideoFormatGbra
	// VideoFormatGbra10Be: planar 4:4:4:4 ARGB, 10 bits per channel (Since:
	// 1.12).
	VideoFormatGbra10Be
	// VideoFormatGbra10LE: planar 4:4:4:4 ARGB, 10 bits per channel (Since:
	// 1.12).
	VideoFormatGbra10LE
	// VideoFormatGbr12Be: planar 4:4:4 RGB, 12 bits per channel (Since: 1.12).
	VideoFormatGbr12Be
	// VideoFormatGbr12LE: planar 4:4:4 RGB, 12 bits per channel (Since: 1.12).
	VideoFormatGbr12LE
	// VideoFormatGbra12Be: planar 4:4:4:4 ARGB, 12 bits per channel (Since:
	// 1.12).
	VideoFormatGbra12Be
	// VideoFormatGbra12LE: planar 4:4:4:4 ARGB, 12 bits per channel (Since:
	// 1.12).
	VideoFormatGbra12LE
	// VideoFormatI42012Be: planar 4:2:0 YUV, 12 bits per channel (Since: 1.12).
	VideoFormatI42012Be
	// VideoFormatI42012LE: planar 4:2:0 YUV, 12 bits per channel (Since: 1.12).
	VideoFormatI42012LE
	// VideoFormatI42212Be: planar 4:2:2 YUV, 12 bits per channel (Since: 1.12).
	VideoFormatI42212Be
	// VideoFormatI42212LE: planar 4:2:2 YUV, 12 bits per channel (Since: 1.12).
	VideoFormatI42212LE
	// VideoFormatY44412Be: planar 4:4:4 YUV, 12 bits per channel (Since: 1.12).
	VideoFormatY44412Be
	// VideoFormatY44412LE: planar 4:4:4 YUV, 12 bits per channel (Since: 1.12).
	VideoFormatY44412LE
	// VideoFormatGray10LE32: 10-bit grayscale, packed into 32bit words (2 bits
	// padding) (Since: 1.14).
	VideoFormatGray10LE32
	// VideoFormatNv1210LE32: 10-bit variant of GST_VIDEO_FORMAT_NV12, packed
	// into 32bit words (MSB 2 bits padding) (Since: 1.14).
	VideoFormatNv1210LE32
	// VideoFormatNv1610LE32: 10-bit variant of GST_VIDEO_FORMAT_NV16, packed
	// into 32bit words (MSB 2 bits padding) (Since: 1.14).
	VideoFormatNv1610LE32
	// VideoFormatNv1210LE40: fully packed variant of NV12_10LE32 (Since: 1.16).
	VideoFormatNv1210LE40
	// VideoFormatY210: packed 4:2:2 YUV, 10 bits per channel (Since: 1.16).
	VideoFormatY210
	// VideoFormatY410: packed 4:4:4 YUV, 10 bits per channel(A-V-Y-U...)
	// (Since: 1.16).
	VideoFormatY410
	// VideoFormatVuya: packed 4:4:4 YUV with alpha channel (V0-U0-Y0-A0...)
	// (Since: 1.16).
	VideoFormatVuya
	// VideoFormatBGR10A2LE: packed 4:4:4 RGB with alpha channel(B-G-R-A),
	// 10 bits for R/G/B channel and MSB 2 bits for alpha channel (Since: 1.16).
	VideoFormatBGR10A2LE
	// VideoFormatRGB10A2LE: packed 4:4:4 RGB with alpha channel(R-G-B-A),
	// 10 bits for R/G/B channel and MSB 2 bits for alpha channel (Since: 1.18).
	VideoFormatRGB10A2LE
	// VideoFormatY44416Be: planar 4:4:4 YUV, 16 bits per channel (Since: 1.18).
	VideoFormatY44416Be
	// VideoFormatY44416LE: planar 4:4:4 YUV, 16 bits per channel (Since: 1.18).
	VideoFormatY44416LE
	// VideoFormatP016Be: planar 4:2:0 YUV with interleaved UV plane, 16 bits
	// per channel (Since: 1.18).
	VideoFormatP016Be
	// VideoFormatP016LE: planar 4:2:0 YUV with interleaved UV plane, 16 bits
	// per channel (Since: 1.18).
	VideoFormatP016LE
	// VideoFormatP012Be: planar 4:2:0 YUV with interleaved UV plane, 12 bits
	// per channel (Since: 1.18).
	VideoFormatP012Be
	// VideoFormatP012LE: planar 4:2:0 YUV with interleaved UV plane, 12 bits
	// per channel (Since: 1.18).
	VideoFormatP012LE
	// VideoFormatY212Be: packed 4:2:2 YUV, 12 bits per channel (Y-U-Y-V)
	// (Since: 1.18).
	VideoFormatY212Be
	// VideoFormatY212LE: packed 4:2:2 YUV, 12 bits per channel (Y-U-Y-V)
	// (Since: 1.18).
	VideoFormatY212LE
	// VideoFormatY412Be: packed 4:4:4:4 YUV, 12 bits per channel(U-Y-V-A...)
	// (Since: 1.18).
	VideoFormatY412Be
	// VideoFormatY412LE: packed 4:4:4:4 YUV, 12 bits per channel(U-Y-V-A...)
	// (Since: 1.18).
	VideoFormatY412LE
	// VideoFormatNv124L4: NV12 with 4x4 tiles in linear order.
	VideoFormatNv124L4
	// VideoFormatNv1232L32: NV12 with 32x32 tiles in linear order.
	VideoFormatNv1232L32
	// VideoFormatRgbp: planar 4:4:4 RGB, R-G-B order.
	VideoFormatRgbp
	// VideoFormatBgrp: planar 4:4:4 RGB, B-G-R order.
	VideoFormatBgrp
	// VideoFormatAv12: planar 4:2:0 YUV with interleaved UV plane with alpha as
	// 3rd plane.
	VideoFormatAv12
	// VideoFormatARGB64LE: RGB with alpha channel first, 16 bits (little
	// endian) per channel.
	VideoFormatARGB64LE
	// VideoFormatARGB64Be: RGB with alpha channel first, 16 bits (big endian)
	// per channel.
	VideoFormatARGB64Be
	// VideoFormatRGBA64LE: RGB with alpha channel last, 16 bits (little endian)
	// per channel.
	VideoFormatRGBA64LE
	// VideoFormatRGBA64Be: RGB with alpha channel last, 16 bits (big endian)
	// per channel.
	VideoFormatRGBA64Be
	// VideoFormatBgra64LE: reverse RGB with alpha channel last, 16 bits (little
	// endian) per channel.
	VideoFormatBgra64LE
	// VideoFormatBgra64Be: reverse RGB with alpha channel last, 16 bits (big
	// endian) per channel.
	VideoFormatBgra64Be
	// VideoFormatAbgr64LE: reverse RGB with alpha channel first, 16 bits
	// (little endian) per channel.
	VideoFormatAbgr64LE
	// VideoFormatAbgr64Be: reverse RGB with alpha channel first, 16 bits (big
	// endian) per channel.
	VideoFormatAbgr64Be
	// VideoFormatNv1216L32S: NV12 with 16x32 Y tiles and 16x16 UV tiles.
	VideoFormatNv1216L32S
	// VideoFormatNv128L128: NV12 with 8x128 tiles in linear order.
	VideoFormatNv128L128
	// VideoFormatNv1210Be8L128: NV12 10bit big endian with 8x128 tiles in
	// linear order.
	VideoFormatNv1210Be8L128
	// VideoFormatNv1210LE404L4: GST_VIDEO_FORMAT_NV12_10LE40 with 4x4
	// pixels tiles (5 bytes per tile row). This format is produced by
	// Verisilicon/Hantro decoders.
	VideoFormatNv1210LE404L4
	// VideoFormatDmaDRM: GST_VIDEO_FORMAT_DMA_DRM represent the DMA DRM special
	// format. It's only used with memory:DMABuf CapsFeatures, where an extra
	// parameter (drm-format) is required to define the image format and its
	// memory layout.
	VideoFormatDmaDRM
	// VideoFormatMt2110T: mediatek 10bit NV12 little endian with 16x32 tiles in
	// linear order, tile 2 bits.
	VideoFormatMt2110T
	// VideoFormatMt2110R: mediatek 10bit NV12 little endian with 16x32 tiles in
	// linear order, raster 2 bits.
	VideoFormatMt2110R
	// VideoFormatA422: planar 4:4:2:2 YUV, 8 bits per channel.
	VideoFormatA422
	// VideoFormatA444: planar 4:4:4:4 YUV, 8 bits per channel.
	VideoFormatA444
	// VideoFormatA44412LE: planar 4:4:4:4 YUV, 12 bits per channel.
	VideoFormatA44412LE
	// VideoFormatA44412Be: planar 4:4:4:4 YUV, 12 bits per channel.
	VideoFormatA44412Be
	// VideoFormatA42212LE: planar 4:4:2:2 YUV, 12 bits per channel.
	VideoFormatA42212LE
	// VideoFormatA42212Be: planar 4:4:2:2 YUV, 12 bits per channel.
	VideoFormatA42212Be
	// VideoFormatA42012LE: planar 4:4:2:0 YUV, 12 bits per channel.
	VideoFormatA42012LE
	// VideoFormatA42012Be: planar 4:4:2:0 YUV, 12 bits per channel.
	VideoFormatA42012Be
	// VideoFormatA44416LE: planar 4:4:4:4 YUV, 16 bits per channel.
	VideoFormatA44416LE
	// VideoFormatA44416Be: planar 4:4:4:4 YUV, 16 bits per channel.
	VideoFormatA44416Be
	// VideoFormatA42216LE: planar 4:4:2:2 YUV, 16 bits per channel.
	VideoFormatA42216LE
	// VideoFormatA42216Be: planar 4:4:2:2 YUV, 16 bits per channel.
	VideoFormatA42216Be
	// VideoFormatA42016LE: planar 4:4:2:0 YUV, 16 bits per channel.
	VideoFormatA42016LE
	// VideoFormatA42016Be: planar 4:4:2:0 YUV, 16 bits per channel.
	VideoFormatA42016Be
	// VideoFormatGbr16LE: planar 4:4:4 RGB, 16 bits per channel.
	VideoFormatGbr16LE
	// VideoFormatGbr16Be: planar 4:4:4 RGB, 16 bits per channel.
	VideoFormatGbr16Be
	// VideoFormatRbga: packed RGB with alpha, 8 bits per channel.
	VideoFormatRbga
)

func marshalVideoFormat(p uintptr) (interface{}, error) {
	return VideoFormat(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoFormat.
func (v VideoFormat) String() string {
	switch v {
	case VideoFormatUnknown:
		return "Unknown"
	case VideoFormatEncoded:
		return "Encoded"
	case VideoFormatI420:
		return "I420"
	case VideoFormatYV12:
		return "YV12"
	case VideoFormatYuy2:
		return "Yuy2"
	case VideoFormatUyvy:
		return "Uyvy"
	case VideoFormatAyuv:
		return "Ayuv"
	case VideoFormatRgbx:
		return "Rgbx"
	case VideoFormatBgrx:
		return "Bgrx"
	case VideoFormatXrgb:
		return "Xrgb"
	case VideoFormatXbgr:
		return "Xbgr"
	case VideoFormatRGBA:
		return "RGBA"
	case VideoFormatBgra:
		return "Bgra"
	case VideoFormatARGB:
		return "ARGB"
	case VideoFormatAbgr:
		return "Abgr"
	case VideoFormatRGB:
		return "RGB"
	case VideoFormatBGR:
		return "BGR"
	case VideoFormatY41B:
		return "Y41B"
	case VideoFormatY42B:
		return "Y42B"
	case VideoFormatYvyu:
		return "Yvyu"
	case VideoFormatY444:
		return "Y444"
	case VideoFormatV210:
		return "V210"
	case VideoFormatV216:
		return "V216"
	case VideoFormatNv12:
		return "Nv12"
	case VideoFormatNv21:
		return "Nv21"
	case VideoFormatGray8:
		return "Gray8"
	case VideoFormatGray16Be:
		return "Gray16Be"
	case VideoFormatGray16LE:
		return "Gray16LE"
	case VideoFormatV308:
		return "V308"
	case VideoFormatRGB16:
		return "RGB16"
	case VideoFormatBGR16:
		return "BGR16"
	case VideoFormatRGB15:
		return "RGB15"
	case VideoFormatBGR15:
		return "BGR15"
	case VideoFormatUyvp:
		return "Uyvp"
	case VideoFormatA420:
		return "A420"
	case VideoFormatRGB8P:
		return "RGB8P"
	case VideoFormatYuv9:
		return "Yuv9"
	case VideoFormatYvu9:
		return "Yvu9"
	case VideoFormatIyu1:
		return "Iyu1"
	case VideoFormatARGB64:
		return "ARGB64"
	case VideoFormatAyuv64:
		return "Ayuv64"
	case VideoFormatR210:
		return "R210"
	case VideoFormatI42010Be:
		return "I42010Be"
	case VideoFormatI42010LE:
		return "I42010LE"
	case VideoFormatI42210Be:
		return "I42210Be"
	case VideoFormatI42210LE:
		return "I42210LE"
	case VideoFormatY44410Be:
		return "Y44410Be"
	case VideoFormatY44410LE:
		return "Y44410LE"
	case VideoFormatGbr:
		return "Gbr"
	case VideoFormatGbr10Be:
		return "Gbr10Be"
	case VideoFormatGbr10LE:
		return "Gbr10LE"
	case VideoFormatNv16:
		return "Nv16"
	case VideoFormatNv24:
		return "Nv24"
	case VideoFormatNv1264Z32:
		return "Nv1264Z32"
	case VideoFormatA42010Be:
		return "A42010Be"
	case VideoFormatA42010LE:
		return "A42010LE"
	case VideoFormatA42210Be:
		return "A42210Be"
	case VideoFormatA42210LE:
		return "A42210LE"
	case VideoFormatA44410Be:
		return "A44410Be"
	case VideoFormatA44410LE:
		return "A44410LE"
	case VideoFormatNv61:
		return "Nv61"
	case VideoFormatP01010Be:
		return "P01010Be"
	case VideoFormatP01010LE:
		return "P01010LE"
	case VideoFormatIyu2:
		return "Iyu2"
	case VideoFormatVyuy:
		return "Vyuy"
	case VideoFormatGbra:
		return "Gbra"
	case VideoFormatGbra10Be:
		return "Gbra10Be"
	case VideoFormatGbra10LE:
		return "Gbra10LE"
	case VideoFormatGbr12Be:
		return "Gbr12Be"
	case VideoFormatGbr12LE:
		return "Gbr12LE"
	case VideoFormatGbra12Be:
		return "Gbra12Be"
	case VideoFormatGbra12LE:
		return "Gbra12LE"
	case VideoFormatI42012Be:
		return "I42012Be"
	case VideoFormatI42012LE:
		return "I42012LE"
	case VideoFormatI42212Be:
		return "I42212Be"
	case VideoFormatI42212LE:
		return "I42212LE"
	case VideoFormatY44412Be:
		return "Y44412Be"
	case VideoFormatY44412LE:
		return "Y44412LE"
	case VideoFormatGray10LE32:
		return "Gray10LE32"
	case VideoFormatNv1210LE32:
		return "Nv1210LE32"
	case VideoFormatNv1610LE32:
		return "Nv1610LE32"
	case VideoFormatNv1210LE40:
		return "Nv1210LE40"
	case VideoFormatY210:
		return "Y210"
	case VideoFormatY410:
		return "Y410"
	case VideoFormatVuya:
		return "Vuya"
	case VideoFormatBGR10A2LE:
		return "BGR10A2LE"
	case VideoFormatRGB10A2LE:
		return "RGB10A2LE"
	case VideoFormatY44416Be:
		return "Y44416Be"
	case VideoFormatY44416LE:
		return "Y44416LE"
	case VideoFormatP016Be:
		return "P016Be"
	case VideoFormatP016LE:
		return "P016LE"
	case VideoFormatP012Be:
		return "P012Be"
	case VideoFormatP012LE:
		return "P012LE"
	case VideoFormatY212Be:
		return "Y212Be"
	case VideoFormatY212LE:
		return "Y212LE"
	case VideoFormatY412Be:
		return "Y412Be"
	case VideoFormatY412LE:
		return "Y412LE"
	case VideoFormatNv124L4:
		return "Nv124L4"
	case VideoFormatNv1232L32:
		return "Nv1232L32"
	case VideoFormatRgbp:
		return "Rgbp"
	case VideoFormatBgrp:
		return "Bgrp"
	case VideoFormatAv12:
		return "Av12"
	case VideoFormatARGB64LE:
		return "ARGB64LE"
	case VideoFormatARGB64Be:
		return "ARGB64Be"
	case VideoFormatRGBA64LE:
		return "RGBA64LE"
	case VideoFormatRGBA64Be:
		return "RGBA64Be"
	case VideoFormatBgra64LE:
		return "Bgra64LE"
	case VideoFormatBgra64Be:
		return "Bgra64Be"
	case VideoFormatAbgr64LE:
		return "Abgr64LE"
	case VideoFormatAbgr64Be:
		return "Abgr64Be"
	case VideoFormatNv1216L32S:
		return "Nv1216L32S"
	case VideoFormatNv128L128:
		return "Nv128L128"
	case VideoFormatNv1210Be8L128:
		return "Nv1210Be8L128"
	case VideoFormatNv1210LE404L4:
		return "Nv1210LE404L4"
	case VideoFormatDmaDRM:
		return "DmaDRM"
	case VideoFormatMt2110T:
		return "Mt2110T"
	case VideoFormatMt2110R:
		return "Mt2110R"
	case VideoFormatA422:
		return "A422"
	case VideoFormatA444:
		return "A444"
	case VideoFormatA44412LE:
		return "A44412LE"
	case VideoFormatA44412Be:
		return "A44412Be"
	case VideoFormatA42212LE:
		return "A42212LE"
	case VideoFormatA42212Be:
		return "A42212Be"
	case VideoFormatA42012LE:
		return "A42012LE"
	case VideoFormatA42012Be:
		return "A42012Be"
	case VideoFormatA44416LE:
		return "A44416LE"
	case VideoFormatA44416Be:
		return "A44416Be"
	case VideoFormatA42216LE:
		return "A42216LE"
	case VideoFormatA42216Be:
		return "A42216Be"
	case VideoFormatA42016LE:
		return "A42016LE"
	case VideoFormatA42016Be:
		return "A42016Be"
	case VideoFormatGbr16LE:
		return "Gbr16LE"
	case VideoFormatGbr16Be:
		return "Gbr16Be"
	case VideoFormatRbga:
		return "Rbga"
	default:
		return fmt.Sprintf("VideoFormat(%d)", v)
	}
}

// VideoFormatFromFourcc converts a FOURCC value into the corresponding
// VideoFormat. If the FOURCC cannot be represented by VideoFormat,
// T_VIDEO_FORMAT_UNKNOWN is returned.
//
// The function takes the following parameters:
//
//   - fourcc: FOURCC value representing raw YUV video.
//
// The function returns the following values:
//
//   - videoFormat describing the FOURCC value.
func VideoFormatFromFourcc(fourcc uint32) VideoFormat {
	var _arg1 C.guint32        // out
	var _cret C.GstVideoFormat // in

	_arg1 = C.guint32(fourcc)

	_cret = C.gst_video_format_from_fourcc(_arg1)
	runtime.KeepAlive(fourcc)

	var _videoFormat VideoFormat // out

	_videoFormat = VideoFormat(_cret)

	return _videoFormat
}

// VideoFormatFromMasks: find the VideoFormat for the given parameters.
//
// The function takes the following parameters:
//
//   - depth: amount of bits used for a pixel.
//   - bpp: amount of bits used to store a pixel. This value is bigger than
//     depth.
//   - endianness of the masks, LITTLE_ENDIAN or BIG_ENDIAN.
//   - redMask: red mask.
//   - greenMask: green mask.
//   - blueMask: blue mask.
//   - alphaMask: alpha mask, or 0 if no alpha mask.
//
// The function returns the following values:
//
//   - videoFormat or GST_VIDEO_FORMAT_UNKNOWN when the parameters to not
//     specify a known format.
func VideoFormatFromMasks(depth, bpp, endianness int, redMask, greenMask, blueMask, alphaMask uint) VideoFormat {
	var _arg1 C.gint           // out
	var _arg2 C.gint           // out
	var _arg3 C.gint           // out
	var _arg4 C.guint          // out
	var _arg5 C.guint          // out
	var _arg6 C.guint          // out
	var _arg7 C.guint          // out
	var _cret C.GstVideoFormat // in

	_arg1 = C.gint(depth)
	_arg2 = C.gint(bpp)
	_arg3 = C.gint(endianness)
	_arg4 = C.guint(redMask)
	_arg5 = C.guint(greenMask)
	_arg6 = C.guint(blueMask)
	_arg7 = C.guint(alphaMask)

	_cret = C.gst_video_format_from_masks(_arg1, _arg2, _arg3, _arg4, _arg5, _arg6, _arg7)
	runtime.KeepAlive(depth)
	runtime.KeepAlive(bpp)
	runtime.KeepAlive(endianness)
	runtime.KeepAlive(redMask)
	runtime.KeepAlive(greenMask)
	runtime.KeepAlive(blueMask)
	runtime.KeepAlive(alphaMask)

	var _videoFormat VideoFormat // out

	_videoFormat = VideoFormat(_cret)

	return _videoFormat
}

// VideoFormatFromString: convert the format string to its VideoFormat.
//
// The function takes the following parameters:
//
//   - format string.
//
// The function returns the following values:
//
//   - videoFormat for format or GST_VIDEO_FORMAT_UNKNOWN when the string is not
//     a known format.
func VideoFormatFromString(format string) VideoFormat {
	var _arg1 *C.gchar         // out
	var _cret C.GstVideoFormat // in

	_arg1 = (*C.gchar)(unsafe.Pointer(C.CString(format)))
	defer C.free(unsafe.Pointer(_arg1))

	_cret = C.gst_video_format_from_string(_arg1)
	runtime.KeepAlive(format)

	var _videoFormat VideoFormat // out

	_videoFormat = VideoFormat(_cret)

	return _videoFormat
}

// VideoFormatGetInfo: get the VideoFormatInfo for format.
//
// The function takes the following parameters:
//
//   - format: VideoFormat.
//
// The function returns the following values:
//
//   - videoFormatInfo for format.
func VideoFormatGetInfo(format VideoFormat) *VideoFormatInfo {
	var _arg1 C.GstVideoFormat      // out
	var _cret *C.GstVideoFormatInfo // in

	_arg1 = C.GstVideoFormat(format)

	_cret = C.gst_video_format_get_info(_arg1)
	runtime.KeepAlive(format)

	var _videoFormatInfo *VideoFormatInfo // out

	_videoFormatInfo = (*VideoFormatInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _videoFormatInfo
}

// VideoFormatGetPalette: get the default palette of format. This the palette
// used in the pack function for paletted formats.
//
// The function takes the following parameters:
//
//   - format: VideoFormat.
//
// The function returns the following values:
//
//   - size of the palette in bytes.
//   - gpointer (optional): default palette of format or NULL when format does
//     not have a palette.
func VideoFormatGetPalette(format VideoFormat) (uint, unsafe.Pointer) {
	var _arg1 C.GstVideoFormat // out
	var _arg2 C.gsize          // in
	var _cret C.gconstpointer  // in

	_arg1 = C.GstVideoFormat(format)

	_cret = C.gst_video_format_get_palette(_arg1, &_arg2)
	runtime.KeepAlive(format)

	var _size uint               // out
	var _gpointer unsafe.Pointer // out

	_size = uint(_arg2)
	_gpointer = (unsafe.Pointer)(unsafe.Pointer(_cret))

	return _size, _gpointer
}

// VideoFormatToFourcc converts a VideoFormat value into the corresponding
// FOURCC. Only a few YUV formats have corresponding FOURCC values. If format
// has no corresponding FOURCC value, 0 is returned.
//
// The function takes the following parameters:
//
//   - format video format.
//
// The function returns the following values:
//
//   - guint32: FOURCC corresponding to format.
func VideoFormatToFourcc(format VideoFormat) uint32 {
	var _arg1 C.GstVideoFormat // out
	var _cret C.guint32        // in

	_arg1 = C.GstVideoFormat(format)

	_cret = C.gst_video_format_to_fourcc(_arg1)
	runtime.KeepAlive(format)

	var _guint32 uint32 // out

	_guint32 = uint32(_cret)

	return _guint32
}

// VideoFormatToString returns a string containing a descriptive name for the
// VideoFormat if there is one, or NULL otherwise.
//
// The function takes the following parameters:
//
//   - format video format.
//
// The function returns the following values:
//
//   - utf8: name corresponding to format.
func VideoFormatToString(format VideoFormat) string {
	var _arg1 C.GstVideoFormat // out
	var _cret *C.gchar         // in

	_arg1 = C.GstVideoFormat(format)

	_cret = C.gst_video_format_to_string(_arg1)
	runtime.KeepAlive(format)

	var _utf8 string // out

	_utf8 = C.GoString((*C.gchar)(unsafe.Pointer(_cret)))

	return _utf8
}

// VideoGLTextureOrientation: orientation of the GL texture.
type VideoGLTextureOrientation C.gint

const (
	// VideoGLTextureOrientationXNormalYNormal: top line first in memory,
	// left row first.
	VideoGLTextureOrientationXNormalYNormal VideoGLTextureOrientation = iota
	// VideoGLTextureOrientationXNormalYFlip: bottom line first in memory,
	// left row first.
	VideoGLTextureOrientationXNormalYFlip
	// VideoGLTextureOrientationXFlipYNormal: top line first in memory, right
	// row first.
	VideoGLTextureOrientationXFlipYNormal
	// VideoGLTextureOrientationXFlipYFlip: bottom line first in memory,
	// right row first.
	VideoGLTextureOrientationXFlipYFlip
)

func marshalVideoGLTextureOrientation(p uintptr) (interface{}, error) {
	return VideoGLTextureOrientation(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoGLTextureOrientation.
func (v VideoGLTextureOrientation) String() string {
	switch v {
	case VideoGLTextureOrientationXNormalYNormal:
		return "NormalYNormal"
	case VideoGLTextureOrientationXNormalYFlip:
		return "NormalYFlip"
	case VideoGLTextureOrientationXFlipYNormal:
		return "FlipYNormal"
	case VideoGLTextureOrientationXFlipYFlip:
		return "FlipYFlip"
	default:
		return fmt.Sprintf("VideoGLTextureOrientation(%d)", v)
	}
}

// VideoGLTextureType: GL texture type.
type VideoGLTextureType C.gint

const (
	// VideoGLTextureTypeLuminance: luminance texture, GL_LUMINANCE.
	VideoGLTextureTypeLuminance VideoGLTextureType = iota
	// VideoGLTextureTypeLuminanceAlpha: luminance-alpha texture,
	// GL_LUMINANCE_ALPHA.
	VideoGLTextureTypeLuminanceAlpha
	// VideoGLTextureTypeRGB16: RGB 565 texture, GL_RGB.
	VideoGLTextureTypeRGB16
	// VideoGLTextureTypeRGB: RGB texture, GL_RGB.
	VideoGLTextureTypeRGB
	// VideoGLTextureTypeRGBA: RGBA texture, GL_RGBA.
	VideoGLTextureTypeRGBA
	// VideoGLTextureTypeR: r texture, GL_RED_EXT.
	VideoGLTextureTypeR
	// VideoGLTextureTypeRg: RG texture, GL_RG_EXT.
	VideoGLTextureTypeRg
)

func marshalVideoGLTextureType(p uintptr) (interface{}, error) {
	return VideoGLTextureType(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoGLTextureType.
func (v VideoGLTextureType) String() string {
	switch v {
	case VideoGLTextureTypeLuminance:
		return "Luminance"
	case VideoGLTextureTypeLuminanceAlpha:
		return "LuminanceAlpha"
	case VideoGLTextureTypeRGB16:
		return "RGB16"
	case VideoGLTextureTypeRGB:
		return "RGB"
	case VideoGLTextureTypeRGBA:
		return "RGBA"
	case VideoGLTextureTypeR:
		return "R"
	case VideoGLTextureTypeRg:
		return "Rg"
	default:
		return fmt.Sprintf("VideoGLTextureType(%d)", v)
	}
}

type VideoGammaMode C.gint

const (
	// VideoGammaModeNone: disable gamma handling.
	VideoGammaModeNone VideoGammaMode = iota
	// VideoGammaModeRemap: convert between input and output gamma Different
	// gamma conversion modes.
	VideoGammaModeRemap
)

func marshalVideoGammaMode(p uintptr) (interface{}, error) {
	return VideoGammaMode(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoGammaMode.
func (v VideoGammaMode) String() string {
	switch v {
	case VideoGammaModeNone:
		return "None"
	case VideoGammaModeRemap:
		return "Remap"
	default:
		return fmt.Sprintf("VideoGammaMode(%d)", v)
	}
}

// VideoInterlaceMode: possible values of the VideoInterlaceMode describing the
// interlace mode of the stream.
type VideoInterlaceMode C.gint

const (
	// VideoInterlaceModeProgressive: all frames are progressive.
	VideoInterlaceModeProgressive VideoInterlaceMode = iota
	// VideoInterlaceModeInterleaved: 2 fields are interleaved in one video
	// frame. Extra buffer flags describe the field order.
	VideoInterlaceModeInterleaved
	// VideoInterlaceModeMixed frames contains both interlaced and progressive
	// video, the buffer flags describe the frame and fields.
	VideoInterlaceModeMixed
	// VideoInterlaceModeFields: 2 fields are stored in one buffer, use the
	// frame ID to get access to the required field. For multiview (the 'views'
	// property > 1) the fields of view N can be found at frame ID (N * 2) and
	// (N * 2) + 1. Each field has only half the amount of lines as noted in
	// the height property. This mode requires multiple GstVideoMeta metadata to
	// describe the fields.
	VideoInterlaceModeFields
	// VideoInterlaceModeAlternate: 1 field is stored in one buffer,
	// GST_VIDEO_BUFFER_FLAG_TF or GST_VIDEO_BUFFER_FLAG_BF indicates if the
	// buffer is carrying the top or bottom field, respectively. The top and
	// bottom buffers must alternate in the pipeline, with this mode (Since:
	// 1.16).
	VideoInterlaceModeAlternate
)

func marshalVideoInterlaceMode(p uintptr) (interface{}, error) {
	return VideoInterlaceMode(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoInterlaceMode.
func (v VideoInterlaceMode) String() string {
	switch v {
	case VideoInterlaceModeProgressive:
		return "Progressive"
	case VideoInterlaceModeInterleaved:
		return "Interleaved"
	case VideoInterlaceModeMixed:
		return "Mixed"
	case VideoInterlaceModeFields:
		return "Fields"
	case VideoInterlaceModeAlternate:
		return "Alternate"
	default:
		return fmt.Sprintf("VideoInterlaceMode(%d)", v)
	}
}

// VideoInterlaceModeFromString: convert mode to a VideoInterlaceMode.
//
// The function takes the following parameters:
//
//   - mode: mode.
//
// The function returns the following values:
//
//   - videoInterlaceMode of mode or T_VIDEO_INTERLACE_MODE_PROGRESSIVE when
//     mode is not a valid string representation for a VideoInterlaceMode.
func VideoInterlaceModeFromString(mode string) VideoInterlaceMode {
	var _arg1 *C.gchar                // out
	var _cret C.GstVideoInterlaceMode // in

	_arg1 = (*C.gchar)(unsafe.Pointer(C.CString(mode)))
	defer C.free(unsafe.Pointer(_arg1))

	_cret = C.gst_video_interlace_mode_from_string(_arg1)
	runtime.KeepAlive(mode)

	var _videoInterlaceMode VideoInterlaceMode // out

	_videoInterlaceMode = VideoInterlaceMode(_cret)

	return _videoInterlaceMode
}

// VideoInterlaceModeToString: convert mode to its string representation.
//
// The function takes the following parameters:
//
//   - mode: VideoInterlaceMode.
//
// The function returns the following values:
//
//   - utf8: mode as a string.
func VideoInterlaceModeToString(mode VideoInterlaceMode) string {
	var _arg1 C.GstVideoInterlaceMode // out
	var _cret *C.gchar                // in

	_arg1 = C.GstVideoInterlaceMode(mode)

	_cret = C.gst_video_interlace_mode_to_string(_arg1)
	runtime.KeepAlive(mode)

	var _utf8 string // out

	_utf8 = C.GoString((*C.gchar)(unsafe.Pointer(_cret)))

	return _utf8
}

// VideoMatrixMode: different color matrix conversion modes.
type VideoMatrixMode C.gint

const (
	// VideoMatrixModeFull: do conversion between color matrices.
	VideoMatrixModeFull VideoMatrixMode = iota
	// VideoMatrixModeInputOnly: use the input color matrix to convert to and
	// from R'G'B.
	VideoMatrixModeInputOnly
	// VideoMatrixModeOutputOnly: use the output color matrix to convert to and
	// from R'G'B.
	VideoMatrixModeOutputOnly
	// VideoMatrixModeNone: disable color matrix conversion.
	VideoMatrixModeNone
)

func marshalVideoMatrixMode(p uintptr) (interface{}, error) {
	return VideoMatrixMode(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoMatrixMode.
func (v VideoMatrixMode) String() string {
	switch v {
	case VideoMatrixModeFull:
		return "Full"
	case VideoMatrixModeInputOnly:
		return "InputOnly"
	case VideoMatrixModeOutputOnly:
		return "OutputOnly"
	case VideoMatrixModeNone:
		return "None"
	default:
		return fmt.Sprintf("VideoMatrixMode(%d)", v)
	}
}

// VideoMultiviewFramePacking represents the subset of VideoMultiviewMode values
// that can be applied to any video frame without needing extra metadata.
// It can be used by elements that provide a property to override the multiview
// interpretation of a video stream when the video doesn't contain any markers.
//
// This enum is used (for example) on playbin, to re-interpret a played video
// stream as a stereoscopic video. The individual enum values are equivalent to
// and have the same value as the matching VideoMultiviewMode.
type VideoMultiviewFramePacking C.gint

const (
	// VideoMultiviewFramePackingNone: special value indicating no frame packing
	// info.
	VideoMultiviewFramePackingNone VideoMultiviewFramePacking = -1
	// VideoMultiviewFramePackingMono: all frames are monoscopic.
	VideoMultiviewFramePackingMono VideoMultiviewFramePacking = 0
	// VideoMultiviewFramePackingLeft: all frames represent a left-eye view.
	VideoMultiviewFramePackingLeft VideoMultiviewFramePacking = 1
	// VideoMultiviewFramePackingRight: all frames represent a right-eye view.
	VideoMultiviewFramePackingRight VideoMultiviewFramePacking = 2
	// VideoMultiviewFramePackingSideBySide: left and right eye views are
	// provided in the left and right half of the frame respectively.
	VideoMultiviewFramePackingSideBySide VideoMultiviewFramePacking = 3
	// VideoMultiviewFramePackingSideBySideQuincunx: left and right eye views
	// are provided in the left and right half of the frame, but have been
	// sampled using quincunx method, with half-pixel offset between the 2
	// views.
	VideoMultiviewFramePackingSideBySideQuincunx VideoMultiviewFramePacking = 4
	// VideoMultiviewFramePackingColumnInterleaved: alternating vertical columns
	// of pixels represent the left and right eye view respectively.
	VideoMultiviewFramePackingColumnInterleaved VideoMultiviewFramePacking = 5
	// VideoMultiviewFramePackingRowInterleaved: alternating horizontal rows of
	// pixels represent the left and right eye view respectively.
	VideoMultiviewFramePackingRowInterleaved VideoMultiviewFramePacking = 6
	// VideoMultiviewFramePackingTopBottom: top half of the frame contains the
	// left eye, and the bottom half the right eye.
	VideoMultiviewFramePackingTopBottom VideoMultiviewFramePacking = 7
	// VideoMultiviewFramePackingCheckerboard pixels are arranged with
	// alternating pixels representing left and right eye views in a
	// checkerboard fashion.
	VideoMultiviewFramePackingCheckerboard VideoMultiviewFramePacking = 8
)

func marshalVideoMultiviewFramePacking(p uintptr) (interface{}, error) {
	return VideoMultiviewFramePacking(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoMultiviewFramePacking.
func (v VideoMultiviewFramePacking) String() string {
	switch v {
	case VideoMultiviewFramePackingNone:
		return "None"
	case VideoMultiviewFramePackingMono:
		return "Mono"
	case VideoMultiviewFramePackingLeft:
		return "Left"
	case VideoMultiviewFramePackingRight:
		return "Right"
	case VideoMultiviewFramePackingSideBySide:
		return "SideBySide"
	case VideoMultiviewFramePackingSideBySideQuincunx:
		return "SideBySideQuincunx"
	case VideoMultiviewFramePackingColumnInterleaved:
		return "ColumnInterleaved"
	case VideoMultiviewFramePackingRowInterleaved:
		return "RowInterleaved"
	case VideoMultiviewFramePackingTopBottom:
		return "TopBottom"
	case VideoMultiviewFramePackingCheckerboard:
		return "Checkerboard"
	default:
		return fmt.Sprintf("VideoMultiviewFramePacking(%d)", v)
	}
}

// VideoMultiviewMode: all possible stereoscopic 3D and multiview
// representations. In conjunction with VideoMultiviewFlags, describes how
// multiview content is being transported in the stream.
type VideoMultiviewMode C.gint

const (
	// VideoMultiviewModeNone: special value indicating no multiview
	// information. Used in GstVideoInfo and other places to indicate that no
	// specific multiview handling has been requested or provided. This value is
	// never carried on caps.
	VideoMultiviewModeNone VideoMultiviewMode = -1
	// VideoMultiviewModeMono: all frames are monoscopic.
	VideoMultiviewModeMono VideoMultiviewMode = 0
	// VideoMultiviewModeLeft: all frames represent a left-eye view.
	VideoMultiviewModeLeft VideoMultiviewMode = 1
	// VideoMultiviewModeRight: all frames represent a right-eye view.
	VideoMultiviewModeRight VideoMultiviewMode = 2
	// VideoMultiviewModeSideBySide: left and right eye views are provided in
	// the left and right half of the frame respectively.
	VideoMultiviewModeSideBySide VideoMultiviewMode = 3
	// VideoMultiviewModeSideBySideQuincunx: left and right eye views are
	// provided in the left and right half of the frame, but have been sampled
	// using quincunx method, with half-pixel offset between the 2 views.
	VideoMultiviewModeSideBySideQuincunx VideoMultiviewMode = 4
	// VideoMultiviewModeColumnInterleaved: alternating vertical columns of
	// pixels represent the left and right eye view respectively.
	VideoMultiviewModeColumnInterleaved VideoMultiviewMode = 5
	// VideoMultiviewModeRowInterleaved: alternating horizontal rows of pixels
	// represent the left and right eye view respectively.
	VideoMultiviewModeRowInterleaved VideoMultiviewMode = 6
	// VideoMultiviewModeTopBottom: top half of the frame contains the left eye,
	// and the bottom half the right eye.
	VideoMultiviewModeTopBottom VideoMultiviewMode = 7
	// VideoMultiviewModeCheckerboard pixels are arranged with alternating
	// pixels representing left and right eye views in a checkerboard fashion.
	VideoMultiviewModeCheckerboard VideoMultiviewMode = 8
	// VideoMultiviewModeFrameByFrame: left and right eye views are provided in
	// separate frames alternately.
	VideoMultiviewModeFrameByFrame VideoMultiviewMode = 32
	// VideoMultiviewModeMultiviewFrameByFrame: multiple independent views are
	// provided in separate frames in sequence. This method only applies to
	// raw video buffers at the moment. Specific view identification is via the
	// GstVideoMultiviewMeta and VideoMeta(s) on raw video buffers.
	VideoMultiviewModeMultiviewFrameByFrame VideoMultiviewMode = 33
	// VideoMultiviewModeSeparated: multiple views are provided as separate
	// Memory framebuffers attached to each Buffer, described by the
	// GstVideoMultiviewMeta and VideoMeta(s).
	VideoMultiviewModeSeparated VideoMultiviewMode = 34
)

func marshalVideoMultiviewMode(p uintptr) (interface{}, error) {
	return VideoMultiviewMode(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoMultiviewMode.
func (v VideoMultiviewMode) String() string {
	switch v {
	case VideoMultiviewModeNone:
		return "None"
	case VideoMultiviewModeMono:
		return "Mono"
	case VideoMultiviewModeLeft:
		return "Left"
	case VideoMultiviewModeRight:
		return "Right"
	case VideoMultiviewModeSideBySide:
		return "SideBySide"
	case VideoMultiviewModeSideBySideQuincunx:
		return "SideBySideQuincunx"
	case VideoMultiviewModeColumnInterleaved:
		return "ColumnInterleaved"
	case VideoMultiviewModeRowInterleaved:
		return "RowInterleaved"
	case VideoMultiviewModeTopBottom:
		return "TopBottom"
	case VideoMultiviewModeCheckerboard:
		return "Checkerboard"
	case VideoMultiviewModeFrameByFrame:
		return "FrameByFrame"
	case VideoMultiviewModeMultiviewFrameByFrame:
		return "MultiviewFrameByFrame"
	case VideoMultiviewModeSeparated:
		return "Separated"
	default:
		return fmt.Sprintf("VideoMultiviewMode(%d)", v)
	}
}

// The function takes the following parameters:
//
//   - capsMviewMode: multiview-mode field string from caps.
//
// The function returns the following values:
//
//   - videoMultiviewMode value
//
//     Given a string from a caps multiview-mode field, output the corresponding
//     VideoMultiviewMode or T_VIDEO_MULTIVIEW_MODE_NONE.
func VideoMultiviewModeFromCapsString(capsMviewMode string) VideoMultiviewMode {
	var _arg1 *C.gchar                // out
	var _cret C.GstVideoMultiviewMode // in

	_arg1 = (*C.gchar)(unsafe.Pointer(C.CString(capsMviewMode)))
	defer C.free(unsafe.Pointer(_arg1))

	_cret = C.gst_video_multiview_mode_from_caps_string(_arg1)
	runtime.KeepAlive(capsMviewMode)

	var _videoMultiviewMode VideoMultiviewMode // out

	_videoMultiviewMode = VideoMultiviewMode(_cret)

	return _videoMultiviewMode
}

// VideoMultiviewModeToCapsString: given a VideoMultiviewMode returns the
// multiview-mode caps string for insertion into a caps structure.
//
// The function takes the following parameters:
//
//   - mviewMode: VideoMultiviewMode value.
//
// The function returns the following values:
//
//   - utf8 (optional) caps string representation of the mode, or NULL if
//     invalid.
func VideoMultiviewModeToCapsString(mviewMode VideoMultiviewMode) string {
	var _arg1 C.GstVideoMultiviewMode // out
	var _cret *C.gchar                // in

	_arg1 = C.GstVideoMultiviewMode(mviewMode)

	_cret = C.gst_video_multiview_mode_to_caps_string(_arg1)
	runtime.KeepAlive(mviewMode)

	var _utf8 string // out

	if _cret != nil {
		_utf8 = C.GoString((*C.gchar)(unsafe.Pointer(_cret)))
	}

	return _utf8
}

// VideoOrientationMethod: different video orientation methods.
type VideoOrientationMethod C.gint

const (
	// VideoOrientationIdentity: identity (no rotation).
	VideoOrientationIdentity VideoOrientationMethod = iota
	// VideoOrientation90R: rotate clockwise 90 degrees.
	VideoOrientation90R
	// VideoOrientation180: rotate 180 degrees.
	VideoOrientation180
	// VideoOrientation90L: rotate counter-clockwise 90 degrees.
	VideoOrientation90L
	// VideoOrientationHoriz: flip horizontally.
	VideoOrientationHoriz
	// VideoOrientationVert: flip vertically.
	VideoOrientationVert
	// VideoOrientationUlLr: flip across upper left/lower right diagonal.
	VideoOrientationUlLr
	// VideoOrientationUrLl: flip across upper right/lower left diagonal.
	VideoOrientationUrLl
	// VideoOrientationAuto: select flip method based on image-orientation tag.
	VideoOrientationAuto
	// VideoOrientationCustom: current status depends on plugin internal setup.
	VideoOrientationCustom
)

func marshalVideoOrientationMethod(p uintptr) (interface{}, error) {
	return VideoOrientationMethod(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoOrientationMethod.
func (v VideoOrientationMethod) String() string {
	switch v {
	case VideoOrientationIdentity:
		return "Identity"
	case VideoOrientation90R:
		return "90R"
	case VideoOrientation180:
		return "180"
	case VideoOrientation90L:
		return "90L"
	case VideoOrientationHoriz:
		return "Horiz"
	case VideoOrientationVert:
		return "Vert"
	case VideoOrientationUlLr:
		return "UlLr"
	case VideoOrientationUrLl:
		return "UrLl"
	case VideoOrientationAuto:
		return "Auto"
	case VideoOrientationCustom:
		return "Custom"
	default:
		return fmt.Sprintf("VideoOrientationMethod(%d)", v)
	}
}

// VideoPrimariesMode: different primaries conversion modes.
type VideoPrimariesMode C.gint

const (
	// VideoPrimariesModeNone: disable conversion between primaries.
	VideoPrimariesModeNone VideoPrimariesMode = iota
	// VideoPrimariesModeMergeOnly: do conversion between primaries only when it
	// can be merged with color matrix conversion.
	VideoPrimariesModeMergeOnly
	// VideoPrimariesModeFast: fast conversion between primaries.
	VideoPrimariesModeFast
)

func marshalVideoPrimariesMode(p uintptr) (interface{}, error) {
	return VideoPrimariesMode(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoPrimariesMode.
func (v VideoPrimariesMode) String() string {
	switch v {
	case VideoPrimariesModeNone:
		return "None"
	case VideoPrimariesModeMergeOnly:
		return "MergeOnly"
	case VideoPrimariesModeFast:
		return "Fast"
	default:
		return fmt.Sprintf("VideoPrimariesMode(%d)", v)
	}
}

// VideoResamplerMethod: different subsampling and upsampling methods.
type VideoResamplerMethod C.gint

const (
	// VideoResamplerMethodNearest duplicates the samples when upsampling and
	// drops when downsampling.
	VideoResamplerMethodNearest VideoResamplerMethod = iota
	// VideoResamplerMethodLinear uses linear interpolation to reconstruct
	// missing samples and averaging to downsample.
	VideoResamplerMethodLinear
	// VideoResamplerMethodCubic uses cubic interpolation.
	VideoResamplerMethodCubic
	// VideoResamplerMethodSinc uses sinc interpolation.
	VideoResamplerMethodSinc
	// VideoResamplerMethodLanczos uses lanczos interpolation.
	VideoResamplerMethodLanczos
)

func marshalVideoResamplerMethod(p uintptr) (interface{}, error) {
	return VideoResamplerMethod(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoResamplerMethod.
func (v VideoResamplerMethod) String() string {
	switch v {
	case VideoResamplerMethodNearest:
		return "Nearest"
	case VideoResamplerMethodLinear:
		return "Linear"
	case VideoResamplerMethodCubic:
		return "Cubic"
	case VideoResamplerMethodSinc:
		return "Sinc"
	case VideoResamplerMethodLanczos:
		return "Lanczos"
	default:
		return fmt.Sprintf("VideoResamplerMethod(%d)", v)
	}
}

// VideoTileMode: enum value describing the available tiling modes.
type VideoTileMode C.gint

const (
	// VideoTileModeUnknown: unknown or unset tile mode.
	VideoTileModeUnknown VideoTileMode = 0
	// VideoTileModeZflipz2X2: every four adjacent blocks - two horizontally
	// and two vertically are grouped together and are located in memory in Z or
	// flipped Z order. In case of odd rows, the last row of blocks is arranged
	// in linear order.
	VideoTileModeZflipz2X2 VideoTileMode = 65536
	// VideoTileModeLinear tiles are in row order.
	VideoTileModeLinear VideoTileMode = 131072
)

func marshalVideoTileMode(p uintptr) (interface{}, error) {
	return VideoTileMode(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoTileMode.
func (v VideoTileMode) String() string {
	switch v {
	case VideoTileModeUnknown:
		return "Unknown"
	case VideoTileModeZflipz2X2:
		return "Zflipz2X2"
	case VideoTileModeLinear:
		return "Linear"
	default:
		return fmt.Sprintf("VideoTileMode(%d)", v)
	}
}

// VideoTileType: enum value describing the most common tiling types.
type VideoTileType C.gint

const (
	// VideoTileTypeIndexed tiles are indexed. Use gst_video_tile_get_index ()
	// to retrieve the tile at the requested coordinates.
	VideoTileTypeIndexed VideoTileType = iota
)

func marshalVideoTileType(p uintptr) (interface{}, error) {
	return VideoTileType(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoTileType.
func (v VideoTileType) String() string {
	switch v {
	case VideoTileTypeIndexed:
		return "Indexed"
	default:
		return fmt.Sprintf("VideoTileType(%d)", v)
	}
}

// VideoTransferFunction: video transfer function defines the formula for
// converting between non-linear RGB (R'G'B') and linear RGB.
type VideoTransferFunction C.gint

const (
	// VideoTransferUnknown: unknown transfer function.
	VideoTransferUnknown VideoTransferFunction = iota
	// VideoTransferGamma10: linear RGB, gamma 1.0 curve.
	VideoTransferGamma10
	// VideoTransferGamma18: gamma 1.8 curve.
	VideoTransferGamma18
	// VideoTransferGamma20: gamma 2.0 curve.
	VideoTransferGamma20
	// VideoTransferGamma22: gamma 2.2 curve.
	VideoTransferGamma22
	// VideoTransferBt709: gamma 2.2 curve with a linear segment in the lower
	// range, also ITU-R BT470M / ITU-R BT1700 625 PAL & SECAM / ITU-R BT1361.
	VideoTransferBt709
	// VideoTransferSmpte240M: gamma 2.2 curve with a linear segment in the
	// lower range.
	VideoTransferSmpte240M
	// VideoTransferSrgb: gamma 2.4 curve with a linear segment in the lower
	// range. IEC 61966-2-1 (sRGB or sYCC).
	VideoTransferSrgb
	// VideoTransferGamma28: gamma 2.8 curve, also ITU-R BT470BG.
	VideoTransferGamma28
	// VideoTransferLog100: logarithmic transfer characteristic 100:1 range.
	VideoTransferLog100
	// VideoTransferLog316: logarithmic transfer characteristic 316.22777:1
	// range (100 * sqrt(10) : 1).
	VideoTransferLog316
	// VideoTransferBt202012: gamma 2.2 curve with a linear segment in the lower
	// range. Used for BT.2020 with 12 bits per component. Since: 1.6.
	VideoTransferBt202012
	// VideoTransferAdobergb: gamma 2.19921875. Since: 1.8.
	VideoTransferAdobergb
	// VideoTransferBt202010: rec. ITU-R BT.2020-2 with 10 bits per component.
	// (functionally the same as the values GST_VIDEO_TRANSFER_BT709 and
	// GST_VIDEO_TRANSFER_BT601). Since: 1.18.
	VideoTransferBt202010
	// VideoTransferSmpte2084: SMPTE ST 2084 for 10, 12, 14, and 16-bit systems.
	// Known as perceptual quantization (PQ) Since: 1.18.
	VideoTransferSmpte2084
	// VideoTransferAribStdB67: association of Radio Industries and Businesses
	// (ARIB) STD-B67 and Rec. ITU-R BT.2100-1 hybrid loggamma (HLG) system
	// Since: 1.18.
	VideoTransferAribStdB67
	// VideoTransferBt601: also known as SMPTE170M / ITU-R BT1358 525 or 625 /
	// ITU-R BT1700 NTSC.
	VideoTransferBt601
)

func marshalVideoTransferFunction(p uintptr) (interface{}, error) {
	return VideoTransferFunction(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoTransferFunction.
func (v VideoTransferFunction) String() string {
	switch v {
	case VideoTransferUnknown:
		return "Unknown"
	case VideoTransferGamma10:
		return "Gamma10"
	case VideoTransferGamma18:
		return "Gamma18"
	case VideoTransferGamma20:
		return "Gamma20"
	case VideoTransferGamma22:
		return "Gamma22"
	case VideoTransferBt709:
		return "Bt709"
	case VideoTransferSmpte240M:
		return "Smpte240M"
	case VideoTransferSrgb:
		return "Srgb"
	case VideoTransferGamma28:
		return "Gamma28"
	case VideoTransferLog100:
		return "Log100"
	case VideoTransferLog316:
		return "Log316"
	case VideoTransferBt202012:
		return "Bt202012"
	case VideoTransferAdobergb:
		return "Adobergb"
	case VideoTransferBt202010:
		return "Bt202010"
	case VideoTransferSmpte2084:
		return "Smpte2084"
	case VideoTransferAribStdB67:
		return "AribStdB67"
	case VideoTransferBt601:
		return "Bt601"
	default:
		return fmt.Sprintf("VideoTransferFunction(%d)", v)
	}
}

// VideoTransferFunctionDecode: convert val to its gamma decoded value. This is
// the inverse operation of gst_video_color_transfer_encode().
//
// For a non-linear value L' in the range [0..1], conversion to the linear L is
// in general performed with a power function like:
//
//	L = L' ^ gamma
//
// Depending on func, different formulas might be applied. Some formulas encode
// a linear segment in the lower range.
//
// The function takes the following parameters:
//
//   - fn: VideoTransferFunction.
//   - val: value.
//
// The function returns the following values:
//
//   - gdouble: gamma decoded value of val.
func VideoTransferFunctionDecode(fn VideoTransferFunction, val float64) float64 {
	var _arg1 C.GstVideoTransferFunction // out
	var _arg2 C.gdouble                  // out
	var _cret C.gdouble                  // in

	_arg1 = C.GstVideoTransferFunction(fn)
	_arg2 = C.gdouble(val)

	_cret = C.gst_video_transfer_function_decode(_arg1, _arg2)
	runtime.KeepAlive(fn)
	runtime.KeepAlive(val)

	var _gdouble float64 // out

	_gdouble = float64(_cret)

	return _gdouble
}

// VideoTransferFunctionEncode: convert val to its gamma encoded value.
//
// For a linear value L in the range [0..1], conversion to the non-linear (gamma
// encoded) L' is in general performed with a power function like:
//
//	L' = L ^ (1 / gamma)
//
// Depending on func, different formulas might be applied. Some formulas encode
// a linear segment in the lower range.
//
// The function takes the following parameters:
//
//   - fn: VideoTransferFunction.
//   - val: value.
//
// The function returns the following values:
//
//   - gdouble: gamma encoded value of val.
func VideoTransferFunctionEncode(fn VideoTransferFunction, val float64) float64 {
	var _arg1 C.GstVideoTransferFunction // out
	var _arg2 C.gdouble                  // out
	var _cret C.gdouble                  // in

	_arg1 = C.GstVideoTransferFunction(fn)
	_arg2 = C.gdouble(val)

	_cret = C.gst_video_transfer_function_encode(_arg1, _arg2)
	runtime.KeepAlive(fn)
	runtime.KeepAlive(val)

	var _gdouble float64 // out

	_gdouble = float64(_cret)

	return _gdouble
}

// VideoTransferFunctionFromISO converts the value to the VideoTransferFunction
// The transfer characteristics (TransferCharacteristics) value is defined by
// "ISO/IEC 23001-8 Section 7.2 Table 3" and "ITU-T H.273 Table 3". "H.264 Table
// E-4" and "H.265 Table E.4" share the identical values.
//
// The function takes the following parameters:
//
//   - value: ITU-T H.273 transfer characteristics value.
//
// The function returns the following values:
//
//   - videoTransferFunction: matched VideoTransferFunction.
func VideoTransferFunctionFromISO(value uint) VideoTransferFunction {
	var _arg1 C.guint                    // out
	var _cret C.GstVideoTransferFunction // in

	_arg1 = C.guint(value)

	_cret = C.gst_video_transfer_function_from_iso(_arg1)
	runtime.KeepAlive(value)

	var _videoTransferFunction VideoTransferFunction // out

	_videoTransferFunction = VideoTransferFunction(_cret)

	return _videoTransferFunction
}

// VideoTransferFunctionIsEquivalent returns whether from_func and to_func are
// equivalent. There are cases (e.g. BT601, BT709, and BT2020_10) where several
// functions are functionally identical. In these cases, when doing conversion,
// we should consider them as equivalent. Also, BT2020_12 is the same as the
// aforementioned three for less than 12 bits per pixel.
//
// The function takes the following parameters:
//
//   - fromFunc to convert from.
//   - fromBpp bits per pixel to convert from.
//   - toFunc to convert into.
//   - toBpp bits per pixel to convert into.
//
// The function returns the following values:
//
//   - ok: TRUE if from_func and to_func can be considered equivalent.
func VideoTransferFunctionIsEquivalent(fromFunc VideoTransferFunction, fromBpp uint, toFunc VideoTransferFunction, toBpp uint) bool {
	var _arg1 C.GstVideoTransferFunction // out
	var _arg2 C.guint                    // out
	var _arg3 C.GstVideoTransferFunction // out
	var _arg4 C.guint                    // out
	var _cret C.gboolean                 // in

	_arg1 = C.GstVideoTransferFunction(fromFunc)
	_arg2 = C.guint(fromBpp)
	_arg3 = C.GstVideoTransferFunction(toFunc)
	_arg4 = C.guint(toBpp)

	_cret = C.gst_video_transfer_function_is_equivalent(_arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(fromFunc)
	runtime.KeepAlive(fromBpp)
	runtime.KeepAlive(toFunc)
	runtime.KeepAlive(toBpp)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// VideoTransferFunctionToISO converts VideoTransferFunction to the "transfer
// characteristics" (TransferCharacteristics) value defined by "ISO/IEC 23001-8
// Section 7.2 Table 3" and "ITU-T H.273 Table 3". "H.264 Table E-4" and "H.265
// Table E.4" share the identical values.
//
// The function takes the following parameters:
//
//   - fn: VideoTransferFunction.
//
// The function returns the following values:
//
//   - guint: value of ISO/IEC 23001-8 transfer characteristics.
func VideoTransferFunctionToISO(fn VideoTransferFunction) uint {
	var _arg1 C.GstVideoTransferFunction // out
	var _cret C.guint                    // in

	_arg1 = C.GstVideoTransferFunction(fn)

	_cret = C.gst_video_transfer_function_to_iso(_arg1)
	runtime.KeepAlive(fn)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// VideoVBIParserResult: return values for VideoVBIParser.
type VideoVBIParserResult C.gint

const (
	// VideoVbiParserResultDone: no line were provided, or no more Ancillary
	// data was found.
	VideoVbiParserResultDone VideoVBIParserResult = iota
	// VideoVbiParserResultOK was found.
	VideoVbiParserResultOK
	// VideoVbiParserResultError: error occurred.
	VideoVbiParserResultError
)

func marshalVideoVBIParserResult(p uintptr) (interface{}, error) {
	return VideoVBIParserResult(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for VideoVBIParserResult.
func (v VideoVBIParserResult) String() string {
	switch v {
	case VideoVbiParserResultDone:
		return "Done"
	case VideoVbiParserResultOK:
		return "OK"
	case VideoVbiParserResultError:
		return "Error"
	default:
		return fmt.Sprintf("VideoVBIParserResult(%d)", v)
	}
}

// NavigationModifierType flags to indicate the state of modifier keys and mouse
// buttons in events.
//
// Typical modifier keys are Shift, Control, Meta, Super, Hyper, Alt, Compose,
// Apple, CapsLock or ShiftLock.
type NavigationModifierType C.guint

const (
	NavigationModifierNone NavigationModifierType = 0b0
	// NavigationModifierShiftMask: shift key.
	NavigationModifierShiftMask NavigationModifierType = 0b1
	NavigationModifierLockMask  NavigationModifierType = 0b10
	// NavigationModifierControlMask: control key.
	NavigationModifierControlMask NavigationModifierType = 0b100
	// NavigationModifierMod1Mask: third modifier key.
	NavigationModifierMod1Mask NavigationModifierType = 0b1000
	// NavigationModifierMod2Mask: fourth modifier key.
	NavigationModifierMod2Mask NavigationModifierType = 0b10000
	// NavigationModifierMod3Mask: fifth modifier key.
	NavigationModifierMod3Mask NavigationModifierType = 0b100000
	// NavigationModifierMod4Mask: sixth modifier key.
	NavigationModifierMod4Mask NavigationModifierType = 0b1000000
	// NavigationModifierMod5Mask: seventh modifier key.
	NavigationModifierMod5Mask NavigationModifierType = 0b10000000
	// NavigationModifierButton1Mask: first mouse button (usually the left
	// button).
	NavigationModifierButton1Mask NavigationModifierType = 0b100000000
	// NavigationModifierButton2Mask: second mouse button (usually the right
	// button).
	NavigationModifierButton2Mask NavigationModifierType = 0b1000000000
	// NavigationModifierButton3Mask: third mouse button (usually the mouse
	// wheel button or middle button).
	NavigationModifierButton3Mask NavigationModifierType = 0b10000000000
	// NavigationModifierButton4Mask: fourth mouse button (typically the "Back"
	// button).
	NavigationModifierButton4Mask NavigationModifierType = 0b100000000000
	// NavigationModifierButton5Mask: fifth mouse button (typically the
	// "forward" button).
	NavigationModifierButton5Mask NavigationModifierType = 0b1000000000000
	// NavigationModifierSuperMask: super modifier.
	NavigationModifierSuperMask NavigationModifierType = 0b100000000000000000000000000
	// NavigationModifierHyperMask: hyper modifier.
	NavigationModifierHyperMask NavigationModifierType = 0b1000000000000000000000000000
	// NavigationModifierMetaMask: meta modifier.
	NavigationModifierMetaMask NavigationModifierType = 0b10000000000000000000000000000
	// NavigationModifierMask: mask covering all entries in ModifierType.
	NavigationModifierMask NavigationModifierType = 0b11100000000000001111111111111
)

func marshalNavigationModifierType(p uintptr) (interface{}, error) {
	return NavigationModifierType(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for NavigationModifierType.
func (n NavigationModifierType) String() string {
	if n == 0 {
		return "NavigationModifierType(0)"
	}

	var builder strings.Builder
	builder.Grow(256)

	for n != 0 {
		next := n & (n - 1)
		bit := n - next

		switch bit {
		case NavigationModifierNone:
			builder.WriteString("None|")
		case NavigationModifierShiftMask:
			builder.WriteString("ShiftMask|")
		case NavigationModifierLockMask:
			builder.WriteString("LockMask|")
		case NavigationModifierControlMask:
			builder.WriteString("ControlMask|")
		case NavigationModifierMod1Mask:
			builder.WriteString("Mod1Mask|")
		case NavigationModifierMod2Mask:
			builder.WriteString("Mod2Mask|")
		case NavigationModifierMod3Mask:
			builder.WriteString("Mod3Mask|")
		case NavigationModifierMod4Mask:
			builder.WriteString("Mod4Mask|")
		case NavigationModifierMod5Mask:
			builder.WriteString("Mod5Mask|")
		case NavigationModifierButton1Mask:
			builder.WriteString("Button1Mask|")
		case NavigationModifierButton2Mask:
			builder.WriteString("Button2Mask|")
		case NavigationModifierButton3Mask:
			builder.WriteString("Button3Mask|")
		case NavigationModifierButton4Mask:
			builder.WriteString("Button4Mask|")
		case NavigationModifierButton5Mask:
			builder.WriteString("Button5Mask|")
		case NavigationModifierSuperMask:
			builder.WriteString("SuperMask|")
		case NavigationModifierHyperMask:
			builder.WriteString("HyperMask|")
		case NavigationModifierMetaMask:
			builder.WriteString("MetaMask|")
		case NavigationModifierMask:
			builder.WriteString("Mask|")
		default:
			builder.WriteString(fmt.Sprintf("NavigationModifierType(0b%b)|", bit))
		}

		n = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if n contains other.
func (n NavigationModifierType) Has(other NavigationModifierType) bool {
	return (n & other) == other
}

// VideoBufferFlags: additional video buffer flags. These flags can potentially
// be used on any buffers carrying closed caption data, or video data - even
// encoded data.
//
// Note that these are only valid for Caps of type: video/... and caption/...
// They can conflict with other extended buffer flags.
type VideoBufferFlags C.guint

const (
	// VideoBufferFlagInterlaced: if the Buffer is interlaced. In mixed
	// interlace-mode, this flags specifies if the frame is interlaced or
	// progressive.
	VideoBufferFlagInterlaced VideoBufferFlags = 0b100000000000000000000
	// VideoBufferFlagTff: if the Buffer is interlaced, then the first field in
	// the video frame is the top field. If unset, the bottom field is first.
	VideoBufferFlagTff VideoBufferFlags = 0b1000000000000000000000
	// VideoBufferFlagRff: if the Buffer is interlaced, then the first field (as
	// defined by the GST_VIDEO_BUFFER_FLAG_TFF flag setting) is repeated.
	VideoBufferFlagRff VideoBufferFlags = 0b10000000000000000000000
	// VideoBufferFlagOnefield: if the Buffer is interlaced, then only the first
	// field (as defined by the GST_VIDEO_BUFFER_FLAG_TFF flag setting) is to be
	// displayed (Since: 1.16).
	VideoBufferFlagOnefield VideoBufferFlags = 0b100000000000000000000000
	// VideoBufferFlagMultipleView contains one or more specific views, such as
	// left or right eye view. This flags is set on any buffer that contains
	// non-mono content - even for streams that contain only a single viewpoint.
	// In mixed mono / non-mono streams, the absence of the flag marks mono
	// buffers.
	VideoBufferFlagMultipleView VideoBufferFlags = 0b1000000000000000000000000
	// VideoBufferFlagFirstInBundle: when conveying stereo/multiview content
	// with frame-by-frame methods, this flag marks the first buffer in a bundle
	// of frames that belong together.
	VideoBufferFlagFirstInBundle VideoBufferFlags = 0b10000000000000000000000000
	// VideoBufferFlagTopField: video frame has the top field only. This is
	// the same as GST_VIDEO_BUFFER_FLAG_TFF | GST_VIDEO_BUFFER_FLAG_ONEFIELD
	// (Since: 1.16). Use GST_VIDEO_BUFFER_IS_TOP_FIELD() to check for this
	// flag.
	VideoBufferFlagTopField VideoBufferFlags = 0b101000000000000000000000
	// VideoBufferFlagBottomField: video frame has the bottom field only. This
	// is the same as GST_VIDEO_BUFFER_FLAG_ONEFIELD (GST_VIDEO_BUFFER_FLAG_TFF
	// flag unset) (Since: 1.16). Use GST_VIDEO_BUFFER_IS_BOTTOM_FIELD() to
	// check for this flag.
	VideoBufferFlagBottomField VideoBufferFlags = 0b100000000000000000000000
	// VideoBufferFlagMarker contains the end of a video field or frame boundary
	// such as the last subframe or packet (Since: 1.18).
	VideoBufferFlagMarker VideoBufferFlags = 0b1000000000
	// VideoBufferFlagLast: offset to define more flags.
	VideoBufferFlagLast VideoBufferFlags = 0b10000000000000000000000000000
)

func marshalVideoBufferFlags(p uintptr) (interface{}, error) {
	return VideoBufferFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for VideoBufferFlags.
func (v VideoBufferFlags) String() string {
	if v == 0 {
		return "VideoBufferFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(237)

	for v != 0 {
		next := v & (v - 1)
		bit := v - next

		switch bit {
		case VideoBufferFlagInterlaced:
			builder.WriteString("Interlaced|")
		case VideoBufferFlagTff:
			builder.WriteString("Tff|")
		case VideoBufferFlagRff:
			builder.WriteString("Rff|")
		case VideoBufferFlagOnefield:
			builder.WriteString("Onefield|")
		case VideoBufferFlagMultipleView:
			builder.WriteString("MultipleView|")
		case VideoBufferFlagFirstInBundle:
			builder.WriteString("FirstInBundle|")
		case VideoBufferFlagTopField:
			builder.WriteString("TopField|")
		case VideoBufferFlagMarker:
			builder.WriteString("Marker|")
		case VideoBufferFlagLast:
			builder.WriteString("Last|")
		default:
			builder.WriteString(fmt.Sprintf("VideoBufferFlags(0b%b)|", bit))
		}

		v = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if v contains other.
func (v VideoBufferFlags) Has(other VideoBufferFlags) bool {
	return (v & other) == other
}

// VideoChromaFlags: extra flags that influence the result from
// gst_video_chroma_resample_new().
type VideoChromaFlags C.guint

const (
	// VideoChromaFlagNone: no flags.
	VideoChromaFlagNone VideoChromaFlags = 0b0
	// VideoChromaFlagInterlaced: input is interlaced.
	VideoChromaFlagInterlaced VideoChromaFlags = 0b1
)

func marshalVideoChromaFlags(p uintptr) (interface{}, error) {
	return VideoChromaFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for VideoChromaFlags.
func (v VideoChromaFlags) String() string {
	if v == 0 {
		return "VideoChromaFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(45)

	for v != 0 {
		next := v & (v - 1)
		bit := v - next

		switch bit {
		case VideoChromaFlagNone:
			builder.WriteString("None|")
		case VideoChromaFlagInterlaced:
			builder.WriteString("Interlaced|")
		default:
			builder.WriteString(fmt.Sprintf("VideoChromaFlags(0b%b)|", bit))
		}

		v = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if v contains other.
func (v VideoChromaFlags) Has(other VideoChromaFlags) bool {
	return (v & other) == other
}

// VideoChromaSite various Chroma sitings.
type VideoChromaSite C.guint

const (
	// VideoChromaSiteUnknown: unknown cositing.
	VideoChromaSiteUnknown VideoChromaSite = 0b0
	// VideoChromaSiteNone: no cositing.
	VideoChromaSiteNone VideoChromaSite = 0b1
	// VideoChromaSiteHCosited: chroma is horizontally cosited.
	VideoChromaSiteHCosited VideoChromaSite = 0b10
	// VideoChromaSiteVCosited: chroma is vertically cosited.
	VideoChromaSiteVCosited VideoChromaSite = 0b100
	// VideoChromaSiteAltLine: choma samples are sited on alternate lines.
	VideoChromaSiteAltLine VideoChromaSite = 0b1000
	// VideoChromaSiteCosited: chroma samples cosited with luma samples.
	VideoChromaSiteCosited VideoChromaSite = 0b110
	// VideoChromaSiteJPEG: jpeg style cositing, also for mpeg1 and mjpeg.
	VideoChromaSiteJPEG VideoChromaSite = 0b1
	// VideoChromaSiteMpeg2: mpeg2 style cositing.
	VideoChromaSiteMpeg2 VideoChromaSite = 0b10
	// VideoChromaSiteDv: DV style cositing.
	VideoChromaSiteDv VideoChromaSite = 0b1110
)

func marshalVideoChromaSite(p uintptr) (interface{}, error) {
	return VideoChromaSite(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for VideoChromaSite.
func (v VideoChromaSite) String() string {
	if v == 0 {
		return "VideoChromaSite(0)"
	}

	var builder strings.Builder
	builder.Grow(195)

	for v != 0 {
		next := v & (v - 1)
		bit := v - next

		switch bit {
		case VideoChromaSiteUnknown:
			builder.WriteString("Unknown|")
		case VideoChromaSiteNone:
			builder.WriteString("None|")
		case VideoChromaSiteHCosited:
			builder.WriteString("HCosited|")
		case VideoChromaSiteVCosited:
			builder.WriteString("VCosited|")
		case VideoChromaSiteAltLine:
			builder.WriteString("AltLine|")
		case VideoChromaSiteCosited:
			builder.WriteString("Cosited|")
		case VideoChromaSiteDv:
			builder.WriteString("Dv|")
		default:
			builder.WriteString(fmt.Sprintf("VideoChromaSite(0b%b)|", bit))
		}

		v = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if v contains other.
func (v VideoChromaSite) Has(other VideoChromaSite) bool {
	return (v & other) == other
}

// VideoChromaSiteFromString: convert s to a VideoChromaSite.
//
// The function takes the following parameters:
//
//   - s: chromasite string.
//
// The function returns the following values:
//
//   - videoChromaSite or GST_VIDEO_CHROMA_SITE_UNKNOWN when s does not contain
//     a valid chroma-site description.
func VideoChromaSiteFromString(s string) VideoChromaSite {
	var _arg1 *C.gchar             // out
	var _cret C.GstVideoChromaSite // in

	_arg1 = (*C.gchar)(unsafe.Pointer(C.CString(s)))
	defer C.free(unsafe.Pointer(_arg1))

	_cret = C.gst_video_chroma_site_from_string(_arg1)
	runtime.KeepAlive(s)

	var _videoChromaSite VideoChromaSite // out

	_videoChromaSite = VideoChromaSite(_cret)

	return _videoChromaSite
}

// VideoChromaSiteToString converts site to its string representation.
//
// The function takes the following parameters:
//
//   - site: VideoChromaSite.
//
// The function returns the following values:
//
//   - utf8 (optional): string representation of site or NULL if site contains
//     undefined value or is equal to GST_VIDEO_CHROMA_SITE_UNKNOWN.
func VideoChromaSiteToString(site VideoChromaSite) string {
	var _arg1 C.GstVideoChromaSite // out
	var _cret *C.gchar             // in

	_arg1 = C.GstVideoChromaSite(site)

	_cret = C.gst_video_chroma_site_to_string(_arg1)
	runtime.KeepAlive(site)

	var _utf8 string // out

	if _cret != nil {
		_utf8 = C.GoString((*C.gchar)(unsafe.Pointer(_cret)))
		defer C.free(unsafe.Pointer(_cret))
	}

	return _utf8
}

// VideoCodecFrameFlags flags for VideoCodecFrame.
type VideoCodecFrameFlags C.guint

const (
	// VideoCodecFrameFlagDecodeOnly is the frame only meant to be decoded.
	VideoCodecFrameFlagDecodeOnly VideoCodecFrameFlags = 0b1
	// VideoCodecFrameFlagSyncPoint is the frame a synchronization point
	// (keyframe).
	VideoCodecFrameFlagSyncPoint VideoCodecFrameFlags = 0b10
	// VideoCodecFrameFlagForceKeyframe: should the output frame be made a
	// keyframe.
	VideoCodecFrameFlagForceKeyframe VideoCodecFrameFlags = 0b100
	// VideoCodecFrameFlagForceKeyframeHeaders: should the encoder output stream
	// headers.
	VideoCodecFrameFlagForceKeyframeHeaders VideoCodecFrameFlags = 0b1000
	// VideoCodecFrameFlagCorrupted: buffer data is corrupted.
	VideoCodecFrameFlagCorrupted VideoCodecFrameFlags = 0b10000
)

func marshalVideoCodecFrameFlags(p uintptr) (interface{}, error) {
	return VideoCodecFrameFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for VideoCodecFrameFlags.
func (v VideoCodecFrameFlags) String() string {
	if v == 0 {
		return "VideoCodecFrameFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(160)

	for v != 0 {
		next := v & (v - 1)
		bit := v - next

		switch bit {
		case VideoCodecFrameFlagDecodeOnly:
			builder.WriteString("DecodeOnly|")
		case VideoCodecFrameFlagSyncPoint:
			builder.WriteString("SyncPoint|")
		case VideoCodecFrameFlagForceKeyframe:
			builder.WriteString("ForceKeyframe|")
		case VideoCodecFrameFlagForceKeyframeHeaders:
			builder.WriteString("ForceKeyframeHeaders|")
		case VideoCodecFrameFlagCorrupted:
			builder.WriteString("Corrupted|")
		default:
			builder.WriteString(fmt.Sprintf("VideoCodecFrameFlags(0b%b)|", bit))
		}

		v = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if v contains other.
func (v VideoCodecFrameFlags) Has(other VideoCodecFrameFlags) bool {
	return (v & other) == other
}

// VideoDecoderRequestSyncPointFlags flags to be used in combination with
// gst_video_decoder_request_sync_point(). See the function documentation for
// more details.
type VideoDecoderRequestSyncPointFlags C.guint

const (
	// VideoDecoderRequestSyncPointDiscardInput: discard all following input
	// until the next sync point.
	VideoDecoderRequestSyncPointDiscardInput VideoDecoderRequestSyncPointFlags = 0b1
	// VideoDecoderRequestSyncPointCorruptOutput: discard all following output
	// until the next sync point.
	VideoDecoderRequestSyncPointCorruptOutput VideoDecoderRequestSyncPointFlags = 0b10
)

func marshalVideoDecoderRequestSyncPointFlags(p uintptr) (interface{}, error) {
	return VideoDecoderRequestSyncPointFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for VideoDecoderRequestSyncPointFlags.
func (v VideoDecoderRequestSyncPointFlags) String() string {
	if v == 0 {
		return "VideoDecoderRequestSyncPointFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(82)

	for v != 0 {
		next := v & (v - 1)
		bit := v - next

		switch bit {
		case VideoDecoderRequestSyncPointDiscardInput:
			builder.WriteString("DiscardInput|")
		case VideoDecoderRequestSyncPointCorruptOutput:
			builder.WriteString("CorruptOutput|")
		default:
			builder.WriteString(fmt.Sprintf("VideoDecoderRequestSyncPointFlags(0b%b)|", bit))
		}

		v = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if v contains other.
func (v VideoDecoderRequestSyncPointFlags) Has(other VideoDecoderRequestSyncPointFlags) bool {
	return (v & other) == other
}

// VideoDitherFlags: extra flags that influence the result from
// gst_video_chroma_resample_new().
type VideoDitherFlags C.guint

const (
	// VideoDitherFlagNone: no flags.
	VideoDitherFlagNone VideoDitherFlags = 0b0
	// VideoDitherFlagInterlaced: input is interlaced.
	VideoDitherFlagInterlaced VideoDitherFlags = 0b1
	// VideoDitherFlagQuantize: quantize values in addition to adding dither.
	VideoDitherFlagQuantize VideoDitherFlags = 0b10
)

func marshalVideoDitherFlags(p uintptr) (interface{}, error) {
	return VideoDitherFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for VideoDitherFlags.
func (v VideoDitherFlags) String() string {
	if v == 0 {
		return "VideoDitherFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(69)

	for v != 0 {
		next := v & (v - 1)
		bit := v - next

		switch bit {
		case VideoDitherFlagNone:
			builder.WriteString("None|")
		case VideoDitherFlagInterlaced:
			builder.WriteString("Interlaced|")
		case VideoDitherFlagQuantize:
			builder.WriteString("Quantize|")
		default:
			builder.WriteString(fmt.Sprintf("VideoDitherFlags(0b%b)|", bit))
		}

		v = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if v contains other.
func (v VideoDitherFlags) Has(other VideoDitherFlags) bool {
	return (v & other) == other
}

// VideoFlags: extra video flags.
type VideoFlags C.guint

const (
	// VideoFlagNone: no flags.
	VideoFlagNone VideoFlags = 0b0
	// VideoFlagVariableFPS: variable fps is selected, fps_n and fps_d denote
	// the maximum fps of the video.
	VideoFlagVariableFPS VideoFlags = 0b1
	// VideoFlagPremultipliedAlpha: each color has been scaled by the alpha
	// value.
	VideoFlagPremultipliedAlpha VideoFlags = 0b10
)

func marshalVideoFlags(p uintptr) (interface{}, error) {
	return VideoFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for VideoFlags.
func (v VideoFlags) String() string {
	if v == 0 {
		return "VideoFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(62)

	for v != 0 {
		next := v & (v - 1)
		bit := v - next

		switch bit {
		case VideoFlagNone:
			builder.WriteString("None|")
		case VideoFlagVariableFPS:
			builder.WriteString("VariableFPS|")
		case VideoFlagPremultipliedAlpha:
			builder.WriteString("PremultipliedAlpha|")
		default:
			builder.WriteString(fmt.Sprintf("VideoFlags(0b%b)|", bit))
		}

		v = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if v contains other.
func (v VideoFlags) Has(other VideoFlags) bool {
	return (v & other) == other
}

// VideoFormatFlags: different video flags that a format info can have.
type VideoFormatFlags C.guint

const (
	// VideoFormatFlagYuv: video format is YUV, components are numbered 0=Y,
	// 1=U, 2=V.
	VideoFormatFlagYuv VideoFormatFlags = 0b1
	// VideoFormatFlagRGB: video format is RGB, components are numbered 0=R,
	// 1=G, 2=B.
	VideoFormatFlagRGB VideoFormatFlags = 0b10
	// VideoFormatFlagGray: video is gray, there is one gray component with
	// index 0.
	VideoFormatFlagGray VideoFormatFlags = 0b100
	// VideoFormatFlagAlpha: video format has an alpha components with the
	// number 3.
	VideoFormatFlagAlpha VideoFormatFlags = 0b1000
	// VideoFormatFlagLE: video format has data stored in little endianness.
	VideoFormatFlagLE VideoFormatFlags = 0b10000
	// VideoFormatFlagPalette: video format has a palette. The palette is stored
	// in the second plane and indexes are stored in the first plane.
	VideoFormatFlagPalette VideoFormatFlags = 0b100000
	// VideoFormatFlagComplex: video format has a complex layout that can't be
	// described with the usual information in the VideoFormatInfo.
	VideoFormatFlagComplex VideoFormatFlags = 0b1000000
	// VideoFormatFlagUnpack: this format can be used in a VideoFormatUnpack and
	// VideoFormatPack function.
	VideoFormatFlagUnpack VideoFormatFlags = 0b10000000
	// VideoFormatFlagTiled: format is tiled, there is tiling information in the
	// last plane.
	VideoFormatFlagTiled VideoFormatFlags = 0b100000000
	// VideoFormatFlagSubtiles: tile size varies per plane according to the
	// subsampling.
	VideoFormatFlagSubtiles VideoFormatFlags = 0b1000000000
)

func marshalVideoFormatFlags(p uintptr) (interface{}, error) {
	return VideoFormatFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for VideoFormatFlags.
func (v VideoFormatFlags) String() string {
	if v == 0 {
		return "VideoFormatFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(209)

	for v != 0 {
		next := v & (v - 1)
		bit := v - next

		switch bit {
		case VideoFormatFlagYuv:
			builder.WriteString("Yuv|")
		case VideoFormatFlagRGB:
			builder.WriteString("RGB|")
		case VideoFormatFlagGray:
			builder.WriteString("Gray|")
		case VideoFormatFlagAlpha:
			builder.WriteString("Alpha|")
		case VideoFormatFlagLE:
			builder.WriteString("LE|")
		case VideoFormatFlagPalette:
			builder.WriteString("Palette|")
		case VideoFormatFlagComplex:
			builder.WriteString("Complex|")
		case VideoFormatFlagUnpack:
			builder.WriteString("Unpack|")
		case VideoFormatFlagTiled:
			builder.WriteString("Tiled|")
		case VideoFormatFlagSubtiles:
			builder.WriteString("Subtiles|")
		default:
			builder.WriteString(fmt.Sprintf("VideoFormatFlags(0b%b)|", bit))
		}

		v = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if v contains other.
func (v VideoFormatFlags) Has(other VideoFormatFlags) bool {
	return (v & other) == other
}

// VideoFrameFlags: extra video frame flags.
type VideoFrameFlags C.guint

const (
	// VideoFrameFlagNone: no flags.
	VideoFrameFlagNone VideoFrameFlags = 0b0
	// VideoFrameFlagInterlaced: video frame is interlaced. In mixed
	// interlace-mode, this flag specifies if the frame is interlaced or
	// progressive.
	VideoFrameFlagInterlaced VideoFrameFlags = 0b1
	// VideoFrameFlagTff: video frame has the top field first.
	VideoFrameFlagTff VideoFrameFlags = 0b10
	// VideoFrameFlagRff: video frame has the repeat flag.
	VideoFrameFlagRff VideoFrameFlags = 0b100
	// VideoFrameFlagOnefield: video frame has one field.
	VideoFrameFlagOnefield VideoFrameFlags = 0b1000
	// VideoFrameFlagMultipleView: video contains one or more non-mono views.
	VideoFrameFlagMultipleView VideoFrameFlags = 0b10000
	// VideoFrameFlagFirstInBundle: video frame is the first in a set of
	// corresponding views provided as sequential frames.
	VideoFrameFlagFirstInBundle VideoFrameFlags = 0b100000
	// VideoFrameFlagTopField: video frame has the top field only. This is the
	// same as GST_VIDEO_FRAME_FLAG_TFF | GST_VIDEO_FRAME_FLAG_ONEFIELD (Since:
	// 1.16).
	VideoFrameFlagTopField VideoFrameFlags = 0b1010
	// VideoFrameFlagBottomField: video frame has the bottom field only. This is
	// the same as GST_VIDEO_FRAME_FLAG_ONEFIELD (GST_VIDEO_FRAME_FLAG_TFF flag
	// unset) (Since: 1.16).
	VideoFrameFlagBottomField VideoFrameFlags = 0b1000
)

func marshalVideoFrameFlags(p uintptr) (interface{}, error) {
	return VideoFrameFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for VideoFrameFlags.
func (v VideoFrameFlags) String() string {
	if v == 0 {
		return "VideoFrameFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(206)

	for v != 0 {
		next := v & (v - 1)
		bit := v - next

		switch bit {
		case VideoFrameFlagNone:
			builder.WriteString("None|")
		case VideoFrameFlagInterlaced:
			builder.WriteString("Interlaced|")
		case VideoFrameFlagTff:
			builder.WriteString("Tff|")
		case VideoFrameFlagRff:
			builder.WriteString("Rff|")
		case VideoFrameFlagOnefield:
			builder.WriteString("Onefield|")
		case VideoFrameFlagMultipleView:
			builder.WriteString("MultipleView|")
		case VideoFrameFlagFirstInBundle:
			builder.WriteString("FirstInBundle|")
		case VideoFrameFlagTopField:
			builder.WriteString("TopField|")
		default:
			builder.WriteString(fmt.Sprintf("VideoFrameFlags(0b%b)|", bit))
		}

		v = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if v contains other.
func (v VideoFrameFlags) Has(other VideoFrameFlags) bool {
	return (v & other) == other
}

// VideoFrameMapFlags: additional mapping flags for gst_video_frame_map().
type VideoFrameMapFlags C.guint

const (
	// VideoFrameMapFlagNoRef: don't take another reference of the buffer
	// and store it in the GstVideoFrame. This makes sure that the buffer
	// stays writable while the frame is mapped, but requires that the buffer
	// reference stays valid until the frame is unmapped again.
	VideoFrameMapFlagNoRef VideoFrameMapFlags = 0b10000000000000000
	// VideoFrameMapFlagLast: offset to define more flags.
	VideoFrameMapFlagLast VideoFrameMapFlags = 0b1000000000000000000000000
)

func marshalVideoFrameMapFlags(p uintptr) (interface{}, error) {
	return VideoFrameMapFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for VideoFrameMapFlags.
func (v VideoFrameMapFlags) String() string {
	if v == 0 {
		return "VideoFrameMapFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(44)

	for v != 0 {
		next := v & (v - 1)
		bit := v - next

		switch bit {
		case VideoFrameMapFlagNoRef:
			builder.WriteString("NoRef|")
		case VideoFrameMapFlagLast:
			builder.WriteString("Last|")
		default:
			builder.WriteString(fmt.Sprintf("VideoFrameMapFlags(0b%b)|", bit))
		}

		v = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if v contains other.
func (v VideoFrameMapFlags) Has(other VideoFrameMapFlags) bool {
	return (v & other) == other
}

// VideoMultiviewFlags are used to indicate extra properties of a
// stereo/multiview stream beyond the frame layout and buffer mapping that is
// conveyed in the VideoMultiviewMode.
type VideoMultiviewFlags C.guint

const (
	// VideoMultiviewFlagsNone: no flags.
	VideoMultiviewFlagsNone VideoMultiviewFlags = 0b0
	// VideoMultiviewFlagsRightViewFirst: for stereo streams, the normal
	// arrangement of left and right views is reversed.
	VideoMultiviewFlagsRightViewFirst VideoMultiviewFlags = 0b1
	// VideoMultiviewFlagsLeftFlipped: left view is vertically mirrored.
	VideoMultiviewFlagsLeftFlipped VideoMultiviewFlags = 0b10
	// VideoMultiviewFlagsLeftFlopped: left view is horizontally mirrored.
	VideoMultiviewFlagsLeftFlopped VideoMultiviewFlags = 0b100
	// VideoMultiviewFlagsRightFlipped: right view is vertically mirrored.
	VideoMultiviewFlagsRightFlipped VideoMultiviewFlags = 0b1000
	// VideoMultiviewFlagsRightFlopped: right view is horizontally mirrored.
	VideoMultiviewFlagsRightFlopped VideoMultiviewFlags = 0b10000
	// VideoMultiviewFlagsHalfAspect: for frame-packed multiview modes,
	// indicates that the individual views have been encoded with half
	// the true width or height and should be scaled back up for display.
	// This flag is used for overriding input layout interpretation by adjusting
	// pixel-aspect-ratio. For side-by-side, column interleaved or checkerboard
	// packings, the pixel width will be doubled. For row interleaved and
	// top-bottom encodings, pixel height will be doubled.
	VideoMultiviewFlagsHalfAspect VideoMultiviewFlags = 0b100000000000000
	// VideoMultiviewFlagsMixedMono: video stream contains both mono and
	// multiview portions, signalled on each buffer by the absence or presence
	// of the GST_VIDEO_BUFFER_FLAG_MULTIPLE_VIEW buffer flag.
	VideoMultiviewFlagsMixedMono VideoMultiviewFlags = 0b1000000000000000
)

func marshalVideoMultiviewFlags(p uintptr) (interface{}, error) {
	return VideoMultiviewFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for VideoMultiviewFlags.
func (v VideoMultiviewFlags) String() string {
	if v == 0 {
		return "VideoMultiviewFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(242)

	for v != 0 {
		next := v & (v - 1)
		bit := v - next

		switch bit {
		case VideoMultiviewFlagsNone:
			builder.WriteString("None|")
		case VideoMultiviewFlagsRightViewFirst:
			builder.WriteString("RightViewFirst|")
		case VideoMultiviewFlagsLeftFlipped:
			builder.WriteString("LeftFlipped|")
		case VideoMultiviewFlagsLeftFlopped:
			builder.WriteString("LeftFlopped|")
		case VideoMultiviewFlagsRightFlipped:
			builder.WriteString("RightFlipped|")
		case VideoMultiviewFlagsRightFlopped:
			builder.WriteString("RightFlopped|")
		case VideoMultiviewFlagsHalfAspect:
			builder.WriteString("HalfAspect|")
		case VideoMultiviewFlagsMixedMono:
			builder.WriteString("MixedMono|")
		default:
			builder.WriteString(fmt.Sprintf("VideoMultiviewFlags(0b%b)|", bit))
		}

		v = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if v contains other.
func (v VideoMultiviewFlags) Has(other VideoMultiviewFlags) bool {
	return (v & other) == other
}

// VideoOverlayFormatFlags: overlay format flags.
type VideoOverlayFormatFlags C.guint

const (
	// VideoOverlayFormatFlagNone: no flags.
	VideoOverlayFormatFlagNone VideoOverlayFormatFlags = 0b0
	// VideoOverlayFormatFlagPremultipliedAlpha: RGB are premultiplied by A/255.
	VideoOverlayFormatFlagPremultipliedAlpha VideoOverlayFormatFlags = 0b1
	// VideoOverlayFormatFlagGlobalAlpha: global-alpha value != 1 is set.
	VideoOverlayFormatFlagGlobalAlpha VideoOverlayFormatFlags = 0b10
)

func marshalVideoOverlayFormatFlags(p uintptr) (interface{}, error) {
	return VideoOverlayFormatFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for VideoOverlayFormatFlags.
func (v VideoOverlayFormatFlags) String() string {
	if v == 0 {
		return "VideoOverlayFormatFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(101)

	for v != 0 {
		next := v & (v - 1)
		bit := v - next

		switch bit {
		case VideoOverlayFormatFlagNone:
			builder.WriteString("None|")
		case VideoOverlayFormatFlagPremultipliedAlpha:
			builder.WriteString("PremultipliedAlpha|")
		case VideoOverlayFormatFlagGlobalAlpha:
			builder.WriteString("GlobalAlpha|")
		default:
			builder.WriteString(fmt.Sprintf("VideoOverlayFormatFlags(0b%b)|", bit))
		}

		v = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if v contains other.
func (v VideoOverlayFormatFlags) Has(other VideoOverlayFormatFlags) bool {
	return (v & other) == other
}

// VideoPackFlags: different flags that can be used when packing and unpacking.
type VideoPackFlags C.guint

const (
	// VideoPackFlagNone: no flag.
	VideoPackFlagNone VideoPackFlags = 0b0
	// VideoPackFlagTruncateRange: when the source has a smaller depth than
	// the target format, set the least significant bits of the target to 0.
	// This is likely slightly faster but less accurate. When this flag is not
	// specified, the most significant bits of the source are duplicated in the
	// least significant bits of the destination.
	VideoPackFlagTruncateRange VideoPackFlags = 0b1
	// VideoPackFlagInterlaced: source is interlaced. The unpacked format
	// will be interlaced as well with each line containing information from
	// alternating fields. (Since: 1.2).
	VideoPackFlagInterlaced VideoPackFlags = 0b10
)

func marshalVideoPackFlags(p uintptr) (interface{}, error) {
	return VideoPackFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for VideoPackFlags.
func (v VideoPackFlags) String() string {
	if v == 0 {
		return "VideoPackFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(68)

	for v != 0 {
		next := v & (v - 1)
		bit := v - next

		switch bit {
		case VideoPackFlagNone:
			builder.WriteString("None|")
		case VideoPackFlagTruncateRange:
			builder.WriteString("TruncateRange|")
		case VideoPackFlagInterlaced:
			builder.WriteString("Interlaced|")
		default:
			builder.WriteString(fmt.Sprintf("VideoPackFlags(0b%b)|", bit))
		}

		v = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if v contains other.
func (v VideoPackFlags) Has(other VideoPackFlags) bool {
	return (v & other) == other
}

// VideoResamplerFlags: different resampler flags.
type VideoResamplerFlags C.guint

const (
	// VideoResamplerFlagNone: no flags.
	VideoResamplerFlagNone VideoResamplerFlags = 0b0
	// VideoResamplerFlagHalfTaps: when no taps are given, half the number of
	// calculated taps. This can be used when making scalers for the different
	// fields of an interlaced picture. Since: 1.10.
	VideoResamplerFlagHalfTaps VideoResamplerFlags = 0b1
)

func marshalVideoResamplerFlags(p uintptr) (interface{}, error) {
	return VideoResamplerFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for VideoResamplerFlags.
func (v VideoResamplerFlags) String() string {
	if v == 0 {
		return "VideoResamplerFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(49)

	for v != 0 {
		next := v & (v - 1)
		bit := v - next

		switch bit {
		case VideoResamplerFlagNone:
			builder.WriteString("None|")
		case VideoResamplerFlagHalfTaps:
			builder.WriteString("HalfTaps|")
		default:
			builder.WriteString(fmt.Sprintf("VideoResamplerFlags(0b%b)|", bit))
		}

		v = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if v contains other.
func (v VideoResamplerFlags) Has(other VideoResamplerFlags) bool {
	return (v & other) == other
}

// VideoScalerFlags: different scale flags.
type VideoScalerFlags C.guint

const (
	// VideoScalerFlagNone: no flags.
	VideoScalerFlagNone VideoScalerFlags = 0b0
	// VideoScalerFlagInterlaced: set up a scaler for interlaced content.
	VideoScalerFlagInterlaced VideoScalerFlags = 0b1
)

func marshalVideoScalerFlags(p uintptr) (interface{}, error) {
	return VideoScalerFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for VideoScalerFlags.
func (v VideoScalerFlags) String() string {
	if v == 0 {
		return "VideoScalerFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(45)

	for v != 0 {
		next := v & (v - 1)
		bit := v - next

		switch bit {
		case VideoScalerFlagNone:
			builder.WriteString("None|")
		case VideoScalerFlagInterlaced:
			builder.WriteString("Interlaced|")
		default:
			builder.WriteString(fmt.Sprintf("VideoScalerFlags(0b%b)|", bit))
		}

		v = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if v contains other.
func (v VideoScalerFlags) Has(other VideoScalerFlags) bool {
	return (v & other) == other
}

// VideoTimeCodeFlags flags related to the time code information. For drop
// frame, only 30000/1001 and 60000/1001 frame rates are supported.
type VideoTimeCodeFlags C.guint

const (
	// VideoTimeCodeFlagsNone: no flags.
	VideoTimeCodeFlagsNone VideoTimeCodeFlags = 0b0
	// VideoTimeCodeFlagsDropFrame: whether we have drop frame rate.
	VideoTimeCodeFlagsDropFrame VideoTimeCodeFlags = 0b1
	// VideoTimeCodeFlagsInterlaced: whether we have interlaced video.
	VideoTimeCodeFlagsInterlaced VideoTimeCodeFlags = 0b10
)

func marshalVideoTimeCodeFlags(p uintptr) (interface{}, error) {
	return VideoTimeCodeFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for VideoTimeCodeFlags.
func (v VideoTimeCodeFlags) String() string {
	if v == 0 {
		return "VideoTimeCodeFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(79)

	for v != 0 {
		next := v & (v - 1)
		bit := v - next

		switch bit {
		case VideoTimeCodeFlagsNone:
			builder.WriteString("None|")
		case VideoTimeCodeFlagsDropFrame:
			builder.WriteString("DropFrame|")
		case VideoTimeCodeFlagsInterlaced:
			builder.WriteString("Interlaced|")
		default:
			builder.WriteString(fmt.Sprintf("VideoTimeCodeFlags(0b%b)|", bit))
		}

		v = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if v contains other.
func (v VideoTimeCodeFlags) Has(other VideoTimeCodeFlags) bool {
	return (v & other) == other
}

type VideoConvertSampleCallback func(sample *gst.Sample, err error)

func AncillaryMetaApiGetType() coreglib.Type {
	var _cret C.GType // in

	_cret = C.gst_ancillary_meta_api_get_type()

	var _gType coreglib.Type // out

	_gType = coreglib.Type(_cret)

	return _gType
}

// BufferAddAncillaryMeta adds a new AncillaryMeta to the buffer. The caller is
// responsible for setting the appropriate fields.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//
// The function returns the following values:
//
//   - ancillaryMeta: new AncillaryMeta, or NULL if an error happened.
func BufferAddAncillaryMeta(buffer *gst.Buffer) *AncillaryMeta {
	var _arg1 *C.GstBuffer        // out
	var _cret *C.GstAncillaryMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))

	_cret = C.gst_buffer_add_ancillary_meta(_arg1)
	runtime.KeepAlive(buffer)

	var _ancillaryMeta *AncillaryMeta // out

	_ancillaryMeta = (*AncillaryMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _ancillaryMeta
}

// BufferAddVideoAfdMeta attaches VideoAFDMeta metadata to buffer with the given
// parameters.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//   - field: 0 for progressive or field 1 and 1 for field 2.
//   - spec that applies to AFD value.
//   - afd AFD enumeration.
//
// The function returns the following values:
//
//   - videoAFDMeta on buffer.
func BufferAddVideoAfdMeta(buffer *gst.Buffer, field byte, spec VideoAFDSpec, afd VideoAFDValue) *VideoAFDMeta {
	var _arg1 *C.GstBuffer       // out
	var _arg2 C.guint8           // out
	var _arg3 C.GstVideoAFDSpec  // out
	var _arg4 C.GstVideoAFDValue // out
	var _cret *C.GstVideoAFDMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg2 = C.guint8(field)
	_arg3 = C.GstVideoAFDSpec(spec)
	_arg4 = C.GstVideoAFDValue(afd)

	_cret = C.gst_buffer_add_video_afd_meta(_arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(field)
	runtime.KeepAlive(spec)
	runtime.KeepAlive(afd)

	var _videoAFDMeta *VideoAFDMeta // out

	_videoAFDMeta = (*VideoAFDMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _videoAFDMeta
}

// BufferAddVideoAffineTransformationMeta attaches
// GstVideoAffineTransformationMeta metadata to buffer with the given
// parameters.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//
// The function returns the following values:
//
//   - videoAffineTransformationMeta on buffer.
func BufferAddVideoAffineTransformationMeta(buffer *gst.Buffer) *VideoAffineTransformationMeta {
	var _arg1 *C.GstBuffer                        // out
	var _cret *C.GstVideoAffineTransformationMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))

	_cret = C.gst_buffer_add_video_affine_transformation_meta(_arg1)
	runtime.KeepAlive(buffer)

	var _videoAffineTransformationMeta *VideoAffineTransformationMeta // out

	_videoAffineTransformationMeta = (*VideoAffineTransformationMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _videoAffineTransformationMeta
}

// BufferAddVideoBarMeta attaches VideoBarMeta metadata to buffer with the given
// parameters.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//   - field: 0 for progressive or field 1 and 1 for field 2.
//   - isLetterbox: if true then bar data specifies letterbox, otherwise
//     pillarbox.
//   - barData1: if is_letterbox is true, then the value specifies the last
//     line of a horizontal letterbox bar area at top of reconstructed frame.
//     Otherwise, it specifies the last horizontal luminance sample of a
//     vertical pillarbox bar area at the left side of the reconstructed frame.
//   - barData2: if is_letterbox is true, then the value specifies the first
//     line of a horizontal letterbox bar area at bottom of reconstructed frame.
//     Otherwise, it specifies the first horizontal luminance sample of a
//     vertical pillarbox bar area at the right side of the reconstructed frame.
//
// The function returns the following values:
//
//   - videoBarMeta on buffer.
//
//     See Table 6.11 Bar Data Syntax
//
//     https://www.atsc.org/wp-content/uploads/2015/03/a_53-Part-4-2009.pdf.
func BufferAddVideoBarMeta(buffer *gst.Buffer, field byte, isLetterbox bool, barData1, barData2 uint) *VideoBarMeta {
	var _arg1 *C.GstBuffer       // out
	var _arg2 C.guint8           // out
	var _arg3 C.gboolean         // out
	var _arg4 C.guint            // out
	var _arg5 C.guint            // out
	var _cret *C.GstVideoBarMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg2 = C.guint8(field)
	if isLetterbox {
		_arg3 = C.TRUE
	}
	_arg4 = C.guint(barData1)
	_arg5 = C.guint(barData2)

	_cret = C.gst_buffer_add_video_bar_meta(_arg1, _arg2, _arg3, _arg4, _arg5)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(field)
	runtime.KeepAlive(isLetterbox)
	runtime.KeepAlive(barData1)
	runtime.KeepAlive(barData2)

	var _videoBarMeta *VideoBarMeta // out

	_videoBarMeta = (*VideoBarMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _videoBarMeta
}

// BufferAddVideoCaptionMeta attaches VideoCaptionMeta metadata to buffer with
// the given parameters.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//   - captionType: type of Closed Caption to add.
//   - data: closed Caption data.
//
// The function returns the following values:
//
//   - videoCaptionMeta on buffer.
func BufferAddVideoCaptionMeta(buffer *gst.Buffer, captionType VideoCaptionType, data []byte) *VideoCaptionMeta {
	var _arg1 *C.GstBuffer          // out
	var _arg2 C.GstVideoCaptionType // out
	var _arg3 *C.guint8             // out
	var _arg4 C.gsize
	var _cret *C.GstVideoCaptionMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg2 = C.GstVideoCaptionType(captionType)
	_arg4 = (C.gsize)(len(data))
	if len(data) > 0 {
		_arg3 = (*C.guint8)(unsafe.Pointer(&data[0]))
	}

	_cret = C.gst_buffer_add_video_caption_meta(_arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(captionType)
	runtime.KeepAlive(data)

	var _videoCaptionMeta *VideoCaptionMeta // out

	_videoCaptionMeta = (*VideoCaptionMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _videoCaptionMeta
}

// BufferAddVideoCodecAlphaMeta attaches a VideoCodecAlphaMeta metadata to
// buffer with the given alpha buffer.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//   - alphaBuffer: Buffer.
//
// The function returns the following values:
//
//   - videoCodecAlphaMeta on buffer.
func BufferAddVideoCodecAlphaMeta(buffer, alphaBuffer *gst.Buffer) *VideoCodecAlphaMeta {
	var _arg1 *C.GstBuffer              // out
	var _arg2 *C.GstBuffer              // out
	var _cret *C.GstVideoCodecAlphaMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg2 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(alphaBuffer)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(alphaBuffer)), nil)

	_cret = C.gst_buffer_add_video_codec_alpha_meta(_arg1, _arg2)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(alphaBuffer)

	var _videoCodecAlphaMeta *VideoCodecAlphaMeta // out

	_videoCodecAlphaMeta = (*VideoCodecAlphaMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _videoCodecAlphaMeta
}

// BufferAddVideoMeta attaches GstVideoMeta metadata to buffer with the given
// parameters and the default offsets and strides for format and width x height.
//
// This function calculates the default offsets and strides and then calls
// gst_buffer_add_video_meta_full() with them.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//   - flags: VideoFrameFlags.
//   - format: VideoFormat.
//   - width: width.
//   - height: height.
//
// The function returns the following values:
//
//   - videoMeta on buffer.
func BufferAddVideoMeta(buffer *gst.Buffer, flags VideoFrameFlags, format VideoFormat, width, height uint) *VideoMeta {
	var _arg1 *C.GstBuffer         // out
	var _arg2 C.GstVideoFrameFlags // out
	var _arg3 C.GstVideoFormat     // out
	var _arg4 C.guint              // out
	var _arg5 C.guint              // out
	var _cret *C.GstVideoMeta      // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg2 = C.GstVideoFrameFlags(flags)
	_arg3 = C.GstVideoFormat(format)
	_arg4 = C.guint(width)
	_arg5 = C.guint(height)

	_cret = C.gst_buffer_add_video_meta(_arg1, _arg2, _arg3, _arg4, _arg5)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(flags)
	runtime.KeepAlive(format)
	runtime.KeepAlive(width)
	runtime.KeepAlive(height)

	var _videoMeta *VideoMeta // out

	_videoMeta = (*VideoMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _videoMeta
}

// BufferAddVideoMetaFull attaches GstVideoMeta metadata to buffer with the
// given parameters.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//   - flags: VideoFrameFlags.
//   - format: VideoFormat.
//   - width: width.
//   - height: height.
//   - nPlanes: number of planes.
//   - offset of each plane.
//   - stride of each plane.
//
// The function returns the following values:
//
//   - videoMeta on buffer.
func BufferAddVideoMetaFull(buffer *gst.Buffer, flags VideoFrameFlags, format VideoFormat, width, height, nPlanes uint, offset [4]uint, stride [4]int) *VideoMeta {
	var _arg1 *C.GstBuffer         // out
	var _arg2 C.GstVideoFrameFlags // out
	var _arg3 C.GstVideoFormat     // out
	var _arg4 C.guint              // out
	var _arg5 C.guint              // out
	var _arg6 C.guint              // out
	var _arg7 *C.gsize             // out
	var _arg8 *C.gint              // out
	var _cret *C.GstVideoMeta      // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg2 = C.GstVideoFrameFlags(flags)
	_arg3 = C.GstVideoFormat(format)
	_arg4 = C.guint(width)
	_arg5 = C.guint(height)
	_arg6 = C.guint(nPlanes)
	_arg7 = (*C.gsize)(unsafe.Pointer(&offset))
	{
		var out [4]C.gint
		_arg8 = &out[0]
		for i := 0; i < 4; i++ {
			out[i] = C.gint(stride[i])
		}
	}

	_cret = C.gst_buffer_add_video_meta_full(_arg1, _arg2, _arg3, _arg4, _arg5, _arg6, _arg7, _arg8)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(flags)
	runtime.KeepAlive(format)
	runtime.KeepAlive(width)
	runtime.KeepAlive(height)
	runtime.KeepAlive(nPlanes)
	runtime.KeepAlive(offset)
	runtime.KeepAlive(stride)

	var _videoMeta *VideoMeta // out

	_videoMeta = (*VideoMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _videoMeta
}

// BufferAddVideoOverlayCompositionMeta sets an overlay composition on a buffer.
// The buffer will obtain its own reference to the composition, meaning this
// function does not take ownership of comp.
//
// The function takes the following parameters:
//
//   - buf: Buffer.
//   - comp (optional): VideoOverlayComposition.
//
// The function returns the following values:
//
//   - videoOverlayCompositionMeta: VideoOverlayCompositionMeta.
func BufferAddVideoOverlayCompositionMeta(buf *gst.Buffer, comp *VideoOverlayComposition) *VideoOverlayCompositionMeta {
	var _arg1 *C.GstBuffer                      // out
	var _arg2 *C.GstVideoOverlayComposition     // out
	var _cret *C.GstVideoOverlayCompositionMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buf)))
	if comp != nil {
		_arg2 = (*C.GstVideoOverlayComposition)(gextras.StructNative(unsafe.Pointer(comp)))
	}

	_cret = C.gst_buffer_add_video_overlay_composition_meta(_arg1, _arg2)
	runtime.KeepAlive(buf)
	runtime.KeepAlive(comp)

	var _videoOverlayCompositionMeta *VideoOverlayCompositionMeta // out

	_videoOverlayCompositionMeta = (*VideoOverlayCompositionMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _videoOverlayCompositionMeta
}

// BufferAddVideoRegionOfInterestMeta attaches VideoRegionOfInterestMeta
// metadata to buffer with the given parameters.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//   - roiType: type of the region of interest (e.g. "face").
//   - x: x position.
//   - y: y position.
//   - w: width.
//   - h: height.
//
// The function returns the following values:
//
//   - videoRegionOfInterestMeta on buffer.
func BufferAddVideoRegionOfInterestMeta(buffer *gst.Buffer, roiType string, x, y, w, h uint) *VideoRegionOfInterestMeta {
	var _arg1 *C.GstBuffer                    // out
	var _arg2 *C.gchar                        // out
	var _arg3 C.guint                         // out
	var _arg4 C.guint                         // out
	var _arg5 C.guint                         // out
	var _arg6 C.guint                         // out
	var _cret *C.GstVideoRegionOfInterestMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg2 = (*C.gchar)(unsafe.Pointer(C.CString(roiType)))
	defer C.free(unsafe.Pointer(_arg2))
	_arg3 = C.guint(x)
	_arg4 = C.guint(y)
	_arg5 = C.guint(w)
	_arg6 = C.guint(h)

	_cret = C.gst_buffer_add_video_region_of_interest_meta(_arg1, _arg2, _arg3, _arg4, _arg5, _arg6)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(roiType)
	runtime.KeepAlive(x)
	runtime.KeepAlive(y)
	runtime.KeepAlive(w)
	runtime.KeepAlive(h)

	var _videoRegionOfInterestMeta *VideoRegionOfInterestMeta // out

	_videoRegionOfInterestMeta = (*VideoRegionOfInterestMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _videoRegionOfInterestMeta
}

// BufferAddVideoRegionOfInterestMetaID attaches VideoRegionOfInterestMeta
// metadata to buffer with the given parameters.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//   - roiType: type of the region of interest (e.g. "face").
//   - x: x position.
//   - y: y position.
//   - w: width.
//   - h: height.
//
// The function returns the following values:
//
//   - videoRegionOfInterestMeta on buffer.
func BufferAddVideoRegionOfInterestMetaID(buffer *gst.Buffer, roiType glib.Quark, x, y, w, h uint) *VideoRegionOfInterestMeta {
	var _arg1 *C.GstBuffer                    // out
	var _arg2 C.GQuark                        // out
	var _arg3 C.guint                         // out
	var _arg4 C.guint                         // out
	var _arg5 C.guint                         // out
	var _arg6 C.guint                         // out
	var _cret *C.GstVideoRegionOfInterestMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg2 = C.GQuark(roiType)
	_arg3 = C.guint(x)
	_arg4 = C.guint(y)
	_arg5 = C.guint(w)
	_arg6 = C.guint(h)

	_cret = C.gst_buffer_add_video_region_of_interest_meta_id(_arg1, _arg2, _arg3, _arg4, _arg5, _arg6)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(roiType)
	runtime.KeepAlive(x)
	runtime.KeepAlive(y)
	runtime.KeepAlive(w)
	runtime.KeepAlive(h)

	var _videoRegionOfInterestMeta *VideoRegionOfInterestMeta // out

	_videoRegionOfInterestMeta = (*VideoRegionOfInterestMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _videoRegionOfInterestMeta
}

// BufferAddVideoSeiUserDataUnregisteredMeta attaches
// VideoSEIUserDataUnregisteredMeta metadata to buffer with the given
// parameters.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//   - uuid: user Data Unregistered UUID.
//   - data: SEI User Data Unregistered buffer.
//   - size of the data buffer.
//
// The function returns the following values:
//
//   - videoSEIUserDataUnregisteredMeta on buffer.
func BufferAddVideoSeiUserDataUnregisteredMeta(buffer *gst.Buffer, uuid, data *byte, size uint) *VideoSEIUserDataUnregisteredMeta {
	var _arg1 *C.GstBuffer                           // out
	var _arg2 *C.guint8                              // out
	var _arg3 *C.guint8                              // out
	var _arg4 C.gsize                                // out
	var _cret *C.GstVideoSEIUserDataUnregisteredMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg2 = (*C.guint8)(unsafe.Pointer(uuid))
	_arg3 = (*C.guint8)(unsafe.Pointer(data))
	_arg4 = C.gsize(size)

	_cret = C.gst_buffer_add_video_sei_user_data_unregistered_meta(_arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(uuid)
	runtime.KeepAlive(data)
	runtime.KeepAlive(size)

	var _videoSEIUserDataUnregisteredMeta *VideoSEIUserDataUnregisteredMeta // out

	_videoSEIUserDataUnregisteredMeta = (*VideoSEIUserDataUnregisteredMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _videoSEIUserDataUnregisteredMeta
}

// BufferAddVideoTimeCodeMeta attaches VideoTimeCodeMeta metadata to buffer with
// the given parameters.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//   - tc: VideoTimeCode.
//
// The function returns the following values:
//
//   - videoTimeCodeMeta (optional) on buffer, or (since 1.16) NULL if the
//     timecode was invalid.
func BufferAddVideoTimeCodeMeta(buffer *gst.Buffer, tc *VideoTimeCode) *VideoTimeCodeMeta {
	var _arg1 *C.GstBuffer            // out
	var _arg2 *C.GstVideoTimeCode     // out
	var _cret *C.GstVideoTimeCodeMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg2 = (*C.GstVideoTimeCode)(gextras.StructNative(unsafe.Pointer(tc)))

	_cret = C.gst_buffer_add_video_time_code_meta(_arg1, _arg2)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(tc)

	var _videoTimeCodeMeta *VideoTimeCodeMeta // out

	if _cret != nil {
		_videoTimeCodeMeta = (*VideoTimeCodeMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	}

	return _videoTimeCodeMeta
}

// BufferAddVideoTimeCodeMetaFull attaches VideoTimeCodeMeta metadata to buffer
// with the given parameters.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//   - fpsN: framerate numerator.
//   - fpsD: framerate denominator.
//   - latestDailyJam for the latest daily jam.
//   - flags: VideoTimeCodeFlags.
//   - hours since the daily jam.
//   - minutes since the daily jam.
//   - seconds since the daily jam.
//   - frames since the daily jam.
//   - fieldCount fields since the daily jam.
//
// The function returns the following values:
//
//   - videoTimeCodeMeta (optional) on buffer, or (since 1.16) NULL if the
//     timecode was invalid.
func BufferAddVideoTimeCodeMetaFull(buffer *gst.Buffer, fpsN, fpsD uint, latestDailyJam *glib.DateTime, flags VideoTimeCodeFlags, hours, minutes, seconds, frames, fieldCount uint) *VideoTimeCodeMeta {
	var _arg1 *C.GstBuffer            // out
	var _arg2 C.guint                 // out
	var _arg3 C.guint                 // out
	var _arg4 *C.GDateTime            // out
	var _arg5 C.GstVideoTimeCodeFlags // out
	var _arg6 C.guint                 // out
	var _arg7 C.guint                 // out
	var _arg8 C.guint                 // out
	var _arg9 C.guint                 // out
	var _arg10 C.guint                // out
	var _cret *C.GstVideoTimeCodeMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg2 = C.guint(fpsN)
	_arg3 = C.guint(fpsD)
	_arg4 = (*C.GDateTime)(gextras.StructNative(unsafe.Pointer(latestDailyJam)))
	_arg5 = C.GstVideoTimeCodeFlags(flags)
	_arg6 = C.guint(hours)
	_arg7 = C.guint(minutes)
	_arg8 = C.guint(seconds)
	_arg9 = C.guint(frames)
	_arg10 = C.guint(fieldCount)

	_cret = C.gst_buffer_add_video_time_code_meta_full(_arg1, _arg2, _arg3, _arg4, _arg5, _arg6, _arg7, _arg8, _arg9, _arg10)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(fpsN)
	runtime.KeepAlive(fpsD)
	runtime.KeepAlive(latestDailyJam)
	runtime.KeepAlive(flags)
	runtime.KeepAlive(hours)
	runtime.KeepAlive(minutes)
	runtime.KeepAlive(seconds)
	runtime.KeepAlive(frames)
	runtime.KeepAlive(fieldCount)

	var _videoTimeCodeMeta *VideoTimeCodeMeta // out

	if _cret != nil {
		_videoTimeCodeMeta = (*VideoTimeCodeMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	}

	return _videoTimeCodeMeta
}

// BufferGetVideoMeta: find the VideoMeta on buffer with the lowest id.
//
// Buffers can contain multiple VideoMeta metadata items when dealing with
// multiview buffers.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//
// The function returns the following values:
//
//   - videoMeta (optional) with lowest id (usually 0) or NULL when there is no
//     such metadata on buffer.
func BufferGetVideoMeta(buffer *gst.Buffer) *VideoMeta {
	var _arg1 *C.GstBuffer    // out
	var _cret *C.GstVideoMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))

	_cret = C.gst_buffer_get_video_meta(_arg1)
	runtime.KeepAlive(buffer)

	var _videoMeta *VideoMeta // out

	if _cret != nil {
		_videoMeta = (*VideoMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	}

	return _videoMeta
}

// BufferGetVideoMetaID: find the VideoMeta on buffer with the given id.
//
// Buffers can contain multiple VideoMeta metadata items when dealing with
// multiview buffers.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//   - id: metadata id.
//
// The function returns the following values:
//
//   - videoMeta (optional) with id or NULL when there is no such metadata on
//     buffer.
func BufferGetVideoMetaID(buffer *gst.Buffer, id int) *VideoMeta {
	var _arg1 *C.GstBuffer    // out
	var _arg2 C.gint          // out
	var _cret *C.GstVideoMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg2 = C.gint(id)

	_cret = C.gst_buffer_get_video_meta_id(_arg1, _arg2)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(id)

	var _videoMeta *VideoMeta // out

	if _cret != nil {
		_videoMeta = (*VideoMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	}

	return _videoMeta
}

// BufferGetVideoRegionOfInterestMetaID: find the VideoRegionOfInterestMeta on
// buffer with the given id.
//
// Buffers can contain multiple VideoRegionOfInterestMeta metadata items if
// multiple regions of interests are marked on a frame.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//   - id: metadata id.
//
// The function returns the following values:
//
//   - videoRegionOfInterestMeta (optional) with id or NULL when there is no
//     such metadata on buffer.
func BufferGetVideoRegionOfInterestMetaID(buffer *gst.Buffer, id int) *VideoRegionOfInterestMeta {
	var _arg1 *C.GstBuffer                    // out
	var _arg2 C.gint                          // out
	var _cret *C.GstVideoRegionOfInterestMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg2 = C.gint(id)

	_cret = C.gst_buffer_get_video_region_of_interest_meta_id(_arg1, _arg2)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(id)

	var _videoRegionOfInterestMeta *VideoRegionOfInterestMeta // out

	if _cret != nil {
		_videoRegionOfInterestMeta = (*VideoRegionOfInterestMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	}

	return _videoRegionOfInterestMeta
}

// BufferPoolConfigGetVideoAlignment: get the video alignment from the
// bufferpool configuration config in in align.
//
// The function takes the following parameters:
//
//   - config: Structure.
//   - align: VideoAlignment.
//
// The function returns the following values:
//
//   - ok: TRUE if config could be parsed correctly.
func BufferPoolConfigGetVideoAlignment(config *gst.Structure, align *VideoAlignment) bool {
	var _arg1 *C.GstStructure      // out
	var _arg2 *C.GstVideoAlignment // out
	var _cret C.gboolean           // in

	_arg1 = (*C.GstStructure)(gextras.StructNative(unsafe.Pointer(config)))
	_arg2 = (*C.GstVideoAlignment)(gextras.StructNative(unsafe.Pointer(align)))

	_cret = C.gst_buffer_pool_config_get_video_alignment(_arg1, _arg2)
	runtime.KeepAlive(config)
	runtime.KeepAlive(align)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// BufferPoolConfigSetVideoAlignment: set the video alignment in align to the
// bufferpool configuration config.
//
// The function takes the following parameters:
//
//   - config: Structure.
//   - align: VideoAlignment.
func BufferPoolConfigSetVideoAlignment(config *gst.Structure, align *VideoAlignment) {
	var _arg1 *C.GstStructure      // out
	var _arg2 *C.GstVideoAlignment // out

	_arg1 = (*C.GstStructure)(gextras.StructNative(unsafe.Pointer(config)))
	_arg2 = (*C.GstVideoAlignment)(gextras.StructNative(unsafe.Pointer(align)))

	C.gst_buffer_pool_config_set_video_alignment(_arg1, _arg2)
	runtime.KeepAlive(config)
	runtime.KeepAlive(align)
}

// IsVideoOverlayPrepareWindowHandleMessage: convenience function to check if
// the given message is a "prepare-window-handle" message from a VideoOverlay.
//
// The function takes the following parameters:
//
//   - msg: Message.
//
// The function returns the following values:
//
//   - ok: whether msg is a "prepare-window-handle" message.
func IsVideoOverlayPrepareWindowHandleMessage(msg *gst.Message) bool {
	var _arg1 *C.GstMessage // out
	var _cret C.gboolean    // in

	_arg1 = (*C.GstMessage)(gextras.StructNative(unsafe.Pointer(msg)))

	_cret = C.gst_is_video_overlay_prepare_window_handle_message(_arg1)
	runtime.KeepAlive(msg)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

func VideoAfdMetaApiGetType() coreglib.Type {
	var _cret C.GType // in

	_cret = C.gst_video_afd_meta_api_get_type()

	var _gType coreglib.Type // out

	_gType = coreglib.Type(_cret)

	return _gType
}

func VideoAffineTransformationMetaApiGetType() coreglib.Type {
	var _cret C.GType // in

	_cret = C.gst_video_affine_transformation_meta_api_get_type()

	var _gType coreglib.Type // out

	_gType = coreglib.Type(_cret)

	return _gType
}

func VideoBarMetaApiGetType() coreglib.Type {
	var _cret C.GType // in

	_cret = C.gst_video_bar_meta_api_get_type()

	var _gType coreglib.Type // out

	_gType = coreglib.Type(_cret)

	return _gType
}

// VideoBlend lets you blend the src image into the dest image.
//
// The function takes the following parameters:
//
//   - dest where to blend src in.
//   - src that we want to blend into.
//   - x offset in pixel where the src image should be blended.
//   - y offset in pixel where the src image should be blended.
//   - globalAlpha: global_alpha each per-pixel alpha value is multiplied with.
func VideoBlend(dest, src *VideoFrame, x, y int, globalAlpha float32) bool {
	var _arg1 *C.GstVideoFrame // out
	var _arg2 *C.GstVideoFrame // out
	var _arg3 C.gint           // out
	var _arg4 C.gint           // out
	var _arg5 C.gfloat         // out
	var _cret C.gboolean       // in

	_arg1 = (*C.GstVideoFrame)(gextras.StructNative(unsafe.Pointer(dest)))
	_arg2 = (*C.GstVideoFrame)(gextras.StructNative(unsafe.Pointer(src)))
	_arg3 = C.gint(x)
	_arg4 = C.gint(y)
	_arg5 = C.gfloat(globalAlpha)

	_cret = C.gst_video_blend(_arg1, _arg2, _arg3, _arg4, _arg5)
	runtime.KeepAlive(dest)
	runtime.KeepAlive(src)
	runtime.KeepAlive(x)
	runtime.KeepAlive(y)
	runtime.KeepAlive(globalAlpha)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// VideoBlendScaleLinearRGBA scales a buffer containing RGBA (or AYUV) video.
// This is an internal helper function which is used to scale subtitle overlays,
// and may be deprecated in the near future. Use VideoScaler to scale video
// buffers instead.
//
// The function takes the following parameters:
//
//   - src describing the video data in src_buffer.
//   - srcBuffer: source buffer containing video pixels to scale.
//   - destHeight: height in pixels to scale the video data in src_buffer to.
//   - destWidth: width in pixels to scale the video data in src_buffer to.
//
// The function returns the following values:
//
//   - dest: pointer to a VideoInfo structure that will be filled in with the
//     details for dest_buffer.
//   - destBuffer: pointer to a Buffer variable, which will be set to a
//     newly-allocated buffer containing the scaled pixels.
func VideoBlendScaleLinearRGBA(src *VideoInfo, srcBuffer *gst.Buffer, destHeight, destWidth int) (*VideoInfo, *gst.Buffer) {
	var _arg1 *C.GstVideoInfo // out
	var _arg2 *C.GstBuffer    // out
	var _arg3 C.gint          // out
	var _arg4 C.gint          // out
	var _arg5 C.GstVideoInfo  // in
	var _arg6 *C.GstBuffer    // in

	_arg1 = (*C.GstVideoInfo)(gextras.StructNative(unsafe.Pointer(src)))
	_arg2 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(srcBuffer)))
	_arg3 = C.gint(destHeight)
	_arg4 = C.gint(destWidth)

	C.gst_video_blend_scale_linear_RGBA(_arg1, _arg2, _arg3, _arg4, &_arg5, &_arg6)
	runtime.KeepAlive(src)
	runtime.KeepAlive(srcBuffer)
	runtime.KeepAlive(destHeight)
	runtime.KeepAlive(destWidth)

	var _dest *VideoInfo        // out
	var _destBuffer *gst.Buffer // out

	_dest = (*VideoInfo)(gextras.NewStructNative(unsafe.Pointer((&_arg5))))
	_destBuffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_arg6)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_destBuffer)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _dest, _destBuffer
}

// VideoCalculateDisplayRatio: given the Pixel Aspect Ratio and size of an
// input video frame, and the pixel aspect ratio of the intended display device,
// calculates the actual display ratio the video will be rendered with.
//
// The function takes the following parameters:
//
//   - videoWidth: width of the video frame in pixels.
//   - videoHeight: height of the video frame in pixels.
//   - videoParN: numerator of the pixel aspect ratio of the input video.
//   - videoParD: denominator of the pixel aspect ratio of the input video.
//   - displayParN: numerator of the pixel aspect ratio of the display device.
//   - displayParD: denominator of the pixel aspect ratio of the display device.
//
// The function returns the following values:
//
//   - darN: numerator of the calculated display_ratio.
//   - darD: denominator of the calculated display_ratio.
//   - ok: boolean indicating success and a calculated Display Ratio in the
//     dar_n and dar_d parameters. The return value is FALSE in the case of
//     integer overflow or other error.
func VideoCalculateDisplayRatio(videoWidth, videoHeight, videoParN, videoParD, displayParN, displayParD uint) (darN, darD uint, ok bool) {
	var _arg1 C.guint    // in
	var _arg2 C.guint    // in
	var _arg3 C.guint    // out
	var _arg4 C.guint    // out
	var _arg5 C.guint    // out
	var _arg6 C.guint    // out
	var _arg7 C.guint    // out
	var _arg8 C.guint    // out
	var _cret C.gboolean // in

	_arg3 = C.guint(videoWidth)
	_arg4 = C.guint(videoHeight)
	_arg5 = C.guint(videoParN)
	_arg6 = C.guint(videoParD)
	_arg7 = C.guint(displayParN)
	_arg8 = C.guint(displayParD)

	_cret = C.gst_video_calculate_display_ratio(&_arg1, &_arg2, _arg3, _arg4, _arg5, _arg6, _arg7, _arg8)
	runtime.KeepAlive(videoWidth)
	runtime.KeepAlive(videoHeight)
	runtime.KeepAlive(videoParN)
	runtime.KeepAlive(videoParD)
	runtime.KeepAlive(displayParN)
	runtime.KeepAlive(displayParD)

	var _darN uint // out
	var _darD uint // out
	var _ok bool   // out

	_darN = uint(_arg1)
	_darD = uint(_arg2)
	if _cret != 0 {
		_ok = true
	}

	return _darN, _darD, _ok
}

func VideoCaptionMetaApiGetType() coreglib.Type {
	var _cret C.GType // in

	_cret = C.gst_video_caption_meta_api_get_type()

	var _gType coreglib.Type // out

	_gType = coreglib.Type(_cret)

	return _gType
}

// VideoCenterRect takes src rectangle and position it at the center of dst
// rectangle with or without scaling. It handles clipping if the src rectangle
// is bigger than the dst one and scaling is set to FALSE.
//
// The function takes the following parameters:
//
//   - src: pointer to VideoRectangle describing the source area.
//   - dst: pointer to VideoRectangle describing the destination area.
//   - scaling indicating if scaling should be applied or not.
//
// The function returns the following values:
//
//   - result: pointer to a VideoRectangle which will receive the result area.
func VideoCenterRect(src, dst *VideoRectangle, scaling bool) *VideoRectangle {
	var _arg1 *C.GstVideoRectangle // out
	var _arg2 *C.GstVideoRectangle // out
	var _arg3 C.GstVideoRectangle  // in
	var _arg4 C.gboolean           // out

	_arg1 = (*C.GstVideoRectangle)(gextras.StructNative(unsafe.Pointer(src)))
	_arg2 = (*C.GstVideoRectangle)(gextras.StructNative(unsafe.Pointer(dst)))
	if scaling {
		_arg4 = C.TRUE
	}

	C.gst_video_center_rect(_arg1, _arg2, &_arg3, _arg4)
	runtime.KeepAlive(src)
	runtime.KeepAlive(dst)
	runtime.KeepAlive(scaling)

	var _result *VideoRectangle // out

	_result = (*VideoRectangle)(gextras.NewStructNative(unsafe.Pointer((&_arg3))))

	return _result
}

// VideoChromaFromString: convert s to a VideoChromaSite
//
// Deprecated: Use gst_video_chroma_site_from_string() instead.
//
// The function takes the following parameters:
//
//   - s: chromasite string.
//
// The function returns the following values:
//
//   - videoChromaSite or GST_VIDEO_CHROMA_SITE_UNKNOWN when s does not contain
//     a valid chroma description.
func VideoChromaFromString(s string) VideoChromaSite {
	var _arg1 *C.gchar             // out
	var _cret C.GstVideoChromaSite // in

	_arg1 = (*C.gchar)(unsafe.Pointer(C.CString(s)))
	defer C.free(unsafe.Pointer(_arg1))

	_cret = C.gst_video_chroma_from_string(_arg1)
	runtime.KeepAlive(s)

	var _videoChromaSite VideoChromaSite // out

	_videoChromaSite = VideoChromaSite(_cret)

	return _videoChromaSite
}

// VideoChromaToString converts site to its string representation.
//
// Deprecated: Use gst_video_chroma_site_to_string() instead.
//
// The function takes the following parameters:
//
//   - site: VideoChromaSite.
//
// The function returns the following values:
//
//   - utf8: string describing site.
func VideoChromaToString(site VideoChromaSite) string {
	var _arg1 C.GstVideoChromaSite // out
	var _cret *C.gchar             // in

	_arg1 = C.GstVideoChromaSite(site)

	_cret = C.gst_video_chroma_to_string(_arg1)
	runtime.KeepAlive(site)

	var _utf8 string // out

	_utf8 = C.GoString((*C.gchar)(unsafe.Pointer(_cret)))

	return _utf8
}

// The function returns the following values:
//
//   - gType for the VideoCodecAlphaMeta structure.
func VideoCodecAlphaMetaApiGetType() coreglib.Type {
	var _cret C.GType // in

	_cret = C.gst_video_codec_alpha_meta_api_get_type()

	var _gType coreglib.Type // out

	_gType = coreglib.Type(_cret)

	return _gType
}

// VideoColorTransferDecode: deprecated: Use
// gst_video_transfer_function_decode() instead.
//
// The function takes the following parameters:
//
//   - fn: VideoTransferFunction.
//   - val: value.
func VideoColorTransferDecode(fn VideoTransferFunction, val float64) float64 {
	var _arg1 C.GstVideoTransferFunction // out
	var _arg2 C.gdouble                  // out
	var _cret C.gdouble                  // in

	_arg1 = C.GstVideoTransferFunction(fn)
	_arg2 = C.gdouble(val)

	_cret = C.gst_video_color_transfer_decode(_arg1, _arg2)
	runtime.KeepAlive(fn)
	runtime.KeepAlive(val)

	var _gdouble float64 // out

	_gdouble = float64(_cret)

	return _gdouble
}

// VideoColorTransferEncode: deprecated: Use
// gst_video_transfer_function_encode() instead.
//
// The function takes the following parameters:
//
//   - fn: VideoTransferFunction.
//   - val: value.
func VideoColorTransferEncode(fn VideoTransferFunction, val float64) float64 {
	var _arg1 C.GstVideoTransferFunction // out
	var _arg2 C.gdouble                  // out
	var _cret C.gdouble                  // in

	_arg1 = C.GstVideoTransferFunction(fn)
	_arg2 = C.gdouble(val)

	_cret = C.gst_video_color_transfer_encode(_arg1, _arg2)
	runtime.KeepAlive(fn)
	runtime.KeepAlive(val)

	var _gdouble float64 // out

	_gdouble = float64(_cret)

	return _gdouble
}

// VideoConvertSample converts a raw video buffer into the specified output
// caps.
//
// The output caps can be any raw video formats or any image formats (jpeg, png,
// ...).
//
// The width, height and pixel-aspect-ratio can also be specified in the output
// caps.
//
// The function takes the following parameters:
//
//   - sample: Sample.
//   - toCaps to convert to.
//   - timeout: maximum amount of time allowed for the processing.
//
// The function returns the following values:
//
//   - ret (optional): converted Sample, or NULL if an error happened (in which
//     case err will point to the #GError).
func VideoConvertSample(sample *gst.Sample, toCaps *gst.Caps, timeout gst.ClockTime) (*gst.Sample, error) {
	var _arg1 *C.GstSample   // out
	var _arg2 *C.GstCaps     // out
	var _arg3 C.GstClockTime // out
	var _cret *C.GstSample   // in
	var _cerr *C.GError      // in

	_arg1 = (*C.GstSample)(gextras.StructNative(unsafe.Pointer(sample)))
	_arg2 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(toCaps)))
	_arg3 = C.GstClockTime(timeout)

	_cret = C.gst_video_convert_sample(_arg1, _arg2, _arg3, &_cerr)
	runtime.KeepAlive(sample)
	runtime.KeepAlive(toCaps)
	runtime.KeepAlive(timeout)

	var _ret *gst.Sample // out
	var _goerr error     // out

	if _cret != nil {
		_ret = (*gst.Sample)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_ret)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}
	if _cerr != nil {
		_goerr = gerror.Take(unsafe.Pointer(_cerr))
	}

	return _ret, _goerr
}

// VideoConvertSampleAsync converts a raw video buffer into the specified output
// caps.
//
// The output caps can be any raw video formats or any image formats (jpeg, png,
// ...).
//
// The width, height and pixel-aspect-ratio can also be specified in the output
// caps.
//
// callback will be called after conversion, when an error occurred or if
// conversion didn't finish after timeout. callback will always be called from
// the thread default GMainContext, see g_main_context_get_thread_default().
// If GLib before 2.22 is used, this will always be the global default main
// context.
//
// destroy_notify will be called after the callback was called and user_data is
// not needed anymore.
//
// The function takes the following parameters:
//
//   - sample: Sample.
//   - toCaps to convert to.
//   - timeout: maximum amount of time allowed for the processing.
//   - callback: GstVideoConvertSampleCallback that will be called after
//     conversion.
func VideoConvertSampleAsync(sample *gst.Sample, toCaps *gst.Caps, timeout gst.ClockTime, callback VideoConvertSampleCallback) {
	var _arg1 *C.GstSample                    // out
	var _arg2 *C.GstCaps                      // out
	var _arg3 C.GstClockTime                  // out
	var _arg4 C.GstVideoConvertSampleCallback // out
	var _arg5 C.gpointer
	var _arg6 C.GDestroyNotify

	_arg1 = (*C.GstSample)(gextras.StructNative(unsafe.Pointer(sample)))
	_arg2 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(toCaps)))
	_arg3 = C.GstClockTime(timeout)
	_arg4 = (*[0]byte)(C._gotk4_gstvideo1_VideoConvertSampleCallback)
	_arg5 = C.gpointer(gbox.Assign(callback))
	_arg6 = (C.GDestroyNotify)((*[0]byte)(C.callbackDelete))

	C.gst_video_convert_sample_async(_arg1, _arg2, _arg3, _arg4, _arg5, _arg6)
	runtime.KeepAlive(sample)
	runtime.KeepAlive(toCaps)
	runtime.KeepAlive(timeout)
	runtime.KeepAlive(callback)
}

func VideoCropMetaApiGetType() coreglib.Type {
	var _cret C.GType // in

	_cret = C.gst_video_crop_meta_api_get_type()

	var _gType coreglib.Type // out

	_gType = coreglib.Type(_cret)

	return _gType
}

// VideoDmaDRMFourccFromFormat: converting the video format into dma drm fourcc.
// If no matching fourcc found, then DRM_FORMAT_INVALID is returned.
//
// The function takes the following parameters:
//
//   - format: VideoFormat.
//
// The function returns the following values:
//
//   - guint32: DRM_FORMAT_* corresponding to the format.
func VideoDmaDRMFourccFromFormat(format VideoFormat) uint32 {
	var _arg1 C.GstVideoFormat // out
	var _cret C.guint32        // in

	_arg1 = C.GstVideoFormat(format)

	_cret = C.gst_video_dma_drm_fourcc_from_format(_arg1)
	runtime.KeepAlive(format)

	var _guint32 uint32 // out

	_guint32 = uint32(_cret)

	return _guint32
}

// VideoDmaDRMFourccFromString: convert the format_str string into the drm
// fourcc value. The modifier is also parsed if we want. Please note that
// the format_str should follow the fourcc:modifier kind style, such as
// NV12:0x0100000000000002.
//
// The function takes the following parameters:
//
//   - formatStr: drm format string.
//
// The function returns the following values:
//
//   - modifier (optional): return the modifier in format or NULL to ignore.
//   - guint32: drm fourcc value or DRM_FORMAT_INVALID if format_str is invalid.
func VideoDmaDRMFourccFromString(formatStr string) (uint64, uint32) {
	var _arg1 *C.gchar  // out
	var _arg2 C.guint64 // in
	var _cret C.guint32 // in

	_arg1 = (*C.gchar)(unsafe.Pointer(C.CString(formatStr)))
	defer C.free(unsafe.Pointer(_arg1))

	_cret = C.gst_video_dma_drm_fourcc_from_string(_arg1, &_arg2)
	runtime.KeepAlive(formatStr)

	var _modifier uint64 // out
	var _guint32 uint32  // out

	_modifier = uint64(_arg2)
	_guint32 = uint32(_cret)

	return _modifier, _guint32
}

// VideoDmaDRMFourccToFormat: converting a dma drm fourcc into the video format.
// If no matching video format found, then GST_VIDEO_FORMAT_UNKNOWN is returned.
//
// The function takes the following parameters:
//
//   - fourcc: dma drm value.
//
// The function returns the following values:
//
//   - videoFormat: GST_VIDEO_FORMAT_* corresponding to the fourcc.
func VideoDmaDRMFourccToFormat(fourcc uint32) VideoFormat {
	var _arg1 C.guint32        // out
	var _cret C.GstVideoFormat // in

	_arg1 = C.guint32(fourcc)

	_cret = C.gst_video_dma_drm_fourcc_to_format(_arg1)
	runtime.KeepAlive(fourcc)

	var _videoFormat VideoFormat // out

	_videoFormat = VideoFormat(_cret)

	return _videoFormat
}

// VideoDmaDRMFourccToString returns a string containing drm kind format,
// such as NV12:0x0100000000000002, or NULL otherwise.
//
// The function takes the following parameters:
//
//   - fourcc: drm fourcc value.
//   - modifier: associated modifier value.
//
// The function returns the following values:
//
//   - utf8 (optional): drm kind string composed of to fourcc and modifier.
func VideoDmaDRMFourccToString(fourcc uint32, modifier uint64) string {
	var _arg1 C.guint32 // out
	var _arg2 C.guint64 // out
	var _cret *C.gchar  // in

	_arg1 = C.guint32(fourcc)
	_arg2 = C.guint64(modifier)

	_cret = C.gst_video_dma_drm_fourcc_to_string(_arg1, _arg2)
	runtime.KeepAlive(fourcc)
	runtime.KeepAlive(modifier)

	var _utf8 string // out

	if _cret != nil {
		_utf8 = C.GoString((*C.gchar)(unsafe.Pointer(_cret)))
		defer C.free(unsafe.Pointer(_cret))
	}

	return _utf8
}

// VideoEventIsForceKeyUnit checks if an event is a force key unit event.
// Returns true for both upstream and downstream force key unit events.
//
// The function takes the following parameters:
//
//   - event to check.
//
// The function returns the following values:
//
//   - ok: TRUE if the event is a valid force key unit event.
func VideoEventIsForceKeyUnit(event *gst.Event) bool {
	var _arg1 *C.GstEvent // out
	var _cret C.gboolean  // in

	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C.gst_video_event_is_force_key_unit(_arg1)
	runtime.KeepAlive(event)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// VideoEventNewDownstreamForceKeyUnit creates a new downstream force key unit
// event. A downstream force key unit event can be sent down the pipeline to
// request downstream elements to produce a key unit. A downstream force key
// unit event must also be sent when handling an upstream force key unit event
// to notify downstream that the latter has been handled.
//
// To parse an event created by gst_video_event_new_downstream_force_key_unit()
// use gst_video_event_parse_downstream_force_key_unit().
//
// The function takes the following parameters:
//
//   - timestamp of the buffer that starts a new key unit.
//   - streamTime: stream_time of the buffer that starts a new key unit.
//   - runningTime: running_time of the buffer that starts a new key unit.
//   - allHeaders: TRUE to produce headers when starting a new key unit.
//   - count: integer that can be used to number key units.
//
// The function returns the following values:
//
//   - event: new GstEvent.
func VideoEventNewDownstreamForceKeyUnit(timestamp, streamTime, runningTime gst.ClockTime, allHeaders bool, count uint) *gst.Event {
	var _arg1 C.GstClockTime // out
	var _arg2 C.GstClockTime // out
	var _arg3 C.GstClockTime // out
	var _arg4 C.gboolean     // out
	var _arg5 C.guint        // out
	var _cret *C.GstEvent    // in

	_arg1 = C.GstClockTime(timestamp)
	_arg2 = C.GstClockTime(streamTime)
	_arg3 = C.GstClockTime(runningTime)
	if allHeaders {
		_arg4 = C.TRUE
	}
	_arg5 = C.guint(count)

	_cret = C.gst_video_event_new_downstream_force_key_unit(_arg1, _arg2, _arg3, _arg4, _arg5)
	runtime.KeepAlive(timestamp)
	runtime.KeepAlive(streamTime)
	runtime.KeepAlive(runningTime)
	runtime.KeepAlive(allHeaders)
	runtime.KeepAlive(count)

	var _event *gst.Event // out

	_event = (*gst.Event)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_event)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _event
}

// VideoEventNewStillFrame creates a new Still Frame event. If in_still is TRUE,
// then the event represents the start of a still frame sequence. If it is
// FALSE, then the event ends a still frame sequence.
//
// To parse an event created by gst_video_event_new_still_frame() use
// gst_video_event_parse_still_frame().
//
// The function takes the following parameters:
//
//   - inStill: boolean value for the still-frame state of the event.
//
// The function returns the following values:
//
//   - event: new GstEvent.
func VideoEventNewStillFrame(inStill bool) *gst.Event {
	var _arg1 C.gboolean  // out
	var _cret *C.GstEvent // in

	if inStill {
		_arg1 = C.TRUE
	}

	_cret = C.gst_video_event_new_still_frame(_arg1)
	runtime.KeepAlive(inStill)

	var _event *gst.Event // out

	_event = (*gst.Event)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_event)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _event
}

// VideoEventNewUpstreamForceKeyUnit creates a new upstream force key unit
// event. An upstream force key unit event can be sent to request upstream
// elements to produce a key unit.
//
// running_time can be set to request a new key unit at a specific running_time.
// If set to GST_CLOCK_TIME_NONE, upstream elements will produce a new key unit
// as soon as possible.
//
// To parse an event created by gst_video_event_new_downstream_force_key_unit()
// use gst_video_event_parse_downstream_force_key_unit().
//
// The function takes the following parameters:
//
//   - runningTime: running_time at which a new key unit should be produced.
//   - allHeaders: TRUE to produce headers when starting a new key unit.
//   - count: integer that can be used to number key units.
//
// The function returns the following values:
//
//   - event: new GstEvent.
func VideoEventNewUpstreamForceKeyUnit(runningTime gst.ClockTime, allHeaders bool, count uint) *gst.Event {
	var _arg1 C.GstClockTime // out
	var _arg2 C.gboolean     // out
	var _arg3 C.guint        // out
	var _cret *C.GstEvent    // in

	_arg1 = C.GstClockTime(runningTime)
	if allHeaders {
		_arg2 = C.TRUE
	}
	_arg3 = C.guint(count)

	_cret = C.gst_video_event_new_upstream_force_key_unit(_arg1, _arg2, _arg3)
	runtime.KeepAlive(runningTime)
	runtime.KeepAlive(allHeaders)
	runtime.KeepAlive(count)

	var _event *gst.Event // out

	_event = (*gst.Event)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_event)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _event
}

// VideoEventParseDownstreamForceKeyUnit: get timestamp, stream-time,
// running-time, all-headers and count in the force key unit event. See
// gst_video_event_new_downstream_force_key_unit() for a full description of the
// downstream force key unit event.
//
// running_time will be adjusted for any pad offsets of pads it was passing
// through.
//
// The function takes the following parameters:
//
//   - event to parse.
//
// The function returns the following values:
//
//   - timestamp: pointer to the timestamp in the event.
//   - streamTime: pointer to the stream-time in the event.
//   - runningTime: pointer to the running-time in the event.
//   - allHeaders: pointer to the all_headers flag in the event.
//   - count: pointer to the count field of the event.
//   - ok: TRUE if the event is a valid downstream force key unit event.
func VideoEventParseDownstreamForceKeyUnit(event *gst.Event) (timestamp, streamTime, runningTime gst.ClockTime, allHeaders bool, count uint, ok bool) {
	var _arg1 *C.GstEvent    // out
	var _arg2 C.GstClockTime // in
	var _arg3 C.GstClockTime // in
	var _arg4 C.GstClockTime // in
	var _arg5 C.gboolean     // in
	var _arg6 C.guint        // in
	var _cret C.gboolean     // in

	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C.gst_video_event_parse_downstream_force_key_unit(_arg1, &_arg2, &_arg3, &_arg4, &_arg5, &_arg6)
	runtime.KeepAlive(event)

	var _timestamp gst.ClockTime   // out
	var _streamTime gst.ClockTime  // out
	var _runningTime gst.ClockTime // out
	var _allHeaders bool           // out
	var _count uint                // out
	var _ok bool                   // out

	_timestamp = gst.ClockTime(_arg2)
	_streamTime = gst.ClockTime(_arg3)
	_runningTime = gst.ClockTime(_arg4)
	if _arg5 != 0 {
		_allHeaders = true
	}
	_count = uint(_arg6)
	if _cret != 0 {
		_ok = true
	}

	return _timestamp, _streamTime, _runningTime, _allHeaders, _count, _ok
}

// VideoEventParseStillFrame: parse a Event, identify if it is a Still Frame
// event, and return the still-frame state from the event if it is. If the event
// represents the start of a still frame, the in_still variable will be set to
// TRUE, otherwise FALSE. It is OK to pass NULL for the in_still variable order
// to just check whether the event is a valid still-frame event.
//
// Create a still frame event using gst_video_event_new_still_frame().
//
// The function takes the following parameters:
//
//   - event to parse.
//
// The function returns the following values:
//
//   - inStill: A boolean to receive the still-frame status from the event,
//     or NULL.
//   - ok: TRUE if the event is a valid still-frame event. FALSE if not.
func VideoEventParseStillFrame(event *gst.Event) (inStill, ok bool) {
	var _arg1 *C.GstEvent // out
	var _arg2 C.gboolean  // in
	var _cret C.gboolean  // in

	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C.gst_video_event_parse_still_frame(_arg1, &_arg2)
	runtime.KeepAlive(event)

	var _inStill bool // out
	var _ok bool      // out

	if _arg2 != 0 {
		_inStill = true
	}
	if _cret != 0 {
		_ok = true
	}

	return _inStill, _ok
}

// VideoEventParseUpstreamForceKeyUnit: get running-time,
// all-headers and count in the force key unit event. See
// gst_video_event_new_upstream_force_key_unit() for a full description of the
// upstream force key unit event.
//
// Create an upstream force key unit event using
// gst_video_event_new_upstream_force_key_unit()
//
// running_time will be adjusted for any pad offsets of pads it was passing
// through.
//
// The function takes the following parameters:
//
//   - event to parse.
//
// The function returns the following values:
//
//   - runningTime: pointer to the running_time in the event.
//   - allHeaders: pointer to the all_headers flag in the event.
//   - count: pointer to the count field in the event.
//   - ok: TRUE if the event is a valid upstream force-key-unit event. FALSE if
//     not.
func VideoEventParseUpstreamForceKeyUnit(event *gst.Event) (runningTime gst.ClockTime, allHeaders bool, count uint, ok bool) {
	var _arg1 *C.GstEvent    // out
	var _arg2 C.GstClockTime // in
	var _arg3 C.gboolean     // in
	var _arg4 C.guint        // in
	var _cret C.gboolean     // in

	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C.gst_video_event_parse_upstream_force_key_unit(_arg1, &_arg2, &_arg3, &_arg4)
	runtime.KeepAlive(event)

	var _runningTime gst.ClockTime // out
	var _allHeaders bool           // out
	var _count uint                // out
	var _ok bool                   // out

	_runningTime = gst.ClockTime(_arg2)
	if _arg3 != 0 {
		_allHeaders = true
	}
	_count = uint(_arg4)
	if _cret != 0 {
		_ok = true
	}

	return _runningTime, _allHeaders, _count, _ok
}

// VideoFormatsAny: return all the raw video formats supported by GStreamer
// including special opaque formats such as GST_VIDEO_FORMAT_DMA_DRM for which
// no software conversion exists. This should be use for passthrough template
// cpas.
//
// The function returns the following values:
//
//   - videoFormats: array of VideoFormat.
func VideoFormatsAny() []VideoFormat {
	var _cret *C.GstVideoFormat // in
	var _arg1 C.guint           // in

	_cret = C.gst_video_formats_any(&_arg1)

	var _videoFormats []VideoFormat // out

	_videoFormats = make([]VideoFormat, _arg1)
	copy(_videoFormats, unsafe.Slice((*VideoFormat)(unsafe.Pointer(_cret)), _arg1))

	return _videoFormats
}

// VideoFormatsRaw: return all the raw video formats supported by GStreamer.
//
// The function returns the following values:
//
//   - videoFormats: array of VideoFormat.
func VideoFormatsRaw() []VideoFormat {
	var _cret *C.GstVideoFormat // in
	var _arg1 C.guint           // in

	_cret = C.gst_video_formats_raw(&_arg1)

	var _videoFormats []VideoFormat // out

	_videoFormats = make([]VideoFormat, _arg1)
	copy(_videoFormats, unsafe.Slice((*VideoFormat)(unsafe.Pointer(_cret)), _arg1))

	return _videoFormats
}

func VideoGLTextureUploadMetaApiGetType() coreglib.Type {
	var _cret C.GType // in

	_cret = C.gst_video_gl_texture_upload_meta_api_get_type()

	var _gType coreglib.Type // out

	_gType = coreglib.Type(_cret)

	return _gType
}

// VideoGuessFramerate: given the nominal duration of one video frame, this
// function will check some standard framerates for a close match (within 0.1%)
// and return one if possible,
//
// It will calculate an arbitrary framerate if no close match was found,
// and return FALSE.
//
// It returns FALSE if a duration of 0 is passed.
//
// The function takes the following parameters:
//
//   - duration: nominal duration of one frame.
//
// The function returns the following values:
//
//   - destN (optional): numerator of the calculated framerate.
//   - destD (optional): denominator of the calculated framerate.
//   - ok: TRUE if a close "standard" framerate was recognised, and FALSE
//     otherwise.
func VideoGuessFramerate(duration gst.ClockTime) (destN, destD int, ok bool) {
	var _arg1 C.GstClockTime // out
	var _arg2 C.gint         // in
	var _arg3 C.gint         // in
	var _cret C.gboolean     // in

	_arg1 = C.GstClockTime(duration)

	_cret = C.gst_video_guess_framerate(_arg1, &_arg2, &_arg3)
	runtime.KeepAlive(duration)

	var _destN int // out
	var _destD int // out
	var _ok bool   // out

	_destN = int(_arg2)
	_destD = int(_arg3)
	if _cret != 0 {
		_ok = true
	}

	return _destN, _destD, _ok
}

// VideoIsCommonAspectRatio: given a frame's dimensions and pixel aspect ratio,
// this function will calculate the frame's aspect ratio and compare it against
// a set of common well-known "standard" aspect ratios.
//
// The function takes the following parameters:
//
//   - width: width of the video frame.
//   - height: height of the video frame.
//   - parN: pixel aspect ratio numerator.
//   - parD: pixel aspect ratio denominator.
//
// The function returns the following values:
//
//   - ok: TRUE if a known "standard" aspect ratio was recognised, and FALSE
//     otherwise.
func VideoIsCommonAspectRatio(width, height, parN, parD int) bool {
	var _arg1 C.gint     // out
	var _arg2 C.gint     // out
	var _arg3 C.gint     // out
	var _arg4 C.gint     // out
	var _cret C.gboolean // in

	_arg1 = C.gint(width)
	_arg2 = C.gint(height)
	_arg3 = C.gint(parN)
	_arg4 = C.gint(parD)

	_cret = C.gst_video_is_common_aspect_ratio(_arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(width)
	runtime.KeepAlive(height)
	runtime.KeepAlive(parN)
	runtime.KeepAlive(parD)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// VideoIsDmaDRMCaps: check whether the caps is a dma drm kind caps. Please note
// that the caps should be fixed.
//
// The function takes the following parameters:
//
//   - caps: Caps.
//
// The function returns the following values:
//
//   - ok: TRUE if the caps is a dma drm caps.
func VideoIsDmaDRMCaps(caps *gst.Caps) bool {
	var _arg1 *C.GstCaps // out
	var _cret C.gboolean // in

	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C.gst_video_is_dma_drm_caps(_arg1)
	runtime.KeepAlive(caps)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// VideoMakeRawCaps: return a generic raw video caps for formats defined in
// formats. If formats is NULL returns a caps for all the supported raw video
// formats, see gst_video_formats_raw().
//
// The function takes the following parameters:
//
//   - formats (optional): array of raw VideoFormat, or NULL.
//
// The function returns the following values:
//
//   - caps: video GstCaps.
func VideoMakeRawCaps(formats []VideoFormat) *gst.Caps {
	var _arg1 *C.GstVideoFormat // out
	var _arg2 C.guint
	var _cret *C.GstCaps // in

	_arg2 = (C.guint)(len(formats))
	if len(formats) > 0 {
		_arg1 = (*C.GstVideoFormat)(unsafe.Pointer(&formats[0]))
	}

	_cret = C.gst_video_make_raw_caps(_arg1, _arg2)
	runtime.KeepAlive(formats)

	var _caps *gst.Caps // out

	_caps = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_caps)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _caps
}

// VideoMakeRawCapsWithFeatures: return a generic raw video caps for formats
// defined in formats with features features. If formats is NULL returns a caps
// for all the supported video formats, see gst_video_formats_raw().
//
// The function takes the following parameters:
//
//   - formats (optional): array of raw VideoFormat, or NULL.
//   - features (optional) to set on the caps.
//
// The function returns the following values:
//
//   - caps: video GstCaps.
func VideoMakeRawCapsWithFeatures(formats []VideoFormat, features *gst.CapsFeatures) *gst.Caps {
	var _arg1 *C.GstVideoFormat // out
	var _arg2 C.guint
	var _arg3 *C.GstCapsFeatures // out
	var _cret *C.GstCaps         // in

	_arg2 = (C.guint)(len(formats))
	if len(formats) > 0 {
		_arg1 = (*C.GstVideoFormat)(unsafe.Pointer(&formats[0]))
	}
	if features != nil {
		_arg3 = (*C.GstCapsFeatures)(gextras.StructNative(unsafe.Pointer(features)))
		runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(features)), nil)
	}

	_cret = C.gst_video_make_raw_caps_with_features(_arg1, _arg2, _arg3)
	runtime.KeepAlive(formats)
	runtime.KeepAlive(features)

	var _caps *gst.Caps // out

	_caps = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_caps)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _caps
}

func VideoMetaApiGetType() coreglib.Type {
	var _cret C.GType // in

	_cret = C.gst_video_meta_api_get_type()

	var _gType coreglib.Type // out

	_gType = coreglib.Type(_cret)

	return _gType
}

// The function returns the following values:
//
//   - value: const #GValue containing a list of stereo video modes
//
//     Utility function that returns a #GValue with a GstList of packed stereo
//     video modes with double the height of a single view for use in caps
//     negotiations. Currently this is top-bottom and row-interleaved.
func VideoMultiviewGetDoubledHeightModes() *coreglib.Value {
	var _cret *C.GValue // in

	_cret = C.gst_video_multiview_get_doubled_height_modes()

	var _value *coreglib.Value // out

	_value = coreglib.ValueFromNative(unsafe.Pointer(_cret))

	return _value
}

// The function returns the following values:
//
//   - value: const #GValue containing a list of stereo video modes
//
//     Utility function that returns a #GValue with a GstList of packed stereo
//     video modes that have double the width/height of a single view for use in
//     caps negotiation. Currently this is just 'checkerboard' layout.
func VideoMultiviewGetDoubledSizeModes() *coreglib.Value {
	var _cret *C.GValue // in

	_cret = C.gst_video_multiview_get_doubled_size_modes()

	var _value *coreglib.Value // out

	_value = coreglib.ValueFromNative(unsafe.Pointer(_cret))

	return _value
}

// The function returns the following values:
//
//   - value: const #GValue containing a list of stereo video modes
//
//     Utility function that returns a #GValue with a GstList of packed stereo
//     video modes with double the width of a single view for use in caps
//     negotiations. Currently this is side-by-side, side-by-side-quincunx and
//     column-interleaved.
func VideoMultiviewGetDoubledWidthModes() *coreglib.Value {
	var _cret *C.GValue // in

	_cret = C.gst_video_multiview_get_doubled_width_modes()

	var _value *coreglib.Value // out

	_value = coreglib.ValueFromNative(unsafe.Pointer(_cret))

	return _value
}

// The function returns the following values:
//
//   - value: const #GValue containing a list of mono video modes
//
//     Utility function that returns a #GValue with a GstList of mono video
//     modes (mono/left/right) for use in caps negotiations.
func VideoMultiviewGetMonoModes() *coreglib.Value {
	var _cret *C.GValue // in

	_cret = C.gst_video_multiview_get_mono_modes()

	var _value *coreglib.Value // out

	_value = coreglib.ValueFromNative(unsafe.Pointer(_cret))

	return _value
}

// The function returns the following values:
//
//   - value: const #GValue containing a list of 'unpacked' stereo video modes
//
//     Utility function that returns a #GValue with a GstList of unpacked stereo
//     video modes (separated/frame-by-frame/frame-by-frame-multiview) for use
//     in caps negotiations.
func VideoMultiviewGetUnpackedModes() *coreglib.Value {
	var _cret *C.GValue // in

	_cret = C.gst_video_multiview_get_unpacked_modes()

	var _value *coreglib.Value // out

	_value = coreglib.ValueFromNative(unsafe.Pointer(_cret))

	return _value
}

// The function takes the following parameters:
//
//   - mvMode: VideoMultiviewMode.
//   - width: video frame width in pixels.
//   - height: video frame height in pixels.
//   - parN: numerator of the video pixel-aspect-ratio.
//   - parD: denominator of the video pixel-aspect-ratio.
//
// The function returns the following values:
//
//   - ok: boolean indicating whether the T_VIDEO_MULTIVIEW_FLAGS_HALF_ASPECT
//     flag should be set.
//
//     Utility function that heuristically guess whether a frame-packed
//     stereoscopic video contains half width/height encoded views, or
//     full-frame views by looking at the overall display aspect ratio.
func VideoMultiviewGuessHalfAspect(mvMode VideoMultiviewMode, width, height, parN, parD uint) bool {
	var _arg1 C.GstVideoMultiviewMode // out
	var _arg2 C.guint                 // out
	var _arg3 C.guint                 // out
	var _arg4 C.guint                 // out
	var _arg5 C.guint                 // out
	var _cret C.gboolean              // in

	_arg1 = C.GstVideoMultiviewMode(mvMode)
	_arg2 = C.guint(width)
	_arg3 = C.guint(height)
	_arg4 = C.guint(parN)
	_arg5 = C.guint(parD)

	_cret = C.gst_video_multiview_guess_half_aspect(_arg1, _arg2, _arg3, _arg4, _arg5)
	runtime.KeepAlive(mvMode)
	runtime.KeepAlive(width)
	runtime.KeepAlive(height)
	runtime.KeepAlive(parN)
	runtime.KeepAlive(parD)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// VideoMultiviewVideoInfoChangeMode: utility function that transforms the
// width/height/PAR and multiview mode and flags of a VideoInfo into the
// requested mode.
//
// The function takes the following parameters:
//
//   - info structure to operate on.
//   - outMviewMode: VideoMultiviewMode value.
//   - outMviewFlags: set of VideoMultiviewFlags.
func VideoMultiviewVideoInfoChangeMode(info *VideoInfo, outMviewMode VideoMultiviewMode, outMviewFlags VideoMultiviewFlags) {
	var _arg1 *C.GstVideoInfo          // out
	var _arg2 C.GstVideoMultiviewMode  // out
	var _arg3 C.GstVideoMultiviewFlags // out

	_arg1 = (*C.GstVideoInfo)(gextras.StructNative(unsafe.Pointer(info)))
	_arg2 = C.GstVideoMultiviewMode(outMviewMode)
	_arg3 = C.GstVideoMultiviewFlags(outMviewFlags)

	C.gst_video_multiview_video_info_change_mode(_arg1, _arg2, _arg3)
	runtime.KeepAlive(info)
	runtime.KeepAlive(outMviewMode)
	runtime.KeepAlive(outMviewFlags)
}

func VideoOverlayCompositionMetaApiGetType() coreglib.Type {
	var _cret C.GType // in

	_cret = C.gst_video_overlay_composition_meta_api_get_type()

	var _gType coreglib.Type // out

	_gType = coreglib.Type(_cret)

	return _gType
}

func VideoRegionOfInterestMetaApiGetType() coreglib.Type {
	var _cret C.GType // in

	_cret = C.gst_video_region_of_interest_meta_api_get_type()

	var _gType coreglib.Type // out

	_gType = coreglib.Type(_cret)

	return _gType
}

// The function returns the following values:
//
//   - gType for the VideoSEIUserDataUnregisteredMeta structure.
func VideoSeiUserDataUnregisteredMetaApiGetType() coreglib.Type {
	var _cret C.GType // in

	_cret = C.gst_video_sei_user_data_unregistered_meta_api_get_type()

	var _gType coreglib.Type // out

	_gType = coreglib.Type(_cret)

	return _gType
}

// VideoSeiUserDataUnregisteredParsePrecisionTimeStamp parses and returns the
// Precision Time Stamp (ST 0604) from the SEI User Data Unregistered buffer.
//
// The function takes the following parameters:
//
//   - userData: VideoSEIUserDataUnregisteredMeta.
//
// The function returns the following values:
//
//   - status: user Data Unregistered UUID.
//   - precisionTimeStamp: parsed Precision Time Stamp SEI.
//   - ok: true if data is a Precision Time Stamp and it was parsed correctly.
func VideoSeiUserDataUnregisteredParsePrecisionTimeStamp(userData *VideoSEIUserDataUnregisteredMeta) (byte, uint64, bool) {
	var _arg1 *C.GstVideoSEIUserDataUnregisteredMeta // out
	var _arg2 C.guint8                               // in
	var _arg3 C.guint64                              // in
	var _cret C.gboolean                             // in

	_arg1 = (*C.GstVideoSEIUserDataUnregisteredMeta)(gextras.StructNative(unsafe.Pointer(userData)))

	_cret = C.gst_video_sei_user_data_unregistered_parse_precision_time_stamp(_arg1, &_arg2, &_arg3)
	runtime.KeepAlive(userData)

	var _status byte               // out
	var _precisionTimeStamp uint64 // out
	var _ok bool                   // out

	_status = byte(_arg2)
	_precisionTimeStamp = uint64(_arg3)
	if _cret != 0 {
		_ok = true
	}

	return _status, _precisionTimeStamp, _ok
}

// VideoTileGetIndex: get the tile index of the tile at coordinates x and y in
// the tiled image of x_tiles by y_tiles.
//
// Use this method when mode is of type GST_VIDEO_TILE_TYPE_INDEXED.
//
// The function takes the following parameters:
//
//   - mode: VideoTileMode.
//   - x coordinate.
//   - y coordinate.
//   - xTiles: number of horizintal tiles.
//   - yTiles: number of vertical tiles.
//
// The function returns the following values:
//
//   - guint: index of the tile at x and y in the tiled image of x_tiles by
//     y_tiles.
func VideoTileGetIndex(mode VideoTileMode, x, y, xTiles, yTiles int) uint {
	var _arg1 C.GstVideoTileMode // out
	var _arg2 C.gint             // out
	var _arg3 C.gint             // out
	var _arg4 C.gint             // out
	var _arg5 C.gint             // out
	var _cret C.guint            // in

	_arg1 = C.GstVideoTileMode(mode)
	_arg2 = C.gint(x)
	_arg3 = C.gint(y)
	_arg4 = C.gint(xTiles)
	_arg5 = C.gint(yTiles)

	_cret = C.gst_video_tile_get_index(_arg1, _arg2, _arg3, _arg4, _arg5)
	runtime.KeepAlive(mode)
	runtime.KeepAlive(x)
	runtime.KeepAlive(y)
	runtime.KeepAlive(xTiles)
	runtime.KeepAlive(yTiles)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

func VideoTimeCodeMetaApiGetType() coreglib.Type {
	var _cret C.GType // in

	_cret = C.gst_video_time_code_meta_api_get_type()

	var _gType coreglib.Type // out

	_gType = coreglib.Type(_cret)

	return _gType
}

// ColorBalance: this interface is implemented by elements which can perform
// some color balance operation on video frames they process. For example,
// modifying the brightness, contrast, hue or saturation.
//
// Example elements are 'xvimagesink' and 'colorbalance'.
//
// ColorBalance wraps an interface. This means the user can get the
// underlying type by calling Cast().
type ColorBalance struct {
	_ [0]func() // equal guard
	*coreglib.Object
}

var (
	_ coreglib.Objector = (*ColorBalance)(nil)
)

// ColorBalancer describes ColorBalance's interface methods.
type ColorBalancer interface {
	coreglib.Objector

	// BalanceType: get the ColorBalanceType of this implementation.
	BalanceType() ColorBalanceType
	// Value: retrieve the current value of the indicated channel, between
	// min_value and max_value.
	Value(channel *ColorBalanceChannel) int
	// ListChannels: retrieve a list of the available channels.
	ListChannels() []*ColorBalanceChannel
	// SetValue sets the current value of the channel to the passed value,
	// which must be between min_value and max_value.
	SetValue(channel *ColorBalanceChannel, value int)
	// ValueChanged: helper function called by implementations of the
	// GstColorBalance interface.
	ValueChanged(channel *ColorBalanceChannel, value int)

	// Value-changed: fired when the value of the indicated channel has changed.
	ConnectValueChanged(func(channel *ColorBalanceChannel, value int)) coreglib.SignalHandle
}

var _ ColorBalancer = (*ColorBalance)(nil)

func wrapColorBalance(obj *coreglib.Object) *ColorBalance {
	return &ColorBalance{
		Object: obj,
	}
}

func marshalColorBalance(p uintptr) (interface{}, error) {
	return wrapColorBalance(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

// ConnectValueChanged: fired when the value of the indicated channel has
// changed.
func (balance *ColorBalance) ConnectValueChanged(f func(channel *ColorBalanceChannel, value int)) coreglib.SignalHandle {
	return coreglib.ConnectGeneratedClosure(balance, "value-changed", false, unsafe.Pointer(C._gotk4_gstvideo1_ColorBalance_ConnectValueChanged), f)
}

// BalanceType: get the ColorBalanceType of this implementation.
//
// The function returns the following values:
//
//   - colorBalanceType: the ColorBalanceType.
func (balance *ColorBalance) BalanceType() ColorBalanceType {
	var _arg0 *C.GstColorBalance    // out
	var _cret C.GstColorBalanceType // in

	_arg0 = (*C.GstColorBalance)(unsafe.Pointer(coreglib.BaseObject(balance).Native()))

	_cret = C.gst_color_balance_get_balance_type(_arg0)
	runtime.KeepAlive(balance)

	var _colorBalanceType ColorBalanceType // out

	_colorBalanceType = ColorBalanceType(_cret)

	return _colorBalanceType
}

// Value: retrieve the current value of the indicated channel, between min_value
// and max_value.
//
// See Also: The ColorBalanceChannel.min_value and ColorBalanceChannel.max_value
// members of the ColorBalanceChannel object.
//
// The function takes the following parameters:
//
//   - channel: ColorBalanceChannel instance.
//
// The function returns the following values:
//
//   - gint: current value of the channel.
func (balance *ColorBalance) Value(channel *ColorBalanceChannel) int {
	var _arg0 *C.GstColorBalance        // out
	var _arg1 *C.GstColorBalanceChannel // out
	var _cret C.gint                    // in

	_arg0 = (*C.GstColorBalance)(unsafe.Pointer(coreglib.BaseObject(balance).Native()))
	_arg1 = (*C.GstColorBalanceChannel)(unsafe.Pointer(coreglib.BaseObject(channel).Native()))

	_cret = C.gst_color_balance_get_value(_arg0, _arg1)
	runtime.KeepAlive(balance)
	runtime.KeepAlive(channel)

	var _gint int // out

	_gint = int(_cret)

	return _gint
}

// ListChannels: retrieve a list of the available channels.
//
// The function returns the following values:
//
//   - list: a GList containing pointers to ColorBalanceChannel objects.
//     The list is owned by the ColorBalance instance and must not be freed.
func (balance *ColorBalance) ListChannels() []*ColorBalanceChannel {
	var _arg0 *C.GstColorBalance // out
	var _cret *C.GList           // in

	_arg0 = (*C.GstColorBalance)(unsafe.Pointer(coreglib.BaseObject(balance).Native()))

	_cret = C.gst_color_balance_list_channels(_arg0)
	runtime.KeepAlive(balance)

	var _list []*ColorBalanceChannel // out

	_list = make([]*ColorBalanceChannel, 0, gextras.ListSize(unsafe.Pointer(_cret)))
	gextras.MoveList(unsafe.Pointer(_cret), false, func(v unsafe.Pointer) {
		src := (*C.GstColorBalanceChannel)(v)
		var dst *ColorBalanceChannel // out
		dst = wrapColorBalanceChannel(coreglib.Take(unsafe.Pointer(src)))
		_list = append(_list, dst)
	})

	return _list
}

// SetValue sets the current value of the channel to the passed value, which
// must be between min_value and max_value.
//
// See Also: The ColorBalanceChannel.min_value and ColorBalanceChannel.max_value
// members of the ColorBalanceChannel object.
//
// The function takes the following parameters:
//
//   - channel: ColorBalanceChannel instance.
//   - value: new value for the channel.
func (balance *ColorBalance) SetValue(channel *ColorBalanceChannel, value int) {
	var _arg0 *C.GstColorBalance        // out
	var _arg1 *C.GstColorBalanceChannel // out
	var _arg2 C.gint                    // out

	_arg0 = (*C.GstColorBalance)(unsafe.Pointer(coreglib.BaseObject(balance).Native()))
	_arg1 = (*C.GstColorBalanceChannel)(unsafe.Pointer(coreglib.BaseObject(channel).Native()))
	_arg2 = C.gint(value)

	C.gst_color_balance_set_value(_arg0, _arg1, _arg2)
	runtime.KeepAlive(balance)
	runtime.KeepAlive(channel)
	runtime.KeepAlive(value)
}

// ValueChanged: helper function called by implementations of the
// GstColorBalance interface. It fires the ColorBalance::value-changed signal
// on the instance, and the ColorBalanceChannel::value-changed signal on the
// channel object.
//
// The function takes the following parameters:
//
//   - channel whose value has changed.
//   - value: new value of the channel.
func (balance *ColorBalance) ValueChanged(channel *ColorBalanceChannel, value int) {
	var _arg0 *C.GstColorBalance        // out
	var _arg1 *C.GstColorBalanceChannel // out
	var _arg2 C.gint                    // out

	_arg0 = (*C.GstColorBalance)(unsafe.Pointer(coreglib.BaseObject(balance).Native()))
	_arg1 = (*C.GstColorBalanceChannel)(unsafe.Pointer(coreglib.BaseObject(channel).Native()))
	_arg2 = C.gint(value)

	C.gst_color_balance_value_changed(_arg0, _arg1, _arg2)
	runtime.KeepAlive(balance)
	runtime.KeepAlive(channel)
	runtime.KeepAlive(value)
}

// balanceType: get the ColorBalanceType of this implementation.
//
// The function returns the following values:
//
//   - colorBalanceType: the ColorBalanceType.
func (balance *ColorBalance) balanceType() ColorBalanceType {
	gclass := (*C.GstColorBalanceInterface)(coreglib.PeekParentClass(balance))
	fnarg := gclass.get_balance_type

	var _arg0 *C.GstColorBalance    // out
	var _cret C.GstColorBalanceType // in

	_arg0 = (*C.GstColorBalance)(unsafe.Pointer(coreglib.BaseObject(balance).Native()))

	_cret = C._gotk4_gstvideo1_ColorBalance_virtual_get_balance_type(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(balance)

	var _colorBalanceType ColorBalanceType // out

	_colorBalanceType = ColorBalanceType(_cret)

	return _colorBalanceType
}

// Value: retrieve the current value of the indicated channel, between min_value
// and max_value.
//
// See Also: The ColorBalanceChannel.min_value and ColorBalanceChannel.max_value
// members of the ColorBalanceChannel object.
//
// The function takes the following parameters:
//
//   - channel: ColorBalanceChannel instance.
//
// The function returns the following values:
//
//   - gint: current value of the channel.
func (balance *ColorBalance) value(channel *ColorBalanceChannel) int {
	gclass := (*C.GstColorBalanceInterface)(coreglib.PeekParentClass(balance))
	fnarg := gclass.get_value

	var _arg0 *C.GstColorBalance        // out
	var _arg1 *C.GstColorBalanceChannel // out
	var _cret C.gint                    // in

	_arg0 = (*C.GstColorBalance)(unsafe.Pointer(coreglib.BaseObject(balance).Native()))
	_arg1 = (*C.GstColorBalanceChannel)(unsafe.Pointer(coreglib.BaseObject(channel).Native()))

	_cret = C._gotk4_gstvideo1_ColorBalance_virtual_get_value(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(balance)
	runtime.KeepAlive(channel)

	var _gint int // out

	_gint = int(_cret)

	return _gint
}

// listChannels: retrieve a list of the available channels.
//
// The function returns the following values:
//
//   - list: a GList containing pointers to ColorBalanceChannel objects.
//     The list is owned by the ColorBalance instance and must not be freed.
func (balance *ColorBalance) listChannels() []*ColorBalanceChannel {
	gclass := (*C.GstColorBalanceInterface)(coreglib.PeekParentClass(balance))
	fnarg := gclass.list_channels

	var _arg0 *C.GstColorBalance // out
	var _cret *C.GList           // in

	_arg0 = (*C.GstColorBalance)(unsafe.Pointer(coreglib.BaseObject(balance).Native()))

	_cret = C._gotk4_gstvideo1_ColorBalance_virtual_list_channels(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(balance)

	var _list []*ColorBalanceChannel // out

	_list = make([]*ColorBalanceChannel, 0, gextras.ListSize(unsafe.Pointer(_cret)))
	gextras.MoveList(unsafe.Pointer(_cret), false, func(v unsafe.Pointer) {
		src := (*C.GstColorBalanceChannel)(v)
		var dst *ColorBalanceChannel // out
		dst = wrapColorBalanceChannel(coreglib.Take(unsafe.Pointer(src)))
		_list = append(_list, dst)
	})

	return _list
}

// setValue sets the current value of the channel to the passed value, which
// must be between min_value and max_value.
//
// See Also: The ColorBalanceChannel.min_value and ColorBalanceChannel.max_value
// members of the ColorBalanceChannel object.
//
// The function takes the following parameters:
//
//   - channel: ColorBalanceChannel instance.
//   - value: new value for the channel.
func (balance *ColorBalance) setValue(channel *ColorBalanceChannel, value int) {
	gclass := (*C.GstColorBalanceInterface)(coreglib.PeekParentClass(balance))
	fnarg := gclass.set_value

	var _arg0 *C.GstColorBalance        // out
	var _arg1 *C.GstColorBalanceChannel // out
	var _arg2 C.gint                    // out

	_arg0 = (*C.GstColorBalance)(unsafe.Pointer(coreglib.BaseObject(balance).Native()))
	_arg1 = (*C.GstColorBalanceChannel)(unsafe.Pointer(coreglib.BaseObject(channel).Native()))
	_arg2 = C.gint(value)

	C._gotk4_gstvideo1_ColorBalance_virtual_set_value(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(balance)
	runtime.KeepAlive(channel)
	runtime.KeepAlive(value)
}

// valueChanged: helper function called by implementations of the
// GstColorBalance interface. It fires the ColorBalance::value-changed signal
// on the instance, and the ColorBalanceChannel::value-changed signal on the
// channel object.
//
// The function takes the following parameters:
//
//   - channel whose value has changed.
//   - value: new value of the channel.
func (balance *ColorBalance) valueChanged(channel *ColorBalanceChannel, value int) {
	gclass := (*C.GstColorBalanceInterface)(coreglib.PeekParentClass(balance))
	fnarg := gclass.value_changed

	var _arg0 *C.GstColorBalance        // out
	var _arg1 *C.GstColorBalanceChannel // out
	var _arg2 C.gint                    // out

	_arg0 = (*C.GstColorBalance)(unsafe.Pointer(coreglib.BaseObject(balance).Native()))
	_arg1 = (*C.GstColorBalanceChannel)(unsafe.Pointer(coreglib.BaseObject(channel).Native()))
	_arg2 = C.gint(value)

	C._gotk4_gstvideo1_ColorBalance_virtual_value_changed(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(balance)
	runtime.KeepAlive(channel)
	runtime.KeepAlive(value)
}

// Navigation interface is used for creating and injecting navigation related
// events such as mouse button presses, cursor motion and key presses.
// The associated library also provides methods for parsing received events,
// and for sending and receiving navigation related bus events. One main usecase
// is DVD menu navigation.
//
// The main parts of the API are:
//
// * The GstNavigation interface, implemented by elements which provide an
// application with the ability to create and inject navigation events into
// the pipeline. * GstNavigation event handling API. GstNavigation events are
// created in response to calls on a GstNavigation interface implementation,
// and sent in the pipeline. Upstream elements can use the navigation event API
// functions to parse the contents of received messages.
//
// * GstNavigation message handling API. GstNavigation messages may be sent on
// the message bus to inform applications of navigation related changes in the
// pipeline, such as the mouse moving over a clickable region, or the set of
// available angles changing.
//
// The GstNavigation message functions provide functions for creating and
// parsing custom bus messages for signaling GstNavigation changes.
//
// Navigation wraps an interface. This means the user can get the
// underlying type by calling Cast().
type Navigation struct {
	_ [0]func() // equal guard
	*coreglib.Object
}

var (
	_ coreglib.Objector = (*Navigation)(nil)
)

// Navigationer describes Navigation's interface methods.
type Navigationer interface {
	coreglib.Objector

	// SendCommand sends the indicated command to the navigation interface.
	SendCommand(command NavigationCommand)
	SendEvent(structure *gst.Structure)
	// SendEventSimple sends an event to the navigation interface.
	SendEventSimple(event *gst.Event)
	SendKeyEvent(event, key string)
	// SendMouseEvent sends a mouse event to the navigation interface.
	SendMouseEvent(event string, button int, x, y float64)
	// SendMouseScrollEvent sends a mouse scroll event to the navigation
	// interface.
	SendMouseScrollEvent(x, y, deltaX, deltaY float64)
}

var _ Navigationer = (*Navigation)(nil)

func wrapNavigation(obj *coreglib.Object) *Navigation {
	return &Navigation{
		Object: obj,
	}
}

func marshalNavigation(p uintptr) (interface{}, error) {
	return wrapNavigation(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

// SendCommand sends the indicated command to the navigation interface.
//
// The function takes the following parameters:
//
//   - command to issue.
func (navigation *Navigation) SendCommand(command NavigationCommand) {
	var _arg0 *C.GstNavigation       // out
	var _arg1 C.GstNavigationCommand // out

	_arg0 = (*C.GstNavigation)(unsafe.Pointer(coreglib.BaseObject(navigation).Native()))
	_arg1 = C.GstNavigationCommand(command)

	C.gst_navigation_send_command(_arg0, _arg1)
	runtime.KeepAlive(navigation)
	runtime.KeepAlive(command)
}

func (navigation *Navigation) SendEvent(structure *gst.Structure) {
	var _arg0 *C.GstNavigation // out
	var _arg1 *C.GstStructure  // out

	_arg0 = (*C.GstNavigation)(unsafe.Pointer(coreglib.BaseObject(navigation).Native()))
	_arg1 = (*C.GstStructure)(gextras.StructNative(unsafe.Pointer(structure)))

	C.gst_navigation_send_event(_arg0, _arg1)
	runtime.KeepAlive(navigation)
	runtime.KeepAlive(structure)
}

// SendEventSimple sends an event to the navigation interface.
//
// The function takes the following parameters:
//
//   - event to send.
func (navigation *Navigation) SendEventSimple(event *gst.Event) {
	var _arg0 *C.GstNavigation // out
	var _arg1 *C.GstEvent      // out

	_arg0 = (*C.GstNavigation)(unsafe.Pointer(coreglib.BaseObject(navigation).Native()))
	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(event)), nil)

	C.gst_navigation_send_event_simple(_arg0, _arg1)
	runtime.KeepAlive(navigation)
	runtime.KeepAlive(event)
}

// The function takes the following parameters:
//
//   - event: type of the key event. Recognised values are "key-press" and
//     "key-release".
//   - key: character representation of the key. This is typically as produced
//     by XKeysymToString.
func (navigation *Navigation) SendKeyEvent(event, key string) {
	var _arg0 *C.GstNavigation // out
	var _arg1 *C.char          // out
	var _arg2 *C.char          // out

	_arg0 = (*C.GstNavigation)(unsafe.Pointer(coreglib.BaseObject(navigation).Native()))
	_arg1 = (*C.char)(unsafe.Pointer(C.CString(event)))
	defer C.free(unsafe.Pointer(_arg1))
	_arg2 = (*C.char)(unsafe.Pointer(C.CString(key)))
	defer C.free(unsafe.Pointer(_arg2))

	C.gst_navigation_send_key_event(_arg0, _arg1, _arg2)
	runtime.KeepAlive(navigation)
	runtime.KeepAlive(event)
	runtime.KeepAlive(key)
}

// SendMouseEvent sends a mouse event to the navigation interface. Mouse event
// coordinates are sent relative to the display space of the related output
// area. This is usually the size in pixels of the window associated with the
// element implementing the Navigation interface.
//
// The function takes the following parameters:
//
//   - event: type of mouse event, as a text string. Recognised values are
//     "mouse-button-press", "mouse-button-release" and "mouse-move".
//   - button number of the button being pressed or released. Pass 0 for
//     mouse-move events.
//   - x coordinate of the mouse event.
//   - y coordinate of the mouse event.
func (navigation *Navigation) SendMouseEvent(event string, button int, x, y float64) {
	var _arg0 *C.GstNavigation // out
	var _arg1 *C.char          // out
	var _arg2 C.int            // out
	var _arg3 C.double         // out
	var _arg4 C.double         // out

	_arg0 = (*C.GstNavigation)(unsafe.Pointer(coreglib.BaseObject(navigation).Native()))
	_arg1 = (*C.char)(unsafe.Pointer(C.CString(event)))
	defer C.free(unsafe.Pointer(_arg1))
	_arg2 = C.int(button)
	_arg3 = C.double(x)
	_arg4 = C.double(y)

	C.gst_navigation_send_mouse_event(_arg0, _arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(navigation)
	runtime.KeepAlive(event)
	runtime.KeepAlive(button)
	runtime.KeepAlive(x)
	runtime.KeepAlive(y)
}

// SendMouseScrollEvent sends a mouse scroll event to the navigation interface.
// Mouse event coordinates are sent relative to the display space of the related
// output area. This is usually the size in pixels of the window associated with
// the element implementing the Navigation interface.
//
// The function takes the following parameters:
//
//   - x coordinate of the mouse event.
//   - y coordinate of the mouse event.
//   - deltaX: delta_x coordinate of the mouse event.
//   - deltaY: delta_y coordinate of the mouse event.
func (navigation *Navigation) SendMouseScrollEvent(x, y, deltaX, deltaY float64) {
	var _arg0 *C.GstNavigation // out
	var _arg1 C.double         // out
	var _arg2 C.double         // out
	var _arg3 C.double         // out
	var _arg4 C.double         // out

	_arg0 = (*C.GstNavigation)(unsafe.Pointer(coreglib.BaseObject(navigation).Native()))
	_arg1 = C.double(x)
	_arg2 = C.double(y)
	_arg3 = C.double(deltaX)
	_arg4 = C.double(deltaY)

	C.gst_navigation_send_mouse_scroll_event(_arg0, _arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(navigation)
	runtime.KeepAlive(x)
	runtime.KeepAlive(y)
	runtime.KeepAlive(deltaX)
	runtime.KeepAlive(deltaY)
}

// sendEvent: sending a navigation event.
//
// Deprecated: Use NavigationInterface.send_event_simple() instead.
func (navigation *Navigation) sendEvent(structure *gst.Structure) {
	gclass := (*C.GstNavigationInterface)(coreglib.PeekParentClass(navigation))
	fnarg := gclass.send_event

	var _arg0 *C.GstNavigation // out
	var _arg1 *C.GstStructure  // out

	_arg0 = (*C.GstNavigation)(unsafe.Pointer(coreglib.BaseObject(navigation).Native()))
	_arg1 = (*C.GstStructure)(gextras.StructNative(unsafe.Pointer(structure)))

	C._gotk4_gstvideo1_Navigation_virtual_send_event(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(navigation)
	runtime.KeepAlive(structure)
}

// sendEventSimple sends an event to the navigation interface.
//
// The function takes the following parameters:
//
//   - event to send.
func (navigation *Navigation) sendEventSimple(event *gst.Event) {
	gclass := (*C.GstNavigationInterface)(coreglib.PeekParentClass(navigation))
	fnarg := gclass.send_event_simple

	var _arg0 *C.GstNavigation // out
	var _arg1 *C.GstEvent      // out

	_arg0 = (*C.GstNavigation)(unsafe.Pointer(coreglib.BaseObject(navigation).Native()))
	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(event)), nil)

	C._gotk4_gstvideo1_Navigation_virtual_send_event_simple(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(navigation)
	runtime.KeepAlive(event)
}

// NavigationEventGetCoordinates: try to retrieve x and y coordinates of a
// Navigation event.
//
// The function takes the following parameters:
//
//   - event to inspect.
//
// The function returns the following values:
//
//   - x (optional): pointer to a gdouble to receive the x coordinate of the
//     navigation event.
//   - y (optional): pointer to a gdouble to receive the y coordinate of the
//     navigation event.
//   - ok: boolean indicating success.
func NavigationEventGetCoordinates(event *gst.Event) (x, y float64, ok bool) {
	var _arg1 *C.GstEvent // out
	var _arg2 C.gdouble   // in
	var _arg3 C.gdouble   // in
	var _cret C.gboolean  // in

	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C.gst_navigation_event_get_coordinates(_arg1, &_arg2, &_arg3)
	runtime.KeepAlive(event)

	var _x float64 // out
	var _y float64 // out
	var _ok bool   // out

	_x = float64(_arg2)
	_y = float64(_arg3)
	if _cret != 0 {
		_ok = true
	}

	return _x, _y, _ok
}

// NavigationEventGetType: inspect a Event and return the NavigationEventType
// of the event, or T_NAVIGATION_EVENT_INVALID if the event is not a Navigation
// event.
//
// The function takes the following parameters:
//
//   - event to inspect.
func NavigationEventGetType(event *gst.Event) NavigationEventType {
	var _arg1 *C.GstEvent              // out
	var _cret C.GstNavigationEventType // in

	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C.gst_navigation_event_get_type(_arg1)
	runtime.KeepAlive(event)

	var _navigationEventType NavigationEventType // out

	_navigationEventType = NavigationEventType(_cret)

	return _navigationEventType
}

// NavigationEventNewCommand: create a new navigation event given navigation
// command..
//
// The function takes the following parameters:
//
//   - command: navigation command to use.
//
// The function returns the following values:
//
//   - event: new Event.
func NavigationEventNewCommand(command NavigationCommand) *gst.Event {
	var _arg1 C.GstNavigationCommand // out
	var _cret *C.GstEvent            // in

	_arg1 = C.GstNavigationCommand(command)

	_cret = C.gst_navigation_event_new_command(_arg1)
	runtime.KeepAlive(command)

	var _event *gst.Event // out

	_event = (*gst.Event)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_event)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _event
}

// NavigationEventNewKeyPress: create a new navigation event for the given key
// press.
//
// The function takes the following parameters:
//
//   - key: string identifying the key press.
//   - state: bit-mask representing the state of the modifier keys (e.g.
//     Control, Shift and Alt).
//
// The function returns the following values:
//
//   - event: new Event.
func NavigationEventNewKeyPress(key string, state NavigationModifierType) *gst.Event {
	var _arg1 *C.gchar                    // out
	var _arg2 C.GstNavigationModifierType // out
	var _cret *C.GstEvent                 // in

	_arg1 = (*C.gchar)(unsafe.Pointer(C.CString(key)))
	defer C.free(unsafe.Pointer(_arg1))
	_arg2 = C.GstNavigationModifierType(state)

	_cret = C.gst_navigation_event_new_key_press(_arg1, _arg2)
	runtime.KeepAlive(key)
	runtime.KeepAlive(state)

	var _event *gst.Event // out

	_event = (*gst.Event)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_event)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _event
}

// NavigationEventNewKeyRelease: create a new navigation event for the given key
// release.
//
// The function takes the following parameters:
//
//   - key: string identifying the released key.
//   - state: bit-mask representing the state of the modifier keys (e.g.
//     Control, Shift and Alt).
//
// The function returns the following values:
//
//   - event: new Event.
func NavigationEventNewKeyRelease(key string, state NavigationModifierType) *gst.Event {
	var _arg1 *C.gchar                    // out
	var _arg2 C.GstNavigationModifierType // out
	var _cret *C.GstEvent                 // in

	_arg1 = (*C.gchar)(unsafe.Pointer(C.CString(key)))
	defer C.free(unsafe.Pointer(_arg1))
	_arg2 = C.GstNavigationModifierType(state)

	_cret = C.gst_navigation_event_new_key_release(_arg1, _arg2)
	runtime.KeepAlive(key)
	runtime.KeepAlive(state)

	var _event *gst.Event // out

	_event = (*gst.Event)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_event)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _event
}

// NavigationEventNewMouseButtonPress: create a new navigation event for the
// given key mouse button press.
//
// The function takes the following parameters:
//
//   - button: number of the pressed mouse button.
//   - x coordinate of the mouse cursor.
//   - y coordinate of the mouse cursor.
//   - state: bit-mask representing the state of the modifier keys (e.g.
//     Control, Shift and Alt).
//
// The function returns the following values:
//
//   - event: new Event.
func NavigationEventNewMouseButtonPress(button int, x, y float64, state NavigationModifierType) *gst.Event {
	var _arg1 C.gint                      // out
	var _arg2 C.gdouble                   // out
	var _arg3 C.gdouble                   // out
	var _arg4 C.GstNavigationModifierType // out
	var _cret *C.GstEvent                 // in

	_arg1 = C.gint(button)
	_arg2 = C.gdouble(x)
	_arg3 = C.gdouble(y)
	_arg4 = C.GstNavigationModifierType(state)

	_cret = C.gst_navigation_event_new_mouse_button_press(_arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(button)
	runtime.KeepAlive(x)
	runtime.KeepAlive(y)
	runtime.KeepAlive(state)

	var _event *gst.Event // out

	_event = (*gst.Event)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_event)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _event
}

// NavigationEventNewMouseButtonRelease: create a new navigation event for the
// given key mouse button release.
//
// The function takes the following parameters:
//
//   - button: number of the released mouse button.
//   - x coordinate of the mouse cursor.
//   - y coordinate of the mouse cursor.
//   - state: bit-mask representing the state of the modifier keys (e.g.
//     Control, Shift and Alt).
//
// The function returns the following values:
//
//   - event: new Event.
func NavigationEventNewMouseButtonRelease(button int, x, y float64, state NavigationModifierType) *gst.Event {
	var _arg1 C.gint                      // out
	var _arg2 C.gdouble                   // out
	var _arg3 C.gdouble                   // out
	var _arg4 C.GstNavigationModifierType // out
	var _cret *C.GstEvent                 // in

	_arg1 = C.gint(button)
	_arg2 = C.gdouble(x)
	_arg3 = C.gdouble(y)
	_arg4 = C.GstNavigationModifierType(state)

	_cret = C.gst_navigation_event_new_mouse_button_release(_arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(button)
	runtime.KeepAlive(x)
	runtime.KeepAlive(y)
	runtime.KeepAlive(state)

	var _event *gst.Event // out

	_event = (*gst.Event)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_event)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _event
}

// NavigationEventNewMouseMove: create a new navigation event for the new mouse
// location.
//
// The function takes the following parameters:
//
//   - x coordinate of the mouse cursor.
//   - y coordinate of the mouse cursor.
//   - state: bit-mask representing the state of the modifier keys (e.g.
//     Control, Shift and Alt).
//
// The function returns the following values:
//
//   - event: new Event.
func NavigationEventNewMouseMove(x, y float64, state NavigationModifierType) *gst.Event {
	var _arg1 C.gdouble                   // out
	var _arg2 C.gdouble                   // out
	var _arg3 C.GstNavigationModifierType // out
	var _cret *C.GstEvent                 // in

	_arg1 = C.gdouble(x)
	_arg2 = C.gdouble(y)
	_arg3 = C.GstNavigationModifierType(state)

	_cret = C.gst_navigation_event_new_mouse_move(_arg1, _arg2, _arg3)
	runtime.KeepAlive(x)
	runtime.KeepAlive(y)
	runtime.KeepAlive(state)

	var _event *gst.Event // out

	_event = (*gst.Event)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_event)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _event
}

// NavigationEventNewMouseScroll: create a new navigation event for the mouse
// scroll.
//
// The function takes the following parameters:
//
//   - x coordinate of the mouse cursor.
//   - y coordinate of the mouse cursor.
//   - deltaX: x component of the scroll movement.
//   - deltaY: y component of the scroll movement.
//   - state: bit-mask representing the state of the modifier keys (e.g.
//     Control, Shift and Alt).
//
// The function returns the following values:
//
//   - event: new Event.
func NavigationEventNewMouseScroll(x, y, deltaX, deltaY float64, state NavigationModifierType) *gst.Event {
	var _arg1 C.gdouble                   // out
	var _arg2 C.gdouble                   // out
	var _arg3 C.gdouble                   // out
	var _arg4 C.gdouble                   // out
	var _arg5 C.GstNavigationModifierType // out
	var _cret *C.GstEvent                 // in

	_arg1 = C.gdouble(x)
	_arg2 = C.gdouble(y)
	_arg3 = C.gdouble(deltaX)
	_arg4 = C.gdouble(deltaY)
	_arg5 = C.GstNavigationModifierType(state)

	_cret = C.gst_navigation_event_new_mouse_scroll(_arg1, _arg2, _arg3, _arg4, _arg5)
	runtime.KeepAlive(x)
	runtime.KeepAlive(y)
	runtime.KeepAlive(deltaX)
	runtime.KeepAlive(deltaY)
	runtime.KeepAlive(state)

	var _event *gst.Event // out

	_event = (*gst.Event)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_event)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _event
}

// NavigationEventNewTouchCancel: create a new navigation event signalling that
// all currently active touch points are cancelled and should be discarded.
// For example, under Wayland this event might be sent when a swipe passes the
// threshold to be recognized as a gesture by the compositor.
//
// The function takes the following parameters:
//
//   - state: bit-mask representing the state of the modifier keys (e.g.
//     Control, Shift and Alt).
//
// The function returns the following values:
//
//   - event: new Event.
func NavigationEventNewTouchCancel(state NavigationModifierType) *gst.Event {
	var _arg1 C.GstNavigationModifierType // out
	var _cret *C.GstEvent                 // in

	_arg1 = C.GstNavigationModifierType(state)

	_cret = C.gst_navigation_event_new_touch_cancel(_arg1)
	runtime.KeepAlive(state)

	var _event *gst.Event // out

	_event = (*gst.Event)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_event)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _event
}

// NavigationEventNewTouchDown: create a new navigation event for an added touch
// point.
//
// The function takes the following parameters:
//
//   - identifier: number uniquely identifying this touch point. It must stay
//     unique to this touch point at least until an up event is sent for the
//     same identifier, or all touch points are cancelled.
//   - x coordinate of the new touch point.
//   - y coordinate of the new touch point.
//   - pressure: pressure data of the touch point, from 0.0 to 1.0, or NaN if no
//     data is available.
//   - state: bit-mask representing the state of the modifier keys (e.g.
//     Control, Shift and Alt).
//
// The function returns the following values:
//
//   - event: new Event.
func NavigationEventNewTouchDown(identifier uint, x, y, pressure float64, state NavigationModifierType) *gst.Event {
	var _arg1 C.guint                     // out
	var _arg2 C.gdouble                   // out
	var _arg3 C.gdouble                   // out
	var _arg4 C.gdouble                   // out
	var _arg5 C.GstNavigationModifierType // out
	var _cret *C.GstEvent                 // in

	_arg1 = C.guint(identifier)
	_arg2 = C.gdouble(x)
	_arg3 = C.gdouble(y)
	_arg4 = C.gdouble(pressure)
	_arg5 = C.GstNavigationModifierType(state)

	_cret = C.gst_navigation_event_new_touch_down(_arg1, _arg2, _arg3, _arg4, _arg5)
	runtime.KeepAlive(identifier)
	runtime.KeepAlive(x)
	runtime.KeepAlive(y)
	runtime.KeepAlive(pressure)
	runtime.KeepAlive(state)

	var _event *gst.Event // out

	_event = (*gst.Event)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_event)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _event
}

// NavigationEventNewTouchFrame: create a new navigation event signalling
// the end of a touch frame. Touch frames signal that all previous down,
// motion and up events not followed by another touch frame event already should
// be considered simultaneous.
//
// The function takes the following parameters:
//
//   - state: bit-mask representing the state of the modifier keys (e.g.
//     Control, Shift and Alt).
//
// The function returns the following values:
//
//   - event: new Event.
func NavigationEventNewTouchFrame(state NavigationModifierType) *gst.Event {
	var _arg1 C.GstNavigationModifierType // out
	var _cret *C.GstEvent                 // in

	_arg1 = C.GstNavigationModifierType(state)

	_cret = C.gst_navigation_event_new_touch_frame(_arg1)
	runtime.KeepAlive(state)

	var _event *gst.Event // out

	_event = (*gst.Event)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_event)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _event
}

// NavigationEventNewTouchMotion: create a new navigation event for a moved
// touch point.
//
// The function takes the following parameters:
//
//   - identifier: number uniquely identifying this touch point. It must
//     correlate to exactly one previous touch_start event.
//   - x coordinate of the touch point.
//   - y coordinate of the touch point.
//   - pressure: pressure data of the touch point, from 0.0 to 1.0, or NaN if no
//     data is available.
//   - state: bit-mask representing the state of the modifier keys (e.g.
//     Control, Shift and Alt).
//
// The function returns the following values:
//
//   - event: new Event.
func NavigationEventNewTouchMotion(identifier uint, x, y, pressure float64, state NavigationModifierType) *gst.Event {
	var _arg1 C.guint                     // out
	var _arg2 C.gdouble                   // out
	var _arg3 C.gdouble                   // out
	var _arg4 C.gdouble                   // out
	var _arg5 C.GstNavigationModifierType // out
	var _cret *C.GstEvent                 // in

	_arg1 = C.guint(identifier)
	_arg2 = C.gdouble(x)
	_arg3 = C.gdouble(y)
	_arg4 = C.gdouble(pressure)
	_arg5 = C.GstNavigationModifierType(state)

	_cret = C.gst_navigation_event_new_touch_motion(_arg1, _arg2, _arg3, _arg4, _arg5)
	runtime.KeepAlive(identifier)
	runtime.KeepAlive(x)
	runtime.KeepAlive(y)
	runtime.KeepAlive(pressure)
	runtime.KeepAlive(state)

	var _event *gst.Event // out

	_event = (*gst.Event)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_event)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _event
}

// NavigationEventNewTouchUp: create a new navigation event for a removed touch
// point.
//
// The function takes the following parameters:
//
//   - identifier: number uniquely identifying this touch point. It must
//     correlate to exactly one previous down event, but can be reused after
//     sending this event.
//   - x coordinate of the touch point.
//   - y coordinate of the touch point.
//   - state: bit-mask representing the state of the modifier keys (e.g.
//     Control, Shift and Alt).
//
// The function returns the following values:
//
//   - event: new Event.
func NavigationEventNewTouchUp(identifier uint, x, y float64, state NavigationModifierType) *gst.Event {
	var _arg1 C.guint                     // out
	var _arg2 C.gdouble                   // out
	var _arg3 C.gdouble                   // out
	var _arg4 C.GstNavigationModifierType // out
	var _cret *C.GstEvent                 // in

	_arg1 = C.guint(identifier)
	_arg2 = C.gdouble(x)
	_arg3 = C.gdouble(y)
	_arg4 = C.GstNavigationModifierType(state)

	_cret = C.gst_navigation_event_new_touch_up(_arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(identifier)
	runtime.KeepAlive(x)
	runtime.KeepAlive(y)
	runtime.KeepAlive(state)

	var _event *gst.Event // out

	_event = (*gst.Event)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_event)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _event
}

// NavigationEventParseCommand: inspect a Navigation command event and retrieve
// the enum value of the associated command.
//
// The function takes the following parameters:
//
//   - event to inspect.
//
// The function returns the following values:
//
//   - command (optional): pointer to GstNavigationCommand to receive the type
//     of the navigation event.
//   - ok: TRUE if the navigation command could be extracted, otherwise FALSE.
func NavigationEventParseCommand(event *gst.Event) (NavigationCommand, bool) {
	var _arg1 *C.GstEvent            // out
	var _arg2 C.GstNavigationCommand // in
	var _cret C.gboolean             // in

	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C.gst_navigation_event_parse_command(_arg1, &_arg2)
	runtime.KeepAlive(event)

	var _command NavigationCommand // out
	var _ok bool                   // out

	_command = NavigationCommand(_arg2)
	if _cret != 0 {
		_ok = true
	}

	return _command, _ok
}

// NavigationEventParseKeyEvent: note: Modifier keys (as defined in
// NavigationModifierType) press (GST_NAVIGATION_EVENT_KEY_PRESS) and release
// (GST_NAVIGATION_KEY_PRESS) events are generated even if those states are
// present on all other related events.
//
// The function takes the following parameters:
//
//   - event to inspect.
//
// The function returns the following values:
//
//   - key (optional): pointer to a location to receive the string identifying
//     the key press. The returned string is owned by the event, and valid only
//     until the event is unreffed.
//   - ok
func NavigationEventParseKeyEvent(event *gst.Event) (string, bool) {
	var _arg1 *C.GstEvent // out
	var _arg2 *C.gchar    // in
	var _cret C.gboolean  // in

	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C.gst_navigation_event_parse_key_event(_arg1, &_arg2)
	runtime.KeepAlive(event)

	var _key string // out
	var _ok bool    // out

	if _arg2 != nil {
		_key = C.GoString((*C.gchar)(unsafe.Pointer(_arg2)))
	}
	if _cret != 0 {
		_ok = true
	}

	return _key, _ok
}

// The function takes the following parameters:
//
//   - event to modify.
//   - state: bit-mask representing the state of the modifier keys (e.g.
//     Control, Shift and Alt).
//
// The function returns the following values:
//
//   - ok: TRUE if the event is a Navigation event with associated modifiers
//     state, otherwise FALSE.
func NavigationEventParseModifierState(event *gst.Event, state *NavigationModifierType) bool {
	var _arg1 *C.GstEvent                  // out
	var _arg2 *C.GstNavigationModifierType // out
	var _cret C.gboolean                   // in

	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))
	_arg2 = (*C.GstNavigationModifierType)(unsafe.Pointer(state))

	_cret = C.gst_navigation_event_parse_modifier_state(_arg1, _arg2)
	runtime.KeepAlive(event)
	runtime.KeepAlive(state)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// NavigationEventParseMouseButtonEvent: retrieve the details of either
// a Navigation mouse button press event or a mouse button release event.
// Determine which type the event is using gst_navigation_event_get_type() to
// retrieve the NavigationEventType.
//
// The function takes the following parameters:
//
//   - event to inspect.
//
// The function returns the following values:
//
//   - button (optional): pointer to a gint that will receive the button number
//     associated with the event.
//   - x (optional): pointer to a gdouble to receive the x coordinate of the
//     mouse button event.
//   - y (optional): pointer to a gdouble to receive the y coordinate of the
//     mouse button event.
//   - ok: TRUE if the button number and both coordinates could be extracted,
//     otherwise FALSE.
func NavigationEventParseMouseButtonEvent(event *gst.Event) (button int, x, y float64, ok bool) {
	var _arg1 *C.GstEvent // out
	var _arg2 C.gint      // in
	var _arg3 C.gdouble   // in
	var _arg4 C.gdouble   // in
	var _cret C.gboolean  // in

	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C.gst_navigation_event_parse_mouse_button_event(_arg1, &_arg2, &_arg3, &_arg4)
	runtime.KeepAlive(event)

	var _button int // out
	var _x float64  // out
	var _y float64  // out
	var _ok bool    // out

	_button = int(_arg2)
	_x = float64(_arg3)
	_y = float64(_arg4)
	if _cret != 0 {
		_ok = true
	}

	return _button, _x, _y, _ok
}

// NavigationEventParseMouseMoveEvent: inspect a Navigation mouse movement event
// and extract the coordinates of the event.
//
// The function takes the following parameters:
//
//   - event to inspect.
//
// The function returns the following values:
//
//   - x (optional): pointer to a gdouble to receive the x coordinate of the
//     mouse movement.
//   - y (optional): pointer to a gdouble to receive the y coordinate of the
//     mouse movement.
//   - ok: TRUE if both coordinates could be extracted, otherwise FALSE.
func NavigationEventParseMouseMoveEvent(event *gst.Event) (x, y float64, ok bool) {
	var _arg1 *C.GstEvent // out
	var _arg2 C.gdouble   // in
	var _arg3 C.gdouble   // in
	var _cret C.gboolean  // in

	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C.gst_navigation_event_parse_mouse_move_event(_arg1, &_arg2, &_arg3)
	runtime.KeepAlive(event)

	var _x float64 // out
	var _y float64 // out
	var _ok bool   // out

	_x = float64(_arg2)
	_y = float64(_arg3)
	if _cret != 0 {
		_ok = true
	}

	return _x, _y, _ok
}

// NavigationEventParseMouseScrollEvent: inspect a Navigation mouse scroll event
// and extract the coordinates of the event.
//
// The function takes the following parameters:
//
//   - event to inspect.
//
// The function returns the following values:
//
//   - x (optional): pointer to a gdouble to receive the x coordinate of the
//     mouse movement.
//   - y (optional): pointer to a gdouble to receive the y coordinate of the
//     mouse movement.
//   - deltaX (optional): pointer to a gdouble to receive the delta_x coordinate
//     of the mouse movement.
//   - deltaY (optional): pointer to a gdouble to receive the delta_y coordinate
//     of the mouse movement.
//   - ok: TRUE if all coordinates could be extracted, otherwise FALSE.
func NavigationEventParseMouseScrollEvent(event *gst.Event) (x, y, deltaX, deltaY float64, ok bool) {
	var _arg1 *C.GstEvent // out
	var _arg2 C.gdouble   // in
	var _arg3 C.gdouble   // in
	var _arg4 C.gdouble   // in
	var _arg5 C.gdouble   // in
	var _cret C.gboolean  // in

	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C.gst_navigation_event_parse_mouse_scroll_event(_arg1, &_arg2, &_arg3, &_arg4, &_arg5)
	runtime.KeepAlive(event)

	var _x float64      // out
	var _y float64      // out
	var _deltaX float64 // out
	var _deltaY float64 // out
	var _ok bool        // out

	_x = float64(_arg2)
	_y = float64(_arg3)
	_deltaX = float64(_arg4)
	_deltaY = float64(_arg5)
	if _cret != 0 {
		_ok = true
	}

	return _x, _y, _deltaX, _deltaY, _ok
}

// NavigationEventParseTouchEvent: retrieve the details of a Navigation
// touch-down or touch-motion event. Determine which type the event is using
// gst_navigation_event_get_type() to retrieve the NavigationEventType.
//
// The function takes the following parameters:
//
//   - event to inspect.
//
// The function returns the following values:
//
//   - identifier (optional): pointer to a guint that will receive the
//     identifier unique to this touch point.
//   - x (optional): pointer to a gdouble that will receive the x coordinate of
//     the touch event.
//   - y (optional): pointer to a gdouble that will receive the y coordinate of
//     the touch event.
//   - pressure (optional): pointer to a gdouble that will receive the force of
//     the touch event, in the range from 0.0 to 1.0. If pressure data is not
//     available, NaN will be set instead.
//   - ok: TRUE if all details could be extracted, otherwise FALSE.
func NavigationEventParseTouchEvent(event *gst.Event) (identifier uint, x, y, pressure float64, ok bool) {
	var _arg1 *C.GstEvent // out
	var _arg2 C.guint     // in
	var _arg3 C.gdouble   // in
	var _arg4 C.gdouble   // in
	var _arg5 C.gdouble   // in
	var _cret C.gboolean  // in

	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C.gst_navigation_event_parse_touch_event(_arg1, &_arg2, &_arg3, &_arg4, &_arg5)
	runtime.KeepAlive(event)

	var _identifier uint  // out
	var _x float64        // out
	var _y float64        // out
	var _pressure float64 // out
	var _ok bool          // out

	_identifier = uint(_arg2)
	_x = float64(_arg3)
	_y = float64(_arg4)
	_pressure = float64(_arg5)
	if _cret != 0 {
		_ok = true
	}

	return _identifier, _x, _y, _pressure, _ok
}

// NavigationEventParseTouchUpEvent: retrieve the details of a Navigation
// touch-up event.
//
// The function takes the following parameters:
//
//   - event to inspect.
//
// The function returns the following values:
//
//   - identifier (optional): pointer to a guint that will receive the
//     identifier unique to this touch point.
//   - x (optional): pointer to a gdouble that will receive the x coordinate of
//     the touch event.
//   - y (optional): pointer to a gdouble that will receive the y coordinate of
//     the touch event.
//   - ok: TRUE if all details could be extracted, otherwise FALSE.
func NavigationEventParseTouchUpEvent(event *gst.Event) (identifier uint, x, y float64, ok bool) {
	var _arg1 *C.GstEvent // out
	var _arg2 C.guint     // in
	var _arg3 C.gdouble   // in
	var _arg4 C.gdouble   // in
	var _cret C.gboolean  // in

	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C.gst_navigation_event_parse_touch_up_event(_arg1, &_arg2, &_arg3, &_arg4)
	runtime.KeepAlive(event)

	var _identifier uint // out
	var _x float64       // out
	var _y float64       // out
	var _ok bool         // out

	_identifier = uint(_arg2)
	_x = float64(_arg3)
	_y = float64(_arg4)
	if _cret != 0 {
		_ok = true
	}

	return _identifier, _x, _y, _ok
}

// NavigationEventSetCoordinates: try to set x and y coordinates on a Navigation
// event. The event must be writable.
//
// The function takes the following parameters:
//
//   - event to modify.
//   - x coordinate to set.
//   - y coordinate to set.
//
// The function returns the following values:
//
//   - ok: boolean indicating success.
func NavigationEventSetCoordinates(event *gst.Event, x, y float64) bool {
	var _arg1 *C.GstEvent // out
	var _arg2 C.gdouble   // out
	var _arg3 C.gdouble   // out
	var _cret C.gboolean  // in

	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))
	_arg2 = C.gdouble(x)
	_arg3 = C.gdouble(y)

	_cret = C.gst_navigation_event_set_coordinates(_arg1, _arg2, _arg3)
	runtime.KeepAlive(event)
	runtime.KeepAlive(x)
	runtime.KeepAlive(y)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// NavigationMessageGetType: check a bus message to see if it is a Navigation
// event, and return the NavigationMessageType identifying the type of the
// message if so.
//
// The function takes the following parameters:
//
//   - message to inspect.
//
// The function returns the following values:
//
//   - navigationMessageType: type of the Message, or
//     T_NAVIGATION_MESSAGE_INVALID if the message is not a Navigation
//     notification.
func NavigationMessageGetType(message *gst.Message) NavigationMessageType {
	var _arg1 *C.GstMessage              // out
	var _cret C.GstNavigationMessageType // in

	_arg1 = (*C.GstMessage)(gextras.StructNative(unsafe.Pointer(message)))

	_cret = C.gst_navigation_message_get_type(_arg1)
	runtime.KeepAlive(message)

	var _navigationMessageType NavigationMessageType // out

	_navigationMessageType = NavigationMessageType(_cret)

	return _navigationMessageType
}

// NavigationMessageNewAnglesChanged creates a new Navigation message with type
// T_NAVIGATION_MESSAGE_ANGLES_CHANGED for notifying an application that the
// current angle, or current number of angles available in a multiangle video
// has changed.
//
// The function takes the following parameters:
//
//   - src to set as source of the new message.
//   - curAngle: currently selected angle.
//   - nAngles: number of viewing angles now available.
//
// The function returns the following values:
//
//   - message: new Message.
func NavigationMessageNewAnglesChanged(src gst.GstObjector, curAngle, nAngles uint) *gst.Message {
	var _arg1 *C.GstObject  // out
	var _arg2 C.guint       // out
	var _arg3 C.guint       // out
	var _cret *C.GstMessage // in

	_arg1 = (*C.GstObject)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg2 = C.guint(curAngle)
	_arg3 = C.guint(nAngles)

	_cret = C.gst_navigation_message_new_angles_changed(_arg1, _arg2, _arg3)
	runtime.KeepAlive(src)
	runtime.KeepAlive(curAngle)
	runtime.KeepAlive(nAngles)

	var _message *gst.Message // out

	_message = (*gst.Message)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_message)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _message
}

// NavigationMessageNewCommandsChanged creates a new Navigation message with
// type T_NAVIGATION_MESSAGE_COMMANDS_CHANGED.
//
// The function takes the following parameters:
//
//   - src to set as source of the new message.
//
// The function returns the following values:
//
//   - message: new Message.
func NavigationMessageNewCommandsChanged(src gst.GstObjector) *gst.Message {
	var _arg1 *C.GstObject  // out
	var _cret *C.GstMessage // in

	_arg1 = (*C.GstObject)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C.gst_navigation_message_new_commands_changed(_arg1)
	runtime.KeepAlive(src)

	var _message *gst.Message // out

	_message = (*gst.Message)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_message)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _message
}

// NavigationMessageNewEvent creates a new Navigation message with type
// T_NAVIGATION_MESSAGE_EVENT.
//
// The function takes the following parameters:
//
//   - src to set as source of the new message.
//   - event: navigation Event.
//
// The function returns the following values:
//
//   - message: new Message.
func NavigationMessageNewEvent(src gst.GstObjector, event *gst.Event) *gst.Message {
	var _arg1 *C.GstObject  // out
	var _arg2 *C.GstEvent   // out
	var _cret *C.GstMessage // in

	_arg1 = (*C.GstObject)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg2 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C.gst_navigation_message_new_event(_arg1, _arg2)
	runtime.KeepAlive(src)
	runtime.KeepAlive(event)

	var _message *gst.Message // out

	_message = (*gst.Message)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_message)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _message
}

// NavigationMessageNewMouseOver creates a new Navigation message with type
// T_NAVIGATION_MESSAGE_MOUSE_OVER.
//
// The function takes the following parameters:
//
//   - src to set as source of the new message.
//   - active: TRUE if the mouse has entered a clickable area of the display.
//     FALSE if it over a non-clickable area.
//
// The function returns the following values:
//
//   - message: new Message.
func NavigationMessageNewMouseOver(src gst.GstObjector, active bool) *gst.Message {
	var _arg1 *C.GstObject  // out
	var _arg2 C.gboolean    // out
	var _cret *C.GstMessage // in

	_arg1 = (*C.GstObject)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	if active {
		_arg2 = C.TRUE
	}

	_cret = C.gst_navigation_message_new_mouse_over(_arg1, _arg2)
	runtime.KeepAlive(src)
	runtime.KeepAlive(active)

	var _message *gst.Message // out

	_message = (*gst.Message)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_message)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _message
}

// NavigationMessageParseAnglesChanged: parse a Navigation message of type
// GST_NAVIGATION_MESSAGE_ANGLES_CHANGED and extract the cur_angle and n_angles
// parameters.
//
// The function takes the following parameters:
//
//   - message to inspect.
//
// The function returns the following values:
//
//   - curAngle (optional): pointer to a #guint to receive the new current angle
//     number, or NULL.
//   - nAngles (optional): pointer to a #guint to receive the new angle count,
//     or NULL.
//   - ok: TRUE if the message could be successfully parsed. FALSE if not.
func NavigationMessageParseAnglesChanged(message *gst.Message) (curAngle, nAngles uint, ok bool) {
	var _arg1 *C.GstMessage // out
	var _arg2 C.guint       // in
	var _arg3 C.guint       // in
	var _cret C.gboolean    // in

	_arg1 = (*C.GstMessage)(gextras.StructNative(unsafe.Pointer(message)))

	_cret = C.gst_navigation_message_parse_angles_changed(_arg1, &_arg2, &_arg3)
	runtime.KeepAlive(message)

	var _curAngle uint // out
	var _nAngles uint  // out
	var _ok bool       // out

	_curAngle = uint(_arg2)
	_nAngles = uint(_arg3)
	if _cret != 0 {
		_ok = true
	}

	return _curAngle, _nAngles, _ok
}

// NavigationMessageParseEvent: parse a Navigation message of type
// T_NAVIGATION_MESSAGE_EVENT and extract contained Event. The caller must unref
// the event when done with it.
//
// The function takes the following parameters:
//
//   - message to inspect.
//
// The function returns the following values:
//
//   - event (optional): pointer to a Event to receive the contained navigation
//     event.
//   - ok: TRUE if the message could be successfully parsed. FALSE if not.
func NavigationMessageParseEvent(message *gst.Message) (*gst.Event, bool) {
	var _arg1 *C.GstMessage // out
	var _arg2 *C.GstEvent   // in
	var _cret C.gboolean    // in

	_arg1 = (*C.GstMessage)(gextras.StructNative(unsafe.Pointer(message)))

	_cret = C.gst_navigation_message_parse_event(_arg1, &_arg2)
	runtime.KeepAlive(message)

	var _event *gst.Event // out
	var _ok bool          // out

	if _arg2 != nil {
		_event = (*gst.Event)(gextras.NewStructNative(unsafe.Pointer(_arg2)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_event)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.free(intern.C)
			},
		)
	}
	if _cret != 0 {
		_ok = true
	}

	return _event, _ok
}

// NavigationMessageParseMouseOver: parse a Navigation message of type
// T_NAVIGATION_MESSAGE_MOUSE_OVER and extract the active/inactive flag.
// If the mouse over event is marked active, it indicates that the mouse is over
// a clickable area.
//
// The function takes the following parameters:
//
//   - message to inspect.
//
// The function returns the following values:
//
//   - active (optional): pointer to a gboolean to receive the active/inactive
//     state, or NULL.
//   - ok: TRUE if the message could be successfully parsed. FALSE if not.
func NavigationMessageParseMouseOver(message *gst.Message) (active, ok bool) {
	var _arg1 *C.GstMessage // out
	var _arg2 C.gboolean    // in
	var _cret C.gboolean    // in

	_arg1 = (*C.GstMessage)(gextras.StructNative(unsafe.Pointer(message)))

	_cret = C.gst_navigation_message_parse_mouse_over(_arg1, &_arg2)
	runtime.KeepAlive(message)

	var _active bool // out
	var _ok bool     // out

	if _arg2 != 0 {
		_active = true
	}
	if _cret != 0 {
		_ok = true
	}

	return _active, _ok
}

// NavigationQueryGetType: inspect a Query and return the NavigationQueryType
// associated with it if it is a Navigation query.
//
// The function takes the following parameters:
//
//   - query to inspect.
//
// The function returns the following values:
//
//   - navigationQueryType of the query, or T_NAVIGATION_QUERY_INVALID.
func NavigationQueryGetType(query *gst.Query) NavigationQueryType {
	var _arg1 *C.GstQuery              // out
	var _cret C.GstNavigationQueryType // in

	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C.gst_navigation_query_get_type(_arg1)
	runtime.KeepAlive(query)

	var _navigationQueryType NavigationQueryType // out

	_navigationQueryType = NavigationQueryType(_cret)

	return _navigationQueryType
}

// NavigationQueryNewAngles: create a new Navigation angles query. When
// executed, it will query the pipeline for the set of currently available
// angles, which may be greater than one in a multiangle video.
//
// The function returns the following values:
//
//   - query: new query.
func NavigationQueryNewAngles() *gst.Query {
	var _cret *C.GstQuery // in

	_cret = C.gst_navigation_query_new_angles()

	var _query *gst.Query // out

	_query = (*gst.Query)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_query)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _query
}

// NavigationQueryNewCommands: create a new Navigation commands query.
// When executed, it will query the pipeline for the set of currently available
// commands.
//
// The function returns the following values:
//
//   - query: new query.
func NavigationQueryNewCommands() *gst.Query {
	var _cret *C.GstQuery // in

	_cret = C.gst_navigation_query_new_commands()

	var _query *gst.Query // out

	_query = (*gst.Query)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_query)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _query
}

// NavigationQueryParseAngles: parse the current angle number in the Navigation
// angles query into the #guint pointed to by the cur_angle variable,
// and the number of available angles into the #guint pointed to by the n_angles
// variable.
//
// The function takes the following parameters:
//
//   - query: Query.
//
// The function returns the following values:
//
//   - curAngle (optional): pointer to a #guint into which to store the
//     currently selected angle value from the query, or NULL.
//   - nAngles (optional): pointer to a #guint into which to store the number of
//     angles value from the query, or NULL.
//   - ok: TRUE if the query could be successfully parsed. FALSE if not.
func NavigationQueryParseAngles(query *gst.Query) (curAngle, nAngles uint, ok bool) {
	var _arg1 *C.GstQuery // out
	var _arg2 C.guint     // in
	var _arg3 C.guint     // in
	var _cret C.gboolean  // in

	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C.gst_navigation_query_parse_angles(_arg1, &_arg2, &_arg3)
	runtime.KeepAlive(query)

	var _curAngle uint // out
	var _nAngles uint  // out
	var _ok bool       // out

	_curAngle = uint(_arg2)
	_nAngles = uint(_arg3)
	if _cret != 0 {
		_ok = true
	}

	return _curAngle, _nAngles, _ok
}

// NavigationQueryParseCommandsLength: parse the number of commands in the
// Navigation commands query.
//
// The function takes the following parameters:
//
//   - query: Query.
//
// The function returns the following values:
//
//   - nCmds (optional): number of commands in this query.
//   - ok: TRUE if the query could be successfully parsed. FALSE if not.
func NavigationQueryParseCommandsLength(query *gst.Query) (uint, bool) {
	var _arg1 *C.GstQuery // out
	var _arg2 C.guint     // in
	var _cret C.gboolean  // in

	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C.gst_navigation_query_parse_commands_length(_arg1, &_arg2)
	runtime.KeepAlive(query)

	var _nCmds uint // out
	var _ok bool    // out

	_nCmds = uint(_arg2)
	if _cret != 0 {
		_ok = true
	}

	return _nCmds, _ok
}

// NavigationQueryParseCommandsNth: parse the Navigation command query and
// retrieve the nth command from it into cmd. If the list contains less elements
// than nth, cmd will be set to T_NAVIGATION_COMMAND_INVALID.
//
// The function takes the following parameters:
//
//   - query: Query.
//   - nth command to retrieve.
//
// The function returns the following values:
//
//   - cmd (optional): pointer to store the nth command into.
//   - ok: TRUE if the query could be successfully parsed. FALSE if not.
func NavigationQueryParseCommandsNth(query *gst.Query, nth uint) (NavigationCommand, bool) {
	var _arg1 *C.GstQuery            // out
	var _arg2 C.guint                // out
	var _arg3 C.GstNavigationCommand // in
	var _cret C.gboolean             // in

	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))
	_arg2 = C.guint(nth)

	_cret = C.gst_navigation_query_parse_commands_nth(_arg1, _arg2, &_arg3)
	runtime.KeepAlive(query)
	runtime.KeepAlive(nth)

	var _cmd NavigationCommand // out
	var _ok bool               // out

	_cmd = NavigationCommand(_arg3)
	if _cret != 0 {
		_ok = true
	}

	return _cmd, _ok
}

// NavigationQuerySetAngles: set the Navigation angles query result field in
// query.
//
// The function takes the following parameters:
//
//   - query: Query.
//   - curAngle: current viewing angle to set.
//   - nAngles: number of viewing angles to set.
func NavigationQuerySetAngles(query *gst.Query, curAngle, nAngles uint) {
	var _arg1 *C.GstQuery // out
	var _arg2 C.guint     // out
	var _arg3 C.guint     // out

	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))
	_arg2 = C.guint(curAngle)
	_arg3 = C.guint(nAngles)

	C.gst_navigation_query_set_angles(_arg1, _arg2, _arg3)
	runtime.KeepAlive(query)
	runtime.KeepAlive(curAngle)
	runtime.KeepAlive(nAngles)
}

// NavigationQuerySetCommandsv: set the Navigation command query result fields
// in query. The number of commands passed must be equal to n_commands.
//
// The function takes the following parameters:
//
//   - query: Query.
//   - cmds: array containing n_cmds GstNavigationCommand values.
func NavigationQuerySetCommandsv(query *gst.Query, cmds []NavigationCommand) {
	var _arg1 *C.GstQuery             // out
	var _arg3 *C.GstNavigationCommand // out
	var _arg2 C.gint

	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))
	_arg2 = (C.gint)(len(cmds))
	if len(cmds) > 0 {
		_arg3 = (*C.GstNavigationCommand)(unsafe.Pointer(&cmds[0]))
	}

	C.gst_navigation_query_set_commandsv(_arg1, _arg2, _arg3)
	runtime.KeepAlive(query)
	runtime.KeepAlive(cmds)
}

// VideoDirectionOverrider contains methods that are overridable.
type VideoDirectionOverrider interface {
}

// VideoDirection: interface allows unified access to control flipping and
// rotation operations of video-sources or operators.
//
// VideoDirection wraps an interface. This means the user can get the
// underlying type by calling Cast().
type VideoDirection struct {
	_ [0]func() // equal guard
	*coreglib.Object
}

var (
	_ coreglib.Objector = (*VideoDirection)(nil)
)

// VideoDirectioner describes VideoDirection's interface methods.
type VideoDirectioner interface {
	coreglib.Objector

	baseVideoDirection() *VideoDirection
}

var _ VideoDirectioner = (*VideoDirection)(nil)

func ifaceInitVideoDirectioner(gifacePtr, data C.gpointer) {
}

func wrapVideoDirection(obj *coreglib.Object) *VideoDirection {
	return &VideoDirection{
		Object: obj,
	}
}

func marshalVideoDirection(p uintptr) (interface{}, error) {
	return wrapVideoDirection(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (v *VideoDirection) baseVideoDirection() *VideoDirection {
	return v
}

// BaseVideoDirection returns the underlying base object.
func BaseVideoDirection(obj VideoDirectioner) *VideoDirection {
	return obj.baseVideoDirection()
}

// VideoOrientation: interface allows unified access to control flipping and
// autocenter operation of video-sources or operators.
//
// VideoOrientation wraps an interface. This means the user can get the
// underlying type by calling Cast().
type VideoOrientation struct {
	_ [0]func() // equal guard
	*coreglib.Object
}

var (
	_ coreglib.Objector = (*VideoOrientation)(nil)
)

// VideoOrientationer describes VideoOrientation's interface methods.
type VideoOrientationer interface {
	coreglib.Objector

	// Hcenter: get the horizontal centering offset from the given object.
	Hcenter() (int, bool)
	// Hflip: get the horizontal flipping state (TRUE for flipped) from the
	// given object.
	Hflip() (flip, ok bool)
	// Vcenter: get the vertical centering offset from the given object.
	Vcenter() (int, bool)
	// Vflip: get the vertical flipping state (TRUE for flipped) from the given
	// object.
	Vflip() (flip, ok bool)
	// SetHcenter: set the horizontal centering offset for the given object.
	SetHcenter(center int) bool
	// SetHflip: set the horizontal flipping state (TRUE for flipped) for the
	// given object.
	SetHflip(flip bool) bool
	// SetVcenter: set the vertical centering offset for the given object.
	SetVcenter(center int) bool
	// SetVflip: set the vertical flipping state (TRUE for flipped) for the
	// given object.
	SetVflip(flip bool) bool
}

var _ VideoOrientationer = (*VideoOrientation)(nil)

func wrapVideoOrientation(obj *coreglib.Object) *VideoOrientation {
	return &VideoOrientation{
		Object: obj,
	}
}

func marshalVideoOrientation(p uintptr) (interface{}, error) {
	return wrapVideoOrientation(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

// Hcenter: get the horizontal centering offset from the given object.
//
// The function returns the following values:
//
//   - center: return location for the result.
//   - ok: TRUE in case the element supports centering.
func (videoOrientation *VideoOrientation) Hcenter() (int, bool) {
	var _arg0 *C.GstVideoOrientation // out
	var _arg1 C.gint                 // in
	var _cret C.gboolean             // in

	_arg0 = (*C.GstVideoOrientation)(unsafe.Pointer(coreglib.BaseObject(videoOrientation).Native()))

	_cret = C.gst_video_orientation_get_hcenter(_arg0, &_arg1)
	runtime.KeepAlive(videoOrientation)

	var _center int // out
	var _ok bool    // out

	_center = int(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _center, _ok
}

// Hflip: get the horizontal flipping state (TRUE for flipped) from the given
// object.
//
// The function returns the following values:
//
//   - flip: return location for the result.
//   - ok: TRUE in case the element supports flipping.
func (videoOrientation *VideoOrientation) Hflip() (flip, ok bool) {
	var _arg0 *C.GstVideoOrientation // out
	var _arg1 C.gboolean             // in
	var _cret C.gboolean             // in

	_arg0 = (*C.GstVideoOrientation)(unsafe.Pointer(coreglib.BaseObject(videoOrientation).Native()))

	_cret = C.gst_video_orientation_get_hflip(_arg0, &_arg1)
	runtime.KeepAlive(videoOrientation)

	var _flip bool // out
	var _ok bool   // out

	if _arg1 != 0 {
		_flip = true
	}
	if _cret != 0 {
		_ok = true
	}

	return _flip, _ok
}

// Vcenter: get the vertical centering offset from the given object.
//
// The function returns the following values:
//
//   - center: return location for the result.
//   - ok: TRUE in case the element supports centering.
func (videoOrientation *VideoOrientation) Vcenter() (int, bool) {
	var _arg0 *C.GstVideoOrientation // out
	var _arg1 C.gint                 // in
	var _cret C.gboolean             // in

	_arg0 = (*C.GstVideoOrientation)(unsafe.Pointer(coreglib.BaseObject(videoOrientation).Native()))

	_cret = C.gst_video_orientation_get_vcenter(_arg0, &_arg1)
	runtime.KeepAlive(videoOrientation)

	var _center int // out
	var _ok bool    // out

	_center = int(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _center, _ok
}

// Vflip: get the vertical flipping state (TRUE for flipped) from the given
// object.
//
// The function returns the following values:
//
//   - flip: return location for the result.
//   - ok: TRUE in case the element supports flipping.
func (videoOrientation *VideoOrientation) Vflip() (flip, ok bool) {
	var _arg0 *C.GstVideoOrientation // out
	var _arg1 C.gboolean             // in
	var _cret C.gboolean             // in

	_arg0 = (*C.GstVideoOrientation)(unsafe.Pointer(coreglib.BaseObject(videoOrientation).Native()))

	_cret = C.gst_video_orientation_get_vflip(_arg0, &_arg1)
	runtime.KeepAlive(videoOrientation)

	var _flip bool // out
	var _ok bool   // out

	if _arg1 != 0 {
		_flip = true
	}
	if _cret != 0 {
		_ok = true
	}

	return _flip, _ok
}

// SetHcenter: set the horizontal centering offset for the given object.
//
// The function takes the following parameters:
//
//   - center: centering offset.
//
// The function returns the following values:
//
//   - ok: TRUE in case the element supports centering.
func (videoOrientation *VideoOrientation) SetHcenter(center int) bool {
	var _arg0 *C.GstVideoOrientation // out
	var _arg1 C.gint                 // out
	var _cret C.gboolean             // in

	_arg0 = (*C.GstVideoOrientation)(unsafe.Pointer(coreglib.BaseObject(videoOrientation).Native()))
	_arg1 = C.gint(center)

	_cret = C.gst_video_orientation_set_hcenter(_arg0, _arg1)
	runtime.KeepAlive(videoOrientation)
	runtime.KeepAlive(center)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SetHflip: set the horizontal flipping state (TRUE for flipped) for the given
// object.
//
// The function takes the following parameters:
//
//   - flip: use flipping.
//
// The function returns the following values:
//
//   - ok: TRUE in case the element supports flipping.
func (videoOrientation *VideoOrientation) SetHflip(flip bool) bool {
	var _arg0 *C.GstVideoOrientation // out
	var _arg1 C.gboolean             // out
	var _cret C.gboolean             // in

	_arg0 = (*C.GstVideoOrientation)(unsafe.Pointer(coreglib.BaseObject(videoOrientation).Native()))
	if flip {
		_arg1 = C.TRUE
	}

	_cret = C.gst_video_orientation_set_hflip(_arg0, _arg1)
	runtime.KeepAlive(videoOrientation)
	runtime.KeepAlive(flip)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SetVcenter: set the vertical centering offset for the given object.
//
// The function takes the following parameters:
//
//   - center: centering offset.
//
// The function returns the following values:
//
//   - ok: TRUE in case the element supports centering.
func (videoOrientation *VideoOrientation) SetVcenter(center int) bool {
	var _arg0 *C.GstVideoOrientation // out
	var _arg1 C.gint                 // out
	var _cret C.gboolean             // in

	_arg0 = (*C.GstVideoOrientation)(unsafe.Pointer(coreglib.BaseObject(videoOrientation).Native()))
	_arg1 = C.gint(center)

	_cret = C.gst_video_orientation_set_vcenter(_arg0, _arg1)
	runtime.KeepAlive(videoOrientation)
	runtime.KeepAlive(center)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SetVflip: set the vertical flipping state (TRUE for flipped) for the given
// object.
//
// The function takes the following parameters:
//
//   - flip: use flipping.
//
// The function returns the following values:
//
//   - ok: TRUE in case the element supports flipping.
func (videoOrientation *VideoOrientation) SetVflip(flip bool) bool {
	var _arg0 *C.GstVideoOrientation // out
	var _arg1 C.gboolean             // out
	var _cret C.gboolean             // in

	_arg0 = (*C.GstVideoOrientation)(unsafe.Pointer(coreglib.BaseObject(videoOrientation).Native()))
	if flip {
		_arg1 = C.TRUE
	}

	_cret = C.gst_video_orientation_set_vflip(_arg0, _arg1)
	runtime.KeepAlive(videoOrientation)
	runtime.KeepAlive(flip)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Hcenter: get the horizontal centering offset from the given object.
//
// The function returns the following values:
//
//   - center: return location for the result.
//   - ok: TRUE in case the element supports centering.
func (videoOrientation *VideoOrientation) hcenter() (int, bool) {
	gclass := (*C.GstVideoOrientationInterface)(coreglib.PeekParentClass(videoOrientation))
	fnarg := gclass.get_hcenter

	var _arg0 *C.GstVideoOrientation // out
	var _arg1 C.gint                 // in
	var _cret C.gboolean             // in

	_arg0 = (*C.GstVideoOrientation)(unsafe.Pointer(coreglib.BaseObject(videoOrientation).Native()))

	_cret = C._gotk4_gstvideo1_VideoOrientation_virtual_get_hcenter(unsafe.Pointer(fnarg), _arg0, &_arg1)
	runtime.KeepAlive(videoOrientation)

	var _center int // out
	var _ok bool    // out

	_center = int(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _center, _ok
}

// Hflip: get the horizontal flipping state (TRUE for flipped) from the given
// object.
//
// The function returns the following values:
//
//   - flip: return location for the result.
//   - ok: TRUE in case the element supports flipping.
func (videoOrientation *VideoOrientation) hflip() (flip, ok bool) {
	gclass := (*C.GstVideoOrientationInterface)(coreglib.PeekParentClass(videoOrientation))
	fnarg := gclass.get_hflip

	var _arg0 *C.GstVideoOrientation // out
	var _arg1 C.gboolean             // in
	var _cret C.gboolean             // in

	_arg0 = (*C.GstVideoOrientation)(unsafe.Pointer(coreglib.BaseObject(videoOrientation).Native()))

	_cret = C._gotk4_gstvideo1_VideoOrientation_virtual_get_hflip(unsafe.Pointer(fnarg), _arg0, &_arg1)
	runtime.KeepAlive(videoOrientation)

	var _flip bool // out
	var _ok bool   // out

	if _arg1 != 0 {
		_flip = true
	}
	if _cret != 0 {
		_ok = true
	}

	return _flip, _ok
}

// Vcenter: get the vertical centering offset from the given object.
//
// The function returns the following values:
//
//   - center: return location for the result.
//   - ok: TRUE in case the element supports centering.
func (videoOrientation *VideoOrientation) vcenter() (int, bool) {
	gclass := (*C.GstVideoOrientationInterface)(coreglib.PeekParentClass(videoOrientation))
	fnarg := gclass.get_vcenter

	var _arg0 *C.GstVideoOrientation // out
	var _arg1 C.gint                 // in
	var _cret C.gboolean             // in

	_arg0 = (*C.GstVideoOrientation)(unsafe.Pointer(coreglib.BaseObject(videoOrientation).Native()))

	_cret = C._gotk4_gstvideo1_VideoOrientation_virtual_get_vcenter(unsafe.Pointer(fnarg), _arg0, &_arg1)
	runtime.KeepAlive(videoOrientation)

	var _center int // out
	var _ok bool    // out

	_center = int(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _center, _ok
}

// Vflip: get the vertical flipping state (TRUE for flipped) from the given
// object.
//
// The function returns the following values:
//
//   - flip: return location for the result.
//   - ok: TRUE in case the element supports flipping.
func (videoOrientation *VideoOrientation) vflip() (flip, ok bool) {
	gclass := (*C.GstVideoOrientationInterface)(coreglib.PeekParentClass(videoOrientation))
	fnarg := gclass.get_vflip

	var _arg0 *C.GstVideoOrientation // out
	var _arg1 C.gboolean             // in
	var _cret C.gboolean             // in

	_arg0 = (*C.GstVideoOrientation)(unsafe.Pointer(coreglib.BaseObject(videoOrientation).Native()))

	_cret = C._gotk4_gstvideo1_VideoOrientation_virtual_get_vflip(unsafe.Pointer(fnarg), _arg0, &_arg1)
	runtime.KeepAlive(videoOrientation)

	var _flip bool // out
	var _ok bool   // out

	if _arg1 != 0 {
		_flip = true
	}
	if _cret != 0 {
		_ok = true
	}

	return _flip, _ok
}

// setHcenter: set the horizontal centering offset for the given object.
//
// The function takes the following parameters:
//
//   - center: centering offset.
//
// The function returns the following values:
//
//   - ok: TRUE in case the element supports centering.
func (videoOrientation *VideoOrientation) setHcenter(center int) bool {
	gclass := (*C.GstVideoOrientationInterface)(coreglib.PeekParentClass(videoOrientation))
	fnarg := gclass.set_hcenter

	var _arg0 *C.GstVideoOrientation // out
	var _arg1 C.gint                 // out
	var _cret C.gboolean             // in

	_arg0 = (*C.GstVideoOrientation)(unsafe.Pointer(coreglib.BaseObject(videoOrientation).Native()))
	_arg1 = C.gint(center)

	_cret = C._gotk4_gstvideo1_VideoOrientation_virtual_set_hcenter(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(videoOrientation)
	runtime.KeepAlive(center)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// setHflip: set the horizontal flipping state (TRUE for flipped) for the given
// object.
//
// The function takes the following parameters:
//
//   - flip: use flipping.
//
// The function returns the following values:
//
//   - ok: TRUE in case the element supports flipping.
func (videoOrientation *VideoOrientation) setHflip(flip bool) bool {
	gclass := (*C.GstVideoOrientationInterface)(coreglib.PeekParentClass(videoOrientation))
	fnarg := gclass.set_hflip

	var _arg0 *C.GstVideoOrientation // out
	var _arg1 C.gboolean             // out
	var _cret C.gboolean             // in

	_arg0 = (*C.GstVideoOrientation)(unsafe.Pointer(coreglib.BaseObject(videoOrientation).Native()))
	if flip {
		_arg1 = C.TRUE
	}

	_cret = C._gotk4_gstvideo1_VideoOrientation_virtual_set_hflip(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(videoOrientation)
	runtime.KeepAlive(flip)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// setVcenter: set the vertical centering offset for the given object.
//
// The function takes the following parameters:
//
//   - center: centering offset.
//
// The function returns the following values:
//
//   - ok: TRUE in case the element supports centering.
func (videoOrientation *VideoOrientation) setVcenter(center int) bool {
	gclass := (*C.GstVideoOrientationInterface)(coreglib.PeekParentClass(videoOrientation))
	fnarg := gclass.set_vcenter

	var _arg0 *C.GstVideoOrientation // out
	var _arg1 C.gint                 // out
	var _cret C.gboolean             // in

	_arg0 = (*C.GstVideoOrientation)(unsafe.Pointer(coreglib.BaseObject(videoOrientation).Native()))
	_arg1 = C.gint(center)

	_cret = C._gotk4_gstvideo1_VideoOrientation_virtual_set_vcenter(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(videoOrientation)
	runtime.KeepAlive(center)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// setVflip: set the vertical flipping state (TRUE for flipped) for the given
// object.
//
// The function takes the following parameters:
//
//   - flip: use flipping.
//
// The function returns the following values:
//
//   - ok: TRUE in case the element supports flipping.
func (videoOrientation *VideoOrientation) setVflip(flip bool) bool {
	gclass := (*C.GstVideoOrientationInterface)(coreglib.PeekParentClass(videoOrientation))
	fnarg := gclass.set_vflip

	var _arg0 *C.GstVideoOrientation // out
	var _arg1 C.gboolean             // out
	var _cret C.gboolean             // in

	_arg0 = (*C.GstVideoOrientation)(unsafe.Pointer(coreglib.BaseObject(videoOrientation).Native()))
	if flip {
		_arg1 = C.TRUE
	}

	_cret = C._gotk4_gstvideo1_VideoOrientation_virtual_set_vflip(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(videoOrientation)
	runtime.KeepAlive(flip)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// VideoOrientationFromTag parses the "image-orientation" tag and transforms it
// into the VideoOrientationMethod enum.
//
// The function takes the following parameters:
//
//   - taglist: TagList.
//
// The function returns the following values:
//
//   - method: location where to return the orientation.
//   - ok: TRUE if there was a valid "image-orientation" tag in the taglist.
func VideoOrientationFromTag(taglist *gst.TagList) (VideoOrientationMethod, bool) {
	var _arg1 *C.GstTagList               // out
	var _arg2 C.GstVideoOrientationMethod // in
	var _cret C.gboolean                  // in

	_arg1 = (*C.GstTagList)(gextras.StructNative(unsafe.Pointer(taglist)))

	_cret = C.gst_video_orientation_from_tag(_arg1, &_arg2)
	runtime.KeepAlive(taglist)

	var _method VideoOrientationMethod // out
	var _ok bool                       // out

	_method = VideoOrientationMethod(_arg2)
	if _cret != 0 {
		_ok = true
	}

	return _method, _ok
}

// VideoOverlay interface is used for 2 main purposes :
//
// * To get a grab on the Window where the video sink element is going to
// render. This is achieved by either being informed about the Window identifier
// that the video sink element generated, or by forcing the video sink element
// to use a specific Window identifier for rendering. * To force a redrawing
// of the latest video frame the video sink element displayed on the Window.
// Indeed if the Pipeline is in T_STATE_PAUSED state, moving the Window around
// will damage its content. Application developers will want to handle the
// Expose events themselves and force the video sink element to refresh the
// Window's content.
//
// Using the Window created by the video sink is probably the simplest scenario,
// in some cases, though, it might not be flexible enough for application
// developers if they need to catch events such as mouse moves and button
// clicks.
//
// Setting a specific Window identifier on the video sink element is the most
// flexible solution but it has some issues. Indeed the application needs to set
// its Window identifier at the right time to avoid internal Window creation
// from the video sink element. To solve this issue a Message is posted on
// the bus to inform the application that it should set the Window identifier
// immediately. Here is an example on how to do that correctly:
//
//	static GstBusSyncReply
//	create_window (GstBus * bus, GstMessage * message, GstPipeline * pipeline)
//	{
//	 // ignore anything but 'prepare-window-handle' element messages
//	 if (!gst_is_video_overlay_prepare_window_handle_message (message))
//	   return GST_BUS_PASS;
//
//	 win = XCreateSimpleWindow (disp, root, 0, 0, 320, 240, 0, 0, 0);
//
//	 XSetWindowBackgroundPixmap (disp, win, None);
//
//	 XMapRaised (disp, win);
//
//	 XSync (disp, FALSE);
//
//	 gst_video_overlay_set_window_handle (GST_VIDEO_OVERLAY (GST_MESSAGE_SRC (message)),
//	     win);
//
//	 gst_message_unref (message);
//
//	 return GST_BUS_DROP;
//	}
//	...
//	int
//	main (int argc, char **argv)
//	{
//	...
//	 bus = gst_pipeline_get_bus (GST_PIPELINE (pipeline));
//	 gst_bus_set_sync_handler (bus, (GstBusSyncHandler) create_window, pipeline,
//	        NULL);
//	...
//	}
//
// # Two basic usage scenarios
//
// There are two basic usage scenarios: in the simplest case, the application
// uses #playbin or #playsink or knows exactly what particular element is
// used for video output, which is usually the case when the application
// creates the videosink to use (e.g. #xvimagesink, #ximagesink, etc.) itself;
// in this case, the application can just create the videosink element,
// create and realize the window to render the video on and then call
// gst_video_overlay_set_window_handle() directly with the XID or native window
// handle, before starting up the pipeline. As #playbin and #playsink implement
// the video overlay interface and proxy it transparently to the actual video
// sink even if it is created later, this case also applies when using these
// elements.
//
// In the other and more common case, the application does not know in
// advance what GStreamer video sink element will be used for video output.
// This is usually the case when an element such as #autovideosink is used.
// In this case, the video sink element itself is created asynchronously from a
// GStreamer streaming thread some time after the pipeline has been started up.
// When that happens, however, the video sink will need to know right then
// whether to render onto an already existing application window or whether to
// create its own window. This is when it posts a prepare-window-handle message,
// and that is also why this message needs to be handled in a sync bus handler
// which will be called from the streaming thread directly (because the video
// sink will need an answer right then).
//
// As response to the prepare-window-handle element message in the bus sync
// handler, the application may use gst_video_overlay_set_window_handle() to
// tell the video sink to render onto an existing window surface. At this
// point the application should already have obtained the window handle / XID,
// so it just needs to set it. It is generally not advisable to call any GUI
// toolkit functions or window system functions from the streaming thread in
// which the prepare-window-handle message is handled, because most GUI toolkits
// and windowing systems are not thread-safe at all and a lot of care would be
// required to co-ordinate the toolkit and window system calls of the different
// threads (Gtk+ users please note: prior to Gtk+ 2.18 GDK_WINDOW_XID was just a
// simple structure access, so generally fine to do within the bus sync handler;
// this macro was changed to a function call in Gtk+ 2.18 and later, which is
// likely to cause problems when called from a sync handler; see below for a
// better approach without GDK_WINDOW_XID used in the callback).
//
// GstVideoOverlay and Gtk+
//
//	#include <gst/video/videooverlay.h>
//	#include <gtk/gtk.h>
//	#ifdef GDK_WINDOWING_X11
//	#include <gdk/gdkx.h>  // for GDK_WINDOW_XID
//	#endif
//	#ifdef GDK_WINDOWING_WIN32
//	#include <gdk/gdkwin32.h>  // for GDK_WINDOW_HWND
//	#endif
//	...
//	static guintptr video_window_handle = 0;
//	...
//	static GstBusSyncReply
//	bus_sync_handler (GstBus * bus, GstMessage * message, gpointer user_data)
//	{
//	 // ignore anything but 'prepare-window-handle' element messages
//	 if (!gst_is_video_overlay_prepare_window_handle_message (message))
//	   return GST_BUS_PASS;
//
//	 if (video_window_handle != 0) {
//	   GstVideoOverlay *overlay;
//
//	   // GST_MESSAGE_SRC (message) will be the video sink element
//	   overlay = GST_VIDEO_OVERLAY (GST_MESSAGE_SRC (message));
//	   gst_video_overlay_set_window_handle (overlay, video_window_handle);
//	 } else {
//	   g_warning ("Should have obtained video_window_handle by now!");
//	 }
//
//	 gst_message_unref (message);
//	 return GST_BUS_DROP;
//	}
//	...
//	static void
//	video_widget_realize_cb (GtkWidget * widget, gpointer data)
//	{
//	#if GTK_CHECK_VERSION(2,18,0)
//	  // Tell Gtk+/Gdk to create a native window for this widget instead of
//	  // drawing onto the parent widget.
//	  // This is here just for pedagogical purposes, GDK_WINDOW_XID will call
//	  // it as well in newer Gtk versions
//	  if (!gdk_window_ensure_native (widget->window))
//	    g_error ("Couldn't create native window needed for GstVideoOverlay!");
//	#endif
//
//	#ifdef GDK_WINDOWING_X11
//	  {
//	    gulong xid = GDK_WINDOW_XID (gtk_widget_get_window (video_window));
//	    video_window_handle = xid;
//	  }
//	#endif
//	#ifdef GDK_WINDOWING_WIN32
//	  {
//	    HWND wnd = GDK_WINDOW_HWND (gtk_widget_get_window (video_window));
//	    video_window_handle = (guintptr) wnd;
//	  }
//	#endif
//	}
//	...
//	int
//	main (int argc, char **argv)
//	{
//	  GtkWidget *video_window;
//	  GtkWidget *app_window;
//	  ...
//	  app_window = gtk_window_new (GTK_WINDOW_TOPLEVEL);
//	  ...
//	  video_window = gtk_drawing_area_new ();
//	  g_signal_connect (video_window, "realize",
//	      G_CALLBACK (video_widget_realize_cb), NULL);
//	  gtk_widget_set_double_buffered (video_window, FALSE);
//	  ...
//	  // usually the video_window will not be directly embedded into the
//	  // application window like this, but there will be many other widgets
//	  // and the video window will be embedded in one of them instead
//	  gtk_container_add (GTK_CONTAINER (ap_window), video_window);
//	  ...
//	  // show the GUI
//	  gtk_widget_show_all (app_window);
//
//	  // realize window now so that the video window gets created and we can
//	  // obtain its XID/HWND before the pipeline is started up and the videosink
//	  // asks for the XID/HWND of the window to render onto
//	  gtk_widget_realize (video_window);
//
//	  // we should have the XID/HWND now
//	  g_assert (video_window_handle != 0);
//	  ...
//	  // set up sync handler for setting the xid once the pipeline is started
//	  bus = gst_pipeline_get_bus (GST_PIPELINE (pipeline));
//	  gst_bus_set_sync_handler (bus, (GstBusSyncHandler) bus_sync_handler, NULL,
//	      NULL);
//	  gst_object_unref (bus);
//	  ...
//	  gst_element_set_state (pipeline, GST_STATE_PLAYING);
//	  ...
//	}
//
// GstVideoOverlay and Qt
//
//	#include <glib.h>;
//	#include <gst/gst.h>;
//	#include <gst/video/videooverlay.h>;
//
//	#include <QApplication>;
//	#include <QTimer>;
//	#include <QWidget>;
//
//	int main(int argc, char *argv[])
//	{
//	  if (!g_thread_supported ())
//	    g_thread_init (NULL);
//
//	  gst_init (&argc, &argv);
//	  QApplication app(argc, argv);
//	  app.connect(&app, SIGNAL(lastWindowClosed()), &app, SLOT(quit ()));
//
//	  // prepare the pipeline
//
//	  GstElement *pipeline = gst_pipeline_new ("xvoverlay");
//	  GstElement *src = gst_element_factory_make ("videotestsrc", NULL);
//	  GstElement *sink = gst_element_factory_make ("xvimagesink", NULL);
//	  gst_bin_add_many (GST_BIN (pipeline), src, sink, NULL);
//	  gst_element_link (src, sink);
//
//	  // prepare the ui
//
//	  QWidget window;
//	  window.resize(320, 240);
//	  window.show();
//
//	  WId xwinid = window.winId();
//	  gst_video_overlay_set_window_handle (GST_VIDEO_OVERLAY (sink), xwinid);
//
//	  // run the pipeline
//
//	  GstStateChangeReturn sret = gst_element_set_state (pipeline,
//	      GST_STATE_PLAYING);
//	  if (sret == GST_STATE_CHANGE_FAILURE) {
//	    gst_element_set_state (pipeline, GST_STATE_NULL);
//	    gst_object_unref (pipeline);
//	    // Exit application
//	    QTimer::singleShot(0, QApplication::activeWindow(), SLOT(quit()));
//	  }
//
//	  int ret = app.exec();
//
//	  window.hide();
//	  gst_element_set_state (pipeline, GST_STATE_NULL);
//	  gst_object_unref (pipeline);
//
//	  return ret;
//	}.
//
// VideoOverlay wraps an interface. This means the user can get the
// underlying type by calling Cast().
type VideoOverlay struct {
	_ [0]func() // equal guard
	*coreglib.Object
}

var (
	_ coreglib.Objector = (*VideoOverlay)(nil)
)

// VideoOverlayer describes VideoOverlay's interface methods.
type VideoOverlayer interface {
	coreglib.Objector

	// Expose: tell an overlay that it has been exposed.
	Expose()
	// GotWindowHandle: this will post a "have-window-handle" element message on
	// the bus.
	GotWindowHandle(handle uintptr)
	// HandleEvents: tell an overlay that it should handle events from the
	// window system.
	HandleEvents(handleEvents bool)
	// PrepareWindowHandle: this will post a "prepare-window-handle" element
	// message on the bus to give applications an opportunity to call
	// gst_video_overlay_set_window_handle() before a plugin creates its own
	// window.
	PrepareWindowHandle()
	// SetRenderRectangle: configure a subregion as a video target within the
	// window set by gst_video_overlay_set_window_handle().
	SetRenderRectangle(x, y, width, height int) bool
	// SetWindowHandle: this will call the video overlay's set_window_handle
	// method.
	SetWindowHandle(handle uintptr)
}

var _ VideoOverlayer = (*VideoOverlay)(nil)

func wrapVideoOverlay(obj *coreglib.Object) *VideoOverlay {
	return &VideoOverlay{
		Object: obj,
	}
}

func marshalVideoOverlay(p uintptr) (interface{}, error) {
	return wrapVideoOverlay(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

// Expose: tell an overlay that it has been exposed. This will redraw the
// current frame in the drawable even if the pipeline is PAUSED.
func (overlay *VideoOverlay) Expose() {
	var _arg0 *C.GstVideoOverlay // out

	_arg0 = (*C.GstVideoOverlay)(unsafe.Pointer(coreglib.BaseObject(overlay).Native()))

	C.gst_video_overlay_expose(_arg0)
	runtime.KeepAlive(overlay)
}

// GotWindowHandle: this will post a "have-window-handle" element message on the
// bus.
//
// This function should only be used by video overlay plugin developers.
//
// The function takes the following parameters:
//
//   - handle: platform-specific handle referencing the window.
func (overlay *VideoOverlay) GotWindowHandle(handle uintptr) {
	var _arg0 *C.GstVideoOverlay // out
	var _arg1 C.guintptr         // out

	_arg0 = (*C.GstVideoOverlay)(unsafe.Pointer(coreglib.BaseObject(overlay).Native()))
	_arg1 = C.guintptr(handle)

	C.gst_video_overlay_got_window_handle(_arg0, _arg1)
	runtime.KeepAlive(overlay)
	runtime.KeepAlive(handle)
}

// HandleEvents: tell an overlay that it should handle events from the window
// system. These events are forwarded upstream as navigation events. In some
// window system, events are not propagated in the window hierarchy if a client
// is listening for them. This method allows you to disable events handling
// completely from the VideoOverlay.
//
// The function takes the following parameters:
//
//   - handleEvents indicating if events should be handled or not.
func (overlay *VideoOverlay) HandleEvents(handleEvents bool) {
	var _arg0 *C.GstVideoOverlay // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstVideoOverlay)(unsafe.Pointer(coreglib.BaseObject(overlay).Native()))
	if handleEvents {
		_arg1 = C.TRUE
	}

	C.gst_video_overlay_handle_events(_arg0, _arg1)
	runtime.KeepAlive(overlay)
	runtime.KeepAlive(handleEvents)
}

// PrepareWindowHandle: this will post a "prepare-window-handle" element
// message on the bus to give applications an opportunity to call
// gst_video_overlay_set_window_handle() before a plugin creates its own window.
//
// This function should only be used by video overlay plugin developers.
func (overlay *VideoOverlay) PrepareWindowHandle() {
	var _arg0 *C.GstVideoOverlay // out

	_arg0 = (*C.GstVideoOverlay)(unsafe.Pointer(coreglib.BaseObject(overlay).Native()))

	C.gst_video_overlay_prepare_window_handle(_arg0)
	runtime.KeepAlive(overlay)
}

// SetRenderRectangle: configure a subregion as a video target within the window
// set by gst_video_overlay_set_window_handle(). If this is not used or not
// supported the video will fill the area of the window set as the overlay to
// 100%. By specifying the rectangle, the video can be overlayed to a specific
// region of that window only. After setting the new rectangle one should call
// gst_video_overlay_expose() to force a redraw. To unset the region pass -1 for
// the width and height parameters.
//
// This method is needed for non fullscreen video overlay in UI toolkits that do
// not support subwindows.
//
// The function takes the following parameters:
//
//   - x: horizontal offset of the render area inside the window.
//   - y: vertical offset of the render area inside the window.
//   - width of the render area inside the window.
//   - height of the render area inside the window.
//
// The function returns the following values:
//
//   - ok: FALSE if not supported by the sink.
func (overlay *VideoOverlay) SetRenderRectangle(x, y, width, height int) bool {
	var _arg0 *C.GstVideoOverlay // out
	var _arg1 C.gint             // out
	var _arg2 C.gint             // out
	var _arg3 C.gint             // out
	var _arg4 C.gint             // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoOverlay)(unsafe.Pointer(coreglib.BaseObject(overlay).Native()))
	_arg1 = C.gint(x)
	_arg2 = C.gint(y)
	_arg3 = C.gint(width)
	_arg4 = C.gint(height)

	_cret = C.gst_video_overlay_set_render_rectangle(_arg0, _arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(overlay)
	runtime.KeepAlive(x)
	runtime.KeepAlive(y)
	runtime.KeepAlive(width)
	runtime.KeepAlive(height)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SetWindowHandle: this will call the video overlay's set_window_handle method.
// You should use this method to tell to an overlay to display video output to a
// specific window (e.g. an XWindow on X11). Passing 0 as the handle will tell
// the overlay to stop using that window and create an internal one.
//
// The function takes the following parameters:
//
//   - handle referencing the window.
func (overlay *VideoOverlay) SetWindowHandle(handle uintptr) {
	var _arg0 *C.GstVideoOverlay // out
	var _arg1 C.guintptr         // out

	_arg0 = (*C.GstVideoOverlay)(unsafe.Pointer(coreglib.BaseObject(overlay).Native()))
	_arg1 = C.guintptr(handle)

	C.gst_video_overlay_set_window_handle(_arg0, _arg1)
	runtime.KeepAlive(overlay)
	runtime.KeepAlive(handle)
}

// Expose: tell an overlay that it has been exposed. This will redraw the
// current frame in the drawable even if the pipeline is PAUSED.
func (overlay *VideoOverlay) expose() {
	gclass := (*C.GstVideoOverlayInterface)(coreglib.PeekParentClass(overlay))
	fnarg := gclass.expose

	var _arg0 *C.GstVideoOverlay // out

	_arg0 = (*C.GstVideoOverlay)(unsafe.Pointer(coreglib.BaseObject(overlay).Native()))

	C._gotk4_gstvideo1_VideoOverlay_virtual_expose(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(overlay)
}

// handleEvents: tell an overlay that it should handle events from the window
// system. These events are forwarded upstream as navigation events. In some
// window system, events are not propagated in the window hierarchy if a client
// is listening for them. This method allows you to disable events handling
// completely from the VideoOverlay.
//
// The function takes the following parameters:
//
//   - handleEvents indicating if events should be handled or not.
func (overlay *VideoOverlay) handleEvents(handleEvents bool) {
	gclass := (*C.GstVideoOverlayInterface)(coreglib.PeekParentClass(overlay))
	fnarg := gclass.handle_events

	var _arg0 *C.GstVideoOverlay // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstVideoOverlay)(unsafe.Pointer(coreglib.BaseObject(overlay).Native()))
	if handleEvents {
		_arg1 = C.TRUE
	}

	C._gotk4_gstvideo1_VideoOverlay_virtual_handle_events(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(overlay)
	runtime.KeepAlive(handleEvents)
}

// setRenderRectangle: virtual method to set the render rectangle.
//
// The function takes the following parameters:
//
//   - x
//   - y
//   - width
//   - height
func (overlay *VideoOverlay) setRenderRectangle(x, y, width, height int) {
	gclass := (*C.GstVideoOverlayInterface)(coreglib.PeekParentClass(overlay))
	fnarg := gclass.set_render_rectangle

	var _arg0 *C.GstVideoOverlay // out
	var _arg1 C.gint             // out
	var _arg2 C.gint             // out
	var _arg3 C.gint             // out
	var _arg4 C.gint             // out

	_arg0 = (*C.GstVideoOverlay)(unsafe.Pointer(coreglib.BaseObject(overlay).Native()))
	_arg1 = C.gint(x)
	_arg2 = C.gint(y)
	_arg3 = C.gint(width)
	_arg4 = C.gint(height)

	C._gotk4_gstvideo1_VideoOverlay_virtual_set_render_rectangle(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(overlay)
	runtime.KeepAlive(x)
	runtime.KeepAlive(y)
	runtime.KeepAlive(width)
	runtime.KeepAlive(height)
}

// setWindowHandle: this will call the video overlay's set_window_handle method.
// You should use this method to tell to an overlay to display video output to a
// specific window (e.g. an XWindow on X11). Passing 0 as the handle will tell
// the overlay to stop using that window and create an internal one.
//
// The function takes the following parameters:
//
//   - handle referencing the window.
func (overlay *VideoOverlay) setWindowHandle(handle uintptr) {
	gclass := (*C.GstVideoOverlayInterface)(coreglib.PeekParentClass(overlay))
	fnarg := gclass.set_window_handle

	var _arg0 *C.GstVideoOverlay // out
	var _arg1 C.guintptr         // out

	_arg0 = (*C.GstVideoOverlay)(unsafe.Pointer(coreglib.BaseObject(overlay).Native()))
	_arg1 = C.guintptr(handle)

	C._gotk4_gstvideo1_VideoOverlay_virtual_set_window_handle(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(overlay)
	runtime.KeepAlive(handle)
}

// VideoOverlaySetProperty: this helper shall be used by classes implementing
// the VideoOverlay interface that want the render rectangle to be controllable
// using properties. This helper will parse and set the render rectangle calling
// gst_video_overlay_set_render_rectangle().
//
// The function takes the following parameters:
//
//   - object: instance on which the property is set.
//   - lastPropId: highest property ID.
//   - propertyId: property ID.
//   - value to be set.
//
// The function returns the following values:
//
//   - ok: TRUE if the property_id matches the GstVideoOverlay property.
func VideoOverlaySetProperty(object *coreglib.Object, lastPropId int, propertyId uint, value *coreglib.Value) bool {
	var _arg1 *C.GObject // out
	var _arg2 C.gint     // out
	var _arg3 C.guint    // out
	var _arg4 *C.GValue  // out
	var _cret C.gboolean // in

	_arg1 = (*C.GObject)(unsafe.Pointer(object.Native()))
	_arg2 = C.gint(lastPropId)
	_arg3 = C.guint(propertyId)
	_arg4 = (*C.GValue)(unsafe.Pointer(value.Native()))

	_cret = C.gst_video_overlay_set_property(_arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(object)
	runtime.KeepAlive(lastPropId)
	runtime.KeepAlive(propertyId)
	runtime.KeepAlive(value)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// ColorBalanceChannelOverrides contains methods that are overridable.
type ColorBalanceChannelOverrides struct {
	// ValueChanged: default handler for value changed notification.
	ValueChanged func(value int)
}

func defaultColorBalanceChannelOverrides(v *ColorBalanceChannel) ColorBalanceChannelOverrides {
	return ColorBalanceChannelOverrides{
		ValueChanged: v.valueChanged,
	}
}

// ColorBalanceChannel object represents a parameter for modifying the color
// balance implemented by an element providing the ColorBalance interface.
// For example, Hue or Saturation.
type ColorBalanceChannel struct {
	_ [0]func() // equal guard
	*coreglib.Object
}

var (
	_ coreglib.Objector = (*ColorBalanceChannel)(nil)
)

func init() {
	coreglib.RegisterClassInfo[*ColorBalanceChannel, *ColorBalanceChannelClass, ColorBalanceChannelOverrides](
		GTypeColorBalanceChannel,
		initColorBalanceChannelClass,
		wrapColorBalanceChannel,
		defaultColorBalanceChannelOverrides,
	)
}

func initColorBalanceChannelClass(gclass unsafe.Pointer, overrides ColorBalanceChannelOverrides, classInitFunc func(*ColorBalanceChannelClass)) {
	pclass := (*C.GstColorBalanceChannelClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeColorBalanceChannel))))

	if overrides.ValueChanged != nil {
		pclass.value_changed = (*[0]byte)(C._gotk4_gstvideo1_ColorBalanceChannelClass_value_changed)
	}

	if classInitFunc != nil {
		class := (*ColorBalanceChannelClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapColorBalanceChannel(obj *coreglib.Object) *ColorBalanceChannel {
	return &ColorBalanceChannel{
		Object: obj,
	}
}

func marshalColorBalanceChannel(p uintptr) (interface{}, error) {
	return wrapColorBalanceChannel(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

// ConnectValueChanged: fired when the value of the indicated channel has
// changed.
func (v *ColorBalanceChannel) ConnectValueChanged(f func(value int)) coreglib.SignalHandle {
	return coreglib.ConnectGeneratedClosure(v, "value-changed", false, unsafe.Pointer(C._gotk4_gstvideo1_ColorBalanceChannel_ConnectValueChanged), f)
}

// valueChanged: default handler for value changed notification.
func (channel *ColorBalanceChannel) valueChanged(value int) {
	gclass := (*C.GstColorBalanceChannelClass)(coreglib.PeekParentClass(channel))
	fnarg := gclass.value_changed

	var _arg0 *C.GstColorBalanceChannel // out
	var _arg1 C.gint                    // out

	_arg0 = (*C.GstColorBalanceChannel)(unsafe.Pointer(coreglib.BaseObject(channel).Native()))
	_arg1 = C.gint(value)

	C._gotk4_gstvideo1_ColorBalanceChannel_virtual_value_changed(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(channel)
	runtime.KeepAlive(value)
}

// VideoAggregatorOverrides contains methods that are overridable.
type VideoAggregatorOverrides struct {
	// AggregateFrames lets subclasses aggregate frames that are
	// ready. Subclasses should iterate the GstElement.sinkpads
	// and use the already mapped VideoFrame from
	// gst_video_aggregator_pad_get_prepared_frame() or directly use the Buffer
	// from gst_video_aggregator_pad_get_current_buffer() if it needs to map
	// the buffer in a special way. The result of the aggregation should land in
	// outbuffer.
	AggregateFrames func(outbuffer *gst.Buffer) gst.FlowReturn
	// The function takes the following parameters:
	//
	//   - downstreamCaps
	//   - bestInfo
	FindBestFormat func(downstreamCaps *gst.Caps, bestInfo *VideoInfo) bool
	// UpdateCaps: optional. Lets subclasses update the Caps representing the
	// src pad caps before usage. Return NULL to indicate failure.
	UpdateCaps func(caps *gst.Caps) *gst.Caps
}

func defaultVideoAggregatorOverrides(v *VideoAggregator) VideoAggregatorOverrides {
	return VideoAggregatorOverrides{
		AggregateFrames: v.aggregateFrames,
		FindBestFormat:  v.findBestFormat,
		UpdateCaps:      v.updateCaps,
	}
}

// VideoAggregator can accept AYUV, ARGB and BGRA video streams. For each of
// the requested sink pads it will compare the incoming geometry and framerate
// to define the output parameters. Indeed output video frames will have the
// geometry of the biggest incoming video stream and the framerate of the
// fastest incoming one.
//
// VideoAggregator will do colorspace conversion.
//
// Zorder for each input stream can be configured on the VideoAggregatorPad.
type VideoAggregator struct {
	_ [0]func() // equal guard
	gstbase.Aggregator
}

var (
	_ gstbase.Aggregatorrer = (*VideoAggregator)(nil)
)

// VideoAggregatorrer describes types inherited from class VideoAggregator.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type VideoAggregatorrer interface {
	coreglib.Objector
	baseVideoAggregator() *VideoAggregator
}

var _ VideoAggregatorrer = (*VideoAggregator)(nil)

func init() {
	coreglib.RegisterClassInfo[*VideoAggregator, *VideoAggregatorClass, VideoAggregatorOverrides](
		GTypeVideoAggregator,
		initVideoAggregatorClass,
		wrapVideoAggregator,
		defaultVideoAggregatorOverrides,
	)
}

func initVideoAggregatorClass(gclass unsafe.Pointer, overrides VideoAggregatorOverrides, classInitFunc func(*VideoAggregatorClass)) {
	pclass := (*C.GstVideoAggregatorClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeVideoAggregator))))

	if overrides.AggregateFrames != nil {
		pclass.aggregate_frames = (*[0]byte)(C._gotk4_gstvideo1_VideoAggregatorClass_aggregate_frames)
	}

	if overrides.FindBestFormat != nil {
		pclass.find_best_format = (*[0]byte)(C._gotk4_gstvideo1_VideoAggregatorClass_find_best_format)
	}

	if overrides.UpdateCaps != nil {
		pclass.update_caps = (*[0]byte)(C._gotk4_gstvideo1_VideoAggregatorClass_update_caps)
	}

	if classInitFunc != nil {
		class := (*VideoAggregatorClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapVideoAggregator(obj *coreglib.Object) *VideoAggregator {
	return &VideoAggregator{
		Aggregator: gstbase.Aggregator{
			Element: gst.Element{
				GstObject: gst.GstObject{
					InitiallyUnowned: coreglib.InitiallyUnowned{
						Object: obj,
					},
				},
			},
		},
	}
}

func marshalVideoAggregator(p uintptr) (interface{}, error) {
	return wrapVideoAggregator(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (v *VideoAggregator) baseVideoAggregator() *VideoAggregator {
	return v
}

// BaseVideoAggregator returns the underlying base object.
func BaseVideoAggregator(obj VideoAggregatorrer) *VideoAggregator {
	return obj.baseVideoAggregator()
}

// aggregateFrames lets subclasses aggregate frames that are ready. Subclasses
// should iterate the GstElement.sinkpads and use the already mapped VideoFrame
// from gst_video_aggregator_pad_get_prepared_frame() or directly use the
// Buffer from gst_video_aggregator_pad_get_current_buffer() if it needs to map
// the buffer in a special way. The result of the aggregation should land in
// outbuffer.
func (videoaggregator *VideoAggregator) aggregateFrames(outbuffer *gst.Buffer) gst.FlowReturn {
	gclass := (*C.GstVideoAggregatorClass)(coreglib.PeekParentClass(videoaggregator))
	fnarg := gclass.aggregate_frames

	var _arg0 *C.GstVideoAggregator // out
	var _arg1 *C.GstBuffer          // out
	var _cret C.GstFlowReturn       // in

	_arg0 = (*C.GstVideoAggregator)(unsafe.Pointer(coreglib.BaseObject(videoaggregator).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(outbuffer)))

	_cret = C._gotk4_gstvideo1_VideoAggregator_virtual_aggregate_frames(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(videoaggregator)
	runtime.KeepAlive(outbuffer)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// The function takes the following parameters:
//
//   - downstreamCaps
//   - bestInfo
func (vagg *VideoAggregator) findBestFormat(downstreamCaps *gst.Caps, bestInfo *VideoInfo) bool {
	gclass := (*C.GstVideoAggregatorClass)(coreglib.PeekParentClass(vagg))
	fnarg := gclass.find_best_format

	var _arg0 *C.GstVideoAggregator // out
	var _arg1 *C.GstCaps            // out
	var _arg2 *C.GstVideoInfo       // out
	var _arg3 C.gboolean            // in

	_arg0 = (*C.GstVideoAggregator)(unsafe.Pointer(coreglib.BaseObject(vagg).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(downstreamCaps)))
	_arg2 = (*C.GstVideoInfo)(gextras.StructNative(unsafe.Pointer(bestInfo)))

	C._gotk4_gstvideo1_VideoAggregator_virtual_find_best_format(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2, &_arg3)
	runtime.KeepAlive(vagg)
	runtime.KeepAlive(downstreamCaps)
	runtime.KeepAlive(bestInfo)

	var _atLeastOneAlpha bool // out

	if _arg3 != 0 {
		_atLeastOneAlpha = true
	}

	return _atLeastOneAlpha
}

// updateCaps: optional. Lets subclasses update the Caps representing the src
// pad caps before usage. Return NULL to indicate failure.
func (videoaggregator *VideoAggregator) updateCaps(caps *gst.Caps) *gst.Caps {
	gclass := (*C.GstVideoAggregatorClass)(coreglib.PeekParentClass(videoaggregator))
	fnarg := gclass.update_caps

	var _arg0 *C.GstVideoAggregator // out
	var _arg1 *C.GstCaps            // out
	var _cret *C.GstCaps            // in

	_arg0 = (*C.GstVideoAggregator)(unsafe.Pointer(coreglib.BaseObject(videoaggregator).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C._gotk4_gstvideo1_VideoAggregator_virtual_update_caps(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(videoaggregator)
	runtime.KeepAlive(caps)

	var _ret *gst.Caps // out

	_ret = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_ret)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _ret
}

// VideoAggregatorConvertPadOverrides contains methods that are overridable.
type VideoAggregatorConvertPadOverrides struct {
	// The function takes the following parameters:
	//
	//   - agg
	//   - conversionInfo
	CreateConversionInfo func(agg VideoAggregatorrer, conversionInfo *VideoInfo)
}

func defaultVideoAggregatorConvertPadOverrides(v *VideoAggregatorConvertPad) VideoAggregatorConvertPadOverrides {
	return VideoAggregatorConvertPadOverrides{
		CreateConversionInfo: v.createConversionInfo,
	}
}

// VideoAggregatorConvertPad: implementation of GstPad that can be used with
// VideoAggregator.
//
// See VideoAggregator for more details.
type VideoAggregatorConvertPad struct {
	_ [0]func() // equal guard
	VideoAggregatorPad
}

var (
	_ gst.GstObjector = (*VideoAggregatorConvertPad)(nil)
)

func init() {
	coreglib.RegisterClassInfo[*VideoAggregatorConvertPad, *VideoAggregatorConvertPadClass, VideoAggregatorConvertPadOverrides](
		GTypeVideoAggregatorConvertPad,
		initVideoAggregatorConvertPadClass,
		wrapVideoAggregatorConvertPad,
		defaultVideoAggregatorConvertPadOverrides,
	)
}

func initVideoAggregatorConvertPadClass(gclass unsafe.Pointer, overrides VideoAggregatorConvertPadOverrides, classInitFunc func(*VideoAggregatorConvertPadClass)) {
	pclass := (*C.GstVideoAggregatorConvertPadClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeVideoAggregatorConvertPad))))

	if overrides.CreateConversionInfo != nil {
		pclass.create_conversion_info = (*[0]byte)(C._gotk4_gstvideo1_VideoAggregatorConvertPadClass_create_conversion_info)
	}

	if classInitFunc != nil {
		class := (*VideoAggregatorConvertPadClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapVideoAggregatorConvertPad(obj *coreglib.Object) *VideoAggregatorConvertPad {
	return &VideoAggregatorConvertPad{
		VideoAggregatorPad: VideoAggregatorPad{
			AggregatorPad: gstbase.AggregatorPad{
				Pad: gst.Pad{
					GstObject: gst.GstObject{
						InitiallyUnowned: coreglib.InitiallyUnowned{
							Object: obj,
						},
					},
				},
			},
		},
	}
}

func marshalVideoAggregatorConvertPad(p uintptr) (interface{}, error) {
	return wrapVideoAggregatorConvertPad(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

// UpdateConversionInfo requests the pad to check and update the converter
// before the next usage to update for any changes that have happened.
func (pad *VideoAggregatorConvertPad) UpdateConversionInfo() {
	var _arg0 *C.GstVideoAggregatorConvertPad // out

	_arg0 = (*C.GstVideoAggregatorConvertPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))

	C.gst_video_aggregator_convert_pad_update_conversion_info(_arg0)
	runtime.KeepAlive(pad)
}

// The function takes the following parameters:
//
//   - agg
//   - conversionInfo
func (pad *VideoAggregatorConvertPad) createConversionInfo(agg VideoAggregatorrer, conversionInfo *VideoInfo) {
	gclass := (*C.GstVideoAggregatorConvertPadClass)(coreglib.PeekParentClass(pad))
	fnarg := gclass.create_conversion_info

	var _arg0 *C.GstVideoAggregatorConvertPad // out
	var _arg1 *C.GstVideoAggregator           // out
	var _arg2 *C.GstVideoInfo                 // out

	_arg0 = (*C.GstVideoAggregatorConvertPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))
	_arg1 = (*C.GstVideoAggregator)(unsafe.Pointer(coreglib.BaseObject(agg).Native()))
	_arg2 = (*C.GstVideoInfo)(gextras.StructNative(unsafe.Pointer(conversionInfo)))

	C._gotk4_gstvideo1_VideoAggregatorConvertPad_virtual_create_conversion_info(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(pad)
	runtime.KeepAlive(agg)
	runtime.KeepAlive(conversionInfo)
}

// VideoAggregatorPadOverrides contains methods that are overridable.
type VideoAggregatorPadOverrides struct {
	// CleanFrame: clean the frame previously prepared in prepare_frame.
	//
	// The function takes the following parameters:
	//
	//   - videoaggregator
	//   - preparedFrame
	CleanFrame func(videoaggregator VideoAggregatorrer, preparedFrame *VideoFrame)
	// PrepareFrame: prepare the frame from the pad buffer and sets it to
	// prepared_frame. Implementations should always return TRUE. Returning
	// FALSE will cease iteration over subsequent pads.
	//
	// The function takes the following parameters:
	//
	//   - videoaggregator
	//   - buffer
	//   - preparedFrame
	PrepareFrame func(videoaggregator VideoAggregatorrer, buffer *gst.Buffer, preparedFrame *VideoFrame) bool
	// PrepareFrameFinish: finish preparing prepared_frame.
	//
	// If overriden, prepare_frame_start must also be overriden.
	//
	// The function takes the following parameters:
	//
	//   - videoaggregator: parent VideoAggregator.
	//   - preparedFrame to prepare into.
	PrepareFrameFinish func(videoaggregator VideoAggregatorrer, preparedFrame *VideoFrame)
	// PrepareFrameStart: begin preparing the frame from the pad buffer and sets
	// it to prepared_frame.
	//
	// If overriden, prepare_frame_finish must also be overriden.
	//
	// The function takes the following parameters:
	//
	//   - videoaggregator: parent VideoAggregator.
	//   - buffer: input Buffer to prepare.
	//   - preparedFrame to prepare into.
	PrepareFrameStart func(videoaggregator VideoAggregatorrer, buffer *gst.Buffer, preparedFrame *VideoFrame)
	// UpdateConversionInfo: called when either the input or output formats have
	// changed.
	UpdateConversionInfo func()
}

func defaultVideoAggregatorPadOverrides(v *VideoAggregatorPad) VideoAggregatorPadOverrides {
	return VideoAggregatorPadOverrides{
		CleanFrame:           v.cleanFrame,
		PrepareFrame:         v.prepareFrame,
		PrepareFrameFinish:   v.prepareFrameFinish,
		PrepareFrameStart:    v.prepareFrameStart,
		UpdateConversionInfo: v.updateConversionInfo,
	}
}

type VideoAggregatorPad struct {
	_ [0]func() // equal guard
	gstbase.AggregatorPad
}

var (
	_ gst.GstObjector = (*VideoAggregatorPad)(nil)
)

func init() {
	coreglib.RegisterClassInfo[*VideoAggregatorPad, *VideoAggregatorPadClass, VideoAggregatorPadOverrides](
		GTypeVideoAggregatorPad,
		initVideoAggregatorPadClass,
		wrapVideoAggregatorPad,
		defaultVideoAggregatorPadOverrides,
	)
}

func initVideoAggregatorPadClass(gclass unsafe.Pointer, overrides VideoAggregatorPadOverrides, classInitFunc func(*VideoAggregatorPadClass)) {
	pclass := (*C.GstVideoAggregatorPadClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeVideoAggregatorPad))))

	if overrides.CleanFrame != nil {
		pclass.clean_frame = (*[0]byte)(C._gotk4_gstvideo1_VideoAggregatorPadClass_clean_frame)
	}

	if overrides.PrepareFrame != nil {
		pclass.prepare_frame = (*[0]byte)(C._gotk4_gstvideo1_VideoAggregatorPadClass_prepare_frame)
	}

	if overrides.PrepareFrameFinish != nil {
		pclass.prepare_frame_finish = (*[0]byte)(C._gotk4_gstvideo1_VideoAggregatorPadClass_prepare_frame_finish)
	}

	if overrides.PrepareFrameStart != nil {
		pclass.prepare_frame_start = (*[0]byte)(C._gotk4_gstvideo1_VideoAggregatorPadClass_prepare_frame_start)
	}

	if overrides.UpdateConversionInfo != nil {
		pclass.update_conversion_info = (*[0]byte)(C._gotk4_gstvideo1_VideoAggregatorPadClass_update_conversion_info)
	}

	if classInitFunc != nil {
		class := (*VideoAggregatorPadClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapVideoAggregatorPad(obj *coreglib.Object) *VideoAggregatorPad {
	return &VideoAggregatorPad{
		AggregatorPad: gstbase.AggregatorPad{
			Pad: gst.Pad{
				GstObject: gst.GstObject{
					InitiallyUnowned: coreglib.InitiallyUnowned{
						Object: obj,
					},
				},
			},
		},
	}
}

func marshalVideoAggregatorPad(p uintptr) (interface{}, error) {
	return wrapVideoAggregatorPad(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

// CurrentBuffer returns the currently queued buffer that is going to be used
// for the current output frame.
//
// This must only be called from the VideoAggregatorClass::aggregate_frames
// virtual method, or from the VideoAggregatorPadClass::prepare_frame virtual
// method of the aggregator pads.
//
// The return value is only valid until VideoAggregatorClass::aggregate_frames
// or VideoAggregatorPadClass::prepare_frame returns.
//
// The function returns the following values:
//
//   - buffer: currently queued buffer.
func (pad *VideoAggregatorPad) CurrentBuffer() *gst.Buffer {
	var _arg0 *C.GstVideoAggregatorPad // out
	var _cret *C.GstBuffer             // in

	_arg0 = (*C.GstVideoAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))

	_cret = C.gst_video_aggregator_pad_get_current_buffer(_arg0)
	runtime.KeepAlive(pad)

	var _buffer *gst.Buffer // out

	_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	C.gst_mini_object_ref((*C.GstMiniObject)(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_buffer)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _buffer
}

// PreparedFrame returns the currently prepared video frame that has to be
// aggregated into the current output frame.
//
// This must only be called from the VideoAggregatorClass::aggregate_frames
// virtual method, or from the VideoAggregatorPadClass::prepare_frame virtual
// method of the aggregator pads.
//
// The return value is only valid until VideoAggregatorClass::aggregate_frames
// or VideoAggregatorPadClass::prepare_frame returns.
//
// The function returns the following values:
//
//   - videoFrame: currently prepared video frame.
func (pad *VideoAggregatorPad) PreparedFrame() *VideoFrame {
	var _arg0 *C.GstVideoAggregatorPad // out
	var _cret *C.GstVideoFrame         // in

	_arg0 = (*C.GstVideoAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))

	_cret = C.gst_video_aggregator_pad_get_prepared_frame(_arg0)
	runtime.KeepAlive(pad)

	var _videoFrame *VideoFrame // out

	_videoFrame = (*VideoFrame)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _videoFrame
}

// HasCurrentBuffer checks if the pad currently has a buffer queued that is
// going to be used for the current output frame.
//
// This must only be called from the VideoAggregatorClass::aggregate_frames
// virtual method, or from the VideoAggregatorPadClass::prepare_frame virtual
// method of the aggregator pads.
//
// The function returns the following values:
//
//   - ok: TRUE if the pad has currently a buffer queued.
func (pad *VideoAggregatorPad) HasCurrentBuffer() bool {
	var _arg0 *C.GstVideoAggregatorPad // out
	var _cret C.gboolean               // in

	_arg0 = (*C.GstVideoAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))

	_cret = C.gst_video_aggregator_pad_has_current_buffer(_arg0)
	runtime.KeepAlive(pad)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SetNeedsAlpha allows selecting that this pad requires an output format with
// alpha.
//
// The function takes the following parameters:
//
//   - needsAlpha: TRUE if this pad requires alpha output.
func (pad *VideoAggregatorPad) SetNeedsAlpha(needsAlpha bool) {
	var _arg0 *C.GstVideoAggregatorPad // out
	var _arg1 C.gboolean               // out

	_arg0 = (*C.GstVideoAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))
	if needsAlpha {
		_arg1 = C.TRUE
	}

	C.gst_video_aggregator_pad_set_needs_alpha(_arg0, _arg1)
	runtime.KeepAlive(pad)
	runtime.KeepAlive(needsAlpha)
}

// cleanFrame: clean the frame previously prepared in prepare_frame.
//
// The function takes the following parameters:
//
//   - videoaggregator
//   - preparedFrame
func (pad *VideoAggregatorPad) cleanFrame(videoaggregator VideoAggregatorrer, preparedFrame *VideoFrame) {
	gclass := (*C.GstVideoAggregatorPadClass)(coreglib.PeekParentClass(pad))
	fnarg := gclass.clean_frame

	var _arg0 *C.GstVideoAggregatorPad // out
	var _arg1 *C.GstVideoAggregator    // out
	var _arg2 *C.GstVideoFrame         // out

	_arg0 = (*C.GstVideoAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))
	_arg1 = (*C.GstVideoAggregator)(unsafe.Pointer(coreglib.BaseObject(videoaggregator).Native()))
	_arg2 = (*C.GstVideoFrame)(gextras.StructNative(unsafe.Pointer(preparedFrame)))

	C._gotk4_gstvideo1_VideoAggregatorPad_virtual_clean_frame(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(pad)
	runtime.KeepAlive(videoaggregator)
	runtime.KeepAlive(preparedFrame)
}

// prepareFrame: prepare the frame from the pad buffer and sets it to
// prepared_frame. Implementations should always return TRUE. Returning FALSE
// will cease iteration over subsequent pads.
//
// The function takes the following parameters:
//
//   - videoaggregator
//   - buffer
//   - preparedFrame
func (pad *VideoAggregatorPad) prepareFrame(videoaggregator VideoAggregatorrer, buffer *gst.Buffer, preparedFrame *VideoFrame) bool {
	gclass := (*C.GstVideoAggregatorPadClass)(coreglib.PeekParentClass(pad))
	fnarg := gclass.prepare_frame

	var _arg0 *C.GstVideoAggregatorPad // out
	var _arg1 *C.GstVideoAggregator    // out
	var _arg2 *C.GstBuffer             // out
	var _arg3 *C.GstVideoFrame         // out
	var _cret C.gboolean               // in

	_arg0 = (*C.GstVideoAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))
	_arg1 = (*C.GstVideoAggregator)(unsafe.Pointer(coreglib.BaseObject(videoaggregator).Native()))
	_arg2 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg3 = (*C.GstVideoFrame)(gextras.StructNative(unsafe.Pointer(preparedFrame)))

	_cret = C._gotk4_gstvideo1_VideoAggregatorPad_virtual_prepare_frame(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(pad)
	runtime.KeepAlive(videoaggregator)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(preparedFrame)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// prepareFrameFinish: finish preparing prepared_frame.
//
// If overriden, prepare_frame_start must also be overriden.
//
// The function takes the following parameters:
//
//   - videoaggregator: parent VideoAggregator.
//   - preparedFrame to prepare into.
func (pad *VideoAggregatorPad) prepareFrameFinish(videoaggregator VideoAggregatorrer, preparedFrame *VideoFrame) {
	gclass := (*C.GstVideoAggregatorPadClass)(coreglib.PeekParentClass(pad))
	fnarg := gclass.prepare_frame_finish

	var _arg0 *C.GstVideoAggregatorPad // out
	var _arg1 *C.GstVideoAggregator    // out
	var _arg2 *C.GstVideoFrame         // out

	_arg0 = (*C.GstVideoAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))
	_arg1 = (*C.GstVideoAggregator)(unsafe.Pointer(coreglib.BaseObject(videoaggregator).Native()))
	_arg2 = (*C.GstVideoFrame)(gextras.StructNative(unsafe.Pointer(preparedFrame)))

	C._gotk4_gstvideo1_VideoAggregatorPad_virtual_prepare_frame_finish(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(pad)
	runtime.KeepAlive(videoaggregator)
	runtime.KeepAlive(preparedFrame)
}

// prepareFrameStart: begin preparing the frame from the pad buffer and sets it
// to prepared_frame.
//
// If overriden, prepare_frame_finish must also be overriden.
//
// The function takes the following parameters:
//
//   - videoaggregator: parent VideoAggregator.
//   - buffer: input Buffer to prepare.
//   - preparedFrame to prepare into.
func (pad *VideoAggregatorPad) prepareFrameStart(videoaggregator VideoAggregatorrer, buffer *gst.Buffer, preparedFrame *VideoFrame) {
	gclass := (*C.GstVideoAggregatorPadClass)(coreglib.PeekParentClass(pad))
	fnarg := gclass.prepare_frame_start

	var _arg0 *C.GstVideoAggregatorPad // out
	var _arg1 *C.GstVideoAggregator    // out
	var _arg2 *C.GstBuffer             // out
	var _arg3 *C.GstVideoFrame         // out

	_arg0 = (*C.GstVideoAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))
	_arg1 = (*C.GstVideoAggregator)(unsafe.Pointer(coreglib.BaseObject(videoaggregator).Native()))
	_arg2 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg3 = (*C.GstVideoFrame)(gextras.StructNative(unsafe.Pointer(preparedFrame)))

	C._gotk4_gstvideo1_VideoAggregatorPad_virtual_prepare_frame_start(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(pad)
	runtime.KeepAlive(videoaggregator)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(preparedFrame)
}

// updateConversionInfo: called when either the input or output formats have
// changed.
func (pad *VideoAggregatorPad) updateConversionInfo() {
	gclass := (*C.GstVideoAggregatorPadClass)(coreglib.PeekParentClass(pad))
	fnarg := gclass.update_conversion_info

	var _arg0 *C.GstVideoAggregatorPad // out

	_arg0 = (*C.GstVideoAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))

	C._gotk4_gstvideo1_VideoAggregatorPad_virtual_update_conversion_info(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(pad)
}

// VideoAggregatorParallelConvertPadOverrides contains methods that are overridable.
type VideoAggregatorParallelConvertPadOverrides struct {
}

func defaultVideoAggregatorParallelConvertPadOverrides(v *VideoAggregatorParallelConvertPad) VideoAggregatorParallelConvertPadOverrides {
	return VideoAggregatorParallelConvertPadOverrides{}
}

// VideoAggregatorParallelConvertPad: implementation of GstPad that can be used
// with VideoAggregator.
//
// See VideoAggregator for more details.
type VideoAggregatorParallelConvertPad struct {
	_ [0]func() // equal guard
	VideoAggregatorConvertPad
}

var (
	_ gst.GstObjector = (*VideoAggregatorParallelConvertPad)(nil)
)

func init() {
	coreglib.RegisterClassInfo[*VideoAggregatorParallelConvertPad, *VideoAggregatorParallelConvertPadClass, VideoAggregatorParallelConvertPadOverrides](
		GTypeVideoAggregatorParallelConvertPad,
		initVideoAggregatorParallelConvertPadClass,
		wrapVideoAggregatorParallelConvertPad,
		defaultVideoAggregatorParallelConvertPadOverrides,
	)
}

func initVideoAggregatorParallelConvertPadClass(gclass unsafe.Pointer, overrides VideoAggregatorParallelConvertPadOverrides, classInitFunc func(*VideoAggregatorParallelConvertPadClass)) {
	if classInitFunc != nil {
		class := (*VideoAggregatorParallelConvertPadClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapVideoAggregatorParallelConvertPad(obj *coreglib.Object) *VideoAggregatorParallelConvertPad {
	return &VideoAggregatorParallelConvertPad{
		VideoAggregatorConvertPad: VideoAggregatorConvertPad{
			VideoAggregatorPad: VideoAggregatorPad{
				AggregatorPad: gstbase.AggregatorPad{
					Pad: gst.Pad{
						GstObject: gst.GstObject{
							InitiallyUnowned: coreglib.InitiallyUnowned{
								Object: obj,
							},
						},
					},
				},
			},
		},
	}
}

func marshalVideoAggregatorParallelConvertPad(p uintptr) (interface{}, error) {
	return wrapVideoAggregatorParallelConvertPad(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

// VideoBufferPoolOverrides contains methods that are overridable.
type VideoBufferPoolOverrides struct {
}

func defaultVideoBufferPoolOverrides(v *VideoBufferPool) VideoBufferPoolOverrides {
	return VideoBufferPoolOverrides{}
}

type VideoBufferPool struct {
	_ [0]func() // equal guard
	gst.BufferPool
}

var (
	_ gst.GstObjector = (*VideoBufferPool)(nil)
)

func init() {
	coreglib.RegisterClassInfo[*VideoBufferPool, *VideoBufferPoolClass, VideoBufferPoolOverrides](
		GTypeVideoBufferPool,
		initVideoBufferPoolClass,
		wrapVideoBufferPool,
		defaultVideoBufferPoolOverrides,
	)
}

func initVideoBufferPoolClass(gclass unsafe.Pointer, overrides VideoBufferPoolOverrides, classInitFunc func(*VideoBufferPoolClass)) {
	if classInitFunc != nil {
		class := (*VideoBufferPoolClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapVideoBufferPool(obj *coreglib.Object) *VideoBufferPool {
	return &VideoBufferPool{
		BufferPool: gst.BufferPool{
			GstObject: gst.GstObject{
				InitiallyUnowned: coreglib.InitiallyUnowned{
					Object: obj,
				},
			},
		},
	}
}

func marshalVideoBufferPool(p uintptr) (interface{}, error) {
	return wrapVideoBufferPool(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

// NewVideoBufferPool: create a new bufferpool that can allocate video frames.
// This bufferpool supports all the video bufferpool options.
//
// The function returns the following values:
//
//   - videoBufferPool: new BufferPool to allocate video frames.
func NewVideoBufferPool() *VideoBufferPool {
	var _cret *C.GstBufferPool // in

	_cret = C.gst_video_buffer_pool_new()

	var _videoBufferPool *VideoBufferPool // out

	_videoBufferPool = wrapVideoBufferPool(coreglib.AssumeOwnership(unsafe.Pointer(_cret)))

	return _videoBufferPool
}

// VideoDecoderOverrides contains methods that are overridable.
type VideoDecoderOverrides struct {
	// Close: optional. Called when the element changes to GST_STATE_NULL.
	// Allows closing external resources.
	Close func() bool
	// DecideAllocation: optional. Setup the allocation parameters for
	// allocating output buffers. The passed in query contains the result of the
	// downstream allocation query. Subclasses should chain up to the parent
	// implementation to invoke the default handler.
	DecideAllocation func(query *gst.Query) bool
	// Drain: optional. Called to request subclass to decode any data it can at
	// this point, but that more data may arrive after. (e.g. at segment end).
	// Sub-classes should be prepared to handle new data afterward, or seamless
	// segment processing will break. Since: 1.6.
	Drain func() gst.FlowReturn
	// Finish: optional. Called to request subclass to dispatch any pending
	// remaining data at EOS. Sub-classes can refuse to decode new data after.
	Finish func() gst.FlowReturn
	// Flush: optional. Flush all remaining data from the decoder without
	// pushing it downstream. Since: 1.2.
	Flush func() bool
	// Caps: optional. Allows for a custom sink getcaps implementation. If not
	// implemented, default returns gst_video_decoder_proxy_getcaps applied to
	// sink template caps.
	caps func(filter *gst.Caps) *gst.Caps
	// The function takes the following parameters:
	//
	//   - frame to handle.
	HandleFrame func(frame *VideoCodecFrame) gst.FlowReturn
	// The function takes the following parameters:
	//
	//   - timestamp: timestamp of the missing data.
	//   - duration: duration of the missing data.
	//
	// The function returns the following values:
	//
	//   - ok: TRUE if the decoder should be drained afterwards.
	HandleMissingData func(timestamp, duration gst.ClockTime) bool
	// Negotiate with downstream elements to currently configured
	// VideoCodecState. Unmark GST_PAD_FLAG_NEED_RECONFIGURE in any case.
	// But mark it again if negotiate fails.
	//
	// The function returns the following values:
	//
	//   - ok: TRUE if the negotiation succeeded, else FALSE.
	Negotiate func() bool
	// Open: optional. Called when the element changes to GST_STATE_READY.
	// Allows opening external resources.
	Open func() bool
	// Parse: required for non-packetized input. Allows chopping incoming data
	// into manageable units (frames) for subsequent decoding.
	//
	// The function takes the following parameters:
	//
	//   - frame
	//   - adapter
	//   - atEos
	Parse func(frame *VideoCodecFrame, adapter *gstbase.Adapter, atEos bool) gst.FlowReturn
	// ProposeAllocation: optional. Propose buffer allocation parameters
	// for upstream elements. Subclasses should chain up to the parent
	// implementation to invoke the default handler.
	ProposeAllocation func(query *gst.Query) bool
	// Reset: optional. Allows subclass (decoder) to perform post-seek semantics
	// reset. Deprecated.
	Reset func(hard bool) bool
	// SetFormat notifies subclass of incoming data format (caps).
	SetFormat func(state *VideoCodecState) bool
	// SinkEvent: optional. Event handler on the sink pad. This function should
	// return TRUE if the event was handled and should be discarded (i.e.
	// not unref'ed). Subclasses should chain up to the parent implementation to
	// invoke the default handler.
	SinkEvent func(event *gst.Event) bool
	// SinkQuery: optional. Query handler on the sink pad. This function should
	// return TRUE if the query could be performed. Subclasses should chain up
	// to the parent implementation to invoke the default handler. Since: 1.4.
	SinkQuery func(query *gst.Query) bool
	// SrcEvent: optional. Event handler on the source pad. This function should
	// return TRUE if the event was handled and should be discarded (i.e.
	// not unref'ed). Subclasses should chain up to the parent implementation to
	// invoke the default handler.
	SrcEvent func(event *gst.Event) bool
	// SrcQuery: optional. Query handler on the source pad. This function should
	// return TRUE if the query could be performed. Subclasses should chain up
	// to the parent implementation to invoke the default handler. Since: 1.4.
	SrcQuery func(query *gst.Query) bool
	// Start: optional. Called when the element starts processing. Allows
	// opening external resources.
	Start func() bool
	// Stop: optional. Called when the element stops processing. Allows closing
	// external resources.
	Stop func() bool
	// TransformMeta: optional. Transform the metadata on the input buffer to
	// the output buffer. By default this method is copies all meta without tags
	// and meta with only the "video" tag. subclasses can implement this method
	// and return TRUE if the metadata is to be copied. Since: 1.6.
	//
	// The function takes the following parameters:
	//
	//   - frame
	//   - meta
	TransformMeta func(frame *VideoCodecFrame, meta *gst.Meta) bool
}

func defaultVideoDecoderOverrides(v *VideoDecoder) VideoDecoderOverrides {
	return VideoDecoderOverrides{
		Close:             v.close,
		DecideAllocation:  v.decideAllocation,
		Drain:             v.drain,
		Finish:            v.finish,
		Flush:             v.flush,
		caps:              v.caps,
		HandleFrame:       v.handleFrame,
		HandleMissingData: v.handleMissingData,
		Negotiate:         v.negotiate,
		Open:              v.open,
		Parse:             v.parse,
		ProposeAllocation: v.proposeAllocation,
		Reset:             v.reset,
		SetFormat:         v.setFormat,
		SinkEvent:         v.sinkEvent,
		SinkQuery:         v.sinkQuery,
		SrcEvent:          v.srcEvent,
		SrcQuery:          v.srcQuery,
		Start:             v.start,
		Stop:              v.stop,
		TransformMeta:     v.transformMeta,
	}
}

// VideoDecoder: this base class is for video decoders turning encoded data into
// raw video frames.
//
// The GstVideoDecoder base class and derived subclasses should cooperate as
// follows:
//
// Configuration
//
//   - Initially, GstVideoDecoder calls start when the decoder element is
//     activated, which allows the subclass to perform any global setup.
//
//   - GstVideoDecoder calls set_format to inform the subclass of caps
//     describing input video data that it is about to receive, including
//     possibly configuration data. While unlikely, it might be called more than
//     once, if changing input parameters require reconfiguration.
//
//   - Incoming data buffers are processed as needed, described in Data
//     Processing below.
//
//   - GstVideoDecoder calls stop at end of all processing.
//
// Data processing
//
//   - The base class gathers input data, and optionally allows subclass to
//     parse this into subsequently manageable chunks, typically corresponding
//     to and referred to as 'frames'.
//
//   - Each input frame is provided in turn to the subclass' handle_frame
//     callback.
//
//   - When the subclass enables the subframe mode with
//     gst_video_decoder_set_subframe_mode, the base class will provide to
//     the subclass the same input frame with different input buffers to the
//     subclass handle_frame callback. During this call, the subclass needs to
//     take ownership of the input_buffer as GstVideoCodecFrame.input_buffer
//     will have been changed before the next subframe buffer is received.
//     The subclass will call gst_video_decoder_have_last_subframe when a new
//     input frame can be created by the base class. Every subframe will share
//     the same GstVideoCodecFrame.output_buffer to write the decoding result.
//     The subclass is responsible to protect its access.
//
//   - If codec processing results in decoded data, the subclass should call
//     gst_video_decoder_finish_frame to have decoded data pushed downstream. In
//     subframe mode the subclass should call gst_video_decoder_finish_subframe
//     until the last subframe where it should call
//     gst_video_decoder_finish_frame. The subclass can detect the last subframe
//     using GST_VIDEO_BUFFER_FLAG_MARKER on buffers or using its own logic to
//     collect the subframes. In case of decoding failure, the subclass must
//     call gst_video_decoder_drop_frame or gst_video_decoder_drop_subframe,
//     to allow the base class to do timestamp and offset tracking, and possibly
//     to requeue the frame for a later attempt in the case of reverse playback.
//
// Shutdown phase
//
//   - The GstVideoDecoder class calls stop to inform the subclass that data
//     parsing will be stopped.
//
// Additional Notes
//
//   - Seeking/Flushing
//
//   - When the pipeline is seeked or otherwise flushed, the subclass is
//     informed via a call to its reset callback, with the hard parameter set to
//     true. This indicates the subclass should drop any internal data queues
//     and timestamps and prepare for a fresh set of buffers to arrive for
//     parsing and decoding.
//
//   - End Of Stream
//
//   - At end-of-stream, the subclass parse function may be called some final
//     times with the at_eos parameter set to true, indicating that the element
//     should not expect any more data to be arriving, and it should parse and
//     remaining frames and call gst_video_decoder_have_frame() if possible.
//
// The subclass is responsible for providing pad template caps for source and
// sink pads. The pads need to be named "sink" and "src". It also needs to
// provide information about the output caps, when they are known. This may
// be when the base class calls the subclass' set_format function, though it
// might be during decoding, before calling gst_video_decoder_finish_frame.
// This is done via gst_video_decoder_set_output_state
//
// The subclass is also responsible for providing (presentation) timestamps
// (likely based on corresponding input ones). If that is not applicable or
// possible, the base class provides limited framerate based interpolation.
//
// Similarly, the base class provides some limited (legacy) seeking support if
// specifically requested by the subclass, as full-fledged support should rather
// be left to upstream demuxer, parser or alike. This simple approach caters for
// seeking and duration reporting using estimated input bitrates. To enable it,
// a subclass should call gst_video_decoder_set_estimate_rate to enable handling
// of incoming byte-streams.
//
// The base class provides some support for reverse playback, in particular in
// case incoming data is not packetized or upstream does not provide fragments
// on keyframe boundaries. However, the subclass should then be prepared for
// the parsing and frame processing stage to occur separately (in normal forward
// processing, the latter immediately follows the former), The subclass also
// needs to ensure the parsing stage properly marks keyframes, unless it knows
// the upstream elements will do so properly for incoming data.
//
// The bare minimum that a functional subclass needs to implement is:
//
//   - Provide pad templates
//
//   - Inform the base class of output caps via
//     gst_video_decoder_set_output_state
//
//   - Parse input data, if it is not considered packetized from
//     upstream Data will be provided to parse which should invoke
//     gst_video_decoder_add_to_frame and gst_video_decoder_have_frame to
//     separate the data belonging to each video frame.
//
//   - Accept data in handle_frame and provide decoded results to
//     gst_video_decoder_finish_frame, or call gst_video_decoder_drop_frame.
type VideoDecoder struct {
	_ [0]func() // equal guard
	gst.Element
}

var (
	_ gst.Elementer = (*VideoDecoder)(nil)
)

// VideoDecoderer describes types inherited from class VideoDecoder.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type VideoDecoderer interface {
	coreglib.Objector
	baseVideoDecoder() *VideoDecoder
}

var _ VideoDecoderer = (*VideoDecoder)(nil)

func init() {
	coreglib.RegisterClassInfo[*VideoDecoder, *VideoDecoderClass, VideoDecoderOverrides](
		GTypeVideoDecoder,
		initVideoDecoderClass,
		wrapVideoDecoder,
		defaultVideoDecoderOverrides,
	)
}

func initVideoDecoderClass(gclass unsafe.Pointer, overrides VideoDecoderOverrides, classInitFunc func(*VideoDecoderClass)) {
	pclass := (*C.GstVideoDecoderClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeVideoDecoder))))

	if overrides.Close != nil {
		pclass.close = (*[0]byte)(C._gotk4_gstvideo1_VideoDecoderClass_close)
	}

	if overrides.DecideAllocation != nil {
		pclass.decide_allocation = (*[0]byte)(C._gotk4_gstvideo1_VideoDecoderClass_decide_allocation)
	}

	if overrides.Drain != nil {
		pclass.drain = (*[0]byte)(C._gotk4_gstvideo1_VideoDecoderClass_drain)
	}

	if overrides.Finish != nil {
		pclass.finish = (*[0]byte)(C._gotk4_gstvideo1_VideoDecoderClass_finish)
	}

	if overrides.Flush != nil {
		pclass.flush = (*[0]byte)(C._gotk4_gstvideo1_VideoDecoderClass_flush)
	}

	if overrides.caps != nil {
		pclass.getcaps = (*[0]byte)(C._gotk4_gstvideo1_VideoDecoderClass_getcaps)
	}

	if overrides.HandleFrame != nil {
		pclass.handle_frame = (*[0]byte)(C._gotk4_gstvideo1_VideoDecoderClass_handle_frame)
	}

	if overrides.HandleMissingData != nil {
		pclass.handle_missing_data = (*[0]byte)(C._gotk4_gstvideo1_VideoDecoderClass_handle_missing_data)
	}

	if overrides.Negotiate != nil {
		pclass.negotiate = (*[0]byte)(C._gotk4_gstvideo1_VideoDecoderClass_negotiate)
	}

	if overrides.Open != nil {
		pclass.open = (*[0]byte)(C._gotk4_gstvideo1_VideoDecoderClass_open)
	}

	if overrides.Parse != nil {
		pclass.parse = (*[0]byte)(C._gotk4_gstvideo1_VideoDecoderClass_parse)
	}

	if overrides.ProposeAllocation != nil {
		pclass.propose_allocation = (*[0]byte)(C._gotk4_gstvideo1_VideoDecoderClass_propose_allocation)
	}

	if overrides.Reset != nil {
		pclass.reset = (*[0]byte)(C._gotk4_gstvideo1_VideoDecoderClass_reset)
	}

	if overrides.SetFormat != nil {
		pclass.set_format = (*[0]byte)(C._gotk4_gstvideo1_VideoDecoderClass_set_format)
	}

	if overrides.SinkEvent != nil {
		pclass.sink_event = (*[0]byte)(C._gotk4_gstvideo1_VideoDecoderClass_sink_event)
	}

	if overrides.SinkQuery != nil {
		pclass.sink_query = (*[0]byte)(C._gotk4_gstvideo1_VideoDecoderClass_sink_query)
	}

	if overrides.SrcEvent != nil {
		pclass.src_event = (*[0]byte)(C._gotk4_gstvideo1_VideoDecoderClass_src_event)
	}

	if overrides.SrcQuery != nil {
		pclass.src_query = (*[0]byte)(C._gotk4_gstvideo1_VideoDecoderClass_src_query)
	}

	if overrides.Start != nil {
		pclass.start = (*[0]byte)(C._gotk4_gstvideo1_VideoDecoderClass_start)
	}

	if overrides.Stop != nil {
		pclass.stop = (*[0]byte)(C._gotk4_gstvideo1_VideoDecoderClass_stop)
	}

	if overrides.TransformMeta != nil {
		pclass.transform_meta = (*[0]byte)(C._gotk4_gstvideo1_VideoDecoderClass_transform_meta)
	}

	if classInitFunc != nil {
		class := (*VideoDecoderClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapVideoDecoder(obj *coreglib.Object) *VideoDecoder {
	return &VideoDecoder{
		Element: gst.Element{
			GstObject: gst.GstObject{
				InitiallyUnowned: coreglib.InitiallyUnowned{
					Object: obj,
				},
			},
		},
	}
}

func marshalVideoDecoder(p uintptr) (interface{}, error) {
	return wrapVideoDecoder(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (decoder *VideoDecoder) baseVideoDecoder() *VideoDecoder {
	return decoder
}

// BaseVideoDecoder returns the underlying base object.
func BaseVideoDecoder(obj VideoDecoderer) *VideoDecoder {
	return obj.baseVideoDecoder()
}

// AddToFrame removes next n_bytes of input data and adds it to currently parsed
// frame.
//
// The function takes the following parameters:
//
//   - nBytes: number of bytes to add.
func (decoder *VideoDecoder) AddToFrame(nBytes int) {
	var _arg0 *C.GstVideoDecoder // out
	var _arg1 C.int              // out

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = C.int(nBytes)

	C.gst_video_decoder_add_to_frame(_arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(nBytes)
}

// AllocateOutputBuffer: helper function that allocates a buffer to hold a video
// frame for decoder's current VideoCodecState.
//
// You should use gst_video_decoder_allocate_output_frame() instead of this
// function, if possible at all.
//
// The function returns the following values:
//
//   - buffer (optional): allocated buffer, or NULL if no buffer could be
//     allocated (e.g. when downstream is flushing or shutting down).
func (decoder *VideoDecoder) AllocateOutputBuffer() *gst.Buffer {
	var _arg0 *C.GstVideoDecoder // out
	var _cret *C.GstBuffer       // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))

	_cret = C.gst_video_decoder_allocate_output_buffer(_arg0)
	runtime.KeepAlive(decoder)

	var _buffer *gst.Buffer // out

	if _cret != nil {
		_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_buffer)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _buffer
}

// AllocateOutputFrame: helper function that allocates a buffer to hold a video
// frame for decoder's current VideoCodecState. Subclass should already have
// configured video state and set src pad caps.
//
// The buffer allocated here is owned by the frame and you should only keep
// references to the frame, not the buffer.
//
// The function takes the following parameters:
//
//   - frame: VideoCodecFrame.
//
// The function returns the following values:
//
//   - flowReturn: GST_FLOW_OK if an output buffer could be allocated.
func (decoder *VideoDecoder) AllocateOutputFrame(frame *VideoCodecFrame) gst.FlowReturn {
	var _arg0 *C.GstVideoDecoder    // out
	var _arg1 *C.GstVideoCodecFrame // out
	var _cret C.GstFlowReturn       // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	_cret = C.gst_video_decoder_allocate_output_frame(_arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(frame)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// AllocateOutputFrameWithParams: same as
// #gst_video_decoder_allocate_output_frame except it allows passing
// BufferPoolAcquireParams to the sub call gst_buffer_pool_acquire_buffer.
//
// The function takes the following parameters:
//
//   - frame: VideoCodecFrame.
//   - params: BufferPoolAcquireParams.
//
// The function returns the following values:
//
//   - flowReturn: GST_FLOW_OK if an output buffer could be allocated.
func (decoder *VideoDecoder) AllocateOutputFrameWithParams(frame *VideoCodecFrame, params *gst.BufferPoolAcquireParams) gst.FlowReturn {
	var _arg0 *C.GstVideoDecoder            // out
	var _arg1 *C.GstVideoCodecFrame         // out
	var _arg2 *C.GstBufferPoolAcquireParams // out
	var _cret C.GstFlowReturn               // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))
	_arg2 = (*C.GstBufferPoolAcquireParams)(gextras.StructNative(unsafe.Pointer(params)))

	_cret = C.gst_video_decoder_allocate_output_frame_with_params(_arg0, _arg1, _arg2)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(frame)
	runtime.KeepAlive(params)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// DropFrame: similar to gst_video_decoder_finish_frame(), but drops frame
// in any case and posts a QoS message with the frame's details on the bus.
// In any case, the frame is considered finished and released.
//
// The function takes the following parameters:
//
//   - frame to drop.
//
// The function returns the following values:
//
//   - flowReturn usually GST_FLOW_OK.
func (dec *VideoDecoder) DropFrame(frame *VideoCodecFrame) gst.FlowReturn {
	var _arg0 *C.GstVideoDecoder    // out
	var _arg1 *C.GstVideoCodecFrame // out
	var _cret C.GstFlowReturn       // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	_cret = C.gst_video_decoder_drop_frame(_arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(frame)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// DropSubframe drops input data. The frame is not considered finished until the
// whole frame is finished or dropped by the subclass.
//
// The function takes the following parameters:
//
//   - frame: VideoCodecFrame.
//
// The function returns the following values:
//
//   - flowReturn usually GST_FLOW_OK.
func (dec *VideoDecoder) DropSubframe(frame *VideoCodecFrame) gst.FlowReturn {
	var _arg0 *C.GstVideoDecoder    // out
	var _arg1 *C.GstVideoCodecFrame // out
	var _cret C.GstFlowReturn       // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	_cret = C.gst_video_decoder_drop_subframe(_arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(frame)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// FinishFrame: frame should have a valid decoded data buffer, whose metadata
// fields are then appropriately set according to frame data and pushed
// downstream. If no output data is provided, frame is considered skipped.
// In any case, the frame is considered finished and released.
//
// After calling this function the output buffer of the frame is to be
// considered read-only. This function will also change the metadata of the
// buffer.
//
// The function takes the following parameters:
//
//   - frame: decoded VideoCodecFrame.
//
// The function returns the following values:
//
//   - flowReturn resulting from sending data downstream.
func (decoder *VideoDecoder) FinishFrame(frame *VideoCodecFrame) gst.FlowReturn {
	var _arg0 *C.GstVideoDecoder    // out
	var _arg1 *C.GstVideoCodecFrame // out
	var _cret C.GstFlowReturn       // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	_cret = C.gst_video_decoder_finish_frame(_arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(frame)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// FinishSubframe: indicate that a subframe has been finished to be decoded by
// the subclass. This method should be called for all subframes except the last
// subframe where gst_video_decoder_finish_frame should be called instead.
//
// The function takes the following parameters:
//
//   - frame: VideoCodecFrame.
//
// The function returns the following values:
//
//   - flowReturn usually GST_FLOW_OK.
func (decoder *VideoDecoder) FinishSubframe(frame *VideoCodecFrame) gst.FlowReturn {
	var _arg0 *C.GstVideoDecoder    // out
	var _arg1 *C.GstVideoCodecFrame // out
	var _cret C.GstFlowReturn       // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	_cret = C.gst_video_decoder_finish_subframe(_arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(frame)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// Allocator lets VideoDecoder sub-classes to know the memory allocator used by
// the base class and its params.
//
// Unref the allocator after use it.
//
// The function returns the following values:
//
//   - allocator (optional): Allocator used.
//   - params (optional) the AllocationParams of allocator.
func (decoder *VideoDecoder) Allocator() (gst.Allocatorrer, *gst.AllocationParams) {
	var _arg0 *C.GstVideoDecoder    // out
	var _arg1 *C.GstAllocator       // in
	var _arg2 C.GstAllocationParams // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))

	C.gst_video_decoder_get_allocator(_arg0, &_arg1, &_arg2)
	runtime.KeepAlive(decoder)

	var _allocator gst.Allocatorrer   // out
	var _params *gst.AllocationParams // out

	if _arg1 != nil {
		{
			objptr := unsafe.Pointer(_arg1)

			object := coreglib.AssumeOwnership(objptr)
			casted := object.WalkCast(func(obj coreglib.Objector) bool {
				_, ok := obj.(gst.Allocatorrer)
				return ok
			})
			rv, ok := casted.(gst.Allocatorrer)
			if !ok {
				panic("no marshaler for " + object.TypeFromInstance().String() + " matching gst.Allocatorrer")
			}
			_allocator = rv
		}
	}
	_params = (*gst.AllocationParams)(gextras.NewStructNative(unsafe.Pointer((&_arg2))))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_params)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_allocation_params_free((*C.GstAllocationParams)(intern.C))
		},
	)

	return _allocator, _params
}

// The function returns the following values:
//
//   - bufferPool (optional): instance of the BufferPool used by the decoder;
//     free it after use it.
func (decoder *VideoDecoder) BufferPool() *gst.BufferPool {
	var _arg0 *C.GstVideoDecoder // out
	var _cret *C.GstBufferPool   // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))

	_cret = C.gst_video_decoder_get_buffer_pool(_arg0)
	runtime.KeepAlive(decoder)

	var _bufferPool *gst.BufferPool // out

	if _cret != nil {
		{
			obj := coreglib.AssumeOwnership(unsafe.Pointer(_cret))
			_bufferPool = &gst.BufferPool{
				GstObject: gst.GstObject{
					InitiallyUnowned: coreglib.InitiallyUnowned{
						Object: obj,
					},
				},
			}
		}
	}

	return _bufferPool
}

// The function returns the following values:
//
//   - gint: currently configured byte to time conversion setting.
func (dec *VideoDecoder) EstimateRate() int {
	var _arg0 *C.GstVideoDecoder // out
	var _cret C.gint             // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	_cret = C.gst_video_decoder_get_estimate_rate(_arg0)
	runtime.KeepAlive(dec)

	var _gint int // out

	_gint = int(_cret)

	return _gint
}

// Frame: get a pending unfinished VideoCodecFrame.
//
// The function takes the following parameters:
//
//   - frameNumber: system_frame_number of a frame.
//
// The function returns the following values:
//
//   - videoCodecFrame (optional): pending unfinished VideoCodecFrame identified
//     by frame_number.
func (decoder *VideoDecoder) Frame(frameNumber int) *VideoCodecFrame {
	var _arg0 *C.GstVideoDecoder    // out
	var _arg1 C.int                 // out
	var _cret *C.GstVideoCodecFrame // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = C.int(frameNumber)

	_cret = C.gst_video_decoder_get_frame(_arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(frameNumber)

	var _videoCodecFrame *VideoCodecFrame // out

	if _cret != nil {
		_videoCodecFrame = (*VideoCodecFrame)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_videoCodecFrame)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_video_codec_frame_unref((*C.GstVideoCodecFrame)(intern.C))
			},
		)
	}

	return _videoCodecFrame
}

// Frames: get all pending unfinished VideoCodecFrame.
//
// The function returns the following values:
//
//   - list: pending unfinished VideoCodecFrame.
func (decoder *VideoDecoder) Frames() []*VideoCodecFrame {
	var _arg0 *C.GstVideoDecoder // out
	var _cret *C.GList           // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))

	_cret = C.gst_video_decoder_get_frames(_arg0)
	runtime.KeepAlive(decoder)

	var _list []*VideoCodecFrame // out

	_list = make([]*VideoCodecFrame, 0, gextras.ListSize(unsafe.Pointer(_cret)))
	gextras.MoveList(unsafe.Pointer(_cret), true, func(v unsafe.Pointer) {
		src := (*C.GstVideoCodecFrame)(v)
		var dst *VideoCodecFrame // out
		dst = (*VideoCodecFrame)(gextras.NewStructNative(unsafe.Pointer(src)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(dst)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_video_codec_frame_unref((*C.GstVideoCodecFrame)(intern.C))
			},
		)
		_list = append(_list, dst)
	})

	return _list
}

// InputSubframeIndex queries the number of the last subframe received by the
// decoder baseclass in the frame.
//
// The function takes the following parameters:
//
//   - frame to update.
//
// The function returns the following values:
//
//   - guint: current subframe index received in subframe mode, 1 otherwise.
func (decoder *VideoDecoder) InputSubframeIndex(frame *VideoCodecFrame) uint {
	var _arg0 *C.GstVideoDecoder    // out
	var _arg1 *C.GstVideoCodecFrame // out
	var _cret C.guint               // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	_cret = C.gst_video_decoder_get_input_subframe_index(_arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(frame)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// Latency: query the configured decoder latency. Results will be returned via
// min_latency and max_latency.
//
// The function returns the following values:
//
//   - minLatency (optional) address of variable in which to store the
//     configured minimum latency, or NULL.
//   - maxLatency (optional) address of variable in which to store the
//     configured mximum latency, or NULL.
func (decoder *VideoDecoder) Latency() (minLatency, maxLatency gst.ClockTime) {
	var _arg0 *C.GstVideoDecoder // out
	var _arg1 C.GstClockTime     // in
	var _arg2 C.GstClockTime     // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))

	C.gst_video_decoder_get_latency(_arg0, &_arg1, &_arg2)
	runtime.KeepAlive(decoder)

	var _minLatency gst.ClockTime // out
	var _maxLatency gst.ClockTime // out

	_minLatency = gst.ClockTime(_arg1)
	_maxLatency = gst.ClockTime(_arg2)

	return _minLatency, _maxLatency
}

// MaxDecodeTime determines maximum possible decoding time for frame that
// will allow it to decode and arrive in time (as determined by QoS events).
// In particular, a negative result means decoding in time is no longer possible
// and should therefore occur as soon/skippy as possible.
//
// The function takes the following parameters:
//
//   - frame: VideoCodecFrame.
//
// The function returns the following values:
//
//   - clockTimeDiff: max decoding time.
func (decoder *VideoDecoder) MaxDecodeTime(frame *VideoCodecFrame) gst.ClockTimeDiff {
	var _arg0 *C.GstVideoDecoder    // out
	var _arg1 *C.GstVideoCodecFrame // out
	var _cret C.GstClockTimeDiff    // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	_cret = C.gst_video_decoder_get_max_decode_time(_arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(frame)

	var _clockTimeDiff gst.ClockTimeDiff // out

	_clockTimeDiff = gst.ClockTimeDiff(_cret)

	return _clockTimeDiff
}

// The function returns the following values:
//
//   - gint: currently configured decoder tolerated error count.
func (dec *VideoDecoder) MaxErrors() int {
	var _arg0 *C.GstVideoDecoder // out
	var _cret C.gint             // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	_cret = C.gst_video_decoder_get_max_errors(_arg0)
	runtime.KeepAlive(dec)

	var _gint int // out

	_gint = int(_cret)

	return _gint
}

// NeedsFormat queries decoder required format handling.
//
// The function returns the following values:
//
//   - ok: TRUE if required format handling is enabled.
func (dec *VideoDecoder) NeedsFormat() bool {
	var _arg0 *C.GstVideoDecoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	_cret = C.gst_video_decoder_get_needs_format(_arg0)
	runtime.KeepAlive(dec)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// NeedsSyncPoint queries if the decoder requires a sync point before it starts
// outputting data in the beginning.
//
// The function returns the following values:
//
//   - ok: TRUE if a sync point is required in the beginning.
func (dec *VideoDecoder) NeedsSyncPoint() bool {
	var _arg0 *C.GstVideoDecoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	_cret = C.gst_video_decoder_get_needs_sync_point(_arg0)
	runtime.KeepAlive(dec)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// OldestFrame: get the oldest pending unfinished VideoCodecFrame.
//
// The function returns the following values:
//
//   - videoCodecFrame (optional): oldest pending unfinished VideoCodecFrame.
func (decoder *VideoDecoder) OldestFrame() *VideoCodecFrame {
	var _arg0 *C.GstVideoDecoder    // out
	var _cret *C.GstVideoCodecFrame // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))

	_cret = C.gst_video_decoder_get_oldest_frame(_arg0)
	runtime.KeepAlive(decoder)

	var _videoCodecFrame *VideoCodecFrame // out

	if _cret != nil {
		_videoCodecFrame = (*VideoCodecFrame)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_videoCodecFrame)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_video_codec_frame_unref((*C.GstVideoCodecFrame)(intern.C))
			},
		)
	}

	return _videoCodecFrame
}

// OutputState: get the VideoCodecState currently describing the output stream.
//
// The function returns the following values:
//
//   - videoCodecState (optional) describing format of video data.
func (decoder *VideoDecoder) OutputState() *VideoCodecState {
	var _arg0 *C.GstVideoDecoder    // out
	var _cret *C.GstVideoCodecState // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))

	_cret = C.gst_video_decoder_get_output_state(_arg0)
	runtime.KeepAlive(decoder)

	var _videoCodecState *VideoCodecState // out

	if _cret != nil {
		_videoCodecState = (*VideoCodecState)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_videoCodecState)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_video_codec_state_unref((*C.GstVideoCodecState)(intern.C))
			},
		)
	}

	return _videoCodecState
}

// Packetized queries whether input data is considered packetized or not by the
// base class.
//
// The function returns the following values:
//
//   - ok: TRUE if input data is considered packetized.
func (decoder *VideoDecoder) Packetized() bool {
	var _arg0 *C.GstVideoDecoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))

	_cret = C.gst_video_decoder_get_packetized(_arg0)
	runtime.KeepAlive(decoder)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PendingFrameSize returns the number of bytes previously added to the current
// frame by calling gst_video_decoder_add_to_frame().
//
// The function returns the following values:
//
//   - gsize: number of bytes pending for the current frame.
func (decoder *VideoDecoder) PendingFrameSize() uint {
	var _arg0 *C.GstVideoDecoder // out
	var _cret C.gsize            // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))

	_cret = C.gst_video_decoder_get_pending_frame_size(_arg0)
	runtime.KeepAlive(decoder)

	var _gsize uint // out

	_gsize = uint(_cret)

	return _gsize
}

// ProcessedSubframeIndex queries the number of subframes in the frame processed
// by the decoder baseclass.
//
// The function takes the following parameters:
//
//   - frame to update.
//
// The function returns the following values:
//
//   - guint: current subframe processed received in subframe mode.
func (decoder *VideoDecoder) ProcessedSubframeIndex(frame *VideoCodecFrame) uint {
	var _arg0 *C.GstVideoDecoder    // out
	var _arg1 *C.GstVideoCodecFrame // out
	var _cret C.guint               // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	_cret = C.gst_video_decoder_get_processed_subframe_index(_arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(frame)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// The function returns the following values:
//
//   - gdouble: current QoS proportion.
func (decoder *VideoDecoder) QosProportion() float64 {
	var _arg0 *C.GstVideoDecoder // out
	var _cret C.gdouble          // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))

	_cret = C.gst_video_decoder_get_qos_proportion(_arg0)
	runtime.KeepAlive(decoder)

	var _gdouble float64 // out

	_gdouble = float64(_cret)

	return _gdouble
}

// SubframeMode queries whether input data is considered as subframes or not
// by the base class. If FALSE, each input buffer will be considered as a full
// frame.
//
// The function returns the following values:
//
//   - ok: TRUE if input data is considered as sub frames.
func (decoder *VideoDecoder) SubframeMode() bool {
	var _arg0 *C.GstVideoDecoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))

	_cret = C.gst_video_decoder_get_subframe_mode(_arg0)
	runtime.KeepAlive(decoder)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// HaveFrame gathers all data collected for currently parsed frame, gathers
// corresponding metadata and passes it along for further processing, i.e.
// handle_frame.
//
// The function returns the following values:
//
//   - flowReturn: FlowReturn.
func (decoder *VideoDecoder) HaveFrame() gst.FlowReturn {
	var _arg0 *C.GstVideoDecoder // out
	var _cret C.GstFlowReturn    // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))

	_cret = C.gst_video_decoder_have_frame(_arg0)
	runtime.KeepAlive(decoder)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// HaveLastSubframe indicates that the last subframe has been processed by
// the decoder in frame. This will release the current frame in video decoder
// allowing to receive new frames from upstream elements. This method must be
// called in the subclass handle_frame callback.
//
// The function takes the following parameters:
//
//   - frame to update.
//
// The function returns the following values:
//
//   - flowReturn usually GST_FLOW_OK.
func (decoder *VideoDecoder) HaveLastSubframe(frame *VideoCodecFrame) gst.FlowReturn {
	var _arg0 *C.GstVideoDecoder    // out
	var _arg1 *C.GstVideoCodecFrame // out
	var _cret C.GstFlowReturn       // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	_cret = C.gst_video_decoder_have_last_subframe(_arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(frame)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// MergeTags sets the audio decoder tags and how they should be merged with
// any upstream stream tags. This will override any tags previously-set with
// gst_audio_decoder_merge_tags().
//
// Note that this is provided for convenience, and the subclass is not required
// to use this and can still do tag handling on its own.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - tags (optional) to merge, or NULL to unset previously-set tags.
//   - mode to use, usually T_TAG_MERGE_REPLACE.
func (decoder *VideoDecoder) MergeTags(tags *gst.TagList, mode gst.TagMergeMode) {
	var _arg0 *C.GstVideoDecoder // out
	var _arg1 *C.GstTagList      // out
	var _arg2 C.GstTagMergeMode  // out

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	if tags != nil {
		_arg1 = (*C.GstTagList)(gextras.StructNative(unsafe.Pointer(tags)))
	}
	_arg2 = C.GstTagMergeMode(mode)

	C.gst_video_decoder_merge_tags(_arg0, _arg1, _arg2)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(tags)
	runtime.KeepAlive(mode)
}

// Negotiate with downstream elements to currently configured VideoCodecState.
// Unmark GST_PAD_FLAG_NEED_RECONFIGURE in any case. But mark it again if
// negotiate fails.
//
// The function returns the following values:
//
//   - ok: TRUE if the negotiation succeeded, else FALSE.
func (decoder *VideoDecoder) Negotiate() bool {
	var _arg0 *C.GstVideoDecoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))

	_cret = C.gst_video_decoder_negotiate(_arg0)
	runtime.KeepAlive(decoder)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// ProxyGetcaps returns caps that express caps (or sink template caps if caps
// == NULL) restricted to resolution/format/... combinations supported by
// downstream elements.
//
// The function takes the following parameters:
//
//   - caps (optional): initial caps.
//   - filter (optional) caps.
//
// The function returns the following values:
//
//   - ret owned by caller.
func (decoder *VideoDecoder) ProxyGetcaps(caps, filter *gst.Caps) *gst.Caps {
	var _arg0 *C.GstVideoDecoder // out
	var _arg1 *C.GstCaps         // out
	var _arg2 *C.GstCaps         // out
	var _cret *C.GstCaps         // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	if caps != nil {
		_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))
	}
	if filter != nil {
		_arg2 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(filter)))
	}

	_cret = C.gst_video_decoder_proxy_getcaps(_arg0, _arg1, _arg2)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(caps)
	runtime.KeepAlive(filter)

	var _ret *gst.Caps // out

	_ret = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_ret)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _ret
}

// ReleaseFrame: similar to gst_video_decoder_drop_frame(), but simply releases
// frame without any processing other than removing it from list of pending
// frames, after which it is considered finished and released.
//
// The function takes the following parameters:
//
//   - frame to release.
func (dec *VideoDecoder) ReleaseFrame(frame *VideoCodecFrame) {
	var _arg0 *C.GstVideoDecoder    // out
	var _arg1 *C.GstVideoCodecFrame // out

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	C.gst_video_decoder_release_frame(_arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(frame)
}

// RequestSyncPoint allows the VideoDecoder subclass to request from the base
// class that a new sync should be requested from upstream, and that frame
// was the frame when the subclass noticed that a new sync point is required.
// A reason for the subclass to do this could be missing reference frames,
// for example.
//
// The base class will then request a new sync point from upstream
// as long as the time that passed since the last one is exceeding
// VideoDecoder:min-force-key-unit-interval.
//
// The subclass can signal via flags how the frames until the next sync point
// should be handled:
//
//   - If GST_VIDEO_DECODER_REQUEST_SYNC_POINT_DISCARD_INPUT is selected then
//     all following input frames until the next sync point are discarded.
//     This can be useful if the lack of a sync point will prevent all further
//     decoding and the decoder implementation is not very robust in handling
//     missing references frames.
//   - If GST_VIDEO_DECODER_REQUEST_SYNC_POINT_CORRUPT_OUTPUT is selected
//     then all output frames following frame are marked as corrupted via
//     GST_BUFFER_FLAG_CORRUPTED. Corrupted frames can be automatically
//     dropped by the base class, see VideoDecoder:discard-corrupted-frames.
//     Subclasses can manually mark frames as corrupted via
//     GST_VIDEO_CODEC_FRAME_FLAG_CORRUPTED before calling
//     gst_video_decoder_finish_frame().
//
// The function takes the following parameters:
//
//   - frame: VideoCodecFrame.
//   - flags: VideoDecoderRequestSyncPointFlags.
func (dec *VideoDecoder) RequestSyncPoint(frame *VideoCodecFrame, flags VideoDecoderRequestSyncPointFlags) {
	var _arg0 *C.GstVideoDecoder                     // out
	var _arg1 *C.GstVideoCodecFrame                  // out
	var _arg2 C.GstVideoDecoderRequestSyncPointFlags // out

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))
	_arg2 = C.GstVideoDecoderRequestSyncPointFlags(flags)

	C.gst_video_decoder_request_sync_point(_arg0, _arg1, _arg2)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(frame)
	runtime.KeepAlive(flags)
}

// SetEstimateRate allows baseclass to perform byte to time estimated
// conversion.
//
// The function takes the following parameters:
//
//   - enabled: whether to enable byte to time conversion.
func (dec *VideoDecoder) SetEstimateRate(enabled bool) {
	var _arg0 *C.GstVideoDecoder // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	if enabled {
		_arg1 = C.TRUE
	}

	C.gst_video_decoder_set_estimate_rate(_arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(enabled)
}

// SetInterlacedOutputState: same as #gst_video_decoder_set_output_state() but
// also allows you to also set the interlacing mode.
//
// The function takes the following parameters:
//
//   - fmt: VideoFormat.
//   - interlaceMode: VideoInterlaceMode.
//   - width in pixels.
//   - height in pixels.
//   - reference (optional): optional reference VideoCodecState.
//
// The function returns the following values:
//
//   - videoCodecState (optional): newly configured output state.
func (decoder *VideoDecoder) SetInterlacedOutputState(fmt VideoFormat, interlaceMode VideoInterlaceMode, width, height uint, reference *VideoCodecState) *VideoCodecState {
	var _arg0 *C.GstVideoDecoder      // out
	var _arg1 C.GstVideoFormat        // out
	var _arg2 C.GstVideoInterlaceMode // out
	var _arg3 C.guint                 // out
	var _arg4 C.guint                 // out
	var _arg5 *C.GstVideoCodecState   // out
	var _cret *C.GstVideoCodecState   // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = C.GstVideoFormat(fmt)
	_arg2 = C.GstVideoInterlaceMode(interlaceMode)
	_arg3 = C.guint(width)
	_arg4 = C.guint(height)
	if reference != nil {
		_arg5 = (*C.GstVideoCodecState)(gextras.StructNative(unsafe.Pointer(reference)))
	}

	_cret = C.gst_video_decoder_set_interlaced_output_state(_arg0, _arg1, _arg2, _arg3, _arg4, _arg5)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(fmt)
	runtime.KeepAlive(interlaceMode)
	runtime.KeepAlive(width)
	runtime.KeepAlive(height)
	runtime.KeepAlive(reference)

	var _videoCodecState *VideoCodecState // out

	if _cret != nil {
		_videoCodecState = (*VideoCodecState)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_videoCodecState)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_video_codec_state_unref((*C.GstVideoCodecState)(intern.C))
			},
		)
	}

	return _videoCodecState
}

// SetLatency lets VideoDecoder sub-classes tell the baseclass what the decoder
// latency is. If the provided values changed from previously provided ones,
// this will also post a LATENCY message on the bus so the pipeline can
// reconfigure its global latency.
//
// The function takes the following parameters:
//
//   - minLatency: minimum latency.
//   - maxLatency: maximum latency.
func (decoder *VideoDecoder) SetLatency(minLatency, maxLatency gst.ClockTime) {
	var _arg0 *C.GstVideoDecoder // out
	var _arg1 C.GstClockTime     // out
	var _arg2 C.GstClockTime     // out

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = C.GstClockTime(minLatency)
	_arg2 = C.GstClockTime(maxLatency)

	C.gst_video_decoder_set_latency(_arg0, _arg1, _arg2)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(minLatency)
	runtime.KeepAlive(maxLatency)
}

// SetMaxErrors sets numbers of tolerated decoder errors, where a tolerated
// one is then only warned about, but more than tolerated will lead to fatal
// error. You can set -1 for never returning fatal errors. Default is set to
// GST_VIDEO_DECODER_MAX_ERRORS.
//
// The '-1' option was added in 1.4.
//
// The function takes the following parameters:
//
//   - num: max tolerated errors.
func (dec *VideoDecoder) SetMaxErrors(num int) {
	var _arg0 *C.GstVideoDecoder // out
	var _arg1 C.gint             // out

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = C.gint(num)

	C.gst_video_decoder_set_max_errors(_arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(num)
}

// SetNeedsFormat configures decoder format needs. If enabled, subclass needs
// to be negotiated with format caps before it can process any data. It will
// then never be handed any data before it has been configured. Otherwise,
// it might be handed data without having been configured and is then expected
// being able to do so either by default or based on the input data.
//
// The function takes the following parameters:
//
//   - enabled: new state.
func (dec *VideoDecoder) SetNeedsFormat(enabled bool) {
	var _arg0 *C.GstVideoDecoder // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	if enabled {
		_arg1 = C.TRUE
	}

	C.gst_video_decoder_set_needs_format(_arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(enabled)
}

// SetNeedsSyncPoint configures whether the decoder requires a sync point before
// it starts outputting data in the beginning. If enabled, the base class will
// discard all non-sync point frames in the beginning and after a flush and does
// not pass it to the subclass.
//
// If the first frame is not a sync point, the base class will request a sync
// point via the force-key-unit event.
//
// The function takes the following parameters:
//
//   - enabled: new state.
func (dec *VideoDecoder) SetNeedsSyncPoint(enabled bool) {
	var _arg0 *C.GstVideoDecoder // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	if enabled {
		_arg1 = C.TRUE
	}

	C.gst_video_decoder_set_needs_sync_point(_arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(enabled)
}

// SetOutputState creates a new VideoCodecState with the specified fmt, width
// and height as the output state for the decoder. Any previously set output
// state on decoder will be replaced by the newly created one.
//
// If the subclass wishes to copy over existing fields (like pixel aspec ratio,
// or framerate) from an existing VideoCodecState, it can be provided as a
// reference.
//
// If the subclass wishes to override some fields from the output state
// (like pixel-aspect-ratio or framerate) it can do so on the returned
// VideoCodecState.
//
// The new output state will only take effect (set on pads and buffers) starting
// from the next call to #gst_video_decoder_finish_frame().
//
// The function takes the following parameters:
//
//   - fmt: VideoFormat.
//   - width in pixels.
//   - height in pixels.
//   - reference (optional): optional reference VideoCodecState.
//
// The function returns the following values:
//
//   - videoCodecState (optional): newly configured output state.
func (decoder *VideoDecoder) SetOutputState(fmt VideoFormat, width, height uint, reference *VideoCodecState) *VideoCodecState {
	var _arg0 *C.GstVideoDecoder    // out
	var _arg1 C.GstVideoFormat      // out
	var _arg2 C.guint               // out
	var _arg3 C.guint               // out
	var _arg4 *C.GstVideoCodecState // out
	var _cret *C.GstVideoCodecState // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = C.GstVideoFormat(fmt)
	_arg2 = C.guint(width)
	_arg3 = C.guint(height)
	if reference != nil {
		_arg4 = (*C.GstVideoCodecState)(gextras.StructNative(unsafe.Pointer(reference)))
	}

	_cret = C.gst_video_decoder_set_output_state(_arg0, _arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(fmt)
	runtime.KeepAlive(width)
	runtime.KeepAlive(height)
	runtime.KeepAlive(reference)

	var _videoCodecState *VideoCodecState // out

	if _cret != nil {
		_videoCodecState = (*VideoCodecState)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_videoCodecState)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_video_codec_state_unref((*C.GstVideoCodecState)(intern.C))
			},
		)
	}

	return _videoCodecState
}

// SetPacketized allows baseclass to consider input data as packetized or not.
// If the input is packetized, then the parse method will not be called.
//
// The function takes the following parameters:
//
//   - packetized: whether the input data should be considered as packetized.
func (decoder *VideoDecoder) SetPacketized(packetized bool) {
	var _arg0 *C.GstVideoDecoder // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	if packetized {
		_arg1 = C.TRUE
	}

	C.gst_video_decoder_set_packetized(_arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(packetized)
}

// SetSubframeMode: if this is set to TRUE, it informs the base class that the
// subclass can receive the data at a granularity lower than one frame.
//
// Note that in this mode, the subclass has two options. It can either require
// the presence of a GST_VIDEO_BUFFER_FLAG_MARKER to mark the end of a frame.
// Or it can operate in such a way that it will decode a single frame at a time.
// In this second case, every buffer that arrives to the element is considered
// part of the same frame until gst_video_decoder_finish_frame() is called.
//
// In either case, the same VideoCodecFrame will be passed to the
// GstVideoDecoderClass:handle_frame vmethod repeatedly with a different
// GstVideoCodecFrame:input_buffer every time until the end of the frame has
// been signaled using either method. This method must be called during the
// decoder subclass set_format call.
//
// The function takes the following parameters:
//
//   - subframeMode: whether the input data should be considered as subframes.
func (decoder *VideoDecoder) SetSubframeMode(subframeMode bool) {
	var _arg0 *C.GstVideoDecoder // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	if subframeMode {
		_arg1 = C.TRUE
	}

	C.gst_video_decoder_set_subframe_mode(_arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(subframeMode)
}

// SetUseDefaultPadAcceptcaps lets VideoDecoder sub-classes decide if they want
// the sink pad to use the default pad query handler to reply to accept-caps
// queries.
//
// By setting this to true it is possible to further customize the default
// handler with GST_PAD_SET_ACCEPT_INTERSECT and GST_PAD_SET_ACCEPT_TEMPLATE.
//
// The function takes the following parameters:
//
//   - use: if the default pad accept-caps query handling should be used.
func (decoder *VideoDecoder) SetUseDefaultPadAcceptcaps(use bool) {
	var _arg0 *C.GstVideoDecoder // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	if use {
		_arg1 = C.TRUE
	}

	C.gst_video_decoder_set_use_default_pad_acceptcaps(_arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(use)
}

// Close: optional. Called when the element changes to GST_STATE_NULL. Allows
// closing external resources.
func (decoder *VideoDecoder) close() bool {
	gclass := (*C.GstVideoDecoderClass)(coreglib.PeekParentClass(decoder))
	fnarg := gclass.close

	var _arg0 *C.GstVideoDecoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))

	_cret = C._gotk4_gstvideo1_VideoDecoder_virtual_close(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(decoder)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// decideAllocation: optional. Setup the allocation parameters for allocating
// output buffers. The passed in query contains the result of the downstream
// allocation query. Subclasses should chain up to the parent implementation to
// invoke the default handler.
func (decoder *VideoDecoder) decideAllocation(query *gst.Query) bool {
	gclass := (*C.GstVideoDecoderClass)(coreglib.PeekParentClass(decoder))
	fnarg := gclass.decide_allocation

	var _arg0 *C.GstVideoDecoder // out
	var _arg1 *C.GstQuery        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstvideo1_VideoDecoder_virtual_decide_allocation(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Drain: optional. Called to request subclass to decode any data it can at
// this point, but that more data may arrive after. (e.g. at segment end).
// Sub-classes should be prepared to handle new data afterward, or seamless
// segment processing will break. Since: 1.6.
func (decoder *VideoDecoder) drain() gst.FlowReturn {
	gclass := (*C.GstVideoDecoderClass)(coreglib.PeekParentClass(decoder))
	fnarg := gclass.drain

	var _arg0 *C.GstVideoDecoder // out
	var _cret C.GstFlowReturn    // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))

	_cret = C._gotk4_gstvideo1_VideoDecoder_virtual_drain(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(decoder)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// Finish: optional. Called to request subclass to dispatch any pending
// remaining data at EOS. Sub-classes can refuse to decode new data after.
func (decoder *VideoDecoder) finish() gst.FlowReturn {
	gclass := (*C.GstVideoDecoderClass)(coreglib.PeekParentClass(decoder))
	fnarg := gclass.finish

	var _arg0 *C.GstVideoDecoder // out
	var _cret C.GstFlowReturn    // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))

	_cret = C._gotk4_gstvideo1_VideoDecoder_virtual_finish(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(decoder)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// Flush: optional. Flush all remaining data from the decoder without pushing it
// downstream. Since: 1.2.
func (decoder *VideoDecoder) flush() bool {
	gclass := (*C.GstVideoDecoderClass)(coreglib.PeekParentClass(decoder))
	fnarg := gclass.flush

	var _arg0 *C.GstVideoDecoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))

	_cret = C._gotk4_gstvideo1_VideoDecoder_virtual_flush(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(decoder)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Caps: optional. Allows for a custom sink getcaps implementation. If not
// implemented, default returns gst_video_decoder_proxy_getcaps applied to sink
// template caps.
func (decoder *VideoDecoder) caps(filter *gst.Caps) *gst.Caps {
	gclass := (*C.GstVideoDecoderClass)(coreglib.PeekParentClass(decoder))
	fnarg := gclass.getcaps

	var _arg0 *C.GstVideoDecoder // out
	var _arg1 *C.GstCaps         // out
	var _cret *C.GstCaps         // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(filter)))

	_cret = C._gotk4_gstvideo1_VideoDecoder_virtual_getcaps(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(filter)

	var _caps *gst.Caps // out

	_caps = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_caps)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _caps
}

// The function takes the following parameters:
//
//   - frame to handle.
func (decoder *VideoDecoder) handleFrame(frame *VideoCodecFrame) gst.FlowReturn {
	gclass := (*C.GstVideoDecoderClass)(coreglib.PeekParentClass(decoder))
	fnarg := gclass.handle_frame

	var _arg0 *C.GstVideoDecoder    // out
	var _arg1 *C.GstVideoCodecFrame // out
	var _cret C.GstFlowReturn       // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	_cret = C._gotk4_gstvideo1_VideoDecoder_virtual_handle_frame(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(frame)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// The function takes the following parameters:
//
//   - timestamp: timestamp of the missing data.
//   - duration: duration of the missing data.
//
// The function returns the following values:
//
//   - ok: TRUE if the decoder should be drained afterwards.
func (decoder *VideoDecoder) handleMissingData(timestamp, duration gst.ClockTime) bool {
	gclass := (*C.GstVideoDecoderClass)(coreglib.PeekParentClass(decoder))
	fnarg := gclass.handle_missing_data

	var _arg0 *C.GstVideoDecoder // out
	var _arg1 C.GstClockTime     // out
	var _arg2 C.GstClockTime     // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = C.GstClockTime(timestamp)
	_arg2 = C.GstClockTime(duration)

	_cret = C._gotk4_gstvideo1_VideoDecoder_virtual_handle_missing_data(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(timestamp)
	runtime.KeepAlive(duration)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Negotiate: negotiate with downstream elements to currently configured
// VideoCodecState. Unmark GST_PAD_FLAG_NEED_RECONFIGURE in any case. But mark
// it again if negotiate fails.
//
// The function returns the following values:
//
//   - ok: TRUE if the negotiation succeeded, else FALSE.
func (decoder *VideoDecoder) negotiate() bool {
	gclass := (*C.GstVideoDecoderClass)(coreglib.PeekParentClass(decoder))
	fnarg := gclass.negotiate

	var _arg0 *C.GstVideoDecoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))

	_cret = C._gotk4_gstvideo1_VideoDecoder_virtual_negotiate(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(decoder)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Open: optional. Called when the element changes to GST_STATE_READY. Allows
// opening external resources.
func (decoder *VideoDecoder) open() bool {
	gclass := (*C.GstVideoDecoderClass)(coreglib.PeekParentClass(decoder))
	fnarg := gclass.open

	var _arg0 *C.GstVideoDecoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))

	_cret = C._gotk4_gstvideo1_VideoDecoder_virtual_open(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(decoder)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Parse: required for non-packetized input. Allows chopping incoming data into
// manageable units (frames) for subsequent decoding.
//
// The function takes the following parameters:
//
//   - frame
//   - adapter
//   - atEos
func (decoder *VideoDecoder) parse(frame *VideoCodecFrame, adapter *gstbase.Adapter, atEos bool) gst.FlowReturn {
	gclass := (*C.GstVideoDecoderClass)(coreglib.PeekParentClass(decoder))
	fnarg := gclass.parse

	var _arg0 *C.GstVideoDecoder    // out
	var _arg1 *C.GstVideoCodecFrame // out
	var _arg2 *C.GstAdapter         // out
	var _arg3 C.gboolean            // out
	var _cret C.GstFlowReturn       // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))
	_arg2 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))
	if atEos {
		_arg3 = C.TRUE
	}

	_cret = C._gotk4_gstvideo1_VideoDecoder_virtual_parse(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(frame)
	runtime.KeepAlive(adapter)
	runtime.KeepAlive(atEos)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// proposeAllocation: optional. Propose buffer allocation parameters for
// upstream elements. Subclasses should chain up to the parent implementation to
// invoke the default handler.
func (decoder *VideoDecoder) proposeAllocation(query *gst.Query) bool {
	gclass := (*C.GstVideoDecoderClass)(coreglib.PeekParentClass(decoder))
	fnarg := gclass.propose_allocation

	var _arg0 *C.GstVideoDecoder // out
	var _arg1 *C.GstQuery        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstvideo1_VideoDecoder_virtual_propose_allocation(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Reset: optional. Allows subclass (decoder) to perform post-seek semantics
// reset. Deprecated.
func (decoder *VideoDecoder) reset(hard bool) bool {
	gclass := (*C.GstVideoDecoderClass)(coreglib.PeekParentClass(decoder))
	fnarg := gclass.reset

	var _arg0 *C.GstVideoDecoder // out
	var _arg1 C.gboolean         // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	if hard {
		_arg1 = C.TRUE
	}

	_cret = C._gotk4_gstvideo1_VideoDecoder_virtual_reset(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(hard)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// setFormat notifies subclass of incoming data format (caps).
func (decoder *VideoDecoder) setFormat(state *VideoCodecState) bool {
	gclass := (*C.GstVideoDecoderClass)(coreglib.PeekParentClass(decoder))
	fnarg := gclass.set_format

	var _arg0 *C.GstVideoDecoder    // out
	var _arg1 *C.GstVideoCodecState // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = (*C.GstVideoCodecState)(gextras.StructNative(unsafe.Pointer(state)))

	_cret = C._gotk4_gstvideo1_VideoDecoder_virtual_set_format(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(state)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// sinkEvent: optional. Event handler on the sink pad. This function should
// return TRUE if the event was handled and should be discarded (i.e. not
// unref'ed). Subclasses should chain up to the parent implementation to invoke
// the default handler.
func (decoder *VideoDecoder) sinkEvent(event *gst.Event) bool {
	gclass := (*C.GstVideoDecoderClass)(coreglib.PeekParentClass(decoder))
	fnarg := gclass.sink_event

	var _arg0 *C.GstVideoDecoder // out
	var _arg1 *C.GstEvent        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C._gotk4_gstvideo1_VideoDecoder_virtual_sink_event(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(event)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// sinkQuery: optional. Query handler on the sink pad. This function should
// return TRUE if the query could be performed. Subclasses should chain up to
// the parent implementation to invoke the default handler. Since: 1.4.
func (decoder *VideoDecoder) sinkQuery(query *gst.Query) bool {
	gclass := (*C.GstVideoDecoderClass)(coreglib.PeekParentClass(decoder))
	fnarg := gclass.sink_query

	var _arg0 *C.GstVideoDecoder // out
	var _arg1 *C.GstQuery        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstvideo1_VideoDecoder_virtual_sink_query(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// srcEvent: optional. Event handler on the source pad. This function should
// return TRUE if the event was handled and should be discarded (i.e. not
// unref'ed). Subclasses should chain up to the parent implementation to invoke
// the default handler.
func (decoder *VideoDecoder) srcEvent(event *gst.Event) bool {
	gclass := (*C.GstVideoDecoderClass)(coreglib.PeekParentClass(decoder))
	fnarg := gclass.src_event

	var _arg0 *C.GstVideoDecoder // out
	var _arg1 *C.GstEvent        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C._gotk4_gstvideo1_VideoDecoder_virtual_src_event(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(event)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// srcQuery: optional. Query handler on the source pad. This function should
// return TRUE if the query could be performed. Subclasses should chain up to
// the parent implementation to invoke the default handler. Since: 1.4.
func (decoder *VideoDecoder) srcQuery(query *gst.Query) bool {
	gclass := (*C.GstVideoDecoderClass)(coreglib.PeekParentClass(decoder))
	fnarg := gclass.src_query

	var _arg0 *C.GstVideoDecoder // out
	var _arg1 *C.GstQuery        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstvideo1_VideoDecoder_virtual_src_query(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Start: optional. Called when the element starts processing. Allows opening
// external resources.
func (decoder *VideoDecoder) start() bool {
	gclass := (*C.GstVideoDecoderClass)(coreglib.PeekParentClass(decoder))
	fnarg := gclass.start

	var _arg0 *C.GstVideoDecoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))

	_cret = C._gotk4_gstvideo1_VideoDecoder_virtual_start(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(decoder)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Stop: optional. Called when the element stops processing. Allows closing
// external resources.
func (decoder *VideoDecoder) stop() bool {
	gclass := (*C.GstVideoDecoderClass)(coreglib.PeekParentClass(decoder))
	fnarg := gclass.stop

	var _arg0 *C.GstVideoDecoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))

	_cret = C._gotk4_gstvideo1_VideoDecoder_virtual_stop(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(decoder)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// transformMeta: optional. Transform the metadata on the input buffer to the
// output buffer. By default this method is copies all meta without tags and
// meta with only the "video" tag. subclasses can implement this method and
// return TRUE if the metadata is to be copied. Since: 1.6.
//
// The function takes the following parameters:
//
//   - frame
//   - meta
func (decoder *VideoDecoder) transformMeta(frame *VideoCodecFrame, meta *gst.Meta) bool {
	gclass := (*C.GstVideoDecoderClass)(coreglib.PeekParentClass(decoder))
	fnarg := gclass.transform_meta

	var _arg0 *C.GstVideoDecoder    // out
	var _arg1 *C.GstVideoCodecFrame // out
	var _arg2 *C.GstMeta            // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstVideoDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))
	_arg2 = (*C.GstMeta)(gextras.StructNative(unsafe.Pointer(meta)))

	_cret = C._gotk4_gstvideo1_VideoDecoder_virtual_transform_meta(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(frame)
	runtime.KeepAlive(meta)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// VideoEncoderOverrides contains methods that are overridable.
type VideoEncoderOverrides struct {
	// Close: optional. Called when the element changes to GST_STATE_NULL.
	// Allows closing external resources.
	Close func() bool
	// DecideAllocation: optional. Setup the allocation parameters for
	// allocating output buffers. The passed in query contains the result of the
	// downstream allocation query. Subclasses should chain up to the parent
	// implementation to invoke the default handler.
	DecideAllocation func(query *gst.Query) bool
	// Finish: optional. Called to request subclass to dispatch any pending
	// remaining data (e.g. at EOS).
	Finish func() gst.FlowReturn
	// Flush: optional. Flush all remaining data from the encoder without
	// pushing it downstream. Since: 1.2.
	Flush func() bool
	// Caps: optional. Allows for a custom sink getcaps implementation (e.g.
	// for multichannel input specification). If not implemented, default
	// returns gst_video_encoder_proxy_getcaps applied to sink template caps.
	caps func(filter *gst.Caps) *gst.Caps
	// HandleFrame provides input frame to subclass.
	HandleFrame func(frame *VideoCodecFrame) gst.FlowReturn
	// Negotiate with downstream elements to currently configured
	// VideoCodecState. Unmark GST_PAD_FLAG_NEED_RECONFIGURE in any case.
	// But mark it again if negotiate fails.
	//
	// The function returns the following values:
	//
	//   - ok: TRUE if the negotiation succeeded, else FALSE.
	Negotiate func() bool
	// Open: optional. Called when the element changes to GST_STATE_READY.
	// Allows opening external resources.
	Open func() bool
	// PrePush: optional. Allows subclass to push frame downstream in whatever
	// shape or form it deems appropriate. If not provided, provided encoded
	// frame data is simply pushed downstream.
	PrePush func(frame *VideoCodecFrame) gst.FlowReturn
	// ProposeAllocation: optional. Propose buffer allocation parameters
	// for upstream elements. Subclasses should chain up to the parent
	// implementation to invoke the default handler.
	ProposeAllocation func(query *gst.Query) bool
	// Reset: optional. Allows subclass (encoder) to perform post-seek semantics
	// reset. Deprecated.
	Reset func(hard bool) bool
	// SetFormat: optional. Notifies subclass of incoming data format.
	// GstVideoCodecState fields have already been set according to provided
	// caps.
	SetFormat func(state *VideoCodecState) bool
	// SinkEvent: optional. Event handler on the sink pad. This function should
	// return TRUE if the event was handled and should be discarded (i.e.
	// not unref'ed). Subclasses should chain up to the parent implementation to
	// invoke the default handler.
	SinkEvent func(event *gst.Event) bool
	// SinkQuery: optional. Query handler on the sink pad. This function should
	// return TRUE if the query could be performed. Subclasses should chain up
	// to the parent implementation to invoke the default handler. Since: 1.4.
	SinkQuery func(query *gst.Query) bool
	// SrcEvent: optional. Event handler on the source pad. This function should
	// return TRUE if the event was handled and should be discarded (i.e.
	// not unref'ed). Subclasses should chain up to the parent implementation to
	// invoke the default handler.
	SrcEvent func(event *gst.Event) bool
	// SrcQuery: optional. Query handler on the source pad. This function should
	// return TRUE if the query could be performed. Subclasses should chain up
	// to the parent implementation to invoke the default handler. Since: 1.4.
	SrcQuery func(query *gst.Query) bool
	// Start: optional. Called when the element starts processing. Allows
	// opening external resources.
	Start func() bool
	// Stop: optional. Called when the element stops processing. Allows closing
	// external resources.
	Stop func() bool
	// TransformMeta: optional. Transform the metadata on the input buffer to
	// the output buffer. By default this method is copies all meta without tags
	// and meta with only the "video" tag. subclasses can implement this method
	// and return TRUE if the metadata is to be copied. Since: 1.6.
	//
	// The function takes the following parameters:
	//
	//   - frame
	//   - meta
	TransformMeta func(frame *VideoCodecFrame, meta *gst.Meta) bool
}

func defaultVideoEncoderOverrides(v *VideoEncoder) VideoEncoderOverrides {
	return VideoEncoderOverrides{
		Close:             v.close,
		DecideAllocation:  v.decideAllocation,
		Finish:            v.finish,
		Flush:             v.flush,
		caps:              v.caps,
		HandleFrame:       v.handleFrame,
		Negotiate:         v.negotiate,
		Open:              v.open,
		PrePush:           v.prePush,
		ProposeAllocation: v.proposeAllocation,
		Reset:             v.reset,
		SetFormat:         v.setFormat,
		SinkEvent:         v.sinkEvent,
		SinkQuery:         v.sinkQuery,
		SrcEvent:          v.srcEvent,
		SrcQuery:          v.srcQuery,
		Start:             v.start,
		Stop:              v.stop,
		TransformMeta:     v.transformMeta,
	}
}

// VideoEncoder: this base class is for video encoders turning raw video into
// encoded video data.
//
// GstVideoEncoder and subclass should cooperate as follows.
//
// Configuration
//
//   - Initially, GstVideoEncoder calls start when the encoder element is
//     activated, which allows subclass to perform any global setup.
//   - GstVideoEncoder calls set_format to inform subclass of the format of
//     input video data that it is about to receive. Subclass should setup for
//     encoding and configure base class as appropriate (e.g. latency). While
//     unlikely, it might be called more than once, if changing input parameters
//     require reconfiguration. Baseclass will ensure that processing of current
//     configuration is finished.
//   - GstVideoEncoder calls stop at end of all processing.
//
// Data processing
//
//   - Base class collects input data and metadata into a frame and hands this
//     to subclass' handle_frame.
//
//   - If codec processing results in encoded data, subclass should call
//     gst_video_encoder_finish_frame to have encoded data pushed downstream.
//
//   - If implemented, baseclass calls subclass pre_push just prior to pushing
//     to allow subclasses to modify some metadata on the buffer. If it returns
//     GST_FLOW_OK, the buffer is pushed downstream.
//
//   - GstVideoEncoderClass will handle both srcpad and sinkpad events. Sink
//     events will be passed to subclass if event callback has been provided.
//
// Shutdown phase
//
//   - GstVideoEncoder class calls stop to inform the subclass that data parsing
//     will be stopped.
//
// Subclass is responsible for providing pad template caps for source and
// sink pads. The pads need to be named "sink" and "src". It should also
// be able to provide fixed src pad caps in getcaps by the time it calls
// gst_video_encoder_finish_frame.
//
// Things that subclass need to take care of:
//
//   - Provide pad templates
//
//   - Provide source pad caps before pushing the first buffer
//
//   - Accept data in handle_frame and provide encoded results to
//     gst_video_encoder_finish_frame.
//
//     The VideoEncoder:qos property will enable the Quality-of-Service
//     features of the encoder which gather statistics about the real-time
//     performance of the downstream elements. If enabled, subclasses can use
//     gst_video_encoder_get_max_encode_time() to check if input frames are
//     already late and drop them right away to give a chance to the pipeline to
//     catch up.
type VideoEncoder struct {
	_ [0]func() // equal guard
	gst.Element

	gst.Preset
}

var (
	_ gst.Elementer = (*VideoEncoder)(nil)
)

// VideoEncoderer describes types inherited from class VideoEncoder.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type VideoEncoderer interface {
	coreglib.Objector
	baseVideoEncoder() *VideoEncoder
}

var _ VideoEncoderer = (*VideoEncoder)(nil)

func init() {
	coreglib.RegisterClassInfo[*VideoEncoder, *VideoEncoderClass, VideoEncoderOverrides](
		GTypeVideoEncoder,
		initVideoEncoderClass,
		wrapVideoEncoder,
		defaultVideoEncoderOverrides,
	)
}

func initVideoEncoderClass(gclass unsafe.Pointer, overrides VideoEncoderOverrides, classInitFunc func(*VideoEncoderClass)) {
	pclass := (*C.GstVideoEncoderClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeVideoEncoder))))

	if overrides.Close != nil {
		pclass.close = (*[0]byte)(C._gotk4_gstvideo1_VideoEncoderClass_close)
	}

	if overrides.DecideAllocation != nil {
		pclass.decide_allocation = (*[0]byte)(C._gotk4_gstvideo1_VideoEncoderClass_decide_allocation)
	}

	if overrides.Finish != nil {
		pclass.finish = (*[0]byte)(C._gotk4_gstvideo1_VideoEncoderClass_finish)
	}

	if overrides.Flush != nil {
		pclass.flush = (*[0]byte)(C._gotk4_gstvideo1_VideoEncoderClass_flush)
	}

	if overrides.caps != nil {
		pclass.getcaps = (*[0]byte)(C._gotk4_gstvideo1_VideoEncoderClass_getcaps)
	}

	if overrides.HandleFrame != nil {
		pclass.handle_frame = (*[0]byte)(C._gotk4_gstvideo1_VideoEncoderClass_handle_frame)
	}

	if overrides.Negotiate != nil {
		pclass.negotiate = (*[0]byte)(C._gotk4_gstvideo1_VideoEncoderClass_negotiate)
	}

	if overrides.Open != nil {
		pclass.open = (*[0]byte)(C._gotk4_gstvideo1_VideoEncoderClass_open)
	}

	if overrides.PrePush != nil {
		pclass.pre_push = (*[0]byte)(C._gotk4_gstvideo1_VideoEncoderClass_pre_push)
	}

	if overrides.ProposeAllocation != nil {
		pclass.propose_allocation = (*[0]byte)(C._gotk4_gstvideo1_VideoEncoderClass_propose_allocation)
	}

	if overrides.Reset != nil {
		pclass.reset = (*[0]byte)(C._gotk4_gstvideo1_VideoEncoderClass_reset)
	}

	if overrides.SetFormat != nil {
		pclass.set_format = (*[0]byte)(C._gotk4_gstvideo1_VideoEncoderClass_set_format)
	}

	if overrides.SinkEvent != nil {
		pclass.sink_event = (*[0]byte)(C._gotk4_gstvideo1_VideoEncoderClass_sink_event)
	}

	if overrides.SinkQuery != nil {
		pclass.sink_query = (*[0]byte)(C._gotk4_gstvideo1_VideoEncoderClass_sink_query)
	}

	if overrides.SrcEvent != nil {
		pclass.src_event = (*[0]byte)(C._gotk4_gstvideo1_VideoEncoderClass_src_event)
	}

	if overrides.SrcQuery != nil {
		pclass.src_query = (*[0]byte)(C._gotk4_gstvideo1_VideoEncoderClass_src_query)
	}

	if overrides.Start != nil {
		pclass.start = (*[0]byte)(C._gotk4_gstvideo1_VideoEncoderClass_start)
	}

	if overrides.Stop != nil {
		pclass.stop = (*[0]byte)(C._gotk4_gstvideo1_VideoEncoderClass_stop)
	}

	if overrides.TransformMeta != nil {
		pclass.transform_meta = (*[0]byte)(C._gotk4_gstvideo1_VideoEncoderClass_transform_meta)
	}

	if classInitFunc != nil {
		class := (*VideoEncoderClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapVideoEncoder(obj *coreglib.Object) *VideoEncoder {
	return &VideoEncoder{
		Element: gst.Element{
			GstObject: gst.GstObject{
				InitiallyUnowned: coreglib.InitiallyUnowned{
					Object: obj,
				},
			},
		},
		Preset: gst.Preset{
			Object: obj,
		},
	}
}

func marshalVideoEncoder(p uintptr) (interface{}, error) {
	return wrapVideoEncoder(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (encoder *VideoEncoder) baseVideoEncoder() *VideoEncoder {
	return encoder
}

// BaseVideoEncoder returns the underlying base object.
func BaseVideoEncoder(obj VideoEncoderer) *VideoEncoder {
	return obj.baseVideoEncoder()
}

// AllocateOutputBuffer: helper function that allocates a buffer to hold an
// encoded video frame for encoder's current VideoCodecState.
//
// The function takes the following parameters:
//
//   - size of the buffer.
//
// The function returns the following values:
//
//   - buffer: allocated buffer.
func (encoder *VideoEncoder) AllocateOutputBuffer(size uint) *gst.Buffer {
	var _arg0 *C.GstVideoEncoder // out
	var _arg1 C.gsize            // out
	var _cret *C.GstBuffer       // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = C.gsize(size)

	_cret = C.gst_video_encoder_allocate_output_buffer(_arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(size)

	var _buffer *gst.Buffer // out

	_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_buffer)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _buffer
}

// AllocateOutputFrame: helper function that allocates a buffer to hold an
// encoded video frame for encoder's current VideoCodecState. Subclass should
// already have configured video state and set src pad caps.
//
// The buffer allocated here is owned by the frame and you should only keep
// references to the frame, not the buffer.
//
// The function takes the following parameters:
//
//   - frame: VideoCodecFrame.
//   - size of the buffer.
//
// The function returns the following values:
//
//   - flowReturn: GST_FLOW_OK if an output buffer could be allocated.
func (encoder *VideoEncoder) AllocateOutputFrame(frame *VideoCodecFrame, size uint) gst.FlowReturn {
	var _arg0 *C.GstVideoEncoder    // out
	var _arg1 *C.GstVideoCodecFrame // out
	var _arg2 C.gsize               // out
	var _cret C.GstFlowReturn       // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))
	_arg2 = C.gsize(size)

	_cret = C.gst_video_encoder_allocate_output_frame(_arg0, _arg1, _arg2)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(frame)
	runtime.KeepAlive(size)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// FinishFrame: frame must have a valid encoded data buffer, whose metadata
// fields are then appropriately set according to frame data or no buffer at
// all if the frame should be dropped. It is subsequently pushed downstream
// or provided to pre_push. In any case, the frame is considered finished and
// released.
//
// After calling this function the output buffer of the frame is to be
// considered read-only. This function will also change the metadata of the
// buffer.
//
// The function takes the following parameters:
//
//   - frame: encoded VideoCodecFrame.
//
// The function returns the following values:
//
//   - flowReturn resulting from sending data downstream.
func (encoder *VideoEncoder) FinishFrame(frame *VideoCodecFrame) gst.FlowReturn {
	var _arg0 *C.GstVideoEncoder    // out
	var _arg1 *C.GstVideoCodecFrame // out
	var _cret C.GstFlowReturn       // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	_cret = C.gst_video_encoder_finish_frame(_arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(frame)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// FinishSubframe: if multiple subframes are produced for one input frame then
// use this method for each subframe, except for the last one. Before calling
// this function, you need to fill frame->output_buffer with the encoded buffer
// to push.
//
// You must call #gst_video_encoder_finish_frame() for the last sub-frame to
// tell the encoder that the frame has been fully encoded.
//
// This function will change the metadata of frame and frame->output_buffer will
// be pushed downstream.
//
// The function takes the following parameters:
//
//   - frame being encoded.
//
// The function returns the following values:
//
//   - flowReturn resulting from pushing the buffer downstream.
func (encoder *VideoEncoder) FinishSubframe(frame *VideoCodecFrame) gst.FlowReturn {
	var _arg0 *C.GstVideoEncoder    // out
	var _arg1 *C.GstVideoCodecFrame // out
	var _cret C.GstFlowReturn       // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	_cret = C.gst_video_encoder_finish_subframe(_arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(frame)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// Allocator lets VideoEncoder sub-classes to know the memory allocator used by
// the base class and its params.
//
// Unref the allocator after use it.
//
// The function returns the following values:
//
//   - allocator (optional): Allocator used.
//   - params (optional) the AllocationParams of allocator.
func (encoder *VideoEncoder) Allocator() (gst.Allocatorrer, *gst.AllocationParams) {
	var _arg0 *C.GstVideoEncoder    // out
	var _arg1 *C.GstAllocator       // in
	var _arg2 C.GstAllocationParams // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))

	C.gst_video_encoder_get_allocator(_arg0, &_arg1, &_arg2)
	runtime.KeepAlive(encoder)

	var _allocator gst.Allocatorrer   // out
	var _params *gst.AllocationParams // out

	if _arg1 != nil {
		{
			objptr := unsafe.Pointer(_arg1)

			object := coreglib.AssumeOwnership(objptr)
			casted := object.WalkCast(func(obj coreglib.Objector) bool {
				_, ok := obj.(gst.Allocatorrer)
				return ok
			})
			rv, ok := casted.(gst.Allocatorrer)
			if !ok {
				panic("no marshaler for " + object.TypeFromInstance().String() + " matching gst.Allocatorrer")
			}
			_allocator = rv
		}
	}
	_params = (*gst.AllocationParams)(gextras.NewStructNative(unsafe.Pointer((&_arg2))))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_params)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_allocation_params_free((*C.GstAllocationParams)(intern.C))
		},
	)

	return _allocator, _params
}

// Frame: get a pending unfinished VideoCodecFrame.
//
// The function takes the following parameters:
//
//   - frameNumber: system_frame_number of a frame.
//
// The function returns the following values:
//
//   - videoCodecFrame (optional): pending unfinished VideoCodecFrame identified
//     by frame_number.
func (encoder *VideoEncoder) Frame(frameNumber int) *VideoCodecFrame {
	var _arg0 *C.GstVideoEncoder    // out
	var _arg1 C.int                 // out
	var _cret *C.GstVideoCodecFrame // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = C.int(frameNumber)

	_cret = C.gst_video_encoder_get_frame(_arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(frameNumber)

	var _videoCodecFrame *VideoCodecFrame // out

	if _cret != nil {
		_videoCodecFrame = (*VideoCodecFrame)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_videoCodecFrame)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_video_codec_frame_unref((*C.GstVideoCodecFrame)(intern.C))
			},
		)
	}

	return _videoCodecFrame
}

// Frames: get all pending unfinished VideoCodecFrame.
//
// The function returns the following values:
//
//   - list: pending unfinished VideoCodecFrame.
func (encoder *VideoEncoder) Frames() []*VideoCodecFrame {
	var _arg0 *C.GstVideoEncoder // out
	var _cret *C.GList           // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))

	_cret = C.gst_video_encoder_get_frames(_arg0)
	runtime.KeepAlive(encoder)

	var _list []*VideoCodecFrame // out

	_list = make([]*VideoCodecFrame, 0, gextras.ListSize(unsafe.Pointer(_cret)))
	gextras.MoveList(unsafe.Pointer(_cret), true, func(v unsafe.Pointer) {
		src := (*C.GstVideoCodecFrame)(v)
		var dst *VideoCodecFrame // out
		dst = (*VideoCodecFrame)(gextras.NewStructNative(unsafe.Pointer(src)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(dst)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_video_codec_frame_unref((*C.GstVideoCodecFrame)(intern.C))
			},
		)
		_list = append(_list, dst)
	})

	return _list
}

// Latency: query the configured encoding latency. Results will be returned via
// min_latency and max_latency.
//
// The function returns the following values:
//
//   - minLatency (optional) address of variable in which to store the
//     configured minimum latency, or NULL.
//   - maxLatency (optional) address of variable in which to store the
//     configured maximum latency, or NULL.
func (encoder *VideoEncoder) Latency() (minLatency, maxLatency gst.ClockTime) {
	var _arg0 *C.GstVideoEncoder // out
	var _arg1 C.GstClockTime     // in
	var _arg2 C.GstClockTime     // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))

	C.gst_video_encoder_get_latency(_arg0, &_arg1, &_arg2)
	runtime.KeepAlive(encoder)

	var _minLatency gst.ClockTime // out
	var _maxLatency gst.ClockTime // out

	_minLatency = gst.ClockTime(_arg1)
	_maxLatency = gst.ClockTime(_arg2)

	return _minLatency, _maxLatency
}

// MaxEncodeTime determines maximum possible encoding time for frame that
// will allow it to encode and arrive in time (as determined by QoS events).
// In particular, a negative result means encoding in time is no longer possible
// and should therefore occur as soon/skippy as possible.
//
// If no QoS events have been received from downstream, or if VideoEncoder:qos
// is disabled this function returns MAXINT64.
//
// The function takes the following parameters:
//
//   - frame: VideoCodecFrame.
//
// The function returns the following values:
//
//   - clockTimeDiff: max decoding time.
func (encoder *VideoEncoder) MaxEncodeTime(frame *VideoCodecFrame) gst.ClockTimeDiff {
	var _arg0 *C.GstVideoEncoder    // out
	var _arg1 *C.GstVideoCodecFrame // out
	var _cret C.GstClockTimeDiff    // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	_cret = C.gst_video_encoder_get_max_encode_time(_arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(frame)

	var _clockTimeDiff gst.ClockTimeDiff // out

	_clockTimeDiff = gst.ClockTimeDiff(_cret)

	return _clockTimeDiff
}

// MinForceKeyUnitInterval returns the minimum force-keyunit interval,
// see gst_video_encoder_set_min_force_key_unit_interval() for more details.
//
// The function returns the following values:
//
//   - clockTime: minimum force-keyunit interval.
func (encoder *VideoEncoder) MinForceKeyUnitInterval() gst.ClockTime {
	var _arg0 *C.GstVideoEncoder // out
	var _cret C.GstClockTime     // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))

	_cret = C.gst_video_encoder_get_min_force_key_unit_interval(_arg0)
	runtime.KeepAlive(encoder)

	var _clockTime gst.ClockTime // out

	_clockTime = gst.ClockTime(_cret)

	return _clockTime
}

// OldestFrame: get the oldest unfinished pending VideoCodecFrame.
//
// The function returns the following values:
//
//   - videoCodecFrame (optional): oldest unfinished pending VideoCodecFrame.
func (encoder *VideoEncoder) OldestFrame() *VideoCodecFrame {
	var _arg0 *C.GstVideoEncoder    // out
	var _cret *C.GstVideoCodecFrame // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))

	_cret = C.gst_video_encoder_get_oldest_frame(_arg0)
	runtime.KeepAlive(encoder)

	var _videoCodecFrame *VideoCodecFrame // out

	if _cret != nil {
		_videoCodecFrame = (*VideoCodecFrame)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_videoCodecFrame)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_video_codec_frame_unref((*C.GstVideoCodecFrame)(intern.C))
			},
		)
	}

	return _videoCodecFrame
}

// OutputState: get the current VideoCodecState.
//
// The function returns the following values:
//
//   - videoCodecState (optional) describing format of video data.
func (encoder *VideoEncoder) OutputState() *VideoCodecState {
	var _arg0 *C.GstVideoEncoder    // out
	var _cret *C.GstVideoCodecState // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))

	_cret = C.gst_video_encoder_get_output_state(_arg0)
	runtime.KeepAlive(encoder)

	var _videoCodecState *VideoCodecState // out

	if _cret != nil {
		_videoCodecState = (*VideoCodecState)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_videoCodecState)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_video_codec_state_unref((*C.GstVideoCodecState)(intern.C))
			},
		)
	}

	return _videoCodecState
}

// IsQosEnabled checks if encoder is currently configured to handle
// Quality-of-Service events from downstream.
//
// The function returns the following values:
//
//   - ok: TRUE if the encoder is configured to perform Quality-of-Service.
func (encoder *VideoEncoder) IsQosEnabled() bool {
	var _arg0 *C.GstVideoEncoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))

	_cret = C.gst_video_encoder_is_qos_enabled(_arg0)
	runtime.KeepAlive(encoder)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// MergeTags sets the video encoder tags and how they should be merged with
// any upstream stream tags. This will override any tags previously-set with
// gst_video_encoder_merge_tags().
//
// Note that this is provided for convenience, and the subclass is not required
// to use this and can still do tag handling on its own.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - tags (optional) to merge, or NULL to unset previously-set tags.
//   - mode to use, usually T_TAG_MERGE_REPLACE.
func (encoder *VideoEncoder) MergeTags(tags *gst.TagList, mode gst.TagMergeMode) {
	var _arg0 *C.GstVideoEncoder // out
	var _arg1 *C.GstTagList      // out
	var _arg2 C.GstTagMergeMode  // out

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	if tags != nil {
		_arg1 = (*C.GstTagList)(gextras.StructNative(unsafe.Pointer(tags)))
	}
	_arg2 = C.GstTagMergeMode(mode)

	C.gst_video_encoder_merge_tags(_arg0, _arg1, _arg2)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(tags)
	runtime.KeepAlive(mode)
}

// Negotiate with downstream elements to currently configured VideoCodecState.
// Unmark GST_PAD_FLAG_NEED_RECONFIGURE in any case. But mark it again if
// negotiate fails.
//
// The function returns the following values:
//
//   - ok: TRUE if the negotiation succeeded, else FALSE.
func (encoder *VideoEncoder) Negotiate() bool {
	var _arg0 *C.GstVideoEncoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))

	_cret = C.gst_video_encoder_negotiate(_arg0)
	runtime.KeepAlive(encoder)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// ProxyGetcaps returns caps that express caps (or sink template caps if caps
// == NULL) restricted to resolution/format/... combinations supported by
// downstream elements (e.g. muxers).
//
// The function takes the following parameters:
//
//   - caps (optional): initial caps.
//   - filter (optional) caps.
//
// The function returns the following values:
//
//   - ret owned by caller.
func (enc *VideoEncoder) ProxyGetcaps(caps, filter *gst.Caps) *gst.Caps {
	var _arg0 *C.GstVideoEncoder // out
	var _arg1 *C.GstCaps         // out
	var _arg2 *C.GstCaps         // out
	var _cret *C.GstCaps         // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	if caps != nil {
		_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))
	}
	if filter != nil {
		_arg2 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(filter)))
	}

	_cret = C.gst_video_encoder_proxy_getcaps(_arg0, _arg1, _arg2)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(caps)
	runtime.KeepAlive(filter)

	var _ret *gst.Caps // out

	_ret = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_ret)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _ret
}

// SetHeaders: set the codec headers to be sent downstream whenever requested.
//
// The function takes the following parameters:
//
//   - headers: list of Buffer containing the codec header.
func (encoder *VideoEncoder) SetHeaders(headers []*gst.Buffer) {
	var _arg0 *C.GstVideoEncoder // out
	var _arg1 *C.GList           // out

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	for i := len(headers) - 1; i >= 0; i-- {
		src := headers[i]
		var dst *C.GstBuffer // out
		dst = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(src)))
		runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(src)), nil)
		_arg1 = C.g_list_prepend(_arg1, C.gpointer(unsafe.Pointer(dst)))
	}

	C.gst_video_encoder_set_headers(_arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(headers)
}

// SetLatency informs baseclass of encoding latency. If the provided values
// changed from previously provided ones, this will also post a LATENCY message
// on the bus so the pipeline can reconfigure its global latency.
//
// The function takes the following parameters:
//
//   - minLatency: minimum latency.
//   - maxLatency: maximum latency.
func (encoder *VideoEncoder) SetLatency(minLatency, maxLatency gst.ClockTime) {
	var _arg0 *C.GstVideoEncoder // out
	var _arg1 C.GstClockTime     // out
	var _arg2 C.GstClockTime     // out

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = C.GstClockTime(minLatency)
	_arg2 = C.GstClockTime(maxLatency)

	C.gst_video_encoder_set_latency(_arg0, _arg1, _arg2)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(minLatency)
	runtime.KeepAlive(maxLatency)
}

// SetMinForceKeyUnitInterval sets the minimum interval for requesting keyframes
// based on force-keyunit events. Setting this to 0 will allow to handle every
// event, setting this to GST_CLOCK_TIME_NONE causes force-keyunit events to be
// ignored.
//
// The function takes the following parameters:
//
//   - interval: minimum interval.
func (encoder *VideoEncoder) SetMinForceKeyUnitInterval(interval gst.ClockTime) {
	var _arg0 *C.GstVideoEncoder // out
	var _arg1 C.GstClockTime     // out

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = C.GstClockTime(interval)

	C.gst_video_encoder_set_min_force_key_unit_interval(_arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(interval)
}

// SetMinPts: request minimal value for PTS passed to handle_frame.
//
// For streams with reordered frames this can be used to ensure that there is
// enough time to accommodate first DTS, which may be less than first PTS.
//
// The function takes the following parameters:
//
//   - minPts: minimal PTS that will be passed to handle_frame.
func (encoder *VideoEncoder) SetMinPts(minPts gst.ClockTime) {
	var _arg0 *C.GstVideoEncoder // out
	var _arg1 C.GstClockTime     // out

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = C.GstClockTime(minPts)

	C.gst_video_encoder_set_min_pts(_arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(minPts)
}

// SetOutputState creates a new VideoCodecState with the specified caps as the
// output state for the encoder. Any previously set output state on encoder will
// be replaced by the newly created one.
//
// The specified caps should not contain any resolution, pixel-aspect-ratio,
// framerate, codec-data, .... Those should be specified instead in the returned
// VideoCodecState.
//
// If the subclass wishes to copy over existing fields (like pixel aspect ratio,
// or framerate) from an existing VideoCodecState, it can be provided as a
// reference.
//
// If the subclass wishes to override some fields from the output state
// (like pixel-aspect-ratio or framerate) it can do so on the returned
// VideoCodecState.
//
// The new output state will only take effect (set on pads and buffers) starting
// from the next call to #gst_video_encoder_finish_frame().
//
// The function takes the following parameters:
//
//   - caps to use for the output.
//   - reference (optional): optional reference GstVideoCodecState.
//
// The function returns the following values:
//
//   - videoCodecState (optional): newly configured output state.
func (encoder *VideoEncoder) SetOutputState(caps *gst.Caps, reference *VideoCodecState) *VideoCodecState {
	var _arg0 *C.GstVideoEncoder    // out
	var _arg1 *C.GstCaps            // out
	var _arg2 *C.GstVideoCodecState // out
	var _cret *C.GstVideoCodecState // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(caps)), nil)
	if reference != nil {
		_arg2 = (*C.GstVideoCodecState)(gextras.StructNative(unsafe.Pointer(reference)))
	}

	_cret = C.gst_video_encoder_set_output_state(_arg0, _arg1, _arg2)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(caps)
	runtime.KeepAlive(reference)

	var _videoCodecState *VideoCodecState // out

	if _cret != nil {
		_videoCodecState = (*VideoCodecState)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_videoCodecState)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_video_codec_state_unref((*C.GstVideoCodecState)(intern.C))
			},
		)
	}

	return _videoCodecState
}

// SetQosEnabled configures encoder to handle Quality-of-Service events from
// downstream.
//
// The function takes the following parameters:
//
//   - enabled: new qos value.
func (encoder *VideoEncoder) SetQosEnabled(enabled bool) {
	var _arg0 *C.GstVideoEncoder // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	if enabled {
		_arg1 = C.TRUE
	}

	C.gst_video_encoder_set_qos_enabled(_arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(enabled)
}

// Close: optional. Called when the element changes to GST_STATE_NULL. Allows
// closing external resources.
func (encoder *VideoEncoder) close() bool {
	gclass := (*C.GstVideoEncoderClass)(coreglib.PeekParentClass(encoder))
	fnarg := gclass.close

	var _arg0 *C.GstVideoEncoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))

	_cret = C._gotk4_gstvideo1_VideoEncoder_virtual_close(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(encoder)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// decideAllocation: optional. Setup the allocation parameters for allocating
// output buffers. The passed in query contains the result of the downstream
// allocation query. Subclasses should chain up to the parent implementation to
// invoke the default handler.
func (encoder *VideoEncoder) decideAllocation(query *gst.Query) bool {
	gclass := (*C.GstVideoEncoderClass)(coreglib.PeekParentClass(encoder))
	fnarg := gclass.decide_allocation

	var _arg0 *C.GstVideoEncoder // out
	var _arg1 *C.GstQuery        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstvideo1_VideoEncoder_virtual_decide_allocation(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Finish: optional. Called to request subclass to dispatch any pending
// remaining data (e.g. at EOS).
func (encoder *VideoEncoder) finish() gst.FlowReturn {
	gclass := (*C.GstVideoEncoderClass)(coreglib.PeekParentClass(encoder))
	fnarg := gclass.finish

	var _arg0 *C.GstVideoEncoder // out
	var _cret C.GstFlowReturn    // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))

	_cret = C._gotk4_gstvideo1_VideoEncoder_virtual_finish(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(encoder)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// Flush: optional. Flush all remaining data from the encoder without pushing it
// downstream. Since: 1.2.
func (encoder *VideoEncoder) flush() bool {
	gclass := (*C.GstVideoEncoderClass)(coreglib.PeekParentClass(encoder))
	fnarg := gclass.flush

	var _arg0 *C.GstVideoEncoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))

	_cret = C._gotk4_gstvideo1_VideoEncoder_virtual_flush(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(encoder)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Caps: optional. Allows for a custom sink getcaps implementation (e.g.
// for multichannel input specification). If not implemented, default returns
// gst_video_encoder_proxy_getcaps applied to sink template caps.
func (enc *VideoEncoder) caps(filter *gst.Caps) *gst.Caps {
	gclass := (*C.GstVideoEncoderClass)(coreglib.PeekParentClass(enc))
	fnarg := gclass.getcaps

	var _arg0 *C.GstVideoEncoder // out
	var _arg1 *C.GstCaps         // out
	var _cret *C.GstCaps         // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(filter)))

	_cret = C._gotk4_gstvideo1_VideoEncoder_virtual_getcaps(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(filter)

	var _caps *gst.Caps // out

	_caps = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_caps)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _caps
}

// handleFrame provides input frame to subclass.
func (encoder *VideoEncoder) handleFrame(frame *VideoCodecFrame) gst.FlowReturn {
	gclass := (*C.GstVideoEncoderClass)(coreglib.PeekParentClass(encoder))
	fnarg := gclass.handle_frame

	var _arg0 *C.GstVideoEncoder    // out
	var _arg1 *C.GstVideoCodecFrame // out
	var _cret C.GstFlowReturn       // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	_cret = C._gotk4_gstvideo1_VideoEncoder_virtual_handle_frame(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(frame)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// Negotiate: negotiate with downstream elements to currently configured
// VideoCodecState. Unmark GST_PAD_FLAG_NEED_RECONFIGURE in any case. But mark
// it again if negotiate fails.
//
// The function returns the following values:
//
//   - ok: TRUE if the negotiation succeeded, else FALSE.
func (encoder *VideoEncoder) negotiate() bool {
	gclass := (*C.GstVideoEncoderClass)(coreglib.PeekParentClass(encoder))
	fnarg := gclass.negotiate

	var _arg0 *C.GstVideoEncoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))

	_cret = C._gotk4_gstvideo1_VideoEncoder_virtual_negotiate(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(encoder)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Open: optional. Called when the element changes to GST_STATE_READY. Allows
// opening external resources.
func (encoder *VideoEncoder) open() bool {
	gclass := (*C.GstVideoEncoderClass)(coreglib.PeekParentClass(encoder))
	fnarg := gclass.open

	var _arg0 *C.GstVideoEncoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))

	_cret = C._gotk4_gstvideo1_VideoEncoder_virtual_open(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(encoder)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// prePush: optional. Allows subclass to push frame downstream in whatever shape
// or form it deems appropriate. If not provided, provided encoded frame data is
// simply pushed downstream.
func (encoder *VideoEncoder) prePush(frame *VideoCodecFrame) gst.FlowReturn {
	gclass := (*C.GstVideoEncoderClass)(coreglib.PeekParentClass(encoder))
	fnarg := gclass.pre_push

	var _arg0 *C.GstVideoEncoder    // out
	var _arg1 *C.GstVideoCodecFrame // out
	var _cret C.GstFlowReturn       // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	_cret = C._gotk4_gstvideo1_VideoEncoder_virtual_pre_push(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(frame)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// proposeAllocation: optional. Propose buffer allocation parameters for
// upstream elements. Subclasses should chain up to the parent implementation to
// invoke the default handler.
func (encoder *VideoEncoder) proposeAllocation(query *gst.Query) bool {
	gclass := (*C.GstVideoEncoderClass)(coreglib.PeekParentClass(encoder))
	fnarg := gclass.propose_allocation

	var _arg0 *C.GstVideoEncoder // out
	var _arg1 *C.GstQuery        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstvideo1_VideoEncoder_virtual_propose_allocation(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Reset: optional. Allows subclass (encoder) to perform post-seek semantics
// reset. Deprecated.
func (encoder *VideoEncoder) reset(hard bool) bool {
	gclass := (*C.GstVideoEncoderClass)(coreglib.PeekParentClass(encoder))
	fnarg := gclass.reset

	var _arg0 *C.GstVideoEncoder // out
	var _arg1 C.gboolean         // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	if hard {
		_arg1 = C.TRUE
	}

	_cret = C._gotk4_gstvideo1_VideoEncoder_virtual_reset(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(hard)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// setFormat: optional. Notifies subclass of incoming data format.
// GstVideoCodecState fields have already been set according to provided caps.
func (encoder *VideoEncoder) setFormat(state *VideoCodecState) bool {
	gclass := (*C.GstVideoEncoderClass)(coreglib.PeekParentClass(encoder))
	fnarg := gclass.set_format

	var _arg0 *C.GstVideoEncoder    // out
	var _arg1 *C.GstVideoCodecState // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = (*C.GstVideoCodecState)(gextras.StructNative(unsafe.Pointer(state)))

	_cret = C._gotk4_gstvideo1_VideoEncoder_virtual_set_format(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(state)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// sinkEvent: optional. Event handler on the sink pad. This function should
// return TRUE if the event was handled and should be discarded (i.e. not
// unref'ed). Subclasses should chain up to the parent implementation to invoke
// the default handler.
func (encoder *VideoEncoder) sinkEvent(event *gst.Event) bool {
	gclass := (*C.GstVideoEncoderClass)(coreglib.PeekParentClass(encoder))
	fnarg := gclass.sink_event

	var _arg0 *C.GstVideoEncoder // out
	var _arg1 *C.GstEvent        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C._gotk4_gstvideo1_VideoEncoder_virtual_sink_event(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(event)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// sinkQuery: optional. Query handler on the sink pad. This function should
// return TRUE if the query could be performed. Subclasses should chain up to
// the parent implementation to invoke the default handler. Since: 1.4.
func (encoder *VideoEncoder) sinkQuery(query *gst.Query) bool {
	gclass := (*C.GstVideoEncoderClass)(coreglib.PeekParentClass(encoder))
	fnarg := gclass.sink_query

	var _arg0 *C.GstVideoEncoder // out
	var _arg1 *C.GstQuery        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstvideo1_VideoEncoder_virtual_sink_query(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// srcEvent: optional. Event handler on the source pad. This function should
// return TRUE if the event was handled and should be discarded (i.e. not
// unref'ed). Subclasses should chain up to the parent implementation to invoke
// the default handler.
func (encoder *VideoEncoder) srcEvent(event *gst.Event) bool {
	gclass := (*C.GstVideoEncoderClass)(coreglib.PeekParentClass(encoder))
	fnarg := gclass.src_event

	var _arg0 *C.GstVideoEncoder // out
	var _arg1 *C.GstEvent        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C._gotk4_gstvideo1_VideoEncoder_virtual_src_event(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(event)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// srcQuery: optional. Query handler on the source pad. This function should
// return TRUE if the query could be performed. Subclasses should chain up to
// the parent implementation to invoke the default handler. Since: 1.4.
func (encoder *VideoEncoder) srcQuery(query *gst.Query) bool {
	gclass := (*C.GstVideoEncoderClass)(coreglib.PeekParentClass(encoder))
	fnarg := gclass.src_query

	var _arg0 *C.GstVideoEncoder // out
	var _arg1 *C.GstQuery        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstvideo1_VideoEncoder_virtual_src_query(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Start: optional. Called when the element starts processing. Allows opening
// external resources.
func (encoder *VideoEncoder) start() bool {
	gclass := (*C.GstVideoEncoderClass)(coreglib.PeekParentClass(encoder))
	fnarg := gclass.start

	var _arg0 *C.GstVideoEncoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))

	_cret = C._gotk4_gstvideo1_VideoEncoder_virtual_start(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(encoder)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Stop: optional. Called when the element stops processing. Allows closing
// external resources.
func (encoder *VideoEncoder) stop() bool {
	gclass := (*C.GstVideoEncoderClass)(coreglib.PeekParentClass(encoder))
	fnarg := gclass.stop

	var _arg0 *C.GstVideoEncoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))

	_cret = C._gotk4_gstvideo1_VideoEncoder_virtual_stop(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(encoder)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// transformMeta: optional. Transform the metadata on the input buffer to the
// output buffer. By default this method is copies all meta without tags and
// meta with only the "video" tag. subclasses can implement this method and
// return TRUE if the metadata is to be copied. Since: 1.6.
//
// The function takes the following parameters:
//
//   - frame
//   - meta
func (encoder *VideoEncoder) transformMeta(frame *VideoCodecFrame, meta *gst.Meta) bool {
	gclass := (*C.GstVideoEncoderClass)(coreglib.PeekParentClass(encoder))
	fnarg := gclass.transform_meta

	var _arg0 *C.GstVideoEncoder    // out
	var _arg1 *C.GstVideoCodecFrame // out
	var _arg2 *C.GstMeta            // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstVideoEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))
	_arg2 = (*C.GstMeta)(gextras.StructNative(unsafe.Pointer(meta)))

	_cret = C._gotk4_gstvideo1_VideoEncoder_virtual_transform_meta(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(frame)
	runtime.KeepAlive(meta)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// VideoFilterOverrides contains methods that are overridable.
type VideoFilterOverrides struct {
	// SetInfo: function to be called with the negotiated caps and video infos.
	//
	// The function takes the following parameters:
	//
	//   - incaps
	//   - inInfo
	//   - outcaps
	//   - outInfo
	SetInfo func(incaps *gst.Caps, inInfo *VideoInfo, outcaps *gst.Caps, outInfo *VideoInfo) bool
	// TransformFrame: transform a video frame.
	//
	// The function takes the following parameters:
	//
	//   - inframe
	//   - outframe
	TransformFrame func(inframe, outframe *VideoFrame) gst.FlowReturn
	// TransformFrameIP: transform a video frame in place.
	TransformFrameIP func(frame *VideoFrame) gst.FlowReturn
}

func defaultVideoFilterOverrides(v *VideoFilter) VideoFilterOverrides {
	return VideoFilterOverrides{
		SetInfo:          v.setInfo,
		TransformFrame:   v.transformFrame,
		TransformFrameIP: v.transformFrameIP,
	}
}

// VideoFilter provides useful functions and a base class for video filters.
//
// The videofilter will by default enable QoS on the parent GstBaseTransform to
// implement frame dropping.
type VideoFilter struct {
	_ [0]func() // equal guard
	gstbase.BaseTransform
}

var (
	_ gstbase.BaseTransformer = (*VideoFilter)(nil)
)

// VideoFilterer describes types inherited from class VideoFilter.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type VideoFilterer interface {
	coreglib.Objector
	baseVideoFilter() *VideoFilter
}

var _ VideoFilterer = (*VideoFilter)(nil)

func init() {
	coreglib.RegisterClassInfo[*VideoFilter, *VideoFilterClass, VideoFilterOverrides](
		GTypeVideoFilter,
		initVideoFilterClass,
		wrapVideoFilter,
		defaultVideoFilterOverrides,
	)
}

func initVideoFilterClass(gclass unsafe.Pointer, overrides VideoFilterOverrides, classInitFunc func(*VideoFilterClass)) {
	pclass := (*C.GstVideoFilterClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeVideoFilter))))

	if overrides.SetInfo != nil {
		pclass.set_info = (*[0]byte)(C._gotk4_gstvideo1_VideoFilterClass_set_info)
	}

	if overrides.TransformFrame != nil {
		pclass.transform_frame = (*[0]byte)(C._gotk4_gstvideo1_VideoFilterClass_transform_frame)
	}

	if overrides.TransformFrameIP != nil {
		pclass.transform_frame_ip = (*[0]byte)(C._gotk4_gstvideo1_VideoFilterClass_transform_frame_ip)
	}

	if classInitFunc != nil {
		class := (*VideoFilterClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapVideoFilter(obj *coreglib.Object) *VideoFilter {
	return &VideoFilter{
		BaseTransform: gstbase.BaseTransform{
			Element: gst.Element{
				GstObject: gst.GstObject{
					InitiallyUnowned: coreglib.InitiallyUnowned{
						Object: obj,
					},
				},
			},
		},
	}
}

func marshalVideoFilter(p uintptr) (interface{}, error) {
	return wrapVideoFilter(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (v *VideoFilter) baseVideoFilter() *VideoFilter {
	return v
}

// BaseVideoFilter returns the underlying base object.
func BaseVideoFilter(obj VideoFilterer) *VideoFilter {
	return obj.baseVideoFilter()
}

// setInfo: function to be called with the negotiated caps and video infos.
//
// The function takes the following parameters:
//
//   - incaps
//   - inInfo
//   - outcaps
//   - outInfo
func (filter *VideoFilter) setInfo(incaps *gst.Caps, inInfo *VideoInfo, outcaps *gst.Caps, outInfo *VideoInfo) bool {
	gclass := (*C.GstVideoFilterClass)(coreglib.PeekParentClass(filter))
	fnarg := gclass.set_info

	var _arg0 *C.GstVideoFilter // out
	var _arg1 *C.GstCaps        // out
	var _arg2 *C.GstVideoInfo   // out
	var _arg3 *C.GstCaps        // out
	var _arg4 *C.GstVideoInfo   // out
	var _cret C.gboolean        // in

	_arg0 = (*C.GstVideoFilter)(unsafe.Pointer(coreglib.BaseObject(filter).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(incaps)))
	_arg2 = (*C.GstVideoInfo)(gextras.StructNative(unsafe.Pointer(inInfo)))
	_arg3 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(outcaps)))
	_arg4 = (*C.GstVideoInfo)(gextras.StructNative(unsafe.Pointer(outInfo)))

	_cret = C._gotk4_gstvideo1_VideoFilter_virtual_set_info(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(filter)
	runtime.KeepAlive(incaps)
	runtime.KeepAlive(inInfo)
	runtime.KeepAlive(outcaps)
	runtime.KeepAlive(outInfo)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// transformFrame: transform a video frame.
//
// The function takes the following parameters:
//
//   - inframe
//   - outframe
func (filter *VideoFilter) transformFrame(inframe, outframe *VideoFrame) gst.FlowReturn {
	gclass := (*C.GstVideoFilterClass)(coreglib.PeekParentClass(filter))
	fnarg := gclass.transform_frame

	var _arg0 *C.GstVideoFilter // out
	var _arg1 *C.GstVideoFrame  // out
	var _arg2 *C.GstVideoFrame  // out
	var _cret C.GstFlowReturn   // in

	_arg0 = (*C.GstVideoFilter)(unsafe.Pointer(coreglib.BaseObject(filter).Native()))
	_arg1 = (*C.GstVideoFrame)(gextras.StructNative(unsafe.Pointer(inframe)))
	_arg2 = (*C.GstVideoFrame)(gextras.StructNative(unsafe.Pointer(outframe)))

	_cret = C._gotk4_gstvideo1_VideoFilter_virtual_transform_frame(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(filter)
	runtime.KeepAlive(inframe)
	runtime.KeepAlive(outframe)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// transformFrameIP: transform a video frame in place.
func (trans *VideoFilter) transformFrameIP(frame *VideoFrame) gst.FlowReturn {
	gclass := (*C.GstVideoFilterClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.transform_frame_ip

	var _arg0 *C.GstVideoFilter // out
	var _arg1 *C.GstVideoFrame  // out
	var _cret C.GstFlowReturn   // in

	_arg0 = (*C.GstVideoFilter)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	_arg1 = (*C.GstVideoFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	_cret = C._gotk4_gstvideo1_VideoFilter_virtual_transform_frame_ip(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(frame)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// VideoMultiviewFlagsSet: see VideoMultiviewFlags.
type VideoMultiviewFlagsSet struct {
	_ [0]func() // equal guard
	gst.FlagSet
}

var (
	_ coreglib.Objector = (*VideoMultiviewFlagsSet)(nil)
)

func wrapVideoMultiviewFlagsSet(obj *coreglib.Object) *VideoMultiviewFlagsSet {
	return &VideoMultiviewFlagsSet{
		FlagSet: gst.FlagSet{
			Object: obj,
		},
	}
}

func marshalVideoMultiviewFlagsSet(p uintptr) (interface{}, error) {
	return wrapVideoMultiviewFlagsSet(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

// VideoSinkOverrides contains methods that are overridable.
type VideoSinkOverrides struct {
	// SetInfo notifies the subclass of changed VideoInfo.
	//
	// The function takes the following parameters:
	//
	//   - caps: Caps.
	//   - info corresponding to caps.
	SetInfo func(caps *gst.Caps, info *VideoInfo) bool
	// ShowFrame: render a video frame. Maps to BaseSinkClass.render() and
	// BaseSinkClass.preroll() vfuncs. Rendering during preroll will be
	// suppressed if the VideoSink:show-preroll-frame property is set to FALSE.
	ShowFrame func(buf *gst.Buffer) gst.FlowReturn
}

func defaultVideoSinkOverrides(v *VideoSink) VideoSinkOverrides {
	return VideoSinkOverrides{
		SetInfo:   v.setInfo,
		ShowFrame: v.showFrame,
	}
}

// VideoSink provides useful functions and a base class for video sinks.
//
// GstVideoSink will configure the default base sink to drop frames that arrive
// later than 20ms as this is considered the default threshold for observing
// out-of-sync frames.
type VideoSink struct {
	_ [0]func() // equal guard
	gstbase.BaseSink
}

var (
	_ gstbase.BaseSinker = (*VideoSink)(nil)
)

func init() {
	coreglib.RegisterClassInfo[*VideoSink, *VideoSinkClass, VideoSinkOverrides](
		GTypeVideoSink,
		initVideoSinkClass,
		wrapVideoSink,
		defaultVideoSinkOverrides,
	)
}

func initVideoSinkClass(gclass unsafe.Pointer, overrides VideoSinkOverrides, classInitFunc func(*VideoSinkClass)) {
	pclass := (*C.GstVideoSinkClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeVideoSink))))

	if overrides.SetInfo != nil {
		pclass.set_info = (*[0]byte)(C._gotk4_gstvideo1_VideoSinkClass_set_info)
	}

	if overrides.ShowFrame != nil {
		pclass.show_frame = (*[0]byte)(C._gotk4_gstvideo1_VideoSinkClass_show_frame)
	}

	if classInitFunc != nil {
		class := (*VideoSinkClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapVideoSink(obj *coreglib.Object) *VideoSink {
	return &VideoSink{
		BaseSink: gstbase.BaseSink{
			Element: gst.Element{
				GstObject: gst.GstObject{
					InitiallyUnowned: coreglib.InitiallyUnowned{
						Object: obj,
					},
				},
			},
		},
	}
}

func marshalVideoSink(p uintptr) (interface{}, error) {
	return wrapVideoSink(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

// setInfo notifies the subclass of changed VideoInfo.
//
// The function takes the following parameters:
//
//   - caps: Caps.
//   - info corresponding to caps.
func (videoSink *VideoSink) setInfo(caps *gst.Caps, info *VideoInfo) bool {
	gclass := (*C.GstVideoSinkClass)(coreglib.PeekParentClass(videoSink))
	fnarg := gclass.set_info

	var _arg0 *C.GstVideoSink // out
	var _arg1 *C.GstCaps      // out
	var _arg2 *C.GstVideoInfo // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstVideoSink)(unsafe.Pointer(coreglib.BaseObject(videoSink).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))
	_arg2 = (*C.GstVideoInfo)(gextras.StructNative(unsafe.Pointer(info)))

	_cret = C._gotk4_gstvideo1_VideoSink_virtual_set_info(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(videoSink)
	runtime.KeepAlive(caps)
	runtime.KeepAlive(info)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// showFrame: render a video frame. Maps to BaseSinkClass.render() and
// BaseSinkClass.preroll() vfuncs. Rendering during preroll will be suppressed
// if the VideoSink:show-preroll-frame property is set to FALSE.
func (videoSink *VideoSink) showFrame(buf *gst.Buffer) gst.FlowReturn {
	gclass := (*C.GstVideoSinkClass)(coreglib.PeekParentClass(videoSink))
	fnarg := gclass.show_frame

	var _arg0 *C.GstVideoSink // out
	var _arg1 *C.GstBuffer    // out
	var _cret C.GstFlowReturn // in

	_arg0 = (*C.GstVideoSink)(unsafe.Pointer(coreglib.BaseObject(videoSink).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buf)))

	_cret = C._gotk4_gstvideo1_VideoSink_virtual_show_frame(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(videoSink)
	runtime.KeepAlive(buf)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// VideoSinkCenterRect: deprecated: Use gst_video_center_rect() instead.
//
// The function takes the following parameters:
//
//   - src describing the source area.
//   - dst describing the destination area.
//   - scaling indicating if scaling should be applied or not.
//
// The function returns the following values:
//
//   - result: pointer to a VideoRectangle which will receive the result area.
func VideoSinkCenterRect(src, dst *VideoRectangle, scaling bool) *VideoRectangle {
	var _arg1 C.GstVideoRectangle // out
	var _arg2 C.GstVideoRectangle // out
	var _arg3 C.GstVideoRectangle // in
	var _arg4 C.gboolean          // out

	_arg1 = *(*C.GstVideoRectangle)(gextras.StructNative(unsafe.Pointer(src)))
	_arg2 = *(*C.GstVideoRectangle)(gextras.StructNative(unsafe.Pointer(dst)))
	if scaling {
		_arg4 = C.TRUE
	}

	C.gst_video_sink_center_rect(_arg1, _arg2, &_arg3, _arg4)
	runtime.KeepAlive(src)
	runtime.KeepAlive(dst)
	runtime.KeepAlive(scaling)

	var _result *VideoRectangle // out

	_result = (*VideoRectangle)(gextras.NewStructNative(unsafe.Pointer((&_arg3))))

	return _result
}

// AncillaryMeta for carrying SMPTE-291M Ancillary data. Note that all the ADF
// fields (DID to checksum) are 10bit values with parity/non-parity high-bits
// set.
//
// An instance of this type is always passed by reference.
type AncillaryMeta struct {
	*ancillaryMeta
}

// ancillaryMeta is the struct that's finalized.
type ancillaryMeta struct {
	native *C.GstAncillaryMeta
}

// Meta: parent Meta.
func (a *AncillaryMeta) Meta() *gst.Meta {
	valptr := &a.native.meta
	var _v *gst.Meta // out
	_v = (*gst.Meta)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// Field: field where the ancillary data is located.
func (a *AncillaryMeta) Field() AncillaryMetaField {
	valptr := &a.native.field
	var _v AncillaryMetaField // out
	_v = AncillaryMetaField(*valptr)
	return _v
}

// CNotYChannel: which channel (luminance or chrominance) the ancillary data is
// located. 0 if content is SD or stored in the luminance channel (default).
// 1 if HD and stored in the chrominance channel.
func (a *AncillaryMeta) CNotYChannel() bool {
	valptr := &a.native.c_not_y_channel
	var _v bool // out
	if *valptr != 0 {
		_v = true
	}
	return _v
}

// Line: line on which the ancillary data is located (max 11bit). There are two
// special values: 0x7ff if no line is specified (default), 0x7fe to specify the
// ancillary data is on any valid line before active video.
func (a *AncillaryMeta) Line() uint16 {
	valptr := &a.native.line
	var _v uint16 // out
	_v = uint16(*valptr)
	return _v
}

// Offset: location of the ancillary data packet in a SDI raster relative to
// the start of active video (max 12bits). A value of 0 means the ADF of the
// ancillary packet starts immediately following SAV. There are 3 special
// values: 0xfff: No specified location (default), 0xffe: within HANC data
// space, 0xffd: within the ancillary data space located between SAV and EAV.
func (a *AncillaryMeta) Offset() uint16 {
	valptr := &a.native.offset
	var _v uint16 // out
	_v = uint16(*valptr)
	return _v
}

// DID: data Identified.
func (a *AncillaryMeta) DID() uint16 {
	valptr := &a.native.DID
	var _v uint16 // out
	_v = uint16(*valptr)
	return _v
}

// SDIDBlockNumber: secondary Data identification (if type 2) or Data block
// number (if type 1).
func (a *AncillaryMeta) SDIDBlockNumber() uint16 {
	valptr := &a.native.SDID_block_number
	var _v uint16 // out
	_v = uint16(*valptr)
	return _v
}

// DataCount: amount of user data.
func (a *AncillaryMeta) DataCount() uint16 {
	valptr := &a.native.data_count
	var _v uint16 // out
	_v = uint16(*valptr)
	return _v
}

// Data: user data.
func (a *AncillaryMeta) Data() *uint16 {
	valptr := &a.native.data
	var _v *uint16 // out
	_v = (*uint16)(unsafe.Pointer(*valptr))
	return _v
}

// Checksum: checksum of the ADF.
func (a *AncillaryMeta) Checksum() uint16 {
	valptr := &a.native.checksum
	var _v uint16 // out
	_v = uint16(*valptr)
	return _v
}

// CNotYChannel: which channel (luminance or chrominance) the ancillary data is
// located. 0 if content is SD or stored in the luminance channel (default).
// 1 if HD and stored in the chrominance channel.
func (a *AncillaryMeta) SetCNotYChannel(cNotYChannel bool) {
	valptr := &a.native.c_not_y_channel
	if cNotYChannel {
		*valptr = C.TRUE
	}
}

// Line: line on which the ancillary data is located (max 11bit). There are two
// special values: 0x7ff if no line is specified (default), 0x7fe to specify the
// ancillary data is on any valid line before active video.
func (a *AncillaryMeta) SetLine(line uint16) {
	valptr := &a.native.line
	*valptr = C.guint16(line)
}

// Offset: location of the ancillary data packet in a SDI raster relative to
// the start of active video (max 12bits). A value of 0 means the ADF of the
// ancillary packet starts immediately following SAV. There are 3 special
// values: 0xfff: No specified location (default), 0xffe: within HANC data
// space, 0xffd: within the ancillary data space located between SAV and EAV.
func (a *AncillaryMeta) SetOffset(offset uint16) {
	valptr := &a.native.offset
	*valptr = C.guint16(offset)
}

// DID: data Identified.
func (a *AncillaryMeta) SetDID(DID uint16) {
	valptr := &a.native.DID
	*valptr = C.guint16(DID)
}

// SDIDBlockNumber: secondary Data identification (if type 2) or Data block
// number (if type 1).
func (a *AncillaryMeta) SetSDIDBlockNumber(SDIDBlockNumber uint16) {
	valptr := &a.native.SDID_block_number
	*valptr = C.guint16(SDIDBlockNumber)
}

// DataCount: amount of user data.
func (a *AncillaryMeta) SetDataCount(dataCount uint16) {
	valptr := &a.native.data_count
	*valptr = C.guint16(dataCount)
}

// Checksum: checksum of the ADF.
func (a *AncillaryMeta) SetChecksum(checksum uint16) {
	valptr := &a.native.checksum
	*valptr = C.guint16(checksum)
}

func AncillaryMetaGetInfo() *gst.MetaInfo {
	var _cret *C.GstMetaInfo // in

	_cret = C.gst_ancillary_meta_get_info()

	var _metaInfo *gst.MetaInfo // out

	_metaInfo = (*gst.MetaInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _metaInfo
}

// ColorBalanceChannelClass: color-balance channel class.
//
// An instance of this type is always passed by reference.
type ColorBalanceChannelClass struct {
	*colorBalanceChannelClass
}

// colorBalanceChannelClass is the struct that's finalized.
type colorBalanceChannelClass struct {
	native *C.GstColorBalanceChannelClass
}

// ColorBalanceInterface: color-balance interface.
//
// An instance of this type is always passed by reference.
type ColorBalanceInterface struct {
	*colorBalanceInterface
}

// colorBalanceInterface is the struct that's finalized.
type colorBalanceInterface struct {
	native *C.GstColorBalanceInterface
}

// NavigationInterface: navigation interface.
//
// An instance of this type is always passed by reference.
type NavigationInterface struct {
	*navigationInterface
}

// navigationInterface is the struct that's finalized.
type navigationInterface struct {
	native *C.GstNavigationInterface
}

// VideoAFDMeta: active Format Description (AFD)
//
// For details, see Table 6.14 Active Format in:
//
// ATSC Digital Television Standard: Part 4 – MPEG-2 Video System
// Characteristics
//
// https://www.atsc.org/wp-content/uploads/2015/03/a_53-Part-4-2009.pdf
//
// and Active Format Description in Complete list of AFD codes
//
// https://en.wikipedia.org/wiki/Active_Format_DescriptionAFD_codes
//
// and SMPTE ST2016-1
//
// An instance of this type is always passed by reference.
type VideoAFDMeta struct {
	*videoAFDMeta
}

// videoAFDMeta is the struct that's finalized.
type videoAFDMeta struct {
	native *C.GstVideoAFDMeta
}

// Meta: parent Meta.
func (v *VideoAFDMeta) Meta() *gst.Meta {
	valptr := &v.native.meta
	var _v *gst.Meta // out
	_v = (*gst.Meta)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// Field: 0 for progressive or field 1 and 1 for field 2.
func (v *VideoAFDMeta) Field() byte {
	valptr := &v.native.field
	var _v byte // out
	_v = byte(*valptr)
	return _v
}

// Spec that applies to afd.
func (v *VideoAFDMeta) Spec() VideoAFDSpec {
	valptr := &v.native.spec
	var _v VideoAFDSpec // out
	_v = VideoAFDSpec(*valptr)
	return _v
}

// Afd AFD value.
func (v *VideoAFDMeta) Afd() VideoAFDValue {
	valptr := &v.native.afd
	var _v VideoAFDValue // out
	_v = VideoAFDValue(*valptr)
	return _v
}

// Field: 0 for progressive or field 1 and 1 for field 2.
func (v *VideoAFDMeta) SetField(field byte) {
	valptr := &v.native.field
	*valptr = C.guint8(field)
}

func VideoAFDMetaGetInfo() *gst.MetaInfo {
	var _cret *C.GstMetaInfo // in

	_cret = C.gst_video_afd_meta_get_info()

	var _metaInfo *gst.MetaInfo // out

	_metaInfo = (*gst.MetaInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _metaInfo
}

// VideoAffineTransformationMeta: extra buffer metadata for performing an affine
// transformation using a 4x4 matrix. The transformation matrix can be composed
// with gst_video_affine_transformation_meta_apply_matrix().
//
// The vertices operated on are all in the range 0 to 1, not in Normalized
// Device Coordinates (-1 to +1). Transforming points in this space are
// assumed to have an origin at (0.5, 0.5, 0.5) in a left-handed coordinate
// system with the x-axis moving horizontally (positive values to the right),
// the y-axis moving vertically (positive values up the screen) and the z-axis
// perpendicular to the screen (positive values into the screen).
//
// An instance of this type is always passed by reference.
type VideoAffineTransformationMeta struct {
	*videoAffineTransformationMeta
}

// videoAffineTransformationMeta is the struct that's finalized.
type videoAffineTransformationMeta struct {
	native *C.GstVideoAffineTransformationMeta
}

// Meta: parent Meta.
func (v *VideoAffineTransformationMeta) Meta() *gst.Meta {
	valptr := &v.native.meta
	var _v *gst.Meta // out
	_v = (*gst.Meta)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// Matrix: column-major 4x4 transformation matrix.
func (v *VideoAffineTransformationMeta) Matrix() [16]float32 {
	valptr := &v.native.matrix
	var _v [16]float32 // out
	_v = *(*[16]float32)(unsafe.Pointer(&*valptr))
	return _v
}

// ApplyMatrix: apply a transformation using the given 4x4 transformation
// matrix. Performs the multiplication, meta->matrix X matrix.
//
// The function takes the following parameters:
//
//   - matrix: 4x4 transformation matrix to be applied.
func (meta *VideoAffineTransformationMeta) ApplyMatrix(matrix [16]float32) {
	var _arg0 *C.GstVideoAffineTransformationMeta // out
	var _arg1 *C.gfloat                           // out

	_arg0 = (*C.GstVideoAffineTransformationMeta)(gextras.StructNative(unsafe.Pointer(meta)))
	_arg1 = (*C.gfloat)(unsafe.Pointer(&matrix))

	C.gst_video_affine_transformation_meta_apply_matrix(_arg0, _arg1)
	runtime.KeepAlive(meta)
	runtime.KeepAlive(matrix)
}

func VideoAffineTransformationMetaGetInfo() *gst.MetaInfo {
	var _cret *C.GstMetaInfo // in

	_cret = C.gst_video_affine_transformation_meta_get_info()

	var _metaInfo *gst.MetaInfo // out

	_metaInfo = (*gst.MetaInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _metaInfo
}

// VideoAggregatorClass: instance of this type is always passed by reference.
type VideoAggregatorClass struct {
	*videoAggregatorClass
}

// videoAggregatorClass is the struct that's finalized.
type videoAggregatorClass struct {
	native *C.GstVideoAggregatorClass
}

// VideoAggregatorConvertPadClass: instance of this type is always passed by
// reference.
type VideoAggregatorConvertPadClass struct {
	*videoAggregatorConvertPadClass
}

// videoAggregatorConvertPadClass is the struct that's finalized.
type videoAggregatorConvertPadClass struct {
	native *C.GstVideoAggregatorConvertPadClass
}

func (v *VideoAggregatorConvertPadClass) ParentClass() *VideoAggregatorPadClass {
	valptr := &v.native.parent_class
	var _v *VideoAggregatorPadClass // out
	_v = (*VideoAggregatorPadClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// VideoAggregatorPadClass: instance of this type is always passed by reference.
type VideoAggregatorPadClass struct {
	*videoAggregatorPadClass
}

// videoAggregatorPadClass is the struct that's finalized.
type videoAggregatorPadClass struct {
	native *C.GstVideoAggregatorPadClass
}

func (v *VideoAggregatorPadClass) ParentClass() *gstbase.AggregatorPadClass {
	valptr := &v.native.parent_class
	var _v *gstbase.AggregatorPadClass // out
	_v = (*gstbase.AggregatorPadClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

func (v *VideoAggregatorPadClass) GstReserved() [18]unsafe.Pointer {
	valptr := &v.native._gst_reserved
	var _v [18]unsafe.Pointer // out
	{
		src := &*valptr
		for i := 0; i < 18; i++ {
			_v[i] = (unsafe.Pointer)(unsafe.Pointer(src[i]))
		}
	}
	return _v
}

// VideoAggregatorParallelConvertPadClass: instance of this type is always
// passed by reference.
type VideoAggregatorParallelConvertPadClass struct {
	*videoAggregatorParallelConvertPadClass
}

// videoAggregatorParallelConvertPadClass is the struct that's finalized.
type videoAggregatorParallelConvertPadClass struct {
	native *C.GstVideoAggregatorParallelConvertPadClass
}

func (v *VideoAggregatorParallelConvertPadClass) ParentClass() *VideoAggregatorConvertPadClass {
	valptr := &v.native.parent_class
	var _v *VideoAggregatorConvertPadClass // out
	_v = (*VideoAggregatorConvertPadClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// VideoAlignment: extra alignment parameters for the memory of video buffers.
// This structure is usually used to configure the bufferpool if it supports the
// T_BUFFER_POOL_OPTION_VIDEO_ALIGNMENT.
//
// An instance of this type is always passed by reference.
type VideoAlignment struct {
	*videoAlignment
}

// videoAlignment is the struct that's finalized.
type videoAlignment struct {
	native *C.GstVideoAlignment
}

// PaddingTop: extra pixels on the top.
func (v *VideoAlignment) PaddingTop() uint {
	valptr := &v.native.padding_top
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// PaddingBottom: extra pixels on the bottom.
func (v *VideoAlignment) PaddingBottom() uint {
	valptr := &v.native.padding_bottom
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// PaddingLeft: extra pixels on the left side.
func (v *VideoAlignment) PaddingLeft() uint {
	valptr := &v.native.padding_left
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// PaddingRight: extra pixels on the right side.
func (v *VideoAlignment) PaddingRight() uint {
	valptr := &v.native.padding_right
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// StrideAlign: array with extra alignment requirements for the strides.
func (v *VideoAlignment) StrideAlign() [4]uint {
	valptr := &v.native.stride_align
	var _v [4]uint // out
	{
		src := &*valptr
		for i := 0; i < 4; i++ {
			_v[i] = uint(src[i])
		}
	}
	return _v
}

// PaddingTop: extra pixels on the top.
func (v *VideoAlignment) SetPaddingTop(paddingTop uint) {
	valptr := &v.native.padding_top
	*valptr = C.guint(paddingTop)
}

// PaddingBottom: extra pixels on the bottom.
func (v *VideoAlignment) SetPaddingBottom(paddingBottom uint) {
	valptr := &v.native.padding_bottom
	*valptr = C.guint(paddingBottom)
}

// PaddingLeft: extra pixels on the left side.
func (v *VideoAlignment) SetPaddingLeft(paddingLeft uint) {
	valptr := &v.native.padding_left
	*valptr = C.guint(paddingLeft)
}

// PaddingRight: extra pixels on the right side.
func (v *VideoAlignment) SetPaddingRight(paddingRight uint) {
	valptr := &v.native.padding_right
	*valptr = C.guint(paddingRight)
}

// Reset: set align to its default values with no padding and no alignment.
func (align *VideoAlignment) Reset() {
	var _arg0 *C.GstVideoAlignment // out

	_arg0 = (*C.GstVideoAlignment)(gextras.StructNative(unsafe.Pointer(align)))

	C.gst_video_alignment_reset(_arg0)
	runtime.KeepAlive(align)
}

// VideoAncillary: video Ancillary data, according to SMPTE-291M specification.
//
// Note that the contents of the data are always stored as 8bit data (i.e.
// do not contain the parity check bits).
//
// An instance of this type is always passed by reference.
type VideoAncillary struct {
	*videoAncillary
}

// videoAncillary is the struct that's finalized.
type videoAncillary struct {
	native *C.GstVideoAncillary
}

// VideoBarMeta: bar data should be included in video user data whenever the
// rectangular picture area containing useful information does not extend to
// the full height or width of the coded frame and AFD alone is insufficient to
// describe the extent of the image.
//
// Note: either vertical or horizontal bars are specified, but not both.
//
// For more details, see:
//
// https://www.atsc.org/wp-content/uploads/2015/03/a_53-Part-4-2009.pdf
//
// and SMPTE ST2016-1
//
// An instance of this type is always passed by reference.
type VideoBarMeta struct {
	*videoBarMeta
}

// videoBarMeta is the struct that's finalized.
type videoBarMeta struct {
	native *C.GstVideoBarMeta
}

// Meta: parent Meta.
func (v *VideoBarMeta) Meta() *gst.Meta {
	valptr := &v.native.meta
	var _v *gst.Meta // out
	_v = (*gst.Meta)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// Field: 0 for progressive or field 1 and 1 for field 2.
func (v *VideoBarMeta) Field() byte {
	valptr := &v.native.field
	var _v byte // out
	_v = byte(*valptr)
	return _v
}

// IsLetterbox: if true then bar data specifies letterbox, otherwise pillarbox.
func (v *VideoBarMeta) IsLetterbox() bool {
	valptr := &v.native.is_letterbox
	var _v bool // out
	if *valptr != 0 {
		_v = true
	}
	return _v
}

// BarData1: if is_letterbox is true, then the value specifies the last line of
// a horizontal letterbox bar area at top of reconstructed frame. Otherwise,
// it specifies the last horizontal luminance sample of a vertical pillarbox bar
// area at the left side of the reconstructed frame.
func (v *VideoBarMeta) BarData1() uint {
	valptr := &v.native.bar_data1
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// BarData2: if is_letterbox is true, then the value specifies the first line of
// a horizontal letterbox bar area at bottom of reconstructed frame. Otherwise,
// it specifies the first horizontal luminance sample of a vertical pillarbox
// bar area at the right side of the reconstructed frame.
func (v *VideoBarMeta) BarData2() uint {
	valptr := &v.native.bar_data2
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Field: 0 for progressive or field 1 and 1 for field 2.
func (v *VideoBarMeta) SetField(field byte) {
	valptr := &v.native.field
	*valptr = C.guint8(field)
}

// IsLetterbox: if true then bar data specifies letterbox, otherwise pillarbox.
func (v *VideoBarMeta) SetIsLetterbox(isLetterbox bool) {
	valptr := &v.native.is_letterbox
	if isLetterbox {
		*valptr = C.TRUE
	}
}

// BarData1: if is_letterbox is true, then the value specifies the last line of
// a horizontal letterbox bar area at top of reconstructed frame. Otherwise,
// it specifies the last horizontal luminance sample of a vertical pillarbox bar
// area at the left side of the reconstructed frame.
func (v *VideoBarMeta) SetBarData1(barData1 uint) {
	valptr := &v.native.bar_data1
	*valptr = C.guint(barData1)
}

// BarData2: if is_letterbox is true, then the value specifies the first line of
// a horizontal letterbox bar area at bottom of reconstructed frame. Otherwise,
// it specifies the first horizontal luminance sample of a vertical pillarbox
// bar area at the right side of the reconstructed frame.
func (v *VideoBarMeta) SetBarData2(barData2 uint) {
	valptr := &v.native.bar_data2
	*valptr = C.guint(barData2)
}

func VideoBarMetaGetInfo() *gst.MetaInfo {
	var _cret *C.GstMetaInfo // in

	_cret = C.gst_video_bar_meta_get_info()

	var _metaInfo *gst.MetaInfo // out

	_metaInfo = (*gst.MetaInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _metaInfo
}

// VideoBufferPoolClass: instance of this type is always passed by reference.
type VideoBufferPoolClass struct {
	*videoBufferPoolClass
}

// videoBufferPoolClass is the struct that's finalized.
type videoBufferPoolClass struct {
	native *C.GstVideoBufferPoolClass
}

func (v *VideoBufferPoolClass) ParentClass() *gst.BufferPoolClass {
	valptr := &v.native.parent_class
	var _v *gst.BufferPoolClass // out
	_v = (*gst.BufferPoolClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// VideoCaptionMeta: extra buffer metadata providing Closed Caption.
//
// An instance of this type is always passed by reference.
type VideoCaptionMeta struct {
	*videoCaptionMeta
}

// videoCaptionMeta is the struct that's finalized.
type videoCaptionMeta struct {
	native *C.GstVideoCaptionMeta
}

func VideoCaptionMetaGetInfo() *gst.MetaInfo {
	var _cret *C.GstMetaInfo // in

	_cret = C.gst_video_caption_meta_get_info()

	var _metaInfo *gst.MetaInfo // out

	_metaInfo = (*gst.MetaInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _metaInfo
}

// VideoCodecAlphaMeta: this meta is primarily for internal use in GStreamer
// elements to support VP8/VP9 transparent video stored into WebM or Matroska
// containers, or transparent static AV1 images. Nothing prevents you from using
// this meta for custom purposes, but it generally can't be used to easily to
// add support for alpha channels to CODECs or formats that don't support that
// out of the box.
//
// An instance of this type is always passed by reference.
type VideoCodecAlphaMeta struct {
	*videoCodecAlphaMeta
}

// videoCodecAlphaMeta is the struct that's finalized.
type videoCodecAlphaMeta struct {
	native *C.GstVideoCodecAlphaMeta
}

// Meta: parent Meta.
func (v *VideoCodecAlphaMeta) Meta() *gst.Meta {
	valptr := &v.native.meta
	var _v *gst.Meta // out
	_v = (*gst.Meta)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// Buffer: encoded alpha frame.
func (v *VideoCodecAlphaMeta) Buffer() *gst.Buffer {
	valptr := &v.native.buffer
	var _v *gst.Buffer // out
	_v = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_v)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})
	return _v
}

// The function returns the following values:
//
//   - metaInfo pointer that describes VideoCodecAlphaMeta.
func VideoCodecAlphaMetaGetInfo() *gst.MetaInfo {
	var _cret *C.GstMetaInfo // in

	_cret = C.gst_video_codec_alpha_meta_get_info()

	var _metaInfo *gst.MetaInfo // out

	_metaInfo = (*gst.MetaInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _metaInfo
}

// VideoCodecFrame represents a video frame both in raw and encoded form.
//
// An instance of this type is always passed by reference.
type VideoCodecFrame struct {
	*videoCodecFrame
}

// videoCodecFrame is the struct that's finalized.
type videoCodecFrame struct {
	native *C.GstVideoCodecFrame
}

func marshalVideoCodecFrame(p uintptr) (interface{}, error) {
	b := coreglib.ValueFromNative(unsafe.Pointer(p)).Boxed()
	return &VideoCodecFrame{&videoCodecFrame{(*C.GstVideoCodecFrame)(b)}}, nil
}

// SystemFrameNumber: unique identifier for the frame. Use this if you need to
// get hold of the frame later (like when data is being decoded). Typical usage
// in decoders is to set this on the opaque value provided to the library and
// get back the frame using gst_video_decoder_get_frame().
func (v *VideoCodecFrame) SystemFrameNumber() uint32 {
	valptr := &v.native.system_frame_number
	var _v uint32 // out
	_v = uint32(*valptr)
	return _v
}

// Dts: decoding timestamp.
func (v *VideoCodecFrame) Dts() gst.ClockTime {
	valptr := &v.native.dts
	var _v gst.ClockTime // out
	_v = gst.ClockTime(*valptr)
	return _v
}

// Pts: presentation timestamp.
func (v *VideoCodecFrame) Pts() gst.ClockTime {
	valptr := &v.native.pts
	var _v gst.ClockTime // out
	_v = gst.ClockTime(*valptr)
	return _v
}

// Duration of the frame.
func (v *VideoCodecFrame) Duration() gst.ClockTime {
	valptr := &v.native.duration
	var _v gst.ClockTime // out
	_v = gst.ClockTime(*valptr)
	return _v
}

// DistanceFromSync: distance in frames from the last synchronization point.
func (v *VideoCodecFrame) DistanceFromSync() int {
	valptr := &v.native.distance_from_sync
	var _v int // out
	_v = int(*valptr)
	return _v
}

// InputBuffer: input Buffer that created this frame. The buffer is owned by the
// frame and references to the frame instead of the buffer should be kept.
func (v *VideoCodecFrame) InputBuffer() *gst.Buffer {
	valptr := &v.native.input_buffer
	var _v *gst.Buffer // out
	_v = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_v)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})
	return _v
}

// OutputBuffer: output Buffer. Implementations should set this either
// directly, or by using the gst_video_decoder_allocate_output_frame() or
// gst_video_decoder_allocate_output_buffer() methods. The buffer is owned by
// the frame and references to the frame instead of the buffer should be kept.
func (v *VideoCodecFrame) OutputBuffer() *gst.Buffer {
	valptr := &v.native.output_buffer
	var _v *gst.Buffer // out
	_v = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_v)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})
	return _v
}

// Deadline: running time when the frame will be used.
func (v *VideoCodecFrame) Deadline() gst.ClockTime {
	valptr := &v.native.deadline
	var _v gst.ClockTime // out
	_v = gst.ClockTime(*valptr)
	return _v
}

// SystemFrameNumber: unique identifier for the frame. Use this if you need to
// get hold of the frame later (like when data is being decoded). Typical usage
// in decoders is to set this on the opaque value provided to the library and
// get back the frame using gst_video_decoder_get_frame().
func (v *VideoCodecFrame) SetSystemFrameNumber(systemFrameNumber uint32) {
	valptr := &v.native.system_frame_number
	*valptr = C.guint32(systemFrameNumber)
}

// DistanceFromSync: distance in frames from the last synchronization point.
func (v *VideoCodecFrame) SetDistanceFromSync(distanceFromSync int) {
	valptr := &v.native.distance_from_sync
	*valptr = C.int(distanceFromSync)
}

// UserData gets private data set on the frame by the subclass via
// gst_video_codec_frame_set_user_data() previously.
//
// The function returns the following values:
//
//   - gpointer (optional): previously set user_data.
func (frame *VideoCodecFrame) UserData() unsafe.Pointer {
	var _arg0 *C.GstVideoCodecFrame // out
	var _cret C.gpointer            // in

	_arg0 = (*C.GstVideoCodecFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	_cret = C.gst_video_codec_frame_get_user_data(_arg0)
	runtime.KeepAlive(frame)

	var _gpointer unsafe.Pointer // out

	_gpointer = (unsafe.Pointer)(unsafe.Pointer(_cret))

	return _gpointer
}

// VideoCodecState: structure representing the state of an incoming or outgoing
// video stream for encoders and decoders.
//
// Decoders and encoders will receive such a state through their respective
// set_format vmethods.
//
// Decoders and encoders can set the downstream state, by using the
// gst_video_decoder_set_output_state() or gst_video_encoder_set_output_state()
// methods.
//
// An instance of this type is always passed by reference.
type VideoCodecState struct {
	*videoCodecState
}

// videoCodecState is the struct that's finalized.
type videoCodecState struct {
	native *C.GstVideoCodecState
}

func marshalVideoCodecState(p uintptr) (interface{}, error) {
	b := coreglib.ValueFromNative(unsafe.Pointer(p)).Boxed()
	return &VideoCodecState{&videoCodecState{(*C.GstVideoCodecState)(b)}}, nil
}

// Info describing the stream.
func (v *VideoCodecState) Info() *VideoInfo {
	valptr := &v.native.info
	var _v *VideoInfo // out
	_v = (*VideoInfo)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// Caps used in the caps negotiation of the pad.
func (v *VideoCodecState) Caps() *gst.Caps {
	valptr := &v.native.caps
	var _v *gst.Caps // out
	_v = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_v)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})
	return _v
}

// CodecData corresponding to the 'codec_data' field of a stream, or NULL.
func (v *VideoCodecState) CodecData() *gst.Buffer {
	valptr := &v.native.codec_data
	var _v *gst.Buffer // out
	_v = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_v)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})
	return _v
}

// AllocationCaps for allocation query and pool negotiation. Since: 1.10.
func (v *VideoCodecState) AllocationCaps() *gst.Caps {
	valptr := &v.native.allocation_caps
	var _v *gst.Caps // out
	_v = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_v)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})
	return _v
}

// MasteringDisplayInfo: mastering display color volume information (HDR
// metadata) for the stream.
func (v *VideoCodecState) MasteringDisplayInfo() *VideoMasteringDisplayInfo {
	valptr := &v.native.mastering_display_info
	var _v *VideoMasteringDisplayInfo // out
	_v = (*VideoMasteringDisplayInfo)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	return _v
}

// ContentLightLevel: content light level information for the stream.
func (v *VideoCodecState) ContentLightLevel() *VideoContentLightLevel {
	valptr := &v.native.content_light_level
	var _v *VideoContentLightLevel // out
	_v = (*VideoContentLightLevel)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	return _v
}

// VideoColorPrimariesInfo: structure describing the chromaticity coordinates
// of an RGB system. These values can be used to construct a matrix to transform
// RGB to and from the XYZ colorspace.
//
// An instance of this type is always passed by reference.
type VideoColorPrimariesInfo struct {
	*videoColorPrimariesInfo
}

// videoColorPrimariesInfo is the struct that's finalized.
type videoColorPrimariesInfo struct {
	native *C.GstVideoColorPrimariesInfo
}

// Primaries: VideoColorPrimaries.
func (v *VideoColorPrimariesInfo) Primaries() VideoColorPrimaries {
	valptr := &v.native.primaries
	var _v VideoColorPrimaries // out
	_v = VideoColorPrimaries(*valptr)
	return _v
}

// Wx: reference white x coordinate.
func (v *VideoColorPrimariesInfo) Wx() float64 {
	valptr := &v.native.Wx
	var _v float64 // out
	_v = float64(*valptr)
	return _v
}

// Wy: reference white y coordinate.
func (v *VideoColorPrimariesInfo) Wy() float64 {
	valptr := &v.native.Wy
	var _v float64 // out
	_v = float64(*valptr)
	return _v
}

// Rx: red x coordinate.
func (v *VideoColorPrimariesInfo) Rx() float64 {
	valptr := &v.native.Rx
	var _v float64 // out
	_v = float64(*valptr)
	return _v
}

// Ry: red y coordinate.
func (v *VideoColorPrimariesInfo) Ry() float64 {
	valptr := &v.native.Ry
	var _v float64 // out
	_v = float64(*valptr)
	return _v
}

// Gx: green x coordinate.
func (v *VideoColorPrimariesInfo) Gx() float64 {
	valptr := &v.native.Gx
	var _v float64 // out
	_v = float64(*valptr)
	return _v
}

// Gy: green y coordinate.
func (v *VideoColorPrimariesInfo) Gy() float64 {
	valptr := &v.native.Gy
	var _v float64 // out
	_v = float64(*valptr)
	return _v
}

// Bx: blue x coordinate.
func (v *VideoColorPrimariesInfo) Bx() float64 {
	valptr := &v.native.Bx
	var _v float64 // out
	_v = float64(*valptr)
	return _v
}

// By: blue y coordinate.
func (v *VideoColorPrimariesInfo) By() float64 {
	valptr := &v.native.By
	var _v float64 // out
	_v = float64(*valptr)
	return _v
}

// Wx: reference white x coordinate.
func (v *VideoColorPrimariesInfo) SetWx(Wx float64) {
	valptr := &v.native.Wx
	*valptr = C.gdouble(Wx)
}

// Wy: reference white y coordinate.
func (v *VideoColorPrimariesInfo) SetWy(Wy float64) {
	valptr := &v.native.Wy
	*valptr = C.gdouble(Wy)
}

// Rx: red x coordinate.
func (v *VideoColorPrimariesInfo) SetRx(Rx float64) {
	valptr := &v.native.Rx
	*valptr = C.gdouble(Rx)
}

// Ry: red y coordinate.
func (v *VideoColorPrimariesInfo) SetRy(Ry float64) {
	valptr := &v.native.Ry
	*valptr = C.gdouble(Ry)
}

// Gx: green x coordinate.
func (v *VideoColorPrimariesInfo) SetGx(Gx float64) {
	valptr := &v.native.Gx
	*valptr = C.gdouble(Gx)
}

// Gy: green y coordinate.
func (v *VideoColorPrimariesInfo) SetGy(Gy float64) {
	valptr := &v.native.Gy
	*valptr = C.gdouble(Gy)
}

// Bx: blue x coordinate.
func (v *VideoColorPrimariesInfo) SetBx(Bx float64) {
	valptr := &v.native.Bx
	*valptr = C.gdouble(Bx)
}

// By: blue y coordinate.
func (v *VideoColorPrimariesInfo) SetBy(By float64) {
	valptr := &v.native.By
	*valptr = C.gdouble(By)
}

// VideoColorimetry: structure describing the color info.
//
// An instance of this type is always passed by reference.
type VideoColorimetry struct {
	*videoColorimetry
}

// videoColorimetry is the struct that's finalized.
type videoColorimetry struct {
	native *C.GstVideoColorimetry
}

// Range: color range. This is the valid range for the samples. It is used to
// convert the samples to Y'PbPr values.
func (v *VideoColorimetry) Range() VideoColorRange {
	valptr := &v.native._range
	var _v VideoColorRange // out
	_v = VideoColorRange(*valptr)
	return _v
}

// Matrix: color matrix. Used to convert between Y'PbPr and non-linear RGB
// (R'G'B').
func (v *VideoColorimetry) Matrix() VideoColorMatrix {
	valptr := &v.native.matrix
	var _v VideoColorMatrix // out
	_v = VideoColorMatrix(*valptr)
	return _v
}

// Transfer: transfer function. used to convert between R'G'B' and RGB.
func (v *VideoColorimetry) Transfer() VideoTransferFunction {
	valptr := &v.native.transfer
	var _v VideoTransferFunction // out
	_v = VideoTransferFunction(*valptr)
	return _v
}

// Primaries: color primaries. used to convert between R'G'B' and CIE XYZ.
func (v *VideoColorimetry) Primaries() VideoColorPrimaries {
	valptr := &v.native.primaries
	var _v VideoColorPrimaries // out
	_v = VideoColorPrimaries(*valptr)
	return _v
}

// FromString: parse the colorimetry string and update cinfo with the parsed
// values.
//
// The function takes the following parameters:
//
//   - color: colorimetry string.
//
// The function returns the following values:
//
//   - ok: TRUE if color points to valid colorimetry info.
func (cinfo *VideoColorimetry) FromString(color string) bool {
	var _arg0 *C.GstVideoColorimetry // out
	var _arg1 *C.gchar               // out
	var _cret C.gboolean             // in

	_arg0 = (*C.GstVideoColorimetry)(gextras.StructNative(unsafe.Pointer(cinfo)))
	_arg1 = (*C.gchar)(unsafe.Pointer(C.CString(color)))
	defer C.free(unsafe.Pointer(_arg1))

	_cret = C.gst_video_colorimetry_from_string(_arg0, _arg1)
	runtime.KeepAlive(cinfo)
	runtime.KeepAlive(color)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// IsEqual: compare the 2 colorimetry sets for equality.
//
// The function takes the following parameters:
//
//   - other VideoColorimetry.
//
// The function returns the following values:
//
//   - ok: TRUE if cinfo and other are equal.
func (cinfo *VideoColorimetry) IsEqual(other *VideoColorimetry) bool {
	var _arg0 *C.GstVideoColorimetry // out
	var _arg1 *C.GstVideoColorimetry // out
	var _cret C.gboolean             // in

	_arg0 = (*C.GstVideoColorimetry)(gextras.StructNative(unsafe.Pointer(cinfo)))
	_arg1 = (*C.GstVideoColorimetry)(gextras.StructNative(unsafe.Pointer(other)))

	_cret = C.gst_video_colorimetry_is_equal(_arg0, _arg1)
	runtime.KeepAlive(cinfo)
	runtime.KeepAlive(other)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// IsEquivalent: compare the 2 colorimetry sets for functionally equality.
//
// The function takes the following parameters:
//
//   - bitdepth of a format associated with cinfo.
//   - other VideoColorimetry.
//   - otherBitdepth: bitdepth of a format associated with other.
//
// The function returns the following values:
//
//   - ok: TRUE if cinfo and other are equivalent.
func (cinfo *VideoColorimetry) IsEquivalent(bitdepth uint, other *VideoColorimetry, otherBitdepth uint) bool {
	var _arg0 *C.GstVideoColorimetry // out
	var _arg1 C.guint                // out
	var _arg2 *C.GstVideoColorimetry // out
	var _arg3 C.guint                // out
	var _cret C.gboolean             // in

	_arg0 = (*C.GstVideoColorimetry)(gextras.StructNative(unsafe.Pointer(cinfo)))
	_arg1 = C.guint(bitdepth)
	_arg2 = (*C.GstVideoColorimetry)(gextras.StructNative(unsafe.Pointer(other)))
	_arg3 = C.guint(otherBitdepth)

	_cret = C.gst_video_colorimetry_is_equivalent(_arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(cinfo)
	runtime.KeepAlive(bitdepth)
	runtime.KeepAlive(other)
	runtime.KeepAlive(otherBitdepth)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Matches: check if the colorimetry information in info matches that of the
// string color.
//
// The function takes the following parameters:
//
//   - color: colorimetry string.
//
// The function returns the following values:
//
//   - ok: TRUE if color conveys the same colorimetry info as the color
//     information in info.
func (cinfo *VideoColorimetry) Matches(color string) bool {
	var _arg0 *C.GstVideoColorimetry // out
	var _arg1 *C.gchar               // out
	var _cret C.gboolean             // in

	_arg0 = (*C.GstVideoColorimetry)(gextras.StructNative(unsafe.Pointer(cinfo)))
	_arg1 = (*C.gchar)(unsafe.Pointer(C.CString(color)))
	defer C.free(unsafe.Pointer(_arg1))

	_cret = C.gst_video_colorimetry_matches(_arg0, _arg1)
	runtime.KeepAlive(cinfo)
	runtime.KeepAlive(color)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// String: make a string representation of cinfo.
//
// The function returns the following values:
//
//   - utf8 (optional): string representation of cinfo or NULL if all the
//     entries of cinfo are unknown values.
func (cinfo *VideoColorimetry) String() string {
	var _arg0 *C.GstVideoColorimetry // out
	var _cret *C.gchar               // in

	_arg0 = (*C.GstVideoColorimetry)(gextras.StructNative(unsafe.Pointer(cinfo)))

	_cret = C.gst_video_colorimetry_to_string(_arg0)
	runtime.KeepAlive(cinfo)

	var _utf8 string // out

	if _cret != nil {
		_utf8 = C.GoString((*C.gchar)(unsafe.Pointer(_cret)))
		defer C.free(unsafe.Pointer(_cret))
	}

	return _utf8
}

// VideoContentLightLevel: content light level information specified in
// CEA-861.3, Appendix A.
//
// An instance of this type is always passed by reference.
type VideoContentLightLevel struct {
	*videoContentLightLevel
}

// videoContentLightLevel is the struct that's finalized.
type videoContentLightLevel struct {
	native *C.GstVideoContentLightLevel
}

// MaxContentLightLevel: maximum content light level (abbreviated to MaxCLL) in
// candelas per square meter (cd/m^2 and nit).
func (v *VideoContentLightLevel) MaxContentLightLevel() uint16 {
	valptr := &v.native.max_content_light_level
	var _v uint16 // out
	_v = uint16(*valptr)
	return _v
}

// MaxFrameAverageLightLevel: maximum frame average light level (abbreviated to
// MaxFLL) in candelas per square meter (cd/m^2 and nit).
func (v *VideoContentLightLevel) MaxFrameAverageLightLevel() uint16 {
	valptr := &v.native.max_frame_average_light_level
	var _v uint16 // out
	_v = uint16(*valptr)
	return _v
}

// MaxContentLightLevel: maximum content light level (abbreviated to MaxCLL) in
// candelas per square meter (cd/m^2 and nit).
func (v *VideoContentLightLevel) SetMaxContentLightLevel(maxContentLightLevel uint16) {
	valptr := &v.native.max_content_light_level
	*valptr = C.guint16(maxContentLightLevel)
}

// MaxFrameAverageLightLevel: maximum frame average light level (abbreviated to
// MaxFLL) in candelas per square meter (cd/m^2 and nit).
func (v *VideoContentLightLevel) SetMaxFrameAverageLightLevel(maxFrameAverageLightLevel uint16) {
	valptr := &v.native.max_frame_average_light_level
	*valptr = C.guint16(maxFrameAverageLightLevel)
}

// AddToCaps: parse caps and update linfo.
//
// The function takes the following parameters:
//
//   - caps: Caps.
//
// The function returns the following values:
//
//   - ok: TRUE if linfo was successfully set to caps.
func (linfo *VideoContentLightLevel) AddToCaps(caps *gst.Caps) bool {
	var _arg0 *C.GstVideoContentLightLevel // out
	var _arg1 *C.GstCaps                   // out
	var _cret C.gboolean                   // in

	_arg0 = (*C.GstVideoContentLightLevel)(gextras.StructNative(unsafe.Pointer(linfo)))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C.gst_video_content_light_level_add_to_caps(_arg0, _arg1)
	runtime.KeepAlive(linfo)
	runtime.KeepAlive(caps)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// FromCaps: parse caps and update linfo.
//
// The function takes the following parameters:
//
//   - caps: Caps.
//
// The function returns the following values:
//
//   - ok: if caps has VideoContentLightLevel and could be parsed.
func (linfo *VideoContentLightLevel) FromCaps(caps *gst.Caps) bool {
	var _arg0 *C.GstVideoContentLightLevel // out
	var _arg1 *C.GstCaps                   // out
	var _cret C.gboolean                   // in

	_arg0 = (*C.GstVideoContentLightLevel)(gextras.StructNative(unsafe.Pointer(linfo)))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C.gst_video_content_light_level_from_caps(_arg0, _arg1)
	runtime.KeepAlive(linfo)
	runtime.KeepAlive(caps)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// FromString: parse the value of content-light-level caps field and update
// minfo with the parsed values.
//
// The function takes the following parameters:
//
//   - level string from caps.
//
// The function returns the following values:
//
//   - ok: TRUE if linfo points to valid VideoContentLightLevel.
func (linfo *VideoContentLightLevel) FromString(level string) bool {
	var _arg0 *C.GstVideoContentLightLevel // out
	var _arg1 *C.gchar                     // out
	var _cret C.gboolean                   // in

	_arg0 = (*C.GstVideoContentLightLevel)(gextras.StructNative(unsafe.Pointer(linfo)))
	_arg1 = (*C.gchar)(unsafe.Pointer(C.CString(level)))
	defer C.free(unsafe.Pointer(_arg1))

	_cret = C.gst_video_content_light_level_from_string(_arg0, _arg1)
	runtime.KeepAlive(linfo)
	runtime.KeepAlive(level)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Init: initialize linfo.
func (linfo *VideoContentLightLevel) Init() {
	var _arg0 *C.GstVideoContentLightLevel // out

	_arg0 = (*C.GstVideoContentLightLevel)(gextras.StructNative(unsafe.Pointer(linfo)))

	C.gst_video_content_light_level_init(_arg0)
	runtime.KeepAlive(linfo)
}

// IsEqual checks equality between linfo and other.
//
// The function takes the following parameters:
//
//   - other: VideoContentLightLevel.
//
// The function returns the following values:
//
//   - ok: TRUE if linfo and other are equal.
func (linfo *VideoContentLightLevel) IsEqual(other *VideoContentLightLevel) bool {
	var _arg0 *C.GstVideoContentLightLevel // out
	var _arg1 *C.GstVideoContentLightLevel // out
	var _cret C.gboolean                   // in

	_arg0 = (*C.GstVideoContentLightLevel)(gextras.StructNative(unsafe.Pointer(linfo)))
	_arg1 = (*C.GstVideoContentLightLevel)(gextras.StructNative(unsafe.Pointer(other)))

	_cret = C.gst_video_content_light_level_is_equal(_arg0, _arg1)
	runtime.KeepAlive(linfo)
	runtime.KeepAlive(other)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// String: convert linfo to its string representation.
//
// The function returns the following values:
//
//   - utf8: string representation of linfo.
func (linfo *VideoContentLightLevel) String() string {
	var _arg0 *C.GstVideoContentLightLevel // out
	var _cret *C.gchar                     // in

	_arg0 = (*C.GstVideoContentLightLevel)(gextras.StructNative(unsafe.Pointer(linfo)))

	_cret = C.gst_video_content_light_level_to_string(_arg0)
	runtime.KeepAlive(linfo)

	var _utf8 string // out

	_utf8 = C.GoString((*C.gchar)(unsafe.Pointer(_cret)))
	defer C.free(unsafe.Pointer(_cret))

	return _utf8
}

// VideoCropMeta: extra buffer metadata describing image cropping.
//
// An instance of this type is always passed by reference.
type VideoCropMeta struct {
	*videoCropMeta
}

// videoCropMeta is the struct that's finalized.
type videoCropMeta struct {
	native *C.GstVideoCropMeta
}

// Meta: parent Meta.
func (v *VideoCropMeta) Meta() *gst.Meta {
	valptr := &v.native.meta
	var _v *gst.Meta // out
	_v = (*gst.Meta)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// X: horizontal offset.
func (v *VideoCropMeta) X() uint {
	valptr := &v.native.x
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Y: vertical offset.
func (v *VideoCropMeta) Y() uint {
	valptr := &v.native.y
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Width: cropped width.
func (v *VideoCropMeta) Width() uint {
	valptr := &v.native.width
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Height: cropped height.
func (v *VideoCropMeta) Height() uint {
	valptr := &v.native.height
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// X: horizontal offset.
func (v *VideoCropMeta) SetX(x uint) {
	valptr := &v.native.x
	*valptr = C.guint(x)
}

// Y: vertical offset.
func (v *VideoCropMeta) SetY(y uint) {
	valptr := &v.native.y
	*valptr = C.guint(y)
}

// Width: cropped width.
func (v *VideoCropMeta) SetWidth(width uint) {
	valptr := &v.native.width
	*valptr = C.guint(width)
}

// Height: cropped height.
func (v *VideoCropMeta) SetHeight(height uint) {
	valptr := &v.native.height
	*valptr = C.guint(height)
}

func VideoCropMetaGetInfo() *gst.MetaInfo {
	var _cret *C.GstMetaInfo // in

	_cret = C.gst_video_crop_meta_get_info()

	var _metaInfo *gst.MetaInfo // out

	_metaInfo = (*gst.MetaInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _metaInfo
}

// VideoDecoderClass subclasses can override any of the available virtual
// methods or not, as needed. At minimum handle_frame needs to be overridden,
// and set_format and likely as well. If non-packetized input is supported or
// expected, parse needs to be overridden as well.
//
// An instance of this type is always passed by reference.
type VideoDecoderClass struct {
	*videoDecoderClass
}

// videoDecoderClass is the struct that's finalized.
type videoDecoderClass struct {
	native *C.GstVideoDecoderClass
}

// VideoDirectionInterface interface.
//
// An instance of this type is always passed by reference.
type VideoDirectionInterface struct {
	*videoDirectionInterface
}

// videoDirectionInterface is the struct that's finalized.
type videoDirectionInterface struct {
	native *C.GstVideoDirectionInterface
}

// VideoEncoderClass subclasses can override any of the available virtual
// methods or not, as needed. At minimum handle_frame needs to be overridden,
// and set_format and get_caps are likely needed as well.
//
// An instance of this type is always passed by reference.
type VideoEncoderClass struct {
	*videoEncoderClass
}

// videoEncoderClass is the struct that's finalized.
type videoEncoderClass struct {
	native *C.GstVideoEncoderClass
}

// VideoFilterClass: video filter class structure.
//
// An instance of this type is always passed by reference.
type VideoFilterClass struct {
	*videoFilterClass
}

// videoFilterClass is the struct that's finalized.
type videoFilterClass struct {
	native *C.GstVideoFilterClass
}

// ParentClass: parent class structure.
func (v *VideoFilterClass) ParentClass() *gstbase.BaseTransformClass {
	valptr := &v.native.parent_class
	var _v *gstbase.BaseTransformClass // out
	_v = (*gstbase.BaseTransformClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// VideoFormatInfo: information for a video format.
//
// An instance of this type is always passed by reference.
type VideoFormatInfo struct {
	*videoFormatInfo
}

// videoFormatInfo is the struct that's finalized.
type videoFormatInfo struct {
	native *C.GstVideoFormatInfo
}

// Component: fill components with the number of all the components packed in
// plane p for the format info. A value of -1 in components indicates that no
// more components are packed in the plane.
//
// The function takes the following parameters:
//
//   - plane number.
//
// The function returns the following values:
//
//   - components: array used to store component numbers.
func (info *VideoFormatInfo) Component(plane uint) int {
	var _arg0 *C.GstVideoFormatInfo // out
	var _arg1 C.guint               // out
	var _arg2 C.gint                // in

	_arg0 = (*C.GstVideoFormatInfo)(gextras.StructNative(unsafe.Pointer(info)))
	_arg1 = C.guint(plane)

	C.gst_video_format_info_component(_arg0, _arg1, &_arg2)
	runtime.KeepAlive(info)
	runtime.KeepAlive(plane)

	var _components int // out

	_components = int(_arg2)

	return _components
}

// ExtrapolateStride: extrapolate plane stride from the first stride of an
// image. This helper is useful to support legacy API were only one stride is
// supported.
//
// The function takes the following parameters:
//
//   - plane number.
//   - stride: fist plane stride.
//
// The function returns the following values:
//
//   - gint: extrapolated stride for plane.
func (finfo *VideoFormatInfo) ExtrapolateStride(plane int, stride int) int {
	var _arg0 *C.GstVideoFormatInfo // out
	var _arg1 C.gint                // out
	var _arg2 C.gint                // out
	var _cret C.gint                // in

	_arg0 = (*C.GstVideoFormatInfo)(gextras.StructNative(unsafe.Pointer(finfo)))
	_arg1 = C.gint(plane)
	_arg2 = C.gint(stride)

	_cret = C.gst_video_format_info_extrapolate_stride(_arg0, _arg1, _arg2)
	runtime.KeepAlive(finfo)
	runtime.KeepAlive(plane)
	runtime.KeepAlive(stride)

	var _gint int // out

	_gint = int(_cret)

	return _gint
}

// VideoFrame: video frame obtained from gst_video_frame_map()
//
// An instance of this type is always passed by reference.
type VideoFrame struct {
	*videoFrame
}

// videoFrame is the struct that's finalized.
type videoFrame struct {
	native *C.GstVideoFrame
}

// Info: VideoInfo.
func (v *VideoFrame) Info() *VideoInfo {
	valptr := &v.native.info
	var _v *VideoInfo // out
	_v = (*VideoInfo)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// Flags for the frame.
func (v *VideoFrame) Flags() VideoFrameFlags {
	valptr := &v.native.flags
	var _v VideoFrameFlags // out
	_v = VideoFrameFlags(*valptr)
	return _v
}

// Buffer: mapped buffer.
func (v *VideoFrame) Buffer() *gst.Buffer {
	valptr := &v.native.buffer
	var _v *gst.Buffer // out
	_v = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_v)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})
	return _v
}

// Meta: pointer to metadata if any.
func (v *VideoFrame) Meta() unsafe.Pointer {
	valptr := &v.native.meta
	var _v unsafe.Pointer // out
	_v = (unsafe.Pointer)(unsafe.Pointer(*valptr))
	return _v
}

// ID: id of the mapped frame. the id can for example be used to identify the
// frame in case of multiview video.
func (v *VideoFrame) ID() int {
	valptr := &v.native.id
	var _v int // out
	_v = int(*valptr)
	return _v
}

// Data pointers to the plane data.
func (v *VideoFrame) Data() [4]unsafe.Pointer {
	valptr := &v.native.data
	var _v [4]unsafe.Pointer // out
	{
		src := &*valptr
		for i := 0; i < 4; i++ {
			_v[i] = (unsafe.Pointer)(unsafe.Pointer(src[i]))
		}
	}
	return _v
}

// Map mappings of the planes.
func (v *VideoFrame) Map() [4]gst.MapInfo {
	valptr := &v.native._map
	var _v [4]gst.MapInfo // out
	{
		src := &*valptr
		for i := 0; i < 4; i++ {
			_v[i] = *(*gst.MapInfo)(gextras.NewStructNative(unsafe.Pointer((&src[i]))))
		}
	}
	return _v
}

// ID: id of the mapped frame. the id can for example be used to identify the
// frame in case of multiview video.
func (v *VideoFrame) SetID(id int) {
	valptr := &v.native.id
	*valptr = C.gint(id)
}

// Copy the contents from src to dest.
//
// Note: Since: 1.18, dest dimensions are allowed to be smaller than src
// dimensions.
//
// The function takes the following parameters:
//
//   - src: VideoFrame.
//
// The function returns the following values:
//
//   - ok: TRUE if the contents could be copied.
func (dest *VideoFrame) Copy(src *VideoFrame) bool {
	var _arg0 *C.GstVideoFrame // out
	var _arg1 *C.GstVideoFrame // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstVideoFrame)(gextras.StructNative(unsafe.Pointer(dest)))
	_arg1 = (*C.GstVideoFrame)(gextras.StructNative(unsafe.Pointer(src)))

	_cret = C.gst_video_frame_copy(_arg0, _arg1)
	runtime.KeepAlive(dest)
	runtime.KeepAlive(src)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// CopyPlane: copy the plane with index plane from src to dest.
//
// Note: Since: 1.18, dest dimensions are allowed to be smaller than src
// dimensions.
//
// The function takes the following parameters:
//
//   - src: VideoFrame.
//   - plane: plane.
//
// The function returns the following values:
//
//   - ok: TRUE if the contents could be copied.
func (dest *VideoFrame) CopyPlane(src *VideoFrame, plane uint) bool {
	var _arg0 *C.GstVideoFrame // out
	var _arg1 *C.GstVideoFrame // out
	var _arg2 C.guint          // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstVideoFrame)(gextras.StructNative(unsafe.Pointer(dest)))
	_arg1 = (*C.GstVideoFrame)(gextras.StructNative(unsafe.Pointer(src)))
	_arg2 = C.guint(plane)

	_cret = C.gst_video_frame_copy_plane(_arg0, _arg1, _arg2)
	runtime.KeepAlive(dest)
	runtime.KeepAlive(src)
	runtime.KeepAlive(plane)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Unmap the memory previously mapped with gst_video_frame_map.
func (frame *VideoFrame) Unmap() {
	var _arg0 *C.GstVideoFrame // out

	_arg0 = (*C.GstVideoFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	C.gst_video_frame_unmap(_arg0)
	runtime.KeepAlive(frame)
}

// VideoFrameMap: use info and buffer to fill in the values of frame.
// frame is usually allocated on the stack, and you will pass the address to
// the VideoFrame structure allocated on the stack; gst_video_frame_map() will
// then fill in the structures with the various video-specific information you
// need to access the pixels of the video buffer. You can then use accessor
// macros such as GST_VIDEO_FRAME_COMP_DATA(), GST_VIDEO_FRAME_PLANE_DATA(),
// GST_VIDEO_FRAME_COMP_STRIDE(), GST_VIDEO_FRAME_PLANE_STRIDE() etc. to get to
// the pixels.
//
//	GstVideoFrame vframe;
//	...
//	// set RGB pixels to black one at a time
//	if (gst_video_frame_map (&vframe, video_info, video_buffer, GST_MAP_WRITE)) {
//	  guint8 *pixels = GST_VIDEO_FRAME_PLANE_DATA (vframe, 0);
//	  guint stride = GST_VIDEO_FRAME_PLANE_STRIDE (vframe, 0);
//	  guint pixel_stride = GST_VIDEO_FRAME_COMP_PSTRIDE (vframe, 0);
//
//	  for (h = 0; h < height; ++h) {
//	    for (w = 0; w < width; ++w) {
//	      guint8 *pixel = pixels + h * stride + w * pixel_stride;
//
//	      memset (pixel, 0, pixel_stride);
//	    }
//	  }
//
//	  gst_video_frame_unmap (&vframe);
//	}
//	...
//
// All video planes of buffer will be mapped and the pointers will be set in
// frame->data.
//
// The purpose of this function is to make it easy for you to get to the video
// pixels in a generic way, without you having to worry too much about details
// such as whether the video data is allocated in one contiguous memory chunk
// or multiple memory chunks (e.g. one for each plane); or if custom strides and
// custom plane offsets are used or not (as signalled by GstVideoMeta on each
// buffer). This function will just fill the VideoFrame structure with the right
// values and if you use the accessor macros everything will just work and you
// can access the data easily. It also maps the underlying memory chunks for
// you.
//
// The function takes the following parameters:
//
//   - info: VideoInfo.
//   - buffer to map.
//   - flags: MapFlags.
//
// The function returns the following values:
//
//   - frame: pointer to VideoFrame.
//   - ok: TRUE on success.
func VideoFrameMap(info *VideoInfo, buffer *gst.Buffer, flags gst.MapFlags) (*VideoFrame, bool) {
	var _arg1 C.GstVideoFrame // in
	var _arg2 *C.GstVideoInfo // out
	var _arg3 *C.GstBuffer    // out
	var _arg4 C.GstMapFlags   // out
	var _cret C.gboolean      // in

	_arg2 = (*C.GstVideoInfo)(gextras.StructNative(unsafe.Pointer(info)))
	_arg3 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg4 = C.GstMapFlags(flags)

	_cret = C.gst_video_frame_map(&_arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(info)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(flags)

	var _frame *VideoFrame // out
	var _ok bool           // out

	_frame = (*VideoFrame)(gextras.NewStructNative(unsafe.Pointer((&_arg1))))
	if _cret != 0 {
		_ok = true
	}

	return _frame, _ok
}

// VideoFrameMapID: use info and buffer to fill in the values of frame with the
// video frame information of frame id.
//
// When id is -1, the default frame is mapped. When id != -1, this function will
// return FALSE when there is no GstVideoMeta with that id.
//
// All video planes of buffer will be mapped and the pointers will be set in
// frame->data.
//
// The function takes the following parameters:
//
//   - info: VideoInfo.
//   - buffer to map.
//   - id: frame id to map.
//   - flags: MapFlags.
//
// The function returns the following values:
//
//   - frame: pointer to VideoFrame.
//   - ok: TRUE on success.
func VideoFrameMapID(info *VideoInfo, buffer *gst.Buffer, id int, flags gst.MapFlags) (*VideoFrame, bool) {
	var _arg1 C.GstVideoFrame // in
	var _arg2 *C.GstVideoInfo // out
	var _arg3 *C.GstBuffer    // out
	var _arg4 C.gint          // out
	var _arg5 C.GstMapFlags   // out
	var _cret C.gboolean      // in

	_arg2 = (*C.GstVideoInfo)(gextras.StructNative(unsafe.Pointer(info)))
	_arg3 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg4 = C.gint(id)
	_arg5 = C.GstMapFlags(flags)

	_cret = C.gst_video_frame_map_id(&_arg1, _arg2, _arg3, _arg4, _arg5)
	runtime.KeepAlive(info)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(id)
	runtime.KeepAlive(flags)

	var _frame *VideoFrame // out
	var _ok bool           // out

	_frame = (*VideoFrame)(gextras.NewStructNative(unsafe.Pointer((&_arg1))))
	if _cret != 0 {
		_ok = true
	}

	return _frame, _ok
}

// VideoGLTextureUploadMeta: extra buffer metadata for uploading a buffer to an
// OpenGL texture ID. The caller of gst_video_gl_texture_upload_meta_upload()
// must have OpenGL set up and call this from a thread where it is valid to
// upload something to an OpenGL texture.
//
// An instance of this type is always passed by reference.
type VideoGLTextureUploadMeta struct {
	*videoGLTextureUploadMeta
}

// videoGLTextureUploadMeta is the struct that's finalized.
type videoGLTextureUploadMeta struct {
	native *C.GstVideoGLTextureUploadMeta
}

// Meta: parent Meta.
func (v *VideoGLTextureUploadMeta) Meta() *gst.Meta {
	valptr := &v.native.meta
	var _v *gst.Meta // out
	_v = (*gst.Meta)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// TextureOrientation: orientation of the textures.
func (v *VideoGLTextureUploadMeta) TextureOrientation() VideoGLTextureOrientation {
	valptr := &v.native.texture_orientation
	var _v VideoGLTextureOrientation // out
	_v = VideoGLTextureOrientation(*valptr)
	return _v
}

// NTextures: number of textures that are generated.
func (v *VideoGLTextureUploadMeta) NTextures() uint {
	valptr := &v.native.n_textures
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// TextureType: type of each texture.
func (v *VideoGLTextureUploadMeta) TextureType() [4]VideoGLTextureType {
	valptr := &v.native.texture_type
	var _v [4]VideoGLTextureType // out
	_v = *(*[4]VideoGLTextureType)(unsafe.Pointer(&*valptr))
	return _v
}

// NTextures: number of textures that are generated.
func (v *VideoGLTextureUploadMeta) SetNTextures(nTextures uint) {
	valptr := &v.native.n_textures
	*valptr = C.guint(nTextures)
}

// Upload uploads the buffer which owns the meta to a specific texture ID.
//
// The function takes the following parameters:
//
//   - textureId: texture IDs to upload to.
//
// The function returns the following values:
//
//   - ok: TRUE if uploading succeeded, FALSE otherwise.
func (meta *VideoGLTextureUploadMeta) Upload(textureId *uint) bool {
	var _arg0 *C.GstVideoGLTextureUploadMeta // out
	var _arg1 *C.guint                       // out
	var _cret C.gboolean                     // in

	_arg0 = (*C.GstVideoGLTextureUploadMeta)(gextras.StructNative(unsafe.Pointer(meta)))
	_arg1 = (*C.guint)(unsafe.Pointer(textureId))

	_cret = C.gst_video_gl_texture_upload_meta_upload(_arg0, _arg1)
	runtime.KeepAlive(meta)
	runtime.KeepAlive(textureId)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

func VideoGLTextureUploadMetaGetInfo() *gst.MetaInfo {
	var _cret *C.GstMetaInfo // in

	_cret = C.gst_video_gl_texture_upload_meta_get_info()

	var _metaInfo *gst.MetaInfo // out

	_metaInfo = (*gst.MetaInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _metaInfo
}

// VideoInfo: information describing image properties. This information can be
// filled in from GstCaps with gst_video_info_from_caps(). The information is
// also used to store the specific video info when mapping a video frame with
// gst_video_frame_map().
//
// Use the provided macros to access the info in this structure.
//
// An instance of this type is always passed by reference.
type VideoInfo struct {
	*videoInfo
}

// videoInfo is the struct that's finalized.
type videoInfo struct {
	native *C.GstVideoInfo
}

func marshalVideoInfo(p uintptr) (interface{}, error) {
	b := coreglib.ValueFromNative(unsafe.Pointer(p)).Boxed()
	return &VideoInfo{&videoInfo{(*C.GstVideoInfo)(b)}}, nil
}

// NewVideoInfo constructs a struct VideoInfo.
func NewVideoInfo() *VideoInfo {
	var _cret *C.GstVideoInfo // in

	_cret = C.gst_video_info_new()

	var _videoInfo *VideoInfo // out

	_videoInfo = (*VideoInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_videoInfo)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_video_info_free((*C.GstVideoInfo)(intern.C))
		},
	)

	return _videoInfo
}

// NewVideoInfoFromCaps constructs a struct VideoInfo.
func NewVideoInfoFromCaps(caps *gst.Caps) *VideoInfo {
	var _arg1 *C.GstCaps      // out
	var _cret *C.GstVideoInfo // in

	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C.gst_video_info_new_from_caps(_arg1)
	runtime.KeepAlive(caps)

	var _videoInfo *VideoInfo // out

	if _cret != nil {
		_videoInfo = (*VideoInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_videoInfo)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_video_info_free((*C.GstVideoInfo)(intern.C))
			},
		)
	}

	return _videoInfo
}

// Finfo: format info of the video.
func (v *VideoInfo) Finfo() *VideoFormatInfo {
	valptr := &v.native.finfo
	var _v *VideoFormatInfo // out
	_v = (*VideoFormatInfo)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	return _v
}

// InterlaceMode: interlace mode.
func (v *VideoInfo) InterlaceMode() VideoInterlaceMode {
	valptr := &v.native.interlace_mode
	var _v VideoInterlaceMode // out
	_v = VideoInterlaceMode(*valptr)
	return _v
}

// Flags: additional video flags.
func (v *VideoInfo) Flags() VideoFlags {
	valptr := &v.native.flags
	var _v VideoFlags // out
	_v = VideoFlags(*valptr)
	return _v
}

// Width: width of the video.
func (v *VideoInfo) Width() int {
	valptr := &v.native.width
	var _v int // out
	_v = int(*valptr)
	return _v
}

// Height: height of the video.
func (v *VideoInfo) Height() int {
	valptr := &v.native.height
	var _v int // out
	_v = int(*valptr)
	return _v
}

// Size: default size of one frame.
func (v *VideoInfo) Size() uint {
	valptr := &v.native.size
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Views: number of views for multiview video.
func (v *VideoInfo) Views() int {
	valptr := &v.native.views
	var _v int // out
	_v = int(*valptr)
	return _v
}

// ChromaSite: VideoChromaSite.
func (v *VideoInfo) ChromaSite() VideoChromaSite {
	valptr := &v.native.chroma_site
	var _v VideoChromaSite // out
	_v = VideoChromaSite(*valptr)
	return _v
}

// Colorimetry: colorimetry info.
func (v *VideoInfo) Colorimetry() *VideoColorimetry {
	valptr := &v.native.colorimetry
	var _v *VideoColorimetry // out
	_v = (*VideoColorimetry)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// ParN: pixel-aspect-ratio numerator.
func (v *VideoInfo) ParN() int {
	valptr := &v.native.par_n
	var _v int // out
	_v = int(*valptr)
	return _v
}

// ParD: pixel-aspect-ratio denominator.
func (v *VideoInfo) ParD() int {
	valptr := &v.native.par_d
	var _v int // out
	_v = int(*valptr)
	return _v
}

// FPSN: framerate numerator.
func (v *VideoInfo) FPSN() int {
	valptr := &v.native.fps_n
	var _v int // out
	_v = int(*valptr)
	return _v
}

// FPSD: framerate denominator.
func (v *VideoInfo) FPSD() int {
	valptr := &v.native.fps_d
	var _v int // out
	_v = int(*valptr)
	return _v
}

// Offset offsets of the planes.
func (v *VideoInfo) Offset() [4]uint {
	valptr := &v.native.offset
	var _v [4]uint // out
	_v = *(*[4]uint)(unsafe.Pointer(&*valptr))
	return _v
}

// Stride strides of the planes.
func (v *VideoInfo) Stride() [4]int {
	valptr := &v.native.stride
	var _v [4]int // out
	{
		src := &*valptr
		for i := 0; i < 4; i++ {
			_v[i] = int(src[i])
		}
	}
	return _v
}

// Width: width of the video.
func (v *VideoInfo) SetWidth(width int) {
	valptr := &v.native.width
	*valptr = C.gint(width)
}

// Height: height of the video.
func (v *VideoInfo) SetHeight(height int) {
	valptr := &v.native.height
	*valptr = C.gint(height)
}

// Size: default size of one frame.
func (v *VideoInfo) SetSize(size uint) {
	valptr := &v.native.size
	*valptr = C.gsize(size)
}

// Views: number of views for multiview video.
func (v *VideoInfo) SetViews(views int) {
	valptr := &v.native.views
	*valptr = C.gint(views)
}

// ParN: pixel-aspect-ratio numerator.
func (v *VideoInfo) SetParN(parN int) {
	valptr := &v.native.par_n
	*valptr = C.gint(parN)
}

// ParD: pixel-aspect-ratio denominator.
func (v *VideoInfo) SetParD(parD int) {
	valptr := &v.native.par_d
	*valptr = C.gint(parD)
}

// FPSN: framerate numerator.
func (v *VideoInfo) SetFPSN(fpsN int) {
	valptr := &v.native.fps_n
	*valptr = C.gint(fpsN)
}

// FPSD: framerate denominator.
func (v *VideoInfo) SetFPSD(fpsD int) {
	valptr := &v.native.fps_d
	*valptr = C.gint(fpsD)
}

// Align: adjust the offset and stride fields in info so that the padding and
// stride alignment in align is respected.
//
// Extra padding will be added to the right side when stride alignment padding
// is required and align will be updated with the new padding values.
//
// The function takes the following parameters:
//
//   - align: alignment parameters.
//
// The function returns the following values:
//
//   - ok: FALSE if alignment could not be applied, e.g. because the size of a
//     frame can't be represented as a 32 bit integer (Since: 1.12).
func (info *VideoInfo) Align(align *VideoAlignment) bool {
	var _arg0 *C.GstVideoInfo      // out
	var _arg1 *C.GstVideoAlignment // out
	var _cret C.gboolean           // in

	_arg0 = (*C.GstVideoInfo)(gextras.StructNative(unsafe.Pointer(info)))
	_arg1 = (*C.GstVideoAlignment)(gextras.StructNative(unsafe.Pointer(align)))

	_cret = C.gst_video_info_align(_arg0, _arg1)
	runtime.KeepAlive(info)
	runtime.KeepAlive(align)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// AlignFull: extra padding will be added to the right side when stride
// alignment padding is required and align will be updated with the new padding
// values.
//
// This variant of gst_video_info_align() provides the updated size, in bytes,
// of each video plane after the alignment, including all horizontal and
// vertical paddings.
//
// In case of GST_VIDEO_INTERLACE_MODE_ALTERNATE info, the returned sizes are
// the ones used to hold a single field, not the full frame.
//
// The function takes the following parameters:
//
//   - align: alignment parameters.
//
// The function returns the following values:
//
//   - planeSize (optional): array used to store the plane sizes.
//   - ok: FALSE if alignment could not be applied, e.g. because the size of a
//     frame can't be represented as a 32 bit integer.
func (info *VideoInfo) AlignFull(align *VideoAlignment) (uint, bool) {
	var _arg0 *C.GstVideoInfo      // out
	var _arg1 *C.GstVideoAlignment // out
	var _arg2 C.gsize              // in
	var _cret C.gboolean           // in

	_arg0 = (*C.GstVideoInfo)(gextras.StructNative(unsafe.Pointer(info)))
	_arg1 = (*C.GstVideoAlignment)(gextras.StructNative(unsafe.Pointer(align)))

	_cret = C.gst_video_info_align_full(_arg0, _arg1, &_arg2)
	runtime.KeepAlive(info)
	runtime.KeepAlive(align)

	var _planeSize uint // out
	var _ok bool        // out

	_planeSize = uint(_arg2)
	if _cret != 0 {
		_ok = true
	}

	return _planeSize, _ok
}

// Convert converts among various Format types. This function handles
// GST_FORMAT_BYTES, GST_FORMAT_TIME, and GST_FORMAT_DEFAULT. For raw video,
// GST_FORMAT_DEFAULT corresponds to video frames. This function can be used to
// handle pad queries of the type GST_QUERY_CONVERT.
//
// The function takes the following parameters:
//
//   - srcFormat of the src_value.
//   - srcValue: value to convert.
//   - destFormat of the dest_value.
//
// The function returns the following values:
//
//   - destValue: pointer to destination value.
//   - ok: TRUE if the conversion was successful.
func (info *VideoInfo) Convert(srcFormat gst.Format, srcValue int64, destFormat gst.Format) (int64, bool) {
	var _arg0 *C.GstVideoInfo // out
	var _arg1 C.GstFormat     // out
	var _arg2 C.gint64        // out
	var _arg3 C.GstFormat     // out
	var _arg4 C.gint64        // in
	var _cret C.gboolean      // in

	_arg0 = (*C.GstVideoInfo)(gextras.StructNative(unsafe.Pointer(info)))
	_arg1 = C.GstFormat(srcFormat)
	_arg2 = C.gint64(srcValue)
	_arg3 = C.GstFormat(destFormat)

	_cret = C.gst_video_info_convert(_arg0, _arg1, _arg2, _arg3, &_arg4)
	runtime.KeepAlive(info)
	runtime.KeepAlive(srcFormat)
	runtime.KeepAlive(srcValue)
	runtime.KeepAlive(destFormat)

	var _destValue int64 // out
	var _ok bool         // out

	_destValue = int64(_arg4)
	if _cret != 0 {
		_ok = true
	}

	return _destValue, _ok
}

// Copy a GstVideoInfo structure.
//
// The function returns the following values:
//
//   - videoInfo: new VideoInfo. free with gst_video_info_free.
func (info *VideoInfo) Copy() *VideoInfo {
	var _arg0 *C.GstVideoInfo // out
	var _cret *C.GstVideoInfo // in

	_arg0 = (*C.GstVideoInfo)(gextras.StructNative(unsafe.Pointer(info)))

	_cret = C.gst_video_info_copy(_arg0)
	runtime.KeepAlive(info)

	var _videoInfo *VideoInfo // out

	_videoInfo = (*VideoInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_videoInfo)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_video_info_free((*C.GstVideoInfo)(intern.C))
		},
	)

	return _videoInfo
}

// IsEqual compares two VideoInfo and returns whether they are equal or not.
//
// The function takes the following parameters:
//
//   - other: VideoInfo.
//
// The function returns the following values:
//
//   - ok: TRUE if info and other are equal, else FALSE.
func (info *VideoInfo) IsEqual(other *VideoInfo) bool {
	var _arg0 *C.GstVideoInfo // out
	var _arg1 *C.GstVideoInfo // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstVideoInfo)(gextras.StructNative(unsafe.Pointer(info)))
	_arg1 = (*C.GstVideoInfo)(gextras.StructNative(unsafe.Pointer(other)))

	_cret = C.gst_video_info_is_equal(_arg0, _arg1)
	runtime.KeepAlive(info)
	runtime.KeepAlive(other)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SetFormat: set the default info for a video frame of format and width and
// height.
//
// Note: This initializes info first, no values are preserved. This function
// does not set the offsets correctly for interlaced vertically subsampled
// formats.
//
// The function takes the following parameters:
//
//   - format: format.
//   - width: width.
//   - height: height.
//
// The function returns the following values:
//
//   - ok: FALSE if the returned video info is invalid, e.g. because the size of
//     a frame can't be represented as a 32 bit integer (Since: 1.12).
func (info *VideoInfo) SetFormat(format VideoFormat, width uint, height uint) bool {
	var _arg0 *C.GstVideoInfo  // out
	var _arg1 C.GstVideoFormat // out
	var _arg2 C.guint          // out
	var _arg3 C.guint          // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstVideoInfo)(gextras.StructNative(unsafe.Pointer(info)))
	_arg1 = C.GstVideoFormat(format)
	_arg2 = C.guint(width)
	_arg3 = C.guint(height)

	_cret = C.gst_video_info_set_format(_arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(info)
	runtime.KeepAlive(format)
	runtime.KeepAlive(width)
	runtime.KeepAlive(height)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SetInterlacedFormat: same as #gst_video_info_set_format but also allowing to
// set the interlaced mode.
//
// The function takes the following parameters:
//
//   - format: format.
//   - mode: VideoInterlaceMode.
//   - width: width.
//   - height: height.
//
// The function returns the following values:
//
//   - ok: FALSE if the returned video info is invalid, e.g. because the size of
//     a frame can't be represented as a 32 bit integer.
func (info *VideoInfo) SetInterlacedFormat(format VideoFormat, mode VideoInterlaceMode, width uint, height uint) bool {
	var _arg0 *C.GstVideoInfo         // out
	var _arg1 C.GstVideoFormat        // out
	var _arg2 C.GstVideoInterlaceMode // out
	var _arg3 C.guint                 // out
	var _arg4 C.guint                 // out
	var _cret C.gboolean              // in

	_arg0 = (*C.GstVideoInfo)(gextras.StructNative(unsafe.Pointer(info)))
	_arg1 = C.GstVideoFormat(format)
	_arg2 = C.GstVideoInterlaceMode(mode)
	_arg3 = C.guint(width)
	_arg4 = C.guint(height)

	_cret = C.gst_video_info_set_interlaced_format(_arg0, _arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(info)
	runtime.KeepAlive(format)
	runtime.KeepAlive(mode)
	runtime.KeepAlive(width)
	runtime.KeepAlive(height)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// ToCaps: convert the values of info into a Caps.
//
// The function returns the following values:
//
//   - caps: new Caps containing the info of info.
func (info *VideoInfo) ToCaps() *gst.Caps {
	var _arg0 *C.GstVideoInfo // out
	var _cret *C.GstCaps      // in

	_arg0 = (*C.GstVideoInfo)(gextras.StructNative(unsafe.Pointer(info)))

	_cret = C.gst_video_info_to_caps(_arg0)
	runtime.KeepAlive(info)

	var _caps *gst.Caps // out

	_caps = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_caps)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _caps
}

// VideoInfoFromCaps: parse caps and update info.
//
// The function takes the following parameters:
//
//   - caps: Caps.
//
// The function returns the following values:
//
//   - info: VideoInfo.
//   - ok: TRUE if caps could be parsed.
func VideoInfoFromCaps(caps *gst.Caps) (*VideoInfo, bool) {
	var _arg1 C.GstVideoInfo // in
	var _arg2 *C.GstCaps     // out
	var _cret C.gboolean     // in

	_arg2 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C.gst_video_info_from_caps(&_arg1, _arg2)
	runtime.KeepAlive(caps)

	var _info *VideoInfo // out
	var _ok bool         // out

	_info = (*VideoInfo)(gextras.NewStructNative(unsafe.Pointer((&_arg1))))
	if _cret != 0 {
		_ok = true
	}

	return _info, _ok
}

// VideoInfoInit: initialize info with default values.
//
// The function returns the following values:
//
//   - info: VideoInfo.
func VideoInfoInit() *VideoInfo {
	var _arg1 C.GstVideoInfo // in

	C.gst_video_info_init(&_arg1)

	var _info *VideoInfo // out

	_info = (*VideoInfo)(gextras.NewStructNative(unsafe.Pointer((&_arg1))))

	return _info
}

// VideoInfoDmaDRM: information describing a DMABuf image properties. It wraps
// VideoInfo and adds DRM information such as drm-fourcc and drm-modifier,
// required for negotiation and mapping.
//
// An instance of this type is always passed by reference.
type VideoInfoDmaDRM struct {
	*videoInfoDmaDRM
}

// videoInfoDmaDRM is the struct that's finalized.
type videoInfoDmaDRM struct {
	native *C.GstVideoInfoDmaDrm
}

func marshalVideoInfoDmaDRM(p uintptr) (interface{}, error) {
	b := coreglib.ValueFromNative(unsafe.Pointer(p)).Boxed()
	return &VideoInfoDmaDRM{&videoInfoDmaDRM{(*C.GstVideoInfoDmaDrm)(b)}}, nil
}

// NewVideoInfoDmaDRM constructs a struct VideoInfoDmaDRM.
func NewVideoInfoDmaDRM() *VideoInfoDmaDRM {
	var _cret *C.GstVideoInfoDmaDrm // in

	_cret = C.gst_video_info_dma_drm_new()

	var _videoInfoDmaDrm *VideoInfoDmaDRM // out

	_videoInfoDmaDrm = (*VideoInfoDmaDRM)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_videoInfoDmaDrm)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_video_info_dma_drm_free((*C.GstVideoInfoDmaDrm)(intern.C))
		},
	)

	return _videoInfoDmaDrm
}

// NewVideoInfoDmaDRMFromCaps constructs a struct VideoInfoDmaDRM.
func NewVideoInfoDmaDRMFromCaps(caps *gst.Caps) *VideoInfoDmaDRM {
	var _arg1 *C.GstCaps            // out
	var _cret *C.GstVideoInfoDmaDrm // in

	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C.gst_video_info_dma_drm_new_from_caps(_arg1)
	runtime.KeepAlive(caps)

	var _videoInfoDmaDrm *VideoInfoDmaDRM // out

	if _cret != nil {
		_videoInfoDmaDrm = (*VideoInfoDmaDRM)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_videoInfoDmaDrm)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_video_info_dma_drm_free((*C.GstVideoInfoDmaDrm)(intern.C))
			},
		)
	}

	return _videoInfoDmaDrm
}

// Vinfo: associated VideoInfo.
func (v *VideoInfoDmaDRM) Vinfo() *VideoInfo {
	valptr := &v.native.vinfo
	var _v *VideoInfo // out
	_v = (*VideoInfo)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// DRMFourcc: fourcc defined by drm.
func (v *VideoInfoDmaDRM) DRMFourcc() uint32 {
	valptr := &v.native.drm_fourcc
	var _v uint32 // out
	_v = uint32(*valptr)
	return _v
}

// DRMModifier: drm modifier.
func (v *VideoInfoDmaDRM) DRMModifier() uint64 {
	valptr := &v.native.drm_modifier
	var _v uint64 // out
	_v = uint64(*valptr)
	return _v
}

// DRMFourcc: fourcc defined by drm.
func (v *VideoInfoDmaDRM) SetDRMFourcc(drmFourcc uint32) {
	valptr := &v.native.drm_fourcc
	*valptr = C.guint32(drmFourcc)
}

// DRMModifier: drm modifier.
func (v *VideoInfoDmaDRM) SetDRMModifier(drmModifier uint64) {
	valptr := &v.native.drm_modifier
	*valptr = C.guint64(drmModifier)
}

// ToCaps: convert the values of drm_info into a Caps. Please note that the
// caps returned will be a dma drm caps which sets format field to DMA_DRM, and
// contains a new drm-format field. The value of drm-format field is composed of
// a drm fourcc and a modifier, such as NV12:0x0100000000000002.
//
// The function returns the following values:
//
//   - caps (optional): new Caps containing the info in drm_info.
func (drmInfo *VideoInfoDmaDRM) ToCaps() *gst.Caps {
	var _arg0 *C.GstVideoInfoDmaDrm // out
	var _cret *C.GstCaps            // in

	_arg0 = (*C.GstVideoInfoDmaDrm)(gextras.StructNative(unsafe.Pointer(drmInfo)))

	_cret = C.gst_video_info_dma_drm_to_caps(_arg0)
	runtime.KeepAlive(drmInfo)

	var _caps *gst.Caps // out

	if _cret != nil {
		_caps = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_caps)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _caps
}

// ToVideoInfo: convert the VideoInfoDmaDrm into a traditional VideoInfo with
// recognized video format. For DMA kind memory, the non linear DMA format
// should be recognized as T_VIDEO_FORMAT_DMA_DRM. This helper function sets
// info's video format into the default value according to drm_info's drm_fourcc
// field.
//
// The function returns the following values:
//
//   - info: VideoInfo.
//   - ok: TRUE if info is converted correctly.
func (drmInfo *VideoInfoDmaDRM) ToVideoInfo() (*VideoInfo, bool) {
	var _arg0 *C.GstVideoInfoDmaDrm // out
	var _arg1 C.GstVideoInfo        // in
	var _cret C.gboolean            // in

	_arg0 = (*C.GstVideoInfoDmaDrm)(gextras.StructNative(unsafe.Pointer(drmInfo)))

	_cret = C.gst_video_info_dma_drm_to_video_info(_arg0, &_arg1)
	runtime.KeepAlive(drmInfo)

	var _info *VideoInfo // out
	var _ok bool         // out

	_info = (*VideoInfo)(gextras.NewStructNative(unsafe.Pointer((&_arg1))))
	if _cret != 0 {
		_ok = true
	}

	return _info, _ok
}

// VideoInfoDmaDRMFromCaps: parse caps and update info. Please note that the
// caps should be a dma drm caps. The gst_video_is_dma_drm_caps() can be used to
// verify it before calling this function.
//
// The function takes the following parameters:
//
//   - caps: Caps.
//
// The function returns the following values:
//
//   - drmInfo: VideoInfoDmaDrm.
//   - ok: TRUE if caps could be parsed.
func VideoInfoDmaDRMFromCaps(caps *gst.Caps) (*VideoInfoDmaDRM, bool) {
	var _arg1 C.GstVideoInfoDmaDrm // in
	var _arg2 *C.GstCaps           // out
	var _cret C.gboolean           // in

	_arg2 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C.gst_video_info_dma_drm_from_caps(&_arg1, _arg2)
	runtime.KeepAlive(caps)

	var _drmInfo *VideoInfoDmaDRM // out
	var _ok bool                  // out

	_drmInfo = (*VideoInfoDmaDRM)(gextras.NewStructNative(unsafe.Pointer((&_arg1))))
	if _cret != 0 {
		_ok = true
	}

	return _drmInfo, _ok
}

// VideoInfoDmaDRMFromVideoInfo fills drm_info if info's format has a valid drm
// format and modifier is also valid.
//
// The function takes the following parameters:
//
//   - info: VideoInfo.
//   - modifier: associated modifier value.
//
// The function returns the following values:
//
//   - drmInfo: VideoInfoDmaDrm.
//   - ok: TRUE if drm_info is filled correctly.
func VideoInfoDmaDRMFromVideoInfo(info *VideoInfo, modifier uint64) (*VideoInfoDmaDRM, bool) {
	var _arg1 C.GstVideoInfoDmaDrm // in
	var _arg2 *C.GstVideoInfo      // out
	var _arg3 C.guint64            // out
	var _cret C.gboolean           // in

	_arg2 = (*C.GstVideoInfo)(gextras.StructNative(unsafe.Pointer(info)))
	_arg3 = C.guint64(modifier)

	_cret = C.gst_video_info_dma_drm_from_video_info(&_arg1, _arg2, _arg3)
	runtime.KeepAlive(info)
	runtime.KeepAlive(modifier)

	var _drmInfo *VideoInfoDmaDRM // out
	var _ok bool                  // out

	_drmInfo = (*VideoInfoDmaDRM)(gextras.NewStructNative(unsafe.Pointer((&_arg1))))
	if _cret != 0 {
		_ok = true
	}

	return _drmInfo, _ok
}

// VideoInfoDmaDRMInit: initialize drm_info with default values.
//
// The function returns the following values:
//
//   - drmInfo: VideoInfoDmaDrm.
func VideoInfoDmaDRMInit() *VideoInfoDmaDRM {
	var _arg1 C.GstVideoInfoDmaDrm // in

	C.gst_video_info_dma_drm_init(&_arg1)

	var _drmInfo *VideoInfoDmaDRM // out

	_drmInfo = (*VideoInfoDmaDRM)(gextras.NewStructNative(unsafe.Pointer((&_arg1))))

	return _drmInfo
}

// VideoMasteringDisplayInfo: mastering display color volume information defined
// by SMPTE ST 2086 (a.k.a static HDR metadata).
//
// An instance of this type is always passed by reference.
type VideoMasteringDisplayInfo struct {
	*videoMasteringDisplayInfo
}

// videoMasteringDisplayInfo is the struct that's finalized.
type videoMasteringDisplayInfo struct {
	native *C.GstVideoMasteringDisplayInfo
}

// DisplayPrimaries: xy coordinates of primaries in the CIE 1931 color space.
// the index 0 contains red, 1 is for green and 2 is for blue. each value is
// normalized to 50000 (meaning that in unit of 0.00002).
func (v *VideoMasteringDisplayInfo) DisplayPrimaries() [3]VideoMasteringDisplayInfoCoordinates {
	valptr := &v.native.display_primaries
	var _v [3]VideoMasteringDisplayInfoCoordinates // out
	{
		src := &*valptr
		for i := 0; i < 3; i++ {
			_v[i] = *(*VideoMasteringDisplayInfoCoordinates)(gextras.NewStructNative(unsafe.Pointer((&src[i]))))
		}
	}
	return _v
}

// WhitePoint: xy coordinates of white point in the CIE 1931 color space.
// each value is normalized to 50000 (meaning that in unit of 0.00002).
func (v *VideoMasteringDisplayInfo) WhitePoint() *VideoMasteringDisplayInfoCoordinates {
	valptr := &v.native.white_point
	var _v *VideoMasteringDisplayInfoCoordinates // out
	_v = (*VideoMasteringDisplayInfoCoordinates)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// MaxDisplayMasteringLuminance: maximum value of display luminance in unit of
// 0.0001 candelas per square metre (cd/m^2 and nit).
func (v *VideoMasteringDisplayInfo) MaxDisplayMasteringLuminance() uint32 {
	valptr := &v.native.max_display_mastering_luminance
	var _v uint32 // out
	_v = uint32(*valptr)
	return _v
}

// MinDisplayMasteringLuminance: minimum value of display luminance in unit of
// 0.0001 candelas per square metre (cd/m^2 and nit).
func (v *VideoMasteringDisplayInfo) MinDisplayMasteringLuminance() uint32 {
	valptr := &v.native.min_display_mastering_luminance
	var _v uint32 // out
	_v = uint32(*valptr)
	return _v
}

// MaxDisplayMasteringLuminance: maximum value of display luminance in unit of
// 0.0001 candelas per square metre (cd/m^2 and nit).
func (v *VideoMasteringDisplayInfo) SetMaxDisplayMasteringLuminance(maxDisplayMasteringLuminance uint32) {
	valptr := &v.native.max_display_mastering_luminance
	*valptr = C.guint32(maxDisplayMasteringLuminance)
}

// MinDisplayMasteringLuminance: minimum value of display luminance in unit of
// 0.0001 candelas per square metre (cd/m^2 and nit).
func (v *VideoMasteringDisplayInfo) SetMinDisplayMasteringLuminance(minDisplayMasteringLuminance uint32) {
	valptr := &v.native.min_display_mastering_luminance
	*valptr = C.guint32(minDisplayMasteringLuminance)
}

// AddToCaps: set string representation of minfo to caps.
//
// The function takes the following parameters:
//
//   - caps: Caps.
//
// The function returns the following values:
//
//   - ok: TRUE if minfo was successfully set to caps.
func (minfo *VideoMasteringDisplayInfo) AddToCaps(caps *gst.Caps) bool {
	var _arg0 *C.GstVideoMasteringDisplayInfo // out
	var _arg1 *C.GstCaps                      // out
	var _cret C.gboolean                      // in

	_arg0 = (*C.GstVideoMasteringDisplayInfo)(gextras.StructNative(unsafe.Pointer(minfo)))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C.gst_video_mastering_display_info_add_to_caps(_arg0, _arg1)
	runtime.KeepAlive(minfo)
	runtime.KeepAlive(caps)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// FromCaps: parse caps and update minfo.
//
// The function takes the following parameters:
//
//   - caps: Caps.
//
// The function returns the following values:
//
//   - ok: TRUE if caps has VideoMasteringDisplayInfo and could be parsed.
func (minfo *VideoMasteringDisplayInfo) FromCaps(caps *gst.Caps) bool {
	var _arg0 *C.GstVideoMasteringDisplayInfo // out
	var _arg1 *C.GstCaps                      // out
	var _cret C.gboolean                      // in

	_arg0 = (*C.GstVideoMasteringDisplayInfo)(gextras.StructNative(unsafe.Pointer(minfo)))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C.gst_video_mastering_display_info_from_caps(_arg0, _arg1)
	runtime.KeepAlive(minfo)
	runtime.KeepAlive(caps)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Init: initialize minfo.
func (minfo *VideoMasteringDisplayInfo) Init() {
	var _arg0 *C.GstVideoMasteringDisplayInfo // out

	_arg0 = (*C.GstVideoMasteringDisplayInfo)(gextras.StructNative(unsafe.Pointer(minfo)))

	C.gst_video_mastering_display_info_init(_arg0)
	runtime.KeepAlive(minfo)
}

// IsEqual checks equality between minfo and other.
//
// The function takes the following parameters:
//
//   - other: VideoMasteringDisplayInfo.
//
// The function returns the following values:
//
//   - ok: TRUE if minfo and other are equal.
func (minfo *VideoMasteringDisplayInfo) IsEqual(other *VideoMasteringDisplayInfo) bool {
	var _arg0 *C.GstVideoMasteringDisplayInfo // out
	var _arg1 *C.GstVideoMasteringDisplayInfo // out
	var _cret C.gboolean                      // in

	_arg0 = (*C.GstVideoMasteringDisplayInfo)(gextras.StructNative(unsafe.Pointer(minfo)))
	_arg1 = (*C.GstVideoMasteringDisplayInfo)(gextras.StructNative(unsafe.Pointer(other)))

	_cret = C.gst_video_mastering_display_info_is_equal(_arg0, _arg1)
	runtime.KeepAlive(minfo)
	runtime.KeepAlive(other)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// String: convert minfo to its string representation.
//
// The function returns the following values:
//
//   - utf8: string representation of minfo.
func (minfo *VideoMasteringDisplayInfo) String() string {
	var _arg0 *C.GstVideoMasteringDisplayInfo // out
	var _cret *C.gchar                        // in

	_arg0 = (*C.GstVideoMasteringDisplayInfo)(gextras.StructNative(unsafe.Pointer(minfo)))

	_cret = C.gst_video_mastering_display_info_to_string(_arg0)
	runtime.KeepAlive(minfo)

	var _utf8 string // out

	_utf8 = C.GoString((*C.gchar)(unsafe.Pointer(_cret)))
	defer C.free(unsafe.Pointer(_cret))

	return _utf8
}

// VideoMasteringDisplayInfoFromString: extract VideoMasteringDisplayInfo from
// mastering.
//
// The function takes the following parameters:
//
//   - mastering representing VideoMasteringDisplayInfo.
//
// The function returns the following values:
//
//   - minfo: VideoMasteringDisplayInfo.
//   - ok: TRUE if minfo was filled with mastering.
func VideoMasteringDisplayInfoFromString(mastering string) (*VideoMasteringDisplayInfo, bool) {
	var _arg1 C.GstVideoMasteringDisplayInfo // in
	var _arg2 *C.gchar                       // out
	var _cret C.gboolean                     // in

	_arg2 = (*C.gchar)(unsafe.Pointer(C.CString(mastering)))
	defer C.free(unsafe.Pointer(_arg2))

	_cret = C.gst_video_mastering_display_info_from_string(&_arg1, _arg2)
	runtime.KeepAlive(mastering)

	var _minfo *VideoMasteringDisplayInfo // out
	var _ok bool                          // out

	_minfo = (*VideoMasteringDisplayInfo)(gextras.NewStructNative(unsafe.Pointer((&_arg1))))
	if _cret != 0 {
		_ok = true
	}

	return _minfo, _ok
}

// VideoMasteringDisplayInfoCoordinates: used to represent display_primaries
// and white_point of VideoMasteringDisplayInfo struct. See
// VideoMasteringDisplayInfo
//
// An instance of this type is always passed by reference.
type VideoMasteringDisplayInfoCoordinates struct {
	*videoMasteringDisplayInfoCoordinates
}

// videoMasteringDisplayInfoCoordinates is the struct that's finalized.
type videoMasteringDisplayInfoCoordinates struct {
	native *C.GstVideoMasteringDisplayInfoCoordinates
}

// NewVideoMasteringDisplayInfoCoordinates creates a new VideoMasteringDisplayInfoCoordinates instance from the given
// fields. Beware that this function allocates on the Go heap; be careful
// when using it!
func NewVideoMasteringDisplayInfoCoordinates(x, y uint16) VideoMasteringDisplayInfoCoordinates {
	var f0 C.guint16 // out
	f0 = C.guint16(x)
	var f1 C.guint16 // out
	f1 = C.guint16(y)

	v := C.GstVideoMasteringDisplayInfoCoordinates{
		x: f0,
		y: f1,
	}

	return *(*VideoMasteringDisplayInfoCoordinates)(gextras.NewStructNative(unsafe.Pointer(&v)))
}

// X: x coordinate of CIE 1931 color space in unit of 0.00002.
func (v *VideoMasteringDisplayInfoCoordinates) X() uint16 {
	valptr := &v.native.x
	var _v uint16 // out
	_v = uint16(*valptr)
	return _v
}

// Y: y coordinate of CIE 1931 color space in unit of 0.00002.
func (v *VideoMasteringDisplayInfoCoordinates) Y() uint16 {
	valptr := &v.native.y
	var _v uint16 // out
	_v = uint16(*valptr)
	return _v
}

// X: x coordinate of CIE 1931 color space in unit of 0.00002.
func (v *VideoMasteringDisplayInfoCoordinates) SetX(x uint16) {
	valptr := &v.native.x
	*valptr = C.guint16(x)
}

// Y: y coordinate of CIE 1931 color space in unit of 0.00002.
func (v *VideoMasteringDisplayInfoCoordinates) SetY(y uint16) {
	valptr := &v.native.y
	*valptr = C.guint16(y)
}

// VideoMeta: extra buffer metadata describing image properties
//
// This meta can also be used by downstream elements to specifiy their
// buffer layout requirements for upstream. Upstream should try to fit those
// requirements, if possible, in order to prevent buffer copies.
//
// This is done by passing a custom Structure to gst_query_add_allocation_meta()
// when handling the ALLOCATION query. This structure should be named
// 'video-meta' and can have the following fields:
//
// - padding-top (uint): extra pixels on the top
//
// - padding-bottom (uint): extra pixels on the bottom
//
// - padding-left (uint): extra pixels on the left side
//
// - padding-right (uint): extra pixels on the right side The padding fields
// have the same semantic as VideoMeta.alignment and so represent the paddings
// requested on produced video buffers.
//
// Since 1.24 it can be serialized using gst_meta_serialize() and
// gst_meta_deserialize().
//
// An instance of this type is always passed by reference.
type VideoMeta struct {
	*videoMeta
}

// videoMeta is the struct that's finalized.
type videoMeta struct {
	native *C.GstVideoMeta
}

// Meta: parent Meta.
func (v *VideoMeta) Meta() *gst.Meta {
	valptr := &v.native.meta
	var _v *gst.Meta // out
	_v = (*gst.Meta)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// Buffer: buffer this metadata belongs to.
func (v *VideoMeta) Buffer() *gst.Buffer {
	valptr := &v.native.buffer
	var _v *gst.Buffer // out
	_v = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_v)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})
	return _v
}

// Flags: additional video flags.
func (v *VideoMeta) Flags() VideoFrameFlags {
	valptr := &v.native.flags
	var _v VideoFrameFlags // out
	_v = VideoFrameFlags(*valptr)
	return _v
}

// Format: video format.
func (v *VideoMeta) Format() VideoFormat {
	valptr := &v.native.format
	var _v VideoFormat // out
	_v = VideoFormat(*valptr)
	return _v
}

// ID: identifier of the frame.
func (v *VideoMeta) ID() int {
	valptr := &v.native.id
	var _v int // out
	_v = int(*valptr)
	return _v
}

// Width: video width.
func (v *VideoMeta) Width() uint {
	valptr := &v.native.width
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Height: video height.
func (v *VideoMeta) Height() uint {
	valptr := &v.native.height
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// NPlanes: number of planes in the image.
func (v *VideoMeta) NPlanes() uint {
	valptr := &v.native.n_planes
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Offset: array of offsets for the planes. This field might not always be
// valid, it is used by the default implementation of map.
func (v *VideoMeta) Offset() [4]uint {
	valptr := &v.native.offset
	var _v [4]uint // out
	_v = *(*[4]uint)(unsafe.Pointer(&*valptr))
	return _v
}

// Stride: array of strides for the planes. This field might not always be
// valid, it is used by the default implementation of map.
func (v *VideoMeta) Stride() [4]int {
	valptr := &v.native.stride
	var _v [4]int // out
	{
		src := &*valptr
		for i := 0; i < 4; i++ {
			_v[i] = int(src[i])
		}
	}
	return _v
}

// Alignment paddings and alignment constraints of the video buffer.
// It is up to the caller of gst_buffer_add_video_meta_full() to set it using
// gst_video_meta_set_alignment(), if they did not it defaults to no padding and
// no alignment. Since: 1.18.
func (v *VideoMeta) Alignment() *VideoAlignment {
	valptr := &v.native.alignment
	var _v *VideoAlignment // out
	_v = (*VideoAlignment)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// ID: identifier of the frame.
func (v *VideoMeta) SetID(id int) {
	valptr := &v.native.id
	*valptr = C.gint(id)
}

// Width: video width.
func (v *VideoMeta) SetWidth(width uint) {
	valptr := &v.native.width
	*valptr = C.guint(width)
}

// Height: video height.
func (v *VideoMeta) SetHeight(height uint) {
	valptr := &v.native.height
	*valptr = C.guint(height)
}

// NPlanes: number of planes in the image.
func (v *VideoMeta) SetNPlanes(nPlanes uint) {
	valptr := &v.native.n_planes
	*valptr = C.guint(nPlanes)
}

// PlaneHeight: compute the padded height of each plane from meta (padded size
// divided by stride).
//
// It is not valid to call this function with a meta associated to a TILED video
// format.
//
// The function returns the following values:
//
//   - planeHeight: array used to store the plane height.
//   - ok: TRUE if meta's alignment is valid and plane_height has been updated,
//     FALSE otherwise.
func (meta *VideoMeta) PlaneHeight() ([4]uint, bool) {
	var _arg0 *C.GstVideoMeta // out
	var _arg1 [4]C.guint      // in
	var _cret C.gboolean      // in

	_arg0 = (*C.GstVideoMeta)(gextras.StructNative(unsafe.Pointer(meta)))

	_cret = C.gst_video_meta_get_plane_height(_arg0, &_arg1[0])
	runtime.KeepAlive(meta)

	var _planeHeight [4]uint // out
	var _ok bool             // out

	{
		src := &_arg1
		for i := 0; i < 4; i++ {
			_planeHeight[i] = uint(src[i])
		}
	}
	if _cret != 0 {
		_ok = true
	}

	return _planeHeight, _ok
}

// PlaneSize: compute the size, in bytes, of each video plane described in meta
// including any padding and alignment constraint defined in meta->alignment.
//
// The function returns the following values:
//
//   - planeSize: array used to store the plane sizes.
//   - ok: TRUE if meta's alignment is valid and plane_size has been updated,
//     FALSE otherwise.
func (meta *VideoMeta) PlaneSize() ([4]uint, bool) {
	var _arg0 *C.GstVideoMeta // out
	var _arg1 [4]C.gsize      // in
	var _cret C.gboolean      // in

	_arg0 = (*C.GstVideoMeta)(gextras.StructNative(unsafe.Pointer(meta)))

	_cret = C.gst_video_meta_get_plane_size(_arg0, &_arg1[0])
	runtime.KeepAlive(meta)

	var _planeSize [4]uint // out
	var _ok bool           // out

	_planeSize = *(*[4]uint)(unsafe.Pointer(&_arg1))
	if _cret != 0 {
		_ok = true
	}

	return _planeSize, _ok
}

// Map the video plane with index plane in meta and return a pointer to the
// first byte of the plane and the stride of the plane.
//
// The function takes the following parameters:
//
//   - plane: plane.
//   - info: MapInfo.
//   - flags: GstMapFlags.
//
// The function returns the following values:
//
//   - data (optional) of plane.
//   - stride of plane.
//   - ok: TRUE if the map operation was successful.
func (meta *VideoMeta) Map(plane uint, info *gst.MapInfo, flags gst.MapFlags) (unsafe.Pointer, int, bool) {
	var _arg0 *C.GstVideoMeta // out
	var _arg1 C.guint         // out
	var _arg2 *C.GstMapInfo   // out
	var _arg3 C.gpointer      // in
	var _arg4 C.gint          // in
	var _arg5 C.GstMapFlags   // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstVideoMeta)(gextras.StructNative(unsafe.Pointer(meta)))
	_arg1 = C.guint(plane)
	_arg2 = (*C.GstMapInfo)(gextras.StructNative(unsafe.Pointer(info)))
	_arg5 = C.GstMapFlags(flags)

	_cret = C.gst_video_meta_map(_arg0, _arg1, _arg2, &_arg3, &_arg4, _arg5)
	runtime.KeepAlive(meta)
	runtime.KeepAlive(plane)
	runtime.KeepAlive(info)
	runtime.KeepAlive(flags)

	var _data unsafe.Pointer // out
	var _stride int          // out
	var _ok bool             // out

	_data = (unsafe.Pointer)(unsafe.Pointer(_arg3))
	_stride = int(_arg4)
	if _cret != 0 {
		_ok = true
	}

	return _data, _stride, _ok
}

// SetAlignment: set the alignment of meta to alignment. This function checks
// that the paddings defined in alignment are compatible with the strides
// defined in meta and will fail to update if they are not.
//
// The function takes the following parameters:
//
//   - alignment: VideoAlignment.
//
// The function returns the following values:
//
//   - ok: TRUE if alignment's meta has been updated, FALSE if not.
func (meta *VideoMeta) SetAlignment(alignment *VideoAlignment) bool {
	var _arg0 *C.GstVideoMeta     // out
	var _arg1 C.GstVideoAlignment // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstVideoMeta)(gextras.StructNative(unsafe.Pointer(meta)))
	_arg1 = *(*C.GstVideoAlignment)(gextras.StructNative(unsafe.Pointer(alignment)))

	_cret = C.gst_video_meta_set_alignment(_arg0, _arg1)
	runtime.KeepAlive(meta)
	runtime.KeepAlive(alignment)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Unmap a previously mapped plane with gst_video_meta_map().
//
// The function takes the following parameters:
//
//   - plane: plane.
//   - info: MapInfo.
//
// The function returns the following values:
//
//   - ok: TRUE if the memory was successfully unmapped.
func (meta *VideoMeta) Unmap(plane uint, info *gst.MapInfo) bool {
	var _arg0 *C.GstVideoMeta // out
	var _arg1 C.guint         // out
	var _arg2 *C.GstMapInfo   // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstVideoMeta)(gextras.StructNative(unsafe.Pointer(meta)))
	_arg1 = C.guint(plane)
	_arg2 = (*C.GstMapInfo)(gextras.StructNative(unsafe.Pointer(info)))

	_cret = C.gst_video_meta_unmap(_arg0, _arg1, _arg2)
	runtime.KeepAlive(meta)
	runtime.KeepAlive(plane)
	runtime.KeepAlive(info)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

func VideoMetaGetInfo() *gst.MetaInfo {
	var _cret *C.GstMetaInfo // in

	_cret = C.gst_video_meta_get_info()

	var _metaInfo *gst.MetaInfo // out

	_metaInfo = (*gst.MetaInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _metaInfo
}

// VideoMetaTransform: extra data passed to a video transform
// MetaTransformFunction such as: "gst-video-scale".
//
// An instance of this type is always passed by reference.
type VideoMetaTransform struct {
	*videoMetaTransform
}

// videoMetaTransform is the struct that's finalized.
type videoMetaTransform struct {
	native *C.GstVideoMetaTransform
}

// InInfo: input VideoInfo.
func (v *VideoMetaTransform) InInfo() *VideoInfo {
	valptr := &v.native.in_info
	var _v *VideoInfo // out
	_v = (*VideoInfo)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	return _v
}

// OutInfo: output VideoInfo.
func (v *VideoMetaTransform) OutInfo() *VideoInfo {
	valptr := &v.native.out_info
	var _v *VideoInfo // out
	_v = (*VideoInfo)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	return _v
}

// VideoMetaTransformScaleGetQuark: get the #GQuark for the "gst-video-scale"
// metadata transform operation.
//
// The function returns the following values:
//
//   - quark: #GQuark.
func VideoMetaTransformScaleGetQuark() glib.Quark {
	var _cret C.GQuark // in

	_cret = C.gst_video_meta_transform_scale_get_quark()

	var _quark glib.Quark // out

	_quark = glib.Quark(_cret)

	return _quark
}

// VideoOrientationInterface interface.
//
// An instance of this type is always passed by reference.
type VideoOrientationInterface struct {
	*videoOrientationInterface
}

// videoOrientationInterface is the struct that's finalized.
type videoOrientationInterface struct {
	native *C.GstVideoOrientationInterface
}

// VideoOverlayComposition functions to create and handle overlay compositions
// on video buffers.
//
// An overlay composition describes one or more overlay rectangles to be blended
// on top of a video buffer.
//
// This API serves two main purposes:
//
// * it can be used to attach overlay information (subtitles or logos) to
// non-raw video buffers such as GL/VAAPI/VDPAU surfaces. The actual blending
// of the overlay can then be done by e.g. the video sink that processes these
// non-raw buffers.
//
// * it can also be used to blend overlay rectangles on top of raw video
// buffers, thus consolidating blending functionality for raw video in one
// place.
//
// Together, this allows existing overlay elements to easily handle raw and
// non-raw video as input in without major changes (once the overlays have been
// put into a VideoOverlayComposition object anyway) - for raw video the overlay
// can just use the blending function to blend the data on top of the video,
// and for surface buffers it can just attach them to the buffer and let the
// sink render the overlays.
//
// An instance of this type is always passed by reference.
type VideoOverlayComposition struct {
	*videoOverlayComposition
}

// videoOverlayComposition is the struct that's finalized.
type videoOverlayComposition struct {
	native *C.GstVideoOverlayComposition
}

func marshalVideoOverlayComposition(p uintptr) (interface{}, error) {
	b := coreglib.ValueFromNative(unsafe.Pointer(p)).Boxed()
	return &VideoOverlayComposition{&videoOverlayComposition{(*C.GstVideoOverlayComposition)(b)}}, nil
}

// NewVideoOverlayComposition constructs a struct VideoOverlayComposition.
func NewVideoOverlayComposition(rectangle *VideoOverlayRectangle) *VideoOverlayComposition {
	var _arg1 *C.GstVideoOverlayRectangle   // out
	var _cret *C.GstVideoOverlayComposition // in

	if rectangle != nil {
		_arg1 = (*C.GstVideoOverlayRectangle)(gextras.StructNative(unsafe.Pointer(rectangle)))
	}

	_cret = C.gst_video_overlay_composition_new(_arg1)
	runtime.KeepAlive(rectangle)

	var _videoOverlayComposition *VideoOverlayComposition // out

	_videoOverlayComposition = (*VideoOverlayComposition)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_videoOverlayComposition)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _videoOverlayComposition
}

// AddRectangle adds an overlay rectangle to an existing overlay composition
// object. This must be done right after creating the overlay composition.
//
// The function takes the following parameters:
//
//   - rectangle to add to the composition.
func (comp *VideoOverlayComposition) AddRectangle(rectangle *VideoOverlayRectangle) {
	var _arg0 *C.GstVideoOverlayComposition // out
	var _arg1 *C.GstVideoOverlayRectangle   // out

	_arg0 = (*C.GstVideoOverlayComposition)(gextras.StructNative(unsafe.Pointer(comp)))
	_arg1 = (*C.GstVideoOverlayRectangle)(gextras.StructNative(unsafe.Pointer(rectangle)))

	C.gst_video_overlay_composition_add_rectangle(_arg0, _arg1)
	runtime.KeepAlive(comp)
	runtime.KeepAlive(rectangle)
}

// Blend blends the overlay rectangles in comp on top of the raw video data
// contained in video_buf. The data in video_buf must be writable and mapped
// appropriately.
//
// Since video_buf data is read and will be modified, it ought be mapped with
// flag GST_MAP_READWRITE.
//
// The function takes the following parameters:
//
//   - videoBuf containing raw video data in a supported format. It should be
//     mapped using GST_MAP_READWRITE.
func (comp *VideoOverlayComposition) Blend(videoBuf *VideoFrame) bool {
	var _arg0 *C.GstVideoOverlayComposition // out
	var _arg1 *C.GstVideoFrame              // out
	var _cret C.gboolean                    // in

	_arg0 = (*C.GstVideoOverlayComposition)(gextras.StructNative(unsafe.Pointer(comp)))
	_arg1 = (*C.GstVideoFrame)(gextras.StructNative(unsafe.Pointer(videoBuf)))

	_cret = C.gst_video_overlay_composition_blend(_arg0, _arg1)
	runtime.KeepAlive(comp)
	runtime.KeepAlive(videoBuf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Copy makes a copy of comp and all contained rectangles, so that it is
// possible to modify the composition and contained rectangles (e.g. add
// additional rectangles or change the render co-ordinates or render dimension).
// The actual overlay pixel data buffers contained in the rectangles are not
// copied.
//
// The function returns the following values:
//
//   - videoOverlayComposition: new VideoOverlayComposition equivalent to comp.
func (comp *VideoOverlayComposition) Copy() *VideoOverlayComposition {
	var _arg0 *C.GstVideoOverlayComposition // out
	var _cret *C.GstVideoOverlayComposition // in

	_arg0 = (*C.GstVideoOverlayComposition)(gextras.StructNative(unsafe.Pointer(comp)))

	_cret = C.gst_video_overlay_composition_copy(_arg0)
	runtime.KeepAlive(comp)

	var _videoOverlayComposition *VideoOverlayComposition // out

	_videoOverlayComposition = (*VideoOverlayComposition)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_videoOverlayComposition)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _videoOverlayComposition
}

// Rectangle returns the n-th VideoOverlayRectangle contained in comp.
//
// The function takes the following parameters:
//
//   - n: number of the rectangle to get.
//
// The function returns the following values:
//
//   - videoOverlayRectangle (optional): n-th rectangle, or NULL if n is out of
//     bounds. Will not return a new reference, the caller will need to obtain
//     her own reference using gst_video_overlay_rectangle_ref() if needed.
func (comp *VideoOverlayComposition) Rectangle(n uint) *VideoOverlayRectangle {
	var _arg0 *C.GstVideoOverlayComposition // out
	var _arg1 C.guint                       // out
	var _cret *C.GstVideoOverlayRectangle   // in

	_arg0 = (*C.GstVideoOverlayComposition)(gextras.StructNative(unsafe.Pointer(comp)))
	_arg1 = C.guint(n)

	_cret = C.gst_video_overlay_composition_get_rectangle(_arg0, _arg1)
	runtime.KeepAlive(comp)
	runtime.KeepAlive(n)

	var _videoOverlayRectangle *VideoOverlayRectangle // out

	if _cret != nil {
		_videoOverlayRectangle = (*VideoOverlayRectangle)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	}

	return _videoOverlayRectangle
}

// Seqnum returns the sequence number of this composition. Sequence numbers are
// monotonically increasing and unique for overlay compositions and rectangles
// (meaning there will never be a rectangle with the same sequence number as a
// composition).
//
// The function returns the following values:
//
//   - guint: sequence number of comp.
func (comp *VideoOverlayComposition) Seqnum() uint {
	var _arg0 *C.GstVideoOverlayComposition // out
	var _cret C.guint                       // in

	_arg0 = (*C.GstVideoOverlayComposition)(gextras.StructNative(unsafe.Pointer(comp)))

	_cret = C.gst_video_overlay_composition_get_seqnum(_arg0)
	runtime.KeepAlive(comp)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// MakeWritable takes ownership of comp and returns a version of comp that
// is writable (i.e. can be modified). Will either return comp right away, or
// create a new writable copy of comp and unref comp itself. All the contained
// rectangles will also be copied, but the actual overlay pixel data buffers
// contained in the rectangles are not copied.
//
// The function returns the following values:
//
//   - videoOverlayComposition: writable VideoOverlayComposition equivalent to
//     comp.
func (comp *VideoOverlayComposition) MakeWritable() *VideoOverlayComposition {
	var _arg0 *C.GstVideoOverlayComposition // out
	var _cret *C.GstVideoOverlayComposition // in

	_arg0 = (*C.GstVideoOverlayComposition)(gextras.StructNative(unsafe.Pointer(comp)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(comp)), nil)

	_cret = C.gst_video_overlay_composition_make_writable(_arg0)
	runtime.KeepAlive(comp)

	var _videoOverlayComposition *VideoOverlayComposition // out

	_videoOverlayComposition = (*VideoOverlayComposition)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_videoOverlayComposition)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _videoOverlayComposition
}

// NRectangles returns the number of VideoOverlayRectangle<!-- -->s contained in
// comp.
//
// The function returns the following values:
//
//   - guint: number of rectangles.
func (comp *VideoOverlayComposition) NRectangles() uint {
	var _arg0 *C.GstVideoOverlayComposition // out
	var _cret C.guint                       // in

	_arg0 = (*C.GstVideoOverlayComposition)(gextras.StructNative(unsafe.Pointer(comp)))

	_cret = C.gst_video_overlay_composition_n_rectangles(_arg0)
	runtime.KeepAlive(comp)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// VideoOverlayCompositionMeta: extra buffer metadata describing image overlay
// data.
//
// An instance of this type is always passed by reference.
type VideoOverlayCompositionMeta struct {
	*videoOverlayCompositionMeta
}

// videoOverlayCompositionMeta is the struct that's finalized.
type videoOverlayCompositionMeta struct {
	native *C.GstVideoOverlayCompositionMeta
}

// Meta: parent Meta.
func (v *VideoOverlayCompositionMeta) Meta() *gst.Meta {
	valptr := &v.native.meta
	var _v *gst.Meta // out
	_v = (*gst.Meta)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// Overlay: attached VideoOverlayComposition.
func (v *VideoOverlayCompositionMeta) Overlay() *VideoOverlayComposition {
	valptr := &v.native.overlay
	var _v *VideoOverlayComposition // out
	_v = (*VideoOverlayComposition)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	return _v
}

func VideoOverlayCompositionMetaGetInfo() *gst.MetaInfo {
	var _cret *C.GstMetaInfo // in

	_cret = C.gst_video_overlay_composition_meta_get_info()

	var _metaInfo *gst.MetaInfo // out

	_metaInfo = (*gst.MetaInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _metaInfo
}

// VideoOverlayInterface interface
//
// An instance of this type is always passed by reference.
type VideoOverlayInterface struct {
	*videoOverlayInterface
}

// videoOverlayInterface is the struct that's finalized.
type videoOverlayInterface struct {
	native *C.GstVideoOverlayInterface
}

// VideoOverlayRectangle: opaque video overlay rectangle object. A rectangle
// contains a single overlay rectangle which can be added to a composition.
//
// An instance of this type is always passed by reference.
type VideoOverlayRectangle struct {
	*videoOverlayRectangle
}

// videoOverlayRectangle is the struct that's finalized.
type videoOverlayRectangle struct {
	native *C.GstVideoOverlayRectangle
}

func marshalVideoOverlayRectangle(p uintptr) (interface{}, error) {
	b := coreglib.ValueFromNative(unsafe.Pointer(p)).Boxed()
	return &VideoOverlayRectangle{&videoOverlayRectangle{(*C.GstVideoOverlayRectangle)(b)}}, nil
}

// NewVideoOverlayRectangleRaw constructs a struct VideoOverlayRectangle.
func NewVideoOverlayRectangleRaw(pixels *gst.Buffer, renderX int, renderY int, renderWidth uint, renderHeight uint, flags VideoOverlayFormatFlags) *VideoOverlayRectangle {
	var _arg1 *C.GstBuffer                 // out
	var _arg2 C.gint                       // out
	var _arg3 C.gint                       // out
	var _arg4 C.guint                      // out
	var _arg5 C.guint                      // out
	var _arg6 C.GstVideoOverlayFormatFlags // out
	var _cret *C.GstVideoOverlayRectangle  // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(pixels)))
	_arg2 = C.gint(renderX)
	_arg3 = C.gint(renderY)
	_arg4 = C.guint(renderWidth)
	_arg5 = C.guint(renderHeight)
	_arg6 = C.GstVideoOverlayFormatFlags(flags)

	_cret = C.gst_video_overlay_rectangle_new_raw(_arg1, _arg2, _arg3, _arg4, _arg5, _arg6)
	runtime.KeepAlive(pixels)
	runtime.KeepAlive(renderX)
	runtime.KeepAlive(renderY)
	runtime.KeepAlive(renderWidth)
	runtime.KeepAlive(renderHeight)
	runtime.KeepAlive(flags)

	var _videoOverlayRectangle *VideoOverlayRectangle // out

	_videoOverlayRectangle = (*VideoOverlayRectangle)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_videoOverlayRectangle)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _videoOverlayRectangle
}

// Copy makes a copy of rectangle, so that it is possible to modify it (e.g.
// to change the render co-ordinates or render dimension). The actual overlay
// pixel data buffers contained in the rectangle are not copied.
//
// The function returns the following values:
//
//   - videoOverlayRectangle: new VideoOverlayRectangle equivalent to rectangle.
func (rectangle *VideoOverlayRectangle) Copy() *VideoOverlayRectangle {
	var _arg0 *C.GstVideoOverlayRectangle // out
	var _cret *C.GstVideoOverlayRectangle // in

	_arg0 = (*C.GstVideoOverlayRectangle)(gextras.StructNative(unsafe.Pointer(rectangle)))

	_cret = C.gst_video_overlay_rectangle_copy(_arg0)
	runtime.KeepAlive(rectangle)

	var _videoOverlayRectangle *VideoOverlayRectangle // out

	_videoOverlayRectangle = (*VideoOverlayRectangle)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_videoOverlayRectangle)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.free(intern.C)
		},
	)

	return _videoOverlayRectangle
}

// Flags retrieves the flags associated with a VideoOverlayRectangle.
// This is useful if the caller can handle both premultiplied alpha and non
// premultiplied alpha, for example. By knowing whether the rectangle uses
// premultiplied or not, it can request the pixel data in the format it is
// stored in, to avoid unnecessary conversion.
//
// The function returns the following values:
//
//   - videoOverlayFormatFlags associated with the rectangle.
func (rectangle *VideoOverlayRectangle) Flags() VideoOverlayFormatFlags {
	var _arg0 *C.GstVideoOverlayRectangle  // out
	var _cret C.GstVideoOverlayFormatFlags // in

	_arg0 = (*C.GstVideoOverlayRectangle)(gextras.StructNative(unsafe.Pointer(rectangle)))

	_cret = C.gst_video_overlay_rectangle_get_flags(_arg0)
	runtime.KeepAlive(rectangle)

	var _videoOverlayFormatFlags VideoOverlayFormatFlags // out

	_videoOverlayFormatFlags = VideoOverlayFormatFlags(_cret)

	return _videoOverlayFormatFlags
}

// GlobalAlpha retrieves the global-alpha value associated with a
// VideoOverlayRectangle.
//
// The function returns the following values:
//
//   - gfloat: global-alpha value associated with the rectangle.
func (rectangle *VideoOverlayRectangle) GlobalAlpha() float32 {
	var _arg0 *C.GstVideoOverlayRectangle // out
	var _cret C.gfloat                    // in

	_arg0 = (*C.GstVideoOverlayRectangle)(gextras.StructNative(unsafe.Pointer(rectangle)))

	_cret = C.gst_video_overlay_rectangle_get_global_alpha(_arg0)
	runtime.KeepAlive(rectangle)

	var _gfloat float32 // out

	_gfloat = float32(_cret)

	return _gfloat
}

// The function takes the following parameters:
//
//   - flags: flags If a global_alpha value != 1 is set for the rectangle, the
//     caller should set the T_VIDEO_OVERLAY_FORMAT_FLAG_GLOBAL_ALPHA flag if he
//     wants to apply global-alpha himself. If the flag is not set global_alpha
//     is applied internally before returning the pixel-data.
//
// The function returns the following values:
//
//   - buffer holding the ARGB pixel data with width and height of the render
//     dimensions as per gst_video_overlay_rectangle_get_render_rectangle().
//     This function does not return a reference, the caller should obtain a
//     reference of her own with gst_buffer_ref() if needed.
func (rectangle *VideoOverlayRectangle) PixelsARGB(flags VideoOverlayFormatFlags) *gst.Buffer {
	var _arg0 *C.GstVideoOverlayRectangle  // out
	var _arg1 C.GstVideoOverlayFormatFlags // out
	var _cret *C.GstBuffer                 // in

	_arg0 = (*C.GstVideoOverlayRectangle)(gextras.StructNative(unsafe.Pointer(rectangle)))
	_arg1 = C.GstVideoOverlayFormatFlags(flags)

	_cret = C.gst_video_overlay_rectangle_get_pixels_argb(_arg0, _arg1)
	runtime.KeepAlive(rectangle)
	runtime.KeepAlive(flags)

	var _buffer *gst.Buffer // out

	_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	C.gst_mini_object_ref((*C.GstMiniObject)(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_buffer)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _buffer
}

// The function takes the following parameters:
//
//   - flags: flags If a global_alpha value != 1 is set for the rectangle, the
//     caller should set the T_VIDEO_OVERLAY_FORMAT_FLAG_GLOBAL_ALPHA flag if he
//     wants to apply global-alpha himself. If the flag is not set global_alpha
//     is applied internally before returning the pixel-data.
//
// The function returns the following values:
//
//   - buffer holding the AYUV pixel data with width and height of the render
//     dimensions as per gst_video_overlay_rectangle_get_render_rectangle().
//     This function does not return a reference, the caller should obtain a
//     reference of her own with gst_buffer_ref() if needed.
func (rectangle *VideoOverlayRectangle) PixelsAyuv(flags VideoOverlayFormatFlags) *gst.Buffer {
	var _arg0 *C.GstVideoOverlayRectangle  // out
	var _arg1 C.GstVideoOverlayFormatFlags // out
	var _cret *C.GstBuffer                 // in

	_arg0 = (*C.GstVideoOverlayRectangle)(gextras.StructNative(unsafe.Pointer(rectangle)))
	_arg1 = C.GstVideoOverlayFormatFlags(flags)

	_cret = C.gst_video_overlay_rectangle_get_pixels_ayuv(_arg0, _arg1)
	runtime.KeepAlive(rectangle)
	runtime.KeepAlive(flags)

	var _buffer *gst.Buffer // out

	_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	C.gst_mini_object_ref((*C.GstMiniObject)(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_buffer)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _buffer
}

// The function takes the following parameters:
//
//   - flags: flags If a global_alpha value != 1 is set for the rectangle, the
//     caller should set the T_VIDEO_OVERLAY_FORMAT_FLAG_GLOBAL_ALPHA flag if he
//     wants to apply global-alpha himself. If the flag is not set global_alpha
//     is applied internally before returning the pixel-data.
//
// The function returns the following values:
//
//   - buffer holding the pixel data with format as originally provided and
//     specified in video meta with width and height of the render dimensions
//     as per gst_video_overlay_rectangle_get_render_rectangle(). This function
//     does not return a reference, the caller should obtain a reference of her
//     own with gst_buffer_ref() if needed.
func (rectangle *VideoOverlayRectangle) PixelsRaw(flags VideoOverlayFormatFlags) *gst.Buffer {
	var _arg0 *C.GstVideoOverlayRectangle  // out
	var _arg1 C.GstVideoOverlayFormatFlags // out
	var _cret *C.GstBuffer                 // in

	_arg0 = (*C.GstVideoOverlayRectangle)(gextras.StructNative(unsafe.Pointer(rectangle)))
	_arg1 = C.GstVideoOverlayFormatFlags(flags)

	_cret = C.gst_video_overlay_rectangle_get_pixels_raw(_arg0, _arg1)
	runtime.KeepAlive(rectangle)
	runtime.KeepAlive(flags)

	var _buffer *gst.Buffer // out

	_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	C.gst_mini_object_ref((*C.GstMiniObject)(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_buffer)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _buffer
}

// PixelsUnscaledARGB retrieves the pixel data as it is. This is useful if the
// caller can do the scaling itself when handling the overlaying. The rectangle
// will need to be scaled to the render dimensions, which can be retrieved using
// gst_video_overlay_rectangle_get_render_rectangle().
//
// The function takes the following parameters:
//
//   - flags: flags. If a global_alpha value != 1 is set for the rectangle, the
//     caller should set the T_VIDEO_OVERLAY_FORMAT_FLAG_GLOBAL_ALPHA flag if he
//     wants to apply global-alpha himself. If the flag is not set global_alpha
//     is applied internally before returning the pixel-data.
//
// The function returns the following values:
//
//   - buffer holding the ARGB pixel data with VideoMeta set. This function does
//     not return a reference, the caller should obtain a reference of her own
//     with gst_buffer_ref() if needed.
func (rectangle *VideoOverlayRectangle) PixelsUnscaledARGB(flags VideoOverlayFormatFlags) *gst.Buffer {
	var _arg0 *C.GstVideoOverlayRectangle  // out
	var _arg1 C.GstVideoOverlayFormatFlags // out
	var _cret *C.GstBuffer                 // in

	_arg0 = (*C.GstVideoOverlayRectangle)(gextras.StructNative(unsafe.Pointer(rectangle)))
	_arg1 = C.GstVideoOverlayFormatFlags(flags)

	_cret = C.gst_video_overlay_rectangle_get_pixels_unscaled_argb(_arg0, _arg1)
	runtime.KeepAlive(rectangle)
	runtime.KeepAlive(flags)

	var _buffer *gst.Buffer // out

	_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	C.gst_mini_object_ref((*C.GstMiniObject)(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_buffer)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _buffer
}

// PixelsUnscaledAyuv retrieves the pixel data as it is. This is useful if the
// caller can do the scaling itself when handling the overlaying. The rectangle
// will need to be scaled to the render dimensions, which can be retrieved using
// gst_video_overlay_rectangle_get_render_rectangle().
//
// The function takes the following parameters:
//
//   - flags: flags. If a global_alpha value != 1 is set for the rectangle, the
//     caller should set the T_VIDEO_OVERLAY_FORMAT_FLAG_GLOBAL_ALPHA flag if he
//     wants to apply global-alpha himself. If the flag is not set global_alpha
//     is applied internally before returning the pixel-data.
//
// The function returns the following values:
//
//   - buffer holding the AYUV pixel data with VideoMeta set. This function does
//     not return a reference, the caller should obtain a reference of her own
//     with gst_buffer_ref() if needed.
func (rectangle *VideoOverlayRectangle) PixelsUnscaledAyuv(flags VideoOverlayFormatFlags) *gst.Buffer {
	var _arg0 *C.GstVideoOverlayRectangle  // out
	var _arg1 C.GstVideoOverlayFormatFlags // out
	var _cret *C.GstBuffer                 // in

	_arg0 = (*C.GstVideoOverlayRectangle)(gextras.StructNative(unsafe.Pointer(rectangle)))
	_arg1 = C.GstVideoOverlayFormatFlags(flags)

	_cret = C.gst_video_overlay_rectangle_get_pixels_unscaled_ayuv(_arg0, _arg1)
	runtime.KeepAlive(rectangle)
	runtime.KeepAlive(flags)

	var _buffer *gst.Buffer // out

	_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	C.gst_mini_object_ref((*C.GstMiniObject)(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_buffer)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _buffer
}

// PixelsUnscaledRaw retrieves the pixel data as it is. This is useful if the
// caller can do the scaling itself when handling the overlaying. The rectangle
// will need to be scaled to the render dimensions, which can be retrieved using
// gst_video_overlay_rectangle_get_render_rectangle().
//
// The function takes the following parameters:
//
//   - flags: flags. If a global_alpha value != 1 is set for the rectangle, the
//     caller should set the T_VIDEO_OVERLAY_FORMAT_FLAG_GLOBAL_ALPHA flag if he
//     wants to apply global-alpha himself. If the flag is not set global_alpha
//     is applied internally before returning the pixel-data.
//
// The function returns the following values:
//
//   - buffer holding the pixel data with VideoMeta set. This function does not
//     return a reference, the caller should obtain a reference of her own with
//     gst_buffer_ref() if needed.
func (rectangle *VideoOverlayRectangle) PixelsUnscaledRaw(flags VideoOverlayFormatFlags) *gst.Buffer {
	var _arg0 *C.GstVideoOverlayRectangle  // out
	var _arg1 C.GstVideoOverlayFormatFlags // out
	var _cret *C.GstBuffer                 // in

	_arg0 = (*C.GstVideoOverlayRectangle)(gextras.StructNative(unsafe.Pointer(rectangle)))
	_arg1 = C.GstVideoOverlayFormatFlags(flags)

	_cret = C.gst_video_overlay_rectangle_get_pixels_unscaled_raw(_arg0, _arg1)
	runtime.KeepAlive(rectangle)
	runtime.KeepAlive(flags)

	var _buffer *gst.Buffer // out

	_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	C.gst_mini_object_ref((*C.GstMiniObject)(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_buffer)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _buffer
}

// RenderRectangle retrieves the render position and render dimension of the
// overlay rectangle on the video.
//
// The function returns the following values:
//
//   - renderX (optional) address where to store the X render offset.
//   - renderY (optional) address where to store the Y render offset.
//   - renderWidth (optional) address where to store the render width.
//   - renderHeight (optional) address where to store the render height.
//   - ok: TRUE if valid render dimensions were retrieved.
func (rectangle *VideoOverlayRectangle) RenderRectangle() (renderX int, renderY int, renderWidth uint, renderHeight uint, ok bool) {
	var _arg0 *C.GstVideoOverlayRectangle // out
	var _arg1 C.gint                      // in
	var _arg2 C.gint                      // in
	var _arg3 C.guint                     // in
	var _arg4 C.guint                     // in
	var _cret C.gboolean                  // in

	_arg0 = (*C.GstVideoOverlayRectangle)(gextras.StructNative(unsafe.Pointer(rectangle)))

	_cret = C.gst_video_overlay_rectangle_get_render_rectangle(_arg0, &_arg1, &_arg2, &_arg3, &_arg4)
	runtime.KeepAlive(rectangle)

	var _renderX int       // out
	var _renderY int       // out
	var _renderWidth uint  // out
	var _renderHeight uint // out
	var _ok bool           // out

	_renderX = int(_arg1)
	_renderY = int(_arg2)
	_renderWidth = uint(_arg3)
	_renderHeight = uint(_arg4)
	if _cret != 0 {
		_ok = true
	}

	return _renderX, _renderY, _renderWidth, _renderHeight, _ok
}

// Seqnum returns the sequence number of this rectangle. Sequence numbers are
// monotonically increasing and unique for overlay compositions and rectangles
// (meaning there will never be a rectangle with the same sequence number as a
// composition).
//
// Using the sequence number of a rectangle as an indicator for changed
// pixel-data of a rectangle is dangereous. Some API calls, like e.g.
// gst_video_overlay_rectangle_set_global_alpha(), automatically update the per
// rectangle sequence number, which is misleading for renderers/ consumers,
// that handle global-alpha themselves. For them the pixel-data returned by
// gst_video_overlay_rectangle_get_pixels_*() won't be different for different
// global-alpha values. In this case a renderer could also use the GstBuffer
// pointers as a hint for changed pixel-data.
//
// The function returns the following values:
//
//   - guint: sequence number of rectangle.
func (rectangle *VideoOverlayRectangle) Seqnum() uint {
	var _arg0 *C.GstVideoOverlayRectangle // out
	var _cret C.guint                     // in

	_arg0 = (*C.GstVideoOverlayRectangle)(gextras.StructNative(unsafe.Pointer(rectangle)))

	_cret = C.gst_video_overlay_rectangle_get_seqnum(_arg0)
	runtime.KeepAlive(rectangle)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// SetGlobalAlpha sets the global alpha value associated with a
// VideoOverlayRectangle. Per- pixel alpha values are multiplied with this
// value. Valid values: 0 <= global_alpha <= 1; 1 to deactivate.
//
// rectangle must be writable, meaning its refcount must be 1.
// You can make the rectangles inside a VideoOverlayComposition
// writable using gst_video_overlay_composition_make_writable() or
// gst_video_overlay_composition_copy().
//
// The function takes the following parameters:
//
//   - globalAlpha: global alpha value (0 to 1.0).
func (rectangle *VideoOverlayRectangle) SetGlobalAlpha(globalAlpha float32) {
	var _arg0 *C.GstVideoOverlayRectangle // out
	var _arg1 C.gfloat                    // out

	_arg0 = (*C.GstVideoOverlayRectangle)(gextras.StructNative(unsafe.Pointer(rectangle)))
	_arg1 = C.gfloat(globalAlpha)

	C.gst_video_overlay_rectangle_set_global_alpha(_arg0, _arg1)
	runtime.KeepAlive(rectangle)
	runtime.KeepAlive(globalAlpha)
}

// SetRenderRectangle sets the render position and dimensions of the rectangle
// on the video. This function is mainly for elements that modify the size of
// the video in some way (e.g. through scaling or cropping) and need to adjust
// the details of any overlays to match the operation that changed the size.
//
// rectangle must be writable, meaning its refcount must be 1.
// You can make the rectangles inside a VideoOverlayComposition
// writable using gst_video_overlay_composition_make_writable() or
// gst_video_overlay_composition_copy().
//
// The function takes the following parameters:
//
//   - renderX: render X position of rectangle on video.
//   - renderY: render Y position of rectangle on video.
//   - renderWidth: render width of rectangle.
//   - renderHeight: render height of rectangle.
func (rectangle *VideoOverlayRectangle) SetRenderRectangle(renderX int, renderY int, renderWidth uint, renderHeight uint) {
	var _arg0 *C.GstVideoOverlayRectangle // out
	var _arg1 C.gint                      // out
	var _arg2 C.gint                      // out
	var _arg3 C.guint                     // out
	var _arg4 C.guint                     // out

	_arg0 = (*C.GstVideoOverlayRectangle)(gextras.StructNative(unsafe.Pointer(rectangle)))
	_arg1 = C.gint(renderX)
	_arg2 = C.gint(renderY)
	_arg3 = C.guint(renderWidth)
	_arg4 = C.guint(renderHeight)

	C.gst_video_overlay_rectangle_set_render_rectangle(_arg0, _arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(rectangle)
	runtime.KeepAlive(renderX)
	runtime.KeepAlive(renderY)
	runtime.KeepAlive(renderWidth)
	runtime.KeepAlive(renderHeight)
}

// VideoRectangle: helper structure representing a rectangular area.
//
// An instance of this type is always passed by reference.
type VideoRectangle struct {
	*videoRectangle
}

// videoRectangle is the struct that's finalized.
type videoRectangle struct {
	native *C.GstVideoRectangle
}

// NewVideoRectangle creates a new VideoRectangle instance from the given
// fields. Beware that this function allocates on the Go heap; be careful
// when using it!
func NewVideoRectangle(x, y, w, h int) VideoRectangle {
	var f0 C.gint // out
	f0 = C.gint(x)
	var f1 C.gint // out
	f1 = C.gint(y)
	var f2 C.gint // out
	f2 = C.gint(w)
	var f3 C.gint // out
	f3 = C.gint(h)

	v := C.GstVideoRectangle{
		x: f0,
		y: f1,
		w: f2,
		h: f3,
	}

	return *(*VideoRectangle)(gextras.NewStructNative(unsafe.Pointer(&v)))
}

// X coordinate of rectangle's top-left point.
func (v *VideoRectangle) X() int {
	valptr := &v.native.x
	var _v int // out
	_v = int(*valptr)
	return _v
}

// Y coordinate of rectangle's top-left point.
func (v *VideoRectangle) Y() int {
	valptr := &v.native.y
	var _v int // out
	_v = int(*valptr)
	return _v
}

// W: width of the rectangle.
func (v *VideoRectangle) W() int {
	valptr := &v.native.w
	var _v int // out
	_v = int(*valptr)
	return _v
}

// H: height of the rectangle.
func (v *VideoRectangle) H() int {
	valptr := &v.native.h
	var _v int // out
	_v = int(*valptr)
	return _v
}

// X coordinate of rectangle's top-left point.
func (v *VideoRectangle) SetX(x int) {
	valptr := &v.native.x
	*valptr = C.gint(x)
}

// Y coordinate of rectangle's top-left point.
func (v *VideoRectangle) SetY(y int) {
	valptr := &v.native.y
	*valptr = C.gint(y)
}

// W: width of the rectangle.
func (v *VideoRectangle) SetW(w int) {
	valptr := &v.native.w
	*valptr = C.gint(w)
}

// H: height of the rectangle.
func (v *VideoRectangle) SetH(h int) {
	valptr := &v.native.h
	*valptr = C.gint(h)
}

// VideoRegionOfInterestMeta: extra buffer metadata describing an image region
// of interest
//
// An instance of this type is always passed by reference.
type VideoRegionOfInterestMeta struct {
	*videoRegionOfInterestMeta
}

// videoRegionOfInterestMeta is the struct that's finalized.
type videoRegionOfInterestMeta struct {
	native *C.GstVideoRegionOfInterestMeta
}

// Meta: parent Meta.
func (v *VideoRegionOfInterestMeta) Meta() *gst.Meta {
	valptr := &v.native.meta
	var _v *gst.Meta // out
	_v = (*gst.Meta)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// RoiType: GQuark describing the semantic of the Roi (f.i. a face,
// a pedestrian).
func (v *VideoRegionOfInterestMeta) RoiType() glib.Quark {
	valptr := &v.native.roi_type
	var _v glib.Quark // out
	_v = glib.Quark(*valptr)
	return _v
}

// ID: identifier of this particular ROI.
func (v *VideoRegionOfInterestMeta) ID() int {
	valptr := &v.native.id
	var _v int // out
	_v = int(*valptr)
	return _v
}

// ParentID: identifier of its parent ROI, used f.i. for ROI hierarchisation.
func (v *VideoRegionOfInterestMeta) ParentID() int {
	valptr := &v.native.parent_id
	var _v int // out
	_v = int(*valptr)
	return _v
}

// X: x component of upper-left corner.
func (v *VideoRegionOfInterestMeta) X() uint {
	valptr := &v.native.x
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Y: y component of upper-left corner.
func (v *VideoRegionOfInterestMeta) Y() uint {
	valptr := &v.native.y
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// W: bounding box width.
func (v *VideoRegionOfInterestMeta) W() uint {
	valptr := &v.native.w
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// H: bounding box height.
func (v *VideoRegionOfInterestMeta) H() uint {
	valptr := &v.native.h
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// ID: identifier of this particular ROI.
func (v *VideoRegionOfInterestMeta) SetID(id int) {
	valptr := &v.native.id
	*valptr = C.gint(id)
}

// ParentID: identifier of its parent ROI, used f.i. for ROI hierarchisation.
func (v *VideoRegionOfInterestMeta) SetParentID(parentId int) {
	valptr := &v.native.parent_id
	*valptr = C.gint(parentId)
}

// X: x component of upper-left corner.
func (v *VideoRegionOfInterestMeta) SetX(x uint) {
	valptr := &v.native.x
	*valptr = C.guint(x)
}

// Y: y component of upper-left corner.
func (v *VideoRegionOfInterestMeta) SetY(y uint) {
	valptr := &v.native.y
	*valptr = C.guint(y)
}

// W: bounding box width.
func (v *VideoRegionOfInterestMeta) SetW(w uint) {
	valptr := &v.native.w
	*valptr = C.guint(w)
}

// H: bounding box height.
func (v *VideoRegionOfInterestMeta) SetH(h uint) {
	valptr := &v.native.h
	*valptr = C.guint(h)
}

// AddParam: attach element-specific parameters to meta meant to be used by
// downstream elements which may handle this ROI. The name of s is used to
// identify the element these parameters are meant for.
//
// This is typically used to tell encoders how they should encode this specific
// region. For example, a structure named "roi/x264enc" could be used to give
// the QP offsets this encoder should use when encoding the region described
// in meta. Multiple parameters can be defined for the same meta so different
// encoders can be supported by cross platform applications).
//
// The function takes the following parameters:
//
//   - s: Structure.
func (meta *VideoRegionOfInterestMeta) AddParam(s *gst.Structure) {
	var _arg0 *C.GstVideoRegionOfInterestMeta // out
	var _arg1 *C.GstStructure                 // out

	_arg0 = (*C.GstVideoRegionOfInterestMeta)(gextras.StructNative(unsafe.Pointer(meta)))
	_arg1 = (*C.GstStructure)(gextras.StructNative(unsafe.Pointer(s)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(s)), nil)

	C.gst_video_region_of_interest_meta_add_param(_arg0, _arg1)
	runtime.KeepAlive(meta)
	runtime.KeepAlive(s)
}

// Param: retrieve the parameter for meta having name as structure name, or NULL
// if there is none.
//
// The function takes the following parameters:
//
//   - name: name.
//
// The function returns the following values:
//
//   - structure (optional): Structure.
func (meta *VideoRegionOfInterestMeta) Param(name string) *gst.Structure {
	var _arg0 *C.GstVideoRegionOfInterestMeta // out
	var _arg1 *C.gchar                        // out
	var _cret *C.GstStructure                 // in

	_arg0 = (*C.GstVideoRegionOfInterestMeta)(gextras.StructNative(unsafe.Pointer(meta)))
	_arg1 = (*C.gchar)(unsafe.Pointer(C.CString(name)))
	defer C.free(unsafe.Pointer(_arg1))

	_cret = C.gst_video_region_of_interest_meta_get_param(_arg0, _arg1)
	runtime.KeepAlive(meta)
	runtime.KeepAlive(name)

	var _structure *gst.Structure // out

	if _cret != nil {
		_structure = (*gst.Structure)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		C.gst_mini_object_ref((*C.GstMiniObject)(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_structure)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _structure
}

func VideoRegionOfInterestMetaGetInfo() *gst.MetaInfo {
	var _cret *C.GstMetaInfo // in

	_cret = C.gst_video_region_of_interest_meta_get_info()

	var _metaInfo *gst.MetaInfo // out

	_metaInfo = (*gst.MetaInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _metaInfo
}

// VideoResampler is a structure which holds the information required to perform
// various kinds of resampling filtering.
//
// An instance of this type is always passed by reference.
type VideoResampler struct {
	*videoResampler
}

// videoResampler is the struct that's finalized.
type videoResampler struct {
	native *C.GstVideoResampler
}

// InSize: input size.
func (v *VideoResampler) InSize() int {
	valptr := &v.native.in_size
	var _v int // out
	_v = int(*valptr)
	return _v
}

// OutSize: output size.
func (v *VideoResampler) OutSize() int {
	valptr := &v.native.out_size
	var _v int // out
	_v = int(*valptr)
	return _v
}

// MaxTaps: maximum number of taps.
func (v *VideoResampler) MaxTaps() uint {
	valptr := &v.native.max_taps
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// NPhases: number of phases.
func (v *VideoResampler) NPhases() uint {
	valptr := &v.native.n_phases
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Offset: array with the source offset for each output element.
func (v *VideoResampler) Offset() *uint32 {
	valptr := &v.native.offset
	var _v *uint32 // out
	_v = (*uint32)(unsafe.Pointer(*valptr))
	return _v
}

// Phase: array with the phase to use for each output element.
func (v *VideoResampler) Phase() *uint32 {
	valptr := &v.native.phase
	var _v *uint32 // out
	_v = (*uint32)(unsafe.Pointer(*valptr))
	return _v
}

// NTaps: array with new number of taps for each phase.
func (v *VideoResampler) NTaps() *uint32 {
	valptr := &v.native.n_taps
	var _v *uint32 // out
	_v = (*uint32)(unsafe.Pointer(*valptr))
	return _v
}

// Taps taps for all phases.
func (v *VideoResampler) Taps() *float64 {
	valptr := &v.native.taps
	var _v *float64 // out
	_v = (*float64)(unsafe.Pointer(*valptr))
	return _v
}

// InSize: input size.
func (v *VideoResampler) SetInSize(inSize int) {
	valptr := &v.native.in_size
	*valptr = C.gint(inSize)
}

// OutSize: output size.
func (v *VideoResampler) SetOutSize(outSize int) {
	valptr := &v.native.out_size
	*valptr = C.gint(outSize)
}

// MaxTaps: maximum number of taps.
func (v *VideoResampler) SetMaxTaps(maxTaps uint) {
	valptr := &v.native.max_taps
	*valptr = C.guint(maxTaps)
}

// NPhases: number of phases.
func (v *VideoResampler) SetNPhases(nPhases uint) {
	valptr := &v.native.n_phases
	*valptr = C.guint(nPhases)
}

// Clear a previously initialized VideoResampler resampler.
func (resampler *VideoResampler) Clear() {
	var _arg0 *C.GstVideoResampler // out

	_arg0 = (*C.GstVideoResampler)(gextras.StructNative(unsafe.Pointer(resampler)))

	C.gst_video_resampler_clear(_arg0)
	runtime.KeepAlive(resampler)
}

// The function takes the following parameters:
//
//   - method
//   - flags
//   - nPhases
//   - nTaps
//   - shift
//   - inSize
//   - outSize
//   - options
func (resampler *VideoResampler) Init(method VideoResamplerMethod, flags VideoResamplerFlags, nPhases uint, nTaps uint, shift float64, inSize uint, outSize uint, options *gst.Structure) bool {
	var _arg0 *C.GstVideoResampler      // out
	var _arg1 C.GstVideoResamplerMethod // out
	var _arg2 C.GstVideoResamplerFlags  // out
	var _arg3 C.guint                   // out
	var _arg4 C.guint                   // out
	var _arg5 C.gdouble                 // out
	var _arg6 C.guint                   // out
	var _arg7 C.guint                   // out
	var _arg8 *C.GstStructure           // out
	var _cret C.gboolean                // in

	_arg0 = (*C.GstVideoResampler)(gextras.StructNative(unsafe.Pointer(resampler)))
	_arg1 = C.GstVideoResamplerMethod(method)
	_arg2 = C.GstVideoResamplerFlags(flags)
	_arg3 = C.guint(nPhases)
	_arg4 = C.guint(nTaps)
	_arg5 = C.gdouble(shift)
	_arg6 = C.guint(inSize)
	_arg7 = C.guint(outSize)
	_arg8 = (*C.GstStructure)(gextras.StructNative(unsafe.Pointer(options)))

	_cret = C.gst_video_resampler_init(_arg0, _arg1, _arg2, _arg3, _arg4, _arg5, _arg6, _arg7, _arg8)
	runtime.KeepAlive(resampler)
	runtime.KeepAlive(method)
	runtime.KeepAlive(flags)
	runtime.KeepAlive(nPhases)
	runtime.KeepAlive(nTaps)
	runtime.KeepAlive(shift)
	runtime.KeepAlive(inSize)
	runtime.KeepAlive(outSize)
	runtime.KeepAlive(options)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// VideoSEIUserDataUnregisteredMeta: h.264 H.265 metadata from SEI User Data
// Unregistered messages
//
// An instance of this type is always passed by reference.
type VideoSEIUserDataUnregisteredMeta struct {
	*videoSEIUserDataUnregisteredMeta
}

// videoSEIUserDataUnregisteredMeta is the struct that's finalized.
type videoSEIUserDataUnregisteredMeta struct {
	native *C.GstVideoSEIUserDataUnregisteredMeta
}

// Meta: parent Meta.
func (v *VideoSEIUserDataUnregisteredMeta) Meta() *gst.Meta {
	valptr := &v.native.meta
	var _v *gst.Meta // out
	_v = (*gst.Meta)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// UUID: user Data Unregistered UUID.
func (v *VideoSEIUserDataUnregisteredMeta) UUID() [16]byte {
	valptr := &v.native.uuid
	var _v [16]byte // out
	_v = *(*[16]byte)(unsafe.Pointer(&*valptr))
	return _v
}

// Data: unparsed data buffer.
func (v *VideoSEIUserDataUnregisteredMeta) Data() *byte {
	valptr := &v.native.data
	var _v *byte // out
	_v = (*byte)(unsafe.Pointer(*valptr))
	return _v
}

// Size of the data buffer.
func (v *VideoSEIUserDataUnregisteredMeta) Size() uint {
	valptr := &v.native.size
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Size of the data buffer.
func (v *VideoSEIUserDataUnregisteredMeta) SetSize(size uint) {
	valptr := &v.native.size
	*valptr = C.gsize(size)
}

// The function returns the following values:
//
//   - metaInfo pointer that describes VideoSEIUserDataUnregisteredMeta.
func VideoSEIUserDataUnregisteredMetaGetInfo() *gst.MetaInfo {
	var _cret *C.GstMetaInfo // in

	_cret = C.gst_video_sei_user_data_unregistered_meta_get_info()

	var _metaInfo *gst.MetaInfo // out

	_metaInfo = (*gst.MetaInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _metaInfo
}

// VideoSinkClass: video sink class structure. Derived classes should override
// the show_frame virtual function.
//
// An instance of this type is always passed by reference.
type VideoSinkClass struct {
	*videoSinkClass
}

// videoSinkClass is the struct that's finalized.
type videoSinkClass struct {
	native *C.GstVideoSinkClass
}

// ParentClass: parent class structure.
func (v *VideoSinkClass) ParentClass() *gstbase.BaseSinkClass {
	valptr := &v.native.parent_class
	var _v *gstbase.BaseSinkClass // out
	_v = (*gstbase.BaseSinkClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// VideoTileInfo: description of a tile. This structure allow to describe
// arbitrary tile dimensions and sizes.
//
// An instance of this type is always passed by reference.
type VideoTileInfo struct {
	*videoTileInfo
}

// videoTileInfo is the struct that's finalized.
type videoTileInfo struct {
	native *C.GstVideoTileInfo
}

// Width: width in pixels of a tile. This value can be zero if the number of
// pixels per line is not an integer value.
func (v *VideoTileInfo) Width() uint {
	valptr := &v.native.width
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

func (v *VideoTileInfo) Height() uint {
	valptr := &v.native.height
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Stride: stride (in bytes) of a tile line. Regardless if the tile have
// sub-tiles this stride multiplied by the height should be equal to
// VideoTileInfo.size. This value is used to translate into linear stride when
// older APIs are being used to expose this format.
func (v *VideoTileInfo) Stride() uint {
	valptr := &v.native.stride
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Size: size in bytes of a tile. This value must be divisible by
// VideoTileInfo.stride.
func (v *VideoTileInfo) Size() uint {
	valptr := &v.native.size
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Width: width in pixels of a tile. This value can be zero if the number of
// pixels per line is not an integer value.
func (v *VideoTileInfo) SetWidth(width uint) {
	valptr := &v.native.width
	*valptr = C.guint(width)
}

func (v *VideoTileInfo) SetHeight(height uint) {
	valptr := &v.native.height
	*valptr = C.guint(height)
}

// Stride: stride (in bytes) of a tile line. Regardless if the tile have
// sub-tiles this stride multiplied by the height should be equal to
// VideoTileInfo.size. This value is used to translate into linear stride when
// older APIs are being used to expose this format.
func (v *VideoTileInfo) SetStride(stride uint) {
	valptr := &v.native.stride
	*valptr = C.guint(stride)
}

// Size: size in bytes of a tile. This value must be divisible by
// VideoTileInfo.stride.
func (v *VideoTileInfo) SetSize(size uint) {
	valptr := &v.native.size
	*valptr = C.guint(size)
}

// VideoTimeCode: field_count must be 0 for progressive video and 1 or 2 for
// interlaced.
//
// A representation of a SMPTE time code.
//
// hours must be positive and less than 24. Will wrap around otherwise. minutes
// and seconds must be positive and less than 60. frames must be less than or
// equal to config.fps_n / config.fps_d These values are *NOT* automatically
// normalized.
//
// An instance of this type is always passed by reference.
type VideoTimeCode struct {
	*videoTimeCode
}

// videoTimeCode is the struct that's finalized.
type videoTimeCode struct {
	native *C.GstVideoTimeCode
}

func marshalVideoTimeCode(p uintptr) (interface{}, error) {
	b := coreglib.ValueFromNative(unsafe.Pointer(p)).Boxed()
	return &VideoTimeCode{&videoTimeCode{(*C.GstVideoTimeCode)(b)}}, nil
}

// NewVideoTimeCode constructs a struct VideoTimeCode.
func NewVideoTimeCode(fpsN uint, fpsD uint, latestDailyJam *glib.DateTime, flags VideoTimeCodeFlags, hours uint, minutes uint, seconds uint, frames uint, fieldCount uint) *VideoTimeCode {
	var _arg1 C.guint                 // out
	var _arg2 C.guint                 // out
	var _arg3 *C.GDateTime            // out
	var _arg4 C.GstVideoTimeCodeFlags // out
	var _arg5 C.guint                 // out
	var _arg6 C.guint                 // out
	var _arg7 C.guint                 // out
	var _arg8 C.guint                 // out
	var _arg9 C.guint                 // out
	var _cret *C.GstVideoTimeCode     // in

	_arg1 = C.guint(fpsN)
	_arg2 = C.guint(fpsD)
	_arg3 = (*C.GDateTime)(gextras.StructNative(unsafe.Pointer(latestDailyJam)))
	_arg4 = C.GstVideoTimeCodeFlags(flags)
	_arg5 = C.guint(hours)
	_arg6 = C.guint(minutes)
	_arg7 = C.guint(seconds)
	_arg8 = C.guint(frames)
	_arg9 = C.guint(fieldCount)

	_cret = C.gst_video_time_code_new(_arg1, _arg2, _arg3, _arg4, _arg5, _arg6, _arg7, _arg8, _arg9)
	runtime.KeepAlive(fpsN)
	runtime.KeepAlive(fpsD)
	runtime.KeepAlive(latestDailyJam)
	runtime.KeepAlive(flags)
	runtime.KeepAlive(hours)
	runtime.KeepAlive(minutes)
	runtime.KeepAlive(seconds)
	runtime.KeepAlive(frames)
	runtime.KeepAlive(fieldCount)

	var _videoTimeCode *VideoTimeCode // out

	_videoTimeCode = (*VideoTimeCode)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_videoTimeCode)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_video_time_code_free((*C.GstVideoTimeCode)(intern.C))
		},
	)

	return _videoTimeCode
}

// NewVideoTimeCodeEmpty constructs a struct VideoTimeCode.
func NewVideoTimeCodeEmpty() *VideoTimeCode {
	var _cret *C.GstVideoTimeCode // in

	_cret = C.gst_video_time_code_new_empty()

	var _videoTimeCode *VideoTimeCode // out

	_videoTimeCode = (*VideoTimeCode)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_videoTimeCode)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_video_time_code_free((*C.GstVideoTimeCode)(intern.C))
		},
	)

	return _videoTimeCode
}

// NewVideoTimeCodeFromDateTime constructs a struct VideoTimeCode.
func NewVideoTimeCodeFromDateTime(fpsN uint, fpsD uint, dt *glib.DateTime, flags VideoTimeCodeFlags, fieldCount uint) *VideoTimeCode {
	var _arg1 C.guint                 // out
	var _arg2 C.guint                 // out
	var _arg3 *C.GDateTime            // out
	var _arg4 C.GstVideoTimeCodeFlags // out
	var _arg5 C.guint                 // out
	var _cret *C.GstVideoTimeCode     // in

	_arg1 = C.guint(fpsN)
	_arg2 = C.guint(fpsD)
	_arg3 = (*C.GDateTime)(gextras.StructNative(unsafe.Pointer(dt)))
	_arg4 = C.GstVideoTimeCodeFlags(flags)
	_arg5 = C.guint(fieldCount)

	_cret = C.gst_video_time_code_new_from_date_time(_arg1, _arg2, _arg3, _arg4, _arg5)
	runtime.KeepAlive(fpsN)
	runtime.KeepAlive(fpsD)
	runtime.KeepAlive(dt)
	runtime.KeepAlive(flags)
	runtime.KeepAlive(fieldCount)

	var _videoTimeCode *VideoTimeCode // out

	_videoTimeCode = (*VideoTimeCode)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_videoTimeCode)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_video_time_code_free((*C.GstVideoTimeCode)(intern.C))
		},
	)

	return _videoTimeCode
}

// NewVideoTimeCodeFromDateTimeFull constructs a struct VideoTimeCode.
func NewVideoTimeCodeFromDateTimeFull(fpsN uint, fpsD uint, dt *glib.DateTime, flags VideoTimeCodeFlags, fieldCount uint) *VideoTimeCode {
	var _arg1 C.guint                 // out
	var _arg2 C.guint                 // out
	var _arg3 *C.GDateTime            // out
	var _arg4 C.GstVideoTimeCodeFlags // out
	var _arg5 C.guint                 // out
	var _cret *C.GstVideoTimeCode     // in

	_arg1 = C.guint(fpsN)
	_arg2 = C.guint(fpsD)
	_arg3 = (*C.GDateTime)(gextras.StructNative(unsafe.Pointer(dt)))
	_arg4 = C.GstVideoTimeCodeFlags(flags)
	_arg5 = C.guint(fieldCount)

	_cret = C.gst_video_time_code_new_from_date_time_full(_arg1, _arg2, _arg3, _arg4, _arg5)
	runtime.KeepAlive(fpsN)
	runtime.KeepAlive(fpsD)
	runtime.KeepAlive(dt)
	runtime.KeepAlive(flags)
	runtime.KeepAlive(fieldCount)

	var _videoTimeCode *VideoTimeCode // out

	if _cret != nil {
		_videoTimeCode = (*VideoTimeCode)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_videoTimeCode)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_video_time_code_free((*C.GstVideoTimeCode)(intern.C))
			},
		)
	}

	return _videoTimeCode
}

// NewVideoTimeCodeFromString constructs a struct VideoTimeCode.
func NewVideoTimeCodeFromString(tcStr string) *VideoTimeCode {
	var _arg1 *C.gchar            // out
	var _cret *C.GstVideoTimeCode // in

	_arg1 = (*C.gchar)(unsafe.Pointer(C.CString(tcStr)))
	defer C.free(unsafe.Pointer(_arg1))

	_cret = C.gst_video_time_code_new_from_string(_arg1)
	runtime.KeepAlive(tcStr)

	var _videoTimeCode *VideoTimeCode // out

	if _cret != nil {
		_videoTimeCode = (*VideoTimeCode)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_videoTimeCode)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_video_time_code_free((*C.GstVideoTimeCode)(intern.C))
			},
		)
	}

	return _videoTimeCode
}

// Config: corresponding VideoTimeCodeConfig.
func (v *VideoTimeCode) Config() *VideoTimeCodeConfig {
	valptr := &v.native.config
	var _v *VideoTimeCodeConfig // out
	_v = (*VideoTimeCodeConfig)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// Hours hours field of VideoTimeCode.
func (v *VideoTimeCode) Hours() uint {
	valptr := &v.native.hours
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Minutes minutes field of VideoTimeCode.
func (v *VideoTimeCode) Minutes() uint {
	valptr := &v.native.minutes
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Seconds seconds field of VideoTimeCode.
func (v *VideoTimeCode) Seconds() uint {
	valptr := &v.native.seconds
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Frames frames field of VideoTimeCode.
func (v *VideoTimeCode) Frames() uint {
	valptr := &v.native.frames
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// FieldCount: interlaced video field count.
func (v *VideoTimeCode) FieldCount() uint {
	valptr := &v.native.field_count
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Hours hours field of VideoTimeCode.
func (v *VideoTimeCode) SetHours(hours uint) {
	valptr := &v.native.hours
	*valptr = C.guint(hours)
}

// Minutes minutes field of VideoTimeCode.
func (v *VideoTimeCode) SetMinutes(minutes uint) {
	valptr := &v.native.minutes
	*valptr = C.guint(minutes)
}

// Seconds seconds field of VideoTimeCode.
func (v *VideoTimeCode) SetSeconds(seconds uint) {
	valptr := &v.native.seconds
	*valptr = C.guint(seconds)
}

// Frames frames field of VideoTimeCode.
func (v *VideoTimeCode) SetFrames(frames uint) {
	valptr := &v.native.frames
	*valptr = C.guint(frames)
}

// FieldCount: interlaced video field count.
func (v *VideoTimeCode) SetFieldCount(fieldCount uint) {
	valptr := &v.native.field_count
	*valptr = C.guint(fieldCount)
}

// AddFrames adds or subtracts frames amount of frames to tc. tc needs to
// contain valid data, as verified by gst_video_time_code_is_valid().
//
// The function takes the following parameters:
//
//   - frames: how many frames to add or subtract.
func (tc *VideoTimeCode) AddFrames(frames int64) {
	var _arg0 *C.GstVideoTimeCode // out
	var _arg1 C.gint64            // out

	_arg0 = (*C.GstVideoTimeCode)(gextras.StructNative(unsafe.Pointer(tc)))
	_arg1 = C.gint64(frames)

	C.gst_video_time_code_add_frames(_arg0, _arg1)
	runtime.KeepAlive(tc)
	runtime.KeepAlive(frames)
}

// AddInterval: this makes a component-wise addition of tc_inter to tc.
// For example, adding ("01:02:03:04", "00:01:00:00") will return "01:03:03:04".
// When it comes to drop-frame timecodes, adding ("00:00:00;00", "00:01:00:00")
// will return "00:01:00;02" because of drop-frame oddities. However, adding
// ("00:09:00;02", "00:01:00:00") will return "00:10:00;00" because this time we
// can have an exact minute.
//
// The function takes the following parameters:
//
//   - tcInter to add to tc. The interval must contain valid values, except
//     that for drop-frame timecode, it may also contain timecodes which would
//     normally be dropped. These are then corrected to the next reasonable
//     timecode.
//
// The function returns the following values:
//
//   - videoTimeCode (optional): new VideoTimeCode with tc_inter added or NULL
//     if the interval can't be added.
func (tc *VideoTimeCode) AddInterval(tcInter *VideoTimeCodeInterval) *VideoTimeCode {
	var _arg0 *C.GstVideoTimeCode         // out
	var _arg1 *C.GstVideoTimeCodeInterval // out
	var _cret *C.GstVideoTimeCode         // in

	_arg0 = (*C.GstVideoTimeCode)(gextras.StructNative(unsafe.Pointer(tc)))
	_arg1 = (*C.GstVideoTimeCodeInterval)(gextras.StructNative(unsafe.Pointer(tcInter)))

	_cret = C.gst_video_time_code_add_interval(_arg0, _arg1)
	runtime.KeepAlive(tc)
	runtime.KeepAlive(tcInter)

	var _videoTimeCode *VideoTimeCode // out

	if _cret != nil {
		_videoTimeCode = (*VideoTimeCode)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_videoTimeCode)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_video_time_code_free((*C.GstVideoTimeCode)(intern.C))
			},
		)
	}

	return _videoTimeCode
}

// Clear initializes tc with empty/zero/NULL values and frees any memory it
// might currently use.
func (tc *VideoTimeCode) Clear() {
	var _arg0 *C.GstVideoTimeCode // out

	_arg0 = (*C.GstVideoTimeCode)(gextras.StructNative(unsafe.Pointer(tc)))

	C.gst_video_time_code_clear(_arg0)
	runtime.KeepAlive(tc)
}

// Compare compares tc1 and tc2. If both have latest daily jam information,
// it is taken into account. Otherwise, it is assumed that the daily jam of both
// tc1 and tc2 was at the same time. Both time codes must be valid.
//
// The function takes the following parameters:
//
//   - tc2: another valid VideoTimeCode.
//
// The function returns the following values:
//
//   - gint: 1 if tc1 is after tc2, -1 if tc1 is before tc2, 0 otherwise.
func (tc1 *VideoTimeCode) Compare(tc2 *VideoTimeCode) int {
	var _arg0 *C.GstVideoTimeCode // out
	var _arg1 *C.GstVideoTimeCode // out
	var _cret C.gint              // in

	_arg0 = (*C.GstVideoTimeCode)(gextras.StructNative(unsafe.Pointer(tc1)))
	_arg1 = (*C.GstVideoTimeCode)(gextras.StructNative(unsafe.Pointer(tc2)))

	_cret = C.gst_video_time_code_compare(_arg0, _arg1)
	runtime.KeepAlive(tc1)
	runtime.KeepAlive(tc2)

	var _gint int // out

	_gint = int(_cret)

	return _gint
}

// The function returns the following values:
//
//   - videoTimeCode: new VideoTimeCode with the same values as tc.
func (tc *VideoTimeCode) Copy() *VideoTimeCode {
	var _arg0 *C.GstVideoTimeCode // out
	var _cret *C.GstVideoTimeCode // in

	_arg0 = (*C.GstVideoTimeCode)(gextras.StructNative(unsafe.Pointer(tc)))

	_cret = C.gst_video_time_code_copy(_arg0)
	runtime.KeepAlive(tc)

	var _videoTimeCode *VideoTimeCode // out

	_videoTimeCode = (*VideoTimeCode)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_videoTimeCode)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_video_time_code_free((*C.GstVideoTimeCode)(intern.C))
		},
	)

	return _videoTimeCode
}

// The function returns the following values:
//
//   - guint64: how many frames have passed since the daily jam of tc.
func (tc *VideoTimeCode) FramesSinceDailyJam() uint64 {
	var _arg0 *C.GstVideoTimeCode // out
	var _cret C.guint64           // in

	_arg0 = (*C.GstVideoTimeCode)(gextras.StructNative(unsafe.Pointer(tc)))

	_cret = C.gst_video_time_code_frames_since_daily_jam(_arg0)
	runtime.KeepAlive(tc)

	var _guint64 uint64 // out

	_guint64 = uint64(_cret)

	return _guint64
}

// IncrementFrame adds one frame to tc.
func (tc *VideoTimeCode) IncrementFrame() {
	var _arg0 *C.GstVideoTimeCode // out

	_arg0 = (*C.GstVideoTimeCode)(gextras.StructNative(unsafe.Pointer(tc)))

	C.gst_video_time_code_increment_frame(_arg0)
	runtime.KeepAlive(tc)
}

// Init: field_count is 0 for progressive, 1 or 2 for interlaced.
// latest_daiy_jam reference is stolen from caller.
//
// Initializes tc with the given values. The values are not checked for being
// in a valid range. To see if your timecode actually has valid content,
// use gst_video_time_code_is_valid().
//
// The function takes the following parameters:
//
//   - fpsN: numerator of the frame rate.
//   - fpsD: denominator of the frame rate.
//   - latestDailyJam (optional): latest daily jam of the VideoTimeCode.
//   - flags: VideoTimeCodeFlags.
//   - hours field of VideoTimeCode.
//   - minutes field of VideoTimeCode.
//   - seconds field of VideoTimeCode.
//   - frames field of VideoTimeCode.
//   - fieldCount: interlaced video field count.
func (tc *VideoTimeCode) Init(fpsN uint, fpsD uint, latestDailyJam *glib.DateTime, flags VideoTimeCodeFlags, hours uint, minutes uint, seconds uint, frames uint, fieldCount uint) {
	var _arg0 *C.GstVideoTimeCode     // out
	var _arg1 C.guint                 // out
	var _arg2 C.guint                 // out
	var _arg3 *C.GDateTime            // out
	var _arg4 C.GstVideoTimeCodeFlags // out
	var _arg5 C.guint                 // out
	var _arg6 C.guint                 // out
	var _arg7 C.guint                 // out
	var _arg8 C.guint                 // out
	var _arg9 C.guint                 // out

	_arg0 = (*C.GstVideoTimeCode)(gextras.StructNative(unsafe.Pointer(tc)))
	_arg1 = C.guint(fpsN)
	_arg2 = C.guint(fpsD)
	if latestDailyJam != nil {
		_arg3 = (*C.GDateTime)(gextras.StructNative(unsafe.Pointer(latestDailyJam)))
	}
	_arg4 = C.GstVideoTimeCodeFlags(flags)
	_arg5 = C.guint(hours)
	_arg6 = C.guint(minutes)
	_arg7 = C.guint(seconds)
	_arg8 = C.guint(frames)
	_arg9 = C.guint(fieldCount)

	C.gst_video_time_code_init(_arg0, _arg1, _arg2, _arg3, _arg4, _arg5, _arg6, _arg7, _arg8, _arg9)
	runtime.KeepAlive(tc)
	runtime.KeepAlive(fpsN)
	runtime.KeepAlive(fpsD)
	runtime.KeepAlive(latestDailyJam)
	runtime.KeepAlive(flags)
	runtime.KeepAlive(hours)
	runtime.KeepAlive(minutes)
	runtime.KeepAlive(seconds)
	runtime.KeepAlive(frames)
	runtime.KeepAlive(fieldCount)
}

// InitFromDateTime: resulting config->latest_daily_jam is set to midnight,
// and timecode is set to the given time.
//
// Will assert on invalid parameters, use
// gst_video_time_code_init_from_date_time_full() for being able to handle
// invalid parameters.
//
// The function takes the following parameters:
//
//   - fpsN: numerator of the frame rate.
//   - fpsD: denominator of the frame rate.
//   - dt to convert.
//   - flags: VideoTimeCodeFlags.
//   - fieldCount: interlaced video field count.
func (tc *VideoTimeCode) InitFromDateTime(fpsN uint, fpsD uint, dt *glib.DateTime, flags VideoTimeCodeFlags, fieldCount uint) {
	var _arg0 *C.GstVideoTimeCode     // out
	var _arg1 C.guint                 // out
	var _arg2 C.guint                 // out
	var _arg3 *C.GDateTime            // out
	var _arg4 C.GstVideoTimeCodeFlags // out
	var _arg5 C.guint                 // out

	_arg0 = (*C.GstVideoTimeCode)(gextras.StructNative(unsafe.Pointer(tc)))
	_arg1 = C.guint(fpsN)
	_arg2 = C.guint(fpsD)
	_arg3 = (*C.GDateTime)(gextras.StructNative(unsafe.Pointer(dt)))
	_arg4 = C.GstVideoTimeCodeFlags(flags)
	_arg5 = C.guint(fieldCount)

	C.gst_video_time_code_init_from_date_time(_arg0, _arg1, _arg2, _arg3, _arg4, _arg5)
	runtime.KeepAlive(tc)
	runtime.KeepAlive(fpsN)
	runtime.KeepAlive(fpsD)
	runtime.KeepAlive(dt)
	runtime.KeepAlive(flags)
	runtime.KeepAlive(fieldCount)
}

// InitFromDateTimeFull: resulting config->latest_daily_jam is set to midnight,
// and timecode is set to the given time.
//
// The function takes the following parameters:
//
//   - fpsN: numerator of the frame rate.
//   - fpsD: denominator of the frame rate.
//   - dt to convert.
//   - flags: VideoTimeCodeFlags.
//   - fieldCount: interlaced video field count.
//
// The function returns the following values:
//
//   - ok: TRUE if tc could be correctly initialized to a valid timecode.
func (tc *VideoTimeCode) InitFromDateTimeFull(fpsN uint, fpsD uint, dt *glib.DateTime, flags VideoTimeCodeFlags, fieldCount uint) bool {
	var _arg0 *C.GstVideoTimeCode     // out
	var _arg1 C.guint                 // out
	var _arg2 C.guint                 // out
	var _arg3 *C.GDateTime            // out
	var _arg4 C.GstVideoTimeCodeFlags // out
	var _arg5 C.guint                 // out
	var _cret C.gboolean              // in

	_arg0 = (*C.GstVideoTimeCode)(gextras.StructNative(unsafe.Pointer(tc)))
	_arg1 = C.guint(fpsN)
	_arg2 = C.guint(fpsD)
	_arg3 = (*C.GDateTime)(gextras.StructNative(unsafe.Pointer(dt)))
	_arg4 = C.GstVideoTimeCodeFlags(flags)
	_arg5 = C.guint(fieldCount)

	_cret = C.gst_video_time_code_init_from_date_time_full(_arg0, _arg1, _arg2, _arg3, _arg4, _arg5)
	runtime.KeepAlive(tc)
	runtime.KeepAlive(fpsN)
	runtime.KeepAlive(fpsD)
	runtime.KeepAlive(dt)
	runtime.KeepAlive(flags)
	runtime.KeepAlive(fieldCount)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function returns the following values:
//
//   - ok: whether tc is a valid timecode (supported frame rate,
//     hours/minutes/seconds/frames not overflowing).
func (tc *VideoTimeCode) IsValid() bool {
	var _arg0 *C.GstVideoTimeCode // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstVideoTimeCode)(gextras.StructNative(unsafe.Pointer(tc)))

	_cret = C.gst_video_time_code_is_valid(_arg0)
	runtime.KeepAlive(tc)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function returns the following values:
//
//   - guint64: how many nsec have passed since the daily jam of tc.
func (tc *VideoTimeCode) NsecSinceDailyJam() uint64 {
	var _arg0 *C.GstVideoTimeCode // out
	var _cret C.guint64           // in

	_arg0 = (*C.GstVideoTimeCode)(gextras.StructNative(unsafe.Pointer(tc)))

	_cret = C.gst_video_time_code_nsec_since_daily_jam(_arg0)
	runtime.KeepAlive(tc)

	var _guint64 uint64 // out

	_guint64 = uint64(_cret)

	return _guint64
}

// ToDateTime: tc.config->latest_daily_jam is required to be non-NULL.
//
// The function returns the following values:
//
//   - dateTime (optional) representation of tc or NULL if tc has no daily jam.
func (tc *VideoTimeCode) ToDateTime() *glib.DateTime {
	var _arg0 *C.GstVideoTimeCode // out
	var _cret *C.GDateTime        // in

	_arg0 = (*C.GstVideoTimeCode)(gextras.StructNative(unsafe.Pointer(tc)))

	_cret = C.gst_video_time_code_to_date_time(_arg0)
	runtime.KeepAlive(tc)

	var _dateTime *glib.DateTime // out

	if _cret != nil {
		_dateTime = (*glib.DateTime)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_dateTime)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.g_date_time_unref((*C.GDateTime)(intern.C))
			},
		)
	}

	return _dateTime
}

// The function returns the following values:
//
//   - utf8: SMPTE ST 2059-1:2015 string representation of tc. That will take
//     the form hh:mm:ss:ff. The last separator (between seconds and frames) may
//     vary:
//
//     ';' for drop-frame, non-interlaced content and for drop-frame interlaced
//     field 2 ',' for drop-frame interlaced field 1 ':' for non-drop-frame,
//     non-interlaced content and for non-drop-frame interlaced field 2 '.' for
//     non-drop-frame interlaced field 1.
func (tc *VideoTimeCode) String() string {
	var _arg0 *C.GstVideoTimeCode // out
	var _cret *C.gchar            // in

	_arg0 = (*C.GstVideoTimeCode)(gextras.StructNative(unsafe.Pointer(tc)))

	_cret = C.gst_video_time_code_to_string(_arg0)
	runtime.KeepAlive(tc)

	var _utf8 string // out

	_utf8 = C.GoString((*C.gchar)(unsafe.Pointer(_cret)))
	defer C.free(unsafe.Pointer(_cret))

	return _utf8
}

// VideoTimeCodeConfig: supported frame rates: 30000/1001, 60000/1001 (both with
// and without drop frame), and integer frame rates e.g. 25/1, 30/1, 50/1, 60/1.
//
// The configuration of the time code.
//
// An instance of this type is always passed by reference.
type VideoTimeCodeConfig struct {
	*videoTimeCodeConfig
}

// videoTimeCodeConfig is the struct that's finalized.
type videoTimeCodeConfig struct {
	native *C.GstVideoTimeCodeConfig
}

// FPSN: numerator of the frame rate.
func (v *VideoTimeCodeConfig) FPSN() uint {
	valptr := &v.native.fps_n
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// FPSD: denominator of the frame rate.
func (v *VideoTimeCodeConfig) FPSD() uint {
	valptr := &v.native.fps_d
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Flags: corresponding VideoTimeCodeFlags.
func (v *VideoTimeCodeConfig) Flags() VideoTimeCodeFlags {
	valptr := &v.native.flags
	var _v VideoTimeCodeFlags // out
	_v = VideoTimeCodeFlags(*valptr)
	return _v
}

// LatestDailyJam: latest daily jam information, if present, or NULL.
func (v *VideoTimeCodeConfig) LatestDailyJam() *glib.DateTime {
	valptr := &v.native.latest_daily_jam
	var _v *glib.DateTime // out
	_v = (*glib.DateTime)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	C.g_date_time_ref(*valptr)
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_v)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.g_date_time_unref((*C.GDateTime)(intern.C))
		},
	)
	return _v
}

// FPSN: numerator of the frame rate.
func (v *VideoTimeCodeConfig) SetFPSN(fpsN uint) {
	valptr := &v.native.fps_n
	*valptr = C.guint(fpsN)
}

// FPSD: denominator of the frame rate.
func (v *VideoTimeCodeConfig) SetFPSD(fpsD uint) {
	valptr := &v.native.fps_d
	*valptr = C.guint(fpsD)
}

// VideoTimeCodeInterval: representation of a difference between two
// VideoTimeCode instances. Will not necessarily correspond to a real timecode
// (e.g. 00:00:10;00)
//
// An instance of this type is always passed by reference.
type VideoTimeCodeInterval struct {
	*videoTimeCodeInterval
}

// videoTimeCodeInterval is the struct that's finalized.
type videoTimeCodeInterval struct {
	native *C.GstVideoTimeCodeInterval
}

func marshalVideoTimeCodeInterval(p uintptr) (interface{}, error) {
	b := coreglib.ValueFromNative(unsafe.Pointer(p)).Boxed()
	return &VideoTimeCodeInterval{&videoTimeCodeInterval{(*C.GstVideoTimeCodeInterval)(b)}}, nil
}

// NewVideoTimeCodeInterval constructs a struct VideoTimeCodeInterval.
func NewVideoTimeCodeInterval(hours uint, minutes uint, seconds uint, frames uint) *VideoTimeCodeInterval {
	var _arg1 C.guint                     // out
	var _arg2 C.guint                     // out
	var _arg3 C.guint                     // out
	var _arg4 C.guint                     // out
	var _cret *C.GstVideoTimeCodeInterval // in

	_arg1 = C.guint(hours)
	_arg2 = C.guint(minutes)
	_arg3 = C.guint(seconds)
	_arg4 = C.guint(frames)

	_cret = C.gst_video_time_code_interval_new(_arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(hours)
	runtime.KeepAlive(minutes)
	runtime.KeepAlive(seconds)
	runtime.KeepAlive(frames)

	var _videoTimeCodeInterval *VideoTimeCodeInterval // out

	_videoTimeCodeInterval = (*VideoTimeCodeInterval)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_videoTimeCodeInterval)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_video_time_code_interval_free((*C.GstVideoTimeCodeInterval)(intern.C))
		},
	)

	return _videoTimeCodeInterval
}

// NewVideoTimeCodeIntervalFromString constructs a struct VideoTimeCodeInterval.
func NewVideoTimeCodeIntervalFromString(tcInterStr string) *VideoTimeCodeInterval {
	var _arg1 *C.gchar                    // out
	var _cret *C.GstVideoTimeCodeInterval // in

	_arg1 = (*C.gchar)(unsafe.Pointer(C.CString(tcInterStr)))
	defer C.free(unsafe.Pointer(_arg1))

	_cret = C.gst_video_time_code_interval_new_from_string(_arg1)
	runtime.KeepAlive(tcInterStr)

	var _videoTimeCodeInterval *VideoTimeCodeInterval // out

	if _cret != nil {
		_videoTimeCodeInterval = (*VideoTimeCodeInterval)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_videoTimeCodeInterval)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_video_time_code_interval_free((*C.GstVideoTimeCodeInterval)(intern.C))
			},
		)
	}

	return _videoTimeCodeInterval
}

// Hours hours field of VideoTimeCodeInterval.
func (v *VideoTimeCodeInterval) Hours() uint {
	valptr := &v.native.hours
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Minutes minutes field of VideoTimeCodeInterval.
func (v *VideoTimeCodeInterval) Minutes() uint {
	valptr := &v.native.minutes
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Seconds seconds field of VideoTimeCodeInterval.
func (v *VideoTimeCodeInterval) Seconds() uint {
	valptr := &v.native.seconds
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Frames frames field of VideoTimeCodeInterval.
func (v *VideoTimeCodeInterval) Frames() uint {
	valptr := &v.native.frames
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Hours hours field of VideoTimeCodeInterval.
func (v *VideoTimeCodeInterval) SetHours(hours uint) {
	valptr := &v.native.hours
	*valptr = C.guint(hours)
}

// Minutes minutes field of VideoTimeCodeInterval.
func (v *VideoTimeCodeInterval) SetMinutes(minutes uint) {
	valptr := &v.native.minutes
	*valptr = C.guint(minutes)
}

// Seconds seconds field of VideoTimeCodeInterval.
func (v *VideoTimeCodeInterval) SetSeconds(seconds uint) {
	valptr := &v.native.seconds
	*valptr = C.guint(seconds)
}

// Frames frames field of VideoTimeCodeInterval.
func (v *VideoTimeCodeInterval) SetFrames(frames uint) {
	valptr := &v.native.frames
	*valptr = C.guint(frames)
}

// Clear initializes tc with empty/zero/NULL values.
func (tc *VideoTimeCodeInterval) Clear() {
	var _arg0 *C.GstVideoTimeCodeInterval // out

	_arg0 = (*C.GstVideoTimeCodeInterval)(gextras.StructNative(unsafe.Pointer(tc)))

	C.gst_video_time_code_interval_clear(_arg0)
	runtime.KeepAlive(tc)
}

// The function returns the following values:
//
//   - videoTimeCodeInterval: new VideoTimeCodeInterval with the same values as
//     tc.
func (tc *VideoTimeCodeInterval) Copy() *VideoTimeCodeInterval {
	var _arg0 *C.GstVideoTimeCodeInterval // out
	var _cret *C.GstVideoTimeCodeInterval // in

	_arg0 = (*C.GstVideoTimeCodeInterval)(gextras.StructNative(unsafe.Pointer(tc)))

	_cret = C.gst_video_time_code_interval_copy(_arg0)
	runtime.KeepAlive(tc)

	var _videoTimeCodeInterval *VideoTimeCodeInterval // out

	_videoTimeCodeInterval = (*VideoTimeCodeInterval)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_videoTimeCodeInterval)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_video_time_code_interval_free((*C.GstVideoTimeCodeInterval)(intern.C))
		},
	)

	return _videoTimeCodeInterval
}

// Init initializes tc with the given values.
//
// The function takes the following parameters:
//
//   - hours field of VideoTimeCodeInterval.
//   - minutes field of VideoTimeCodeInterval.
//   - seconds field of VideoTimeCodeInterval.
//   - frames field of VideoTimeCodeInterval.
func (tc *VideoTimeCodeInterval) Init(hours uint, minutes uint, seconds uint, frames uint) {
	var _arg0 *C.GstVideoTimeCodeInterval // out
	var _arg1 C.guint                     // out
	var _arg2 C.guint                     // out
	var _arg3 C.guint                     // out
	var _arg4 C.guint                     // out

	_arg0 = (*C.GstVideoTimeCodeInterval)(gextras.StructNative(unsafe.Pointer(tc)))
	_arg1 = C.guint(hours)
	_arg2 = C.guint(minutes)
	_arg3 = C.guint(seconds)
	_arg4 = C.guint(frames)

	C.gst_video_time_code_interval_init(_arg0, _arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(tc)
	runtime.KeepAlive(hours)
	runtime.KeepAlive(minutes)
	runtime.KeepAlive(seconds)
	runtime.KeepAlive(frames)
}

// VideoTimeCodeMeta: extra buffer metadata describing the GstVideoTimeCode of
// the frame.
//
// Each frame is assumed to have its own timecode, i.e. they are not
// automatically incremented/interpolated.
//
// An instance of this type is always passed by reference.
type VideoTimeCodeMeta struct {
	*videoTimeCodeMeta
}

// videoTimeCodeMeta is the struct that's finalized.
type videoTimeCodeMeta struct {
	native *C.GstVideoTimeCodeMeta
}

// Meta: parent Meta.
func (v *VideoTimeCodeMeta) Meta() *gst.Meta {
	valptr := &v.native.meta
	var _v *gst.Meta // out
	_v = (*gst.Meta)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// Tc: gstVideoTimeCode to attach.
func (v *VideoTimeCodeMeta) Tc() *VideoTimeCode {
	valptr := &v.native.tc
	var _v *VideoTimeCode // out
	_v = (*VideoTimeCode)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

func VideoTimeCodeMetaGetInfo() *gst.MetaInfo {
	var _cret *C.GstMetaInfo // in

	_cret = C.gst_video_time_code_meta_get_info()

	var _metaInfo *gst.MetaInfo // out

	_metaInfo = (*gst.MetaInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _metaInfo
}

// VideoVBIEncoder: encoder for writing ancillary data to the Vertical Blanking
// Interval lines of component signals.
//
// An instance of this type is always passed by reference.
type VideoVBIEncoder struct {
	*videoVBIEncoder
}

// videoVBIEncoder is the struct that's finalized.
type videoVBIEncoder struct {
	native *C.GstVideoVBIEncoder
}

func marshalVideoVBIEncoder(p uintptr) (interface{}, error) {
	b := coreglib.ValueFromNative(unsafe.Pointer(p)).Boxed()
	return &VideoVBIEncoder{&videoVBIEncoder{(*C.GstVideoVBIEncoder)(b)}}, nil
}

// NewVideoVBIEncoder constructs a struct VideoVBIEncoder.
func NewVideoVBIEncoder(format VideoFormat, pixelWidth uint32) *VideoVBIEncoder {
	var _arg1 C.GstVideoFormat      // out
	var _arg2 C.guint32             // out
	var _cret *C.GstVideoVBIEncoder // in

	_arg1 = C.GstVideoFormat(format)
	_arg2 = C.guint32(pixelWidth)

	_cret = C.gst_video_vbi_encoder_new(_arg1, _arg2)
	runtime.KeepAlive(format)
	runtime.KeepAlive(pixelWidth)

	var _videoVBIEncoder *VideoVBIEncoder // out

	if _cret != nil {
		_videoVBIEncoder = (*VideoVBIEncoder)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_videoVBIEncoder)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_video_vbi_encoder_free((*C.GstVideoVBIEncoder)(intern.C))
			},
		)
	}

	return _videoVBIEncoder
}

// AddAncillary stores Video Ancillary data, according to SMPTE-291M
// specification.
//
// Note that the contents of the data are always read as 8bit data (i.e.
// do not contain the parity check bits).
//
// The function takes the following parameters:
//
//   - composite: TRUE if composite ADF should be created, component otherwise.
//   - DID: data Identifier.
//   - SDIDBlockNumber: secondary Data Identifier (if type 2) or the Data Block
//     Number (if type 1).
//   - data: user data content of the Ancillary packet. Does not contain the
//     ADF, DID, SDID nor CS.
//
// The function returns the following values:
//
//   - ok: TRUE if enough space was left in the current line, FALSE otherwise.
func (encoder *VideoVBIEncoder) AddAncillary(composite bool, DID byte, SDIDBlockNumber byte, data []byte) bool {
	var _arg0 *C.GstVideoVBIEncoder // out
	var _arg1 C.gboolean            // out
	var _arg2 C.guint8              // out
	var _arg3 C.guint8              // out
	var _arg4 *C.guint8             // out
	var _arg5 C.guint
	var _cret C.gboolean // in

	_arg0 = (*C.GstVideoVBIEncoder)(gextras.StructNative(unsafe.Pointer(encoder)))
	if composite {
		_arg1 = C.TRUE
	}
	_arg2 = C.guint8(DID)
	_arg3 = C.guint8(SDIDBlockNumber)
	_arg5 = (C.guint)(len(data))
	if len(data) > 0 {
		_arg4 = (*C.guint8)(unsafe.Pointer(&data[0]))
	}

	_cret = C.gst_video_vbi_encoder_add_ancillary(_arg0, _arg1, _arg2, _arg3, _arg4, _arg5)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(composite)
	runtime.KeepAlive(DID)
	runtime.KeepAlive(SDIDBlockNumber)
	runtime.KeepAlive(data)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

func (encoder *VideoVBIEncoder) Copy() *VideoVBIEncoder {
	var _arg0 *C.GstVideoVBIEncoder // out
	var _cret *C.GstVideoVBIEncoder // in

	_arg0 = (*C.GstVideoVBIEncoder)(gextras.StructNative(unsafe.Pointer(encoder)))

	_cret = C.gst_video_vbi_encoder_copy(_arg0)
	runtime.KeepAlive(encoder)

	var _videoVBIEncoder *VideoVBIEncoder // out

	_videoVBIEncoder = (*VideoVBIEncoder)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_videoVBIEncoder)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_video_vbi_encoder_free((*C.GstVideoVBIEncoder)(intern.C))
		},
	)

	return _videoVBIEncoder
}

func (encoder *VideoVBIEncoder) WriteLine(data *byte) {
	var _arg0 *C.GstVideoVBIEncoder // out
	var _arg1 *C.guint8             // out

	_arg0 = (*C.GstVideoVBIEncoder)(gextras.StructNative(unsafe.Pointer(encoder)))
	_arg1 = (*C.guint8)(unsafe.Pointer(data))

	C.gst_video_vbi_encoder_write_line(_arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(data)
}

// VideoVBIParser: parser for detecting and extracting GstVideoAncillary data
// from Vertical Blanking Interval lines of component signals.
//
// An instance of this type is always passed by reference.
type VideoVBIParser struct {
	*videoVBIParser
}

// videoVBIParser is the struct that's finalized.
type videoVBIParser struct {
	native *C.GstVideoVBIParser
}

func marshalVideoVBIParser(p uintptr) (interface{}, error) {
	b := coreglib.ValueFromNative(unsafe.Pointer(p)).Boxed()
	return &VideoVBIParser{&videoVBIParser{(*C.GstVideoVBIParser)(b)}}, nil
}

// NewVideoVBIParser constructs a struct VideoVBIParser.
func NewVideoVBIParser(format VideoFormat, pixelWidth uint32) *VideoVBIParser {
	var _arg1 C.GstVideoFormat     // out
	var _arg2 C.guint32            // out
	var _cret *C.GstVideoVBIParser // in

	_arg1 = C.GstVideoFormat(format)
	_arg2 = C.guint32(pixelWidth)

	_cret = C.gst_video_vbi_parser_new(_arg1, _arg2)
	runtime.KeepAlive(format)
	runtime.KeepAlive(pixelWidth)

	var _videoVBIParser *VideoVBIParser // out

	if _cret != nil {
		_videoVBIParser = (*VideoVBIParser)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_videoVBIParser)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_video_vbi_parser_free((*C.GstVideoVBIParser)(intern.C))
			},
		)
	}

	return _videoVBIParser
}

func (parser *VideoVBIParser) Copy() *VideoVBIParser {
	var _arg0 *C.GstVideoVBIParser // out
	var _cret *C.GstVideoVBIParser // in

	_arg0 = (*C.GstVideoVBIParser)(gextras.StructNative(unsafe.Pointer(parser)))

	_cret = C.gst_video_vbi_parser_copy(_arg0)
	runtime.KeepAlive(parser)

	var _videoVBIParser *VideoVBIParser // out

	_videoVBIParser = (*VideoVBIParser)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_videoVBIParser)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_video_vbi_parser_free((*C.GstVideoVBIParser)(intern.C))
		},
	)

	return _videoVBIParser
}

// Ancillary: parse the line provided previously by
// gst_video_vbi_parser_add_line().
//
// The function returns the following values:
//
//   - anc to start the eventual ancillary data.
//   - videoVBIParserResult: GST_VIDEO_VBI_PARSER_RESULT_OK if ancillary data
//     was found and anc was filled. GST_VIDEO_VBI_PARSER_RESULT_DONE if there
//     wasn't any data.
func (parser *VideoVBIParser) Ancillary() (*VideoAncillary, VideoVBIParserResult) {
	var _arg0 *C.GstVideoVBIParser      // out
	var _arg1 C.GstVideoAncillary       // in
	var _cret C.GstVideoVBIParserResult // in

	_arg0 = (*C.GstVideoVBIParser)(gextras.StructNative(unsafe.Pointer(parser)))

	_cret = C.gst_video_vbi_parser_get_ancillary(_arg0, &_arg1)
	runtime.KeepAlive(parser)

	var _anc *VideoAncillary                       // out
	var _videoVBIParserResult VideoVBIParserResult // out

	_anc = (*VideoAncillary)(gextras.NewStructNative(unsafe.Pointer((&_arg1))))
	_videoVBIParserResult = VideoVBIParserResult(_cret)

	return _anc, _videoVBIParserResult
}
