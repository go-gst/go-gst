// Code generated by girgen. DO NOT EDIT.

package gstbase

import (
	"fmt"
	"runtime"
	_ "runtime/cgo"
	"strings"
	"unsafe"

	"github.com/diamondburned/gotk4/pkg/core/gbox"
	"github.com/diamondburned/gotk4/pkg/core/gextras"
	coreglib "github.com/diamondburned/gotk4/pkg/core/glib"
	"github.com/diamondburned/gotk4/pkg/glib/v2"
	"github.com/go-gst/go-gst/pkg/gst"
)

// #cgo pkg-config: gstreamer-base-1.0
// #cgo CFLAGS: -Wno-deprecated-declarations
// #include <stdlib.h>
// #include <glib-object.h>
// #include <gst/base/base.h>
// extern void _gotk4_gstbase1_DataQueue_ConnectFull(gpointer, guintptr);
// extern void _gotk4_gstbase1_DataQueue_ConnectEmpty(gpointer, guintptr);
// extern void _gotk4_gstbase1_DataQueueClass_full(GstDataQueue*);
// extern void _gotk4_gstbase1_DataQueueClass_empty(GstDataQueue*);
// extern void _gotk4_gstbase1_CollectPadsFlushFunction(GstCollectPads*, gpointer);
// extern void _gotk4_gstbase1_BaseTransformClass_before_transform(GstBaseTransform*, GstBuffer*);
// extern void _gotk4_gstbase1_BaseSrcClass_get_times(GstBaseSrc*, GstBuffer*, GstClockTime*, GstClockTime*);
// extern void _gotk4_gstbase1_BaseSinkClass_get_times(GstBaseSink*, GstBuffer*, GstClockTime*, GstClockTime*);
// extern void _gotk4_gstbase1_Aggregator_ConnectSamplesSelected(gpointer, GstSegment*, guint64, guint64, guint64, GstStructure*, guintptr);
// extern void _gotk4_gstbase1_AggregatorPad_ConnectBufferConsumed(gpointer, GstBuffer*, guintptr);
// extern gint _gotk4_gstbase1_CollectPadsCompareFunction(GstCollectPads*, GstCollectData*, GstClockTime, GstCollectData*, GstClockTime, gpointer);
// extern gboolean _gotk4_gstbase1_CollectPadsQueryFunction(GstCollectPads*, GstCollectData*, GstQuery*, gpointer);
// extern gboolean _gotk4_gstbase1_CollectPadsEventFunction(GstCollectPads*, GstCollectData*, GstEvent*, gpointer);
// extern gboolean _gotk4_gstbase1_BaseTransformClass_transform_size(GstBaseTransform*, GstPadDirection, GstCaps*, gsize, GstCaps*, gsize*);
// extern gboolean _gotk4_gstbase1_BaseTransformClass_transform_meta(GstBaseTransform*, GstBuffer*, GstMeta*, GstBuffer*);
// extern gboolean _gotk4_gstbase1_BaseTransformClass_stop(GstBaseTransform*);
// extern gboolean _gotk4_gstbase1_BaseTransformClass_start(GstBaseTransform*);
// extern gboolean _gotk4_gstbase1_BaseTransformClass_src_event(GstBaseTransform*, GstEvent*);
// extern gboolean _gotk4_gstbase1_BaseTransformClass_sink_event(GstBaseTransform*, GstEvent*);
// extern gboolean _gotk4_gstbase1_BaseTransformClass_set_caps(GstBaseTransform*, GstCaps*, GstCaps*);
// extern gboolean _gotk4_gstbase1_BaseTransformClass_query(GstBaseTransform*, GstPadDirection, GstQuery*);
// extern gboolean _gotk4_gstbase1_BaseTransformClass_propose_allocation(GstBaseTransform*, GstQuery*, GstQuery*);
// extern gboolean _gotk4_gstbase1_BaseTransformClass_get_unit_size(GstBaseTransform*, GstCaps*, gsize*);
// extern gboolean _gotk4_gstbase1_BaseTransformClass_filter_meta(GstBaseTransform*, GstQuery*, GType, GstStructure*);
// extern gboolean _gotk4_gstbase1_BaseTransformClass_decide_allocation(GstBaseTransform*, GstQuery*);
// extern gboolean _gotk4_gstbase1_BaseTransformClass_copy_metadata(GstBaseTransform*, GstBuffer*, GstBuffer*);
// extern gboolean _gotk4_gstbase1_BaseTransformClass_accept_caps(GstBaseTransform*, GstPadDirection, GstCaps*);
// extern gboolean _gotk4_gstbase1_BaseSrcClass_unlock_stop(GstBaseSrc*);
// extern gboolean _gotk4_gstbase1_BaseSrcClass_unlock(GstBaseSrc*);
// extern gboolean _gotk4_gstbase1_BaseSrcClass_stop(GstBaseSrc*);
// extern gboolean _gotk4_gstbase1_BaseSrcClass_start(GstBaseSrc*);
// extern gboolean _gotk4_gstbase1_BaseSrcClass_set_caps(GstBaseSrc*, GstCaps*);
// extern gboolean _gotk4_gstbase1_BaseSrcClass_query(GstBaseSrc*, GstQuery*);
// extern gboolean _gotk4_gstbase1_BaseSrcClass_prepare_seek_segment(GstBaseSrc*, GstEvent*, GstSegment*);
// extern gboolean _gotk4_gstbase1_BaseSrcClass_negotiate(GstBaseSrc*);
// extern gboolean _gotk4_gstbase1_BaseSrcClass_is_seekable(GstBaseSrc*);
// extern gboolean _gotk4_gstbase1_BaseSrcClass_get_size(GstBaseSrc*, guint64*);
// extern gboolean _gotk4_gstbase1_BaseSrcClass_event(GstBaseSrc*, GstEvent*);
// extern gboolean _gotk4_gstbase1_BaseSrcClass_do_seek(GstBaseSrc*, GstSegment*);
// extern gboolean _gotk4_gstbase1_BaseSrcClass_decide_allocation(GstBaseSrc*, GstQuery*);
// extern gboolean _gotk4_gstbase1_BaseSinkClass_unlock_stop(GstBaseSink*);
// extern gboolean _gotk4_gstbase1_BaseSinkClass_unlock(GstBaseSink*);
// extern gboolean _gotk4_gstbase1_BaseSinkClass_stop(GstBaseSink*);
// extern gboolean _gotk4_gstbase1_BaseSinkClass_start(GstBaseSink*);
// extern gboolean _gotk4_gstbase1_BaseSinkClass_set_caps(GstBaseSink*, GstCaps*);
// extern gboolean _gotk4_gstbase1_BaseSinkClass_query(GstBaseSink*, GstQuery*);
// extern gboolean _gotk4_gstbase1_BaseSinkClass_propose_allocation(GstBaseSink*, GstQuery*);
// extern gboolean _gotk4_gstbase1_BaseSinkClass_event(GstBaseSink*, GstEvent*);
// extern gboolean _gotk4_gstbase1_BaseSinkClass_activate_pull(GstBaseSink*, gboolean);
// extern gboolean _gotk4_gstbase1_BaseParseClass_stop(GstBaseParse*);
// extern gboolean _gotk4_gstbase1_BaseParseClass_start(GstBaseParse*);
// extern gboolean _gotk4_gstbase1_BaseParseClass_src_query(GstBaseParse*, GstQuery*);
// extern gboolean _gotk4_gstbase1_BaseParseClass_src_event(GstBaseParse*, GstEvent*);
// extern gboolean _gotk4_gstbase1_BaseParseClass_sink_query(GstBaseParse*, GstQuery*);
// extern gboolean _gotk4_gstbase1_BaseParseClass_sink_event(GstBaseParse*, GstEvent*);
// extern gboolean _gotk4_gstbase1_BaseParseClass_set_sink_caps(GstBaseParse*, GstCaps*);
// extern gboolean _gotk4_gstbase1_BaseParseClass_convert(GstBaseParse*, GstFormat, gint64, GstFormat, gint64*);
// extern gboolean _gotk4_gstbase1_AggregatorPadClass_skip_buffer(GstAggregatorPad*, GstAggregator*, GstBuffer*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_stop(GstAggregator*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_start(GstAggregator*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_src_query(GstAggregator*, GstQuery*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_src_event(GstAggregator*, GstEvent*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_src_activate(GstAggregator*, GstPadMode, gboolean);
// extern gboolean _gotk4_gstbase1_AggregatorClass_sink_query_pre_queue(GstAggregator*, GstAggregatorPad*, GstQuery*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_sink_query(GstAggregator*, GstAggregatorPad*, GstQuery*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_sink_event(GstAggregator*, GstAggregatorPad*, GstEvent*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_propose_allocation(GstAggregator*, GstAggregatorPad*, GstQuery*, GstQuery*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_negotiated_src_caps(GstAggregator*, GstCaps*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_negotiate(GstAggregator*);
// extern gboolean _gotk4_gstbase1_AggregatorClass_decide_allocation(GstAggregator*, GstQuery*);
// extern GstSample* _gotk4_gstbase1_AggregatorClass_peek_next_sample(GstAggregator*, GstAggregatorPad*);
// extern GstFlowReturn _gotk4_gstbase1_PushSrcClass_fill(GstPushSrc*, GstBuffer*);
// extern GstFlowReturn _gotk4_gstbase1_PushSrcClass_alloc(GstPushSrc*, GstBuffer**);
// extern GstFlowReturn _gotk4_gstbase1_CollectPadsFunction(GstCollectPads*, gpointer);
// extern GstFlowReturn _gotk4_gstbase1_CollectPadsClipFunction(GstCollectPads*, GstCollectData*, GstBuffer*, GstBuffer**, gpointer);
// extern GstFlowReturn _gotk4_gstbase1_CollectPadsBufferFunction(GstCollectPads*, GstCollectData*, GstBuffer*, gpointer);
// extern GstFlowReturn _gotk4_gstbase1_BaseTransformClass_transform_ip(GstBaseTransform*, GstBuffer*);
// extern GstFlowReturn _gotk4_gstbase1_BaseTransformClass_transform(GstBaseTransform*, GstBuffer*, GstBuffer*);
// extern GstFlowReturn _gotk4_gstbase1_BaseTransformClass_submit_input_buffer(GstBaseTransform*, gboolean, GstBuffer*);
// extern GstFlowReturn _gotk4_gstbase1_BaseTransformClass_prepare_output_buffer(GstBaseTransform*, GstBuffer*, GstBuffer**);
// extern GstFlowReturn _gotk4_gstbase1_BaseTransformClass_generate_output(GstBaseTransform*, GstBuffer**);
// extern GstFlowReturn _gotk4_gstbase1_BaseSrcClass_fill(GstBaseSrc*, guint64, guint, GstBuffer*);
// extern GstFlowReturn _gotk4_gstbase1_BaseSrcClass_alloc(GstBaseSrc*, guint64, guint, GstBuffer**);
// extern GstFlowReturn _gotk4_gstbase1_BaseSinkClass_wait_event(GstBaseSink*, GstEvent*);
// extern GstFlowReturn _gotk4_gstbase1_BaseSinkClass_render_list(GstBaseSink*, GstBufferList*);
// extern GstFlowReturn _gotk4_gstbase1_BaseSinkClass_render(GstBaseSink*, GstBuffer*);
// extern GstFlowReturn _gotk4_gstbase1_BaseSinkClass_preroll(GstBaseSink*, GstBuffer*);
// extern GstFlowReturn _gotk4_gstbase1_BaseSinkClass_prepare_list(GstBaseSink*, GstBufferList*);
// extern GstFlowReturn _gotk4_gstbase1_BaseSinkClass_prepare(GstBaseSink*, GstBuffer*);
// extern GstFlowReturn _gotk4_gstbase1_BaseParseClass_pre_push_frame(GstBaseParse*, GstBaseParseFrame*);
// extern GstFlowReturn _gotk4_gstbase1_BaseParseClass_handle_frame(GstBaseParse*, GstBaseParseFrame*, gint*);
// extern GstFlowReturn _gotk4_gstbase1_BaseParseClass_detect(GstBaseParse*, GstBuffer*);
// extern GstFlowReturn _gotk4_gstbase1_AggregatorPadClass_flush(GstAggregatorPad*, GstAggregator*);
// extern GstFlowReturn _gotk4_gstbase1_AggregatorClass_update_src_caps(GstAggregator*, GstCaps*, GstCaps**);
// extern GstFlowReturn _gotk4_gstbase1_AggregatorClass_sink_event_pre_queue(GstAggregator*, GstAggregatorPad*, GstEvent*);
// extern GstFlowReturn _gotk4_gstbase1_AggregatorClass_flush(GstAggregator*);
// extern GstFlowReturn _gotk4_gstbase1_AggregatorClass_finish_buffer_list(GstAggregator*, GstBufferList*);
// extern GstFlowReturn _gotk4_gstbase1_AggregatorClass_finish_buffer(GstAggregator*, GstBuffer*);
// extern GstFlowReturn _gotk4_gstbase1_AggregatorClass_aggregate(GstAggregator*, gboolean);
// extern GstClockTime _gotk4_gstbase1_AggregatorClass_get_next_time(GstAggregator*);
// extern GstCaps* _gotk4_gstbase1_BaseTransformClass_transform_caps(GstBaseTransform*, GstPadDirection, GstCaps*, GstCaps*);
// extern GstCaps* _gotk4_gstbase1_BaseTransformClass_fixate_caps(GstBaseTransform*, GstPadDirection, GstCaps*, GstCaps*);
// extern GstCaps* _gotk4_gstbase1_BaseSrcClass_get_caps(GstBaseSrc*, GstCaps*);
// extern GstCaps* _gotk4_gstbase1_BaseSrcClass_fixate(GstBaseSrc*, GstCaps*);
// extern GstCaps* _gotk4_gstbase1_BaseSinkClass_get_caps(GstBaseSink*, GstCaps*);
// extern GstCaps* _gotk4_gstbase1_BaseSinkClass_fixate(GstBaseSink*, GstCaps*);
// extern GstCaps* _gotk4_gstbase1_BaseParseClass_get_sink_caps(GstBaseParse*, GstCaps*);
// extern GstCaps* _gotk4_gstbase1_AggregatorClass_fixate_src_caps(GstAggregator*, GstCaps*);
// extern GstBuffer* _gotk4_gstbase1_AggregatorClass_clip(GstAggregator*, GstAggregatorPad*, GstBuffer*);
// GstBuffer* _gotk4_gstbase1_Aggregator_virtual_clip(void* fnptr, GstAggregator* arg0, GstAggregatorPad* arg1, GstBuffer* arg2) {
//   return ((GstBuffer* (*)(GstAggregator*, GstAggregatorPad*, GstBuffer*))(fnptr))(arg0, arg1, arg2);
// };
// GstCaps* _gotk4_gstbase1_Aggregator_virtual_fixate_src_caps(void* fnptr, GstAggregator* arg0, GstCaps* arg1) {
//   return ((GstCaps* (*)(GstAggregator*, GstCaps*))(fnptr))(arg0, arg1);
// };
// GstCaps* _gotk4_gstbase1_BaseParse_virtual_get_sink_caps(void* fnptr, GstBaseParse* arg0, GstCaps* arg1) {
//   return ((GstCaps* (*)(GstBaseParse*, GstCaps*))(fnptr))(arg0, arg1);
// };
// GstCaps* _gotk4_gstbase1_BaseSink_virtual_fixate(void* fnptr, GstBaseSink* arg0, GstCaps* arg1) {
//   return ((GstCaps* (*)(GstBaseSink*, GstCaps*))(fnptr))(arg0, arg1);
// };
// GstCaps* _gotk4_gstbase1_BaseSink_virtual_get_caps(void* fnptr, GstBaseSink* arg0, GstCaps* arg1) {
//   return ((GstCaps* (*)(GstBaseSink*, GstCaps*))(fnptr))(arg0, arg1);
// };
// GstCaps* _gotk4_gstbase1_BaseSrc_virtual_fixate(void* fnptr, GstBaseSrc* arg0, GstCaps* arg1) {
//   return ((GstCaps* (*)(GstBaseSrc*, GstCaps*))(fnptr))(arg0, arg1);
// };
// GstCaps* _gotk4_gstbase1_BaseSrc_virtual_get_caps(void* fnptr, GstBaseSrc* arg0, GstCaps* arg1) {
//   return ((GstCaps* (*)(GstBaseSrc*, GstCaps*))(fnptr))(arg0, arg1);
// };
// GstCaps* _gotk4_gstbase1_BaseTransform_virtual_fixate_caps(void* fnptr, GstBaseTransform* arg0, GstPadDirection arg1, GstCaps* arg2, GstCaps* arg3) {
//   return ((GstCaps* (*)(GstBaseTransform*, GstPadDirection, GstCaps*, GstCaps*))(fnptr))(arg0, arg1, arg2, arg3);
// };
// GstCaps* _gotk4_gstbase1_BaseTransform_virtual_transform_caps(void* fnptr, GstBaseTransform* arg0, GstPadDirection arg1, GstCaps* arg2, GstCaps* arg3) {
//   return ((GstCaps* (*)(GstBaseTransform*, GstPadDirection, GstCaps*, GstCaps*))(fnptr))(arg0, arg1, arg2, arg3);
// };
// GstClockTime _gotk4_gstbase1_Aggregator_virtual_get_next_time(void* fnptr, GstAggregator* arg0) {
//   return ((GstClockTime (*)(GstAggregator*))(fnptr))(arg0);
// };
// GstFlowReturn _gotk4_gstbase1_AggregatorPad_virtual_flush(void* fnptr, GstAggregatorPad* arg0, GstAggregator* arg1) {
//   return ((GstFlowReturn (*)(GstAggregatorPad*, GstAggregator*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstbase1_Aggregator_virtual_aggregate(void* fnptr, GstAggregator* arg0, gboolean arg1) {
//   return ((GstFlowReturn (*)(GstAggregator*, gboolean))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstbase1_Aggregator_virtual_finish_buffer(void* fnptr, GstAggregator* arg0, GstBuffer* arg1) {
//   return ((GstFlowReturn (*)(GstAggregator*, GstBuffer*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstbase1_Aggregator_virtual_finish_buffer_list(void* fnptr, GstAggregator* arg0, GstBufferList* arg1) {
//   return ((GstFlowReturn (*)(GstAggregator*, GstBufferList*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstbase1_Aggregator_virtual_flush(void* fnptr, GstAggregator* arg0) {
//   return ((GstFlowReturn (*)(GstAggregator*))(fnptr))(arg0);
// };
// GstFlowReturn _gotk4_gstbase1_Aggregator_virtual_sink_event_pre_queue(void* fnptr, GstAggregator* arg0, GstAggregatorPad* arg1, GstEvent* arg2) {
//   return ((GstFlowReturn (*)(GstAggregator*, GstAggregatorPad*, GstEvent*))(fnptr))(arg0, arg1, arg2);
// };
// GstFlowReturn _gotk4_gstbase1_Aggregator_virtual_update_src_caps(void* fnptr, GstAggregator* arg0, GstCaps* arg1, GstCaps** arg2) {
//   return ((GstFlowReturn (*)(GstAggregator*, GstCaps*, GstCaps**))(fnptr))(arg0, arg1, arg2);
// };
// GstFlowReturn _gotk4_gstbase1_BaseParse_virtual_detect(void* fnptr, GstBaseParse* arg0, GstBuffer* arg1) {
//   return ((GstFlowReturn (*)(GstBaseParse*, GstBuffer*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstbase1_BaseParse_virtual_handle_frame(void* fnptr, GstBaseParse* arg0, GstBaseParseFrame* arg1, gint* arg2) {
//   return ((GstFlowReturn (*)(GstBaseParse*, GstBaseParseFrame*, gint*))(fnptr))(arg0, arg1, arg2);
// };
// GstFlowReturn _gotk4_gstbase1_BaseParse_virtual_pre_push_frame(void* fnptr, GstBaseParse* arg0, GstBaseParseFrame* arg1) {
//   return ((GstFlowReturn (*)(GstBaseParse*, GstBaseParseFrame*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstbase1_BaseSink_virtual_prepare(void* fnptr, GstBaseSink* arg0, GstBuffer* arg1) {
//   return ((GstFlowReturn (*)(GstBaseSink*, GstBuffer*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstbase1_BaseSink_virtual_prepare_list(void* fnptr, GstBaseSink* arg0, GstBufferList* arg1) {
//   return ((GstFlowReturn (*)(GstBaseSink*, GstBufferList*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstbase1_BaseSink_virtual_preroll(void* fnptr, GstBaseSink* arg0, GstBuffer* arg1) {
//   return ((GstFlowReturn (*)(GstBaseSink*, GstBuffer*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstbase1_BaseSink_virtual_render(void* fnptr, GstBaseSink* arg0, GstBuffer* arg1) {
//   return ((GstFlowReturn (*)(GstBaseSink*, GstBuffer*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstbase1_BaseSink_virtual_render_list(void* fnptr, GstBaseSink* arg0, GstBufferList* arg1) {
//   return ((GstFlowReturn (*)(GstBaseSink*, GstBufferList*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstbase1_BaseSink_virtual_wait_event(void* fnptr, GstBaseSink* arg0, GstEvent* arg1) {
//   return ((GstFlowReturn (*)(GstBaseSink*, GstEvent*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstbase1_BaseSrc_virtual_alloc(void* fnptr, GstBaseSrc* arg0, guint64 arg1, guint arg2, GstBuffer** arg3) {
//   return ((GstFlowReturn (*)(GstBaseSrc*, guint64, guint, GstBuffer**))(fnptr))(arg0, arg1, arg2, arg3);
// };
// GstFlowReturn _gotk4_gstbase1_BaseSrc_virtual_fill(void* fnptr, GstBaseSrc* arg0, guint64 arg1, guint arg2, GstBuffer* arg3) {
//   return ((GstFlowReturn (*)(GstBaseSrc*, guint64, guint, GstBuffer*))(fnptr))(arg0, arg1, arg2, arg3);
// };
// GstFlowReturn _gotk4_gstbase1_BaseTransform_virtual_generate_output(void* fnptr, GstBaseTransform* arg0, GstBuffer** arg1) {
//   return ((GstFlowReturn (*)(GstBaseTransform*, GstBuffer**))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstbase1_BaseTransform_virtual_prepare_output_buffer(void* fnptr, GstBaseTransform* arg0, GstBuffer* arg1, GstBuffer** arg2) {
//   return ((GstFlowReturn (*)(GstBaseTransform*, GstBuffer*, GstBuffer**))(fnptr))(arg0, arg1, arg2);
// };
// GstFlowReturn _gotk4_gstbase1_BaseTransform_virtual_submit_input_buffer(void* fnptr, GstBaseTransform* arg0, gboolean arg1, GstBuffer* arg2) {
//   return ((GstFlowReturn (*)(GstBaseTransform*, gboolean, GstBuffer*))(fnptr))(arg0, arg1, arg2);
// };
// GstFlowReturn _gotk4_gstbase1_BaseTransform_virtual_transform(void* fnptr, GstBaseTransform* arg0, GstBuffer* arg1, GstBuffer* arg2) {
//   return ((GstFlowReturn (*)(GstBaseTransform*, GstBuffer*, GstBuffer*))(fnptr))(arg0, arg1, arg2);
// };
// GstFlowReturn _gotk4_gstbase1_BaseTransform_virtual_transform_ip(void* fnptr, GstBaseTransform* arg0, GstBuffer* arg1) {
//   return ((GstFlowReturn (*)(GstBaseTransform*, GstBuffer*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstbase1_PushSrc_virtual_alloc(void* fnptr, GstPushSrc* arg0, GstBuffer** arg1) {
//   return ((GstFlowReturn (*)(GstPushSrc*, GstBuffer**))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstbase1_PushSrc_virtual_fill(void* fnptr, GstPushSrc* arg0, GstBuffer* arg1) {
//   return ((GstFlowReturn (*)(GstPushSrc*, GstBuffer*))(fnptr))(arg0, arg1);
// };
// GstSample* _gotk4_gstbase1_Aggregator_virtual_peek_next_sample(void* fnptr, GstAggregator* arg0, GstAggregatorPad* arg1) {
//   return ((GstSample* (*)(GstAggregator*, GstAggregatorPad*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_AggregatorPad_virtual_skip_buffer(void* fnptr, GstAggregatorPad* arg0, GstAggregator* arg1, GstBuffer* arg2) {
//   return ((gboolean (*)(GstAggregatorPad*, GstAggregator*, GstBuffer*))(fnptr))(arg0, arg1, arg2);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_decide_allocation(void* fnptr, GstAggregator* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstAggregator*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_negotiate(void* fnptr, GstAggregator* arg0) {
//   return ((gboolean (*)(GstAggregator*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_negotiated_src_caps(void* fnptr, GstAggregator* arg0, GstCaps* arg1) {
//   return ((gboolean (*)(GstAggregator*, GstCaps*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_propose_allocation(void* fnptr, GstAggregator* arg0, GstAggregatorPad* arg1, GstQuery* arg2, GstQuery* arg3) {
//   return ((gboolean (*)(GstAggregator*, GstAggregatorPad*, GstQuery*, GstQuery*))(fnptr))(arg0, arg1, arg2, arg3);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_sink_event(void* fnptr, GstAggregator* arg0, GstAggregatorPad* arg1, GstEvent* arg2) {
//   return ((gboolean (*)(GstAggregator*, GstAggregatorPad*, GstEvent*))(fnptr))(arg0, arg1, arg2);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_sink_query(void* fnptr, GstAggregator* arg0, GstAggregatorPad* arg1, GstQuery* arg2) {
//   return ((gboolean (*)(GstAggregator*, GstAggregatorPad*, GstQuery*))(fnptr))(arg0, arg1, arg2);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_sink_query_pre_queue(void* fnptr, GstAggregator* arg0, GstAggregatorPad* arg1, GstQuery* arg2) {
//   return ((gboolean (*)(GstAggregator*, GstAggregatorPad*, GstQuery*))(fnptr))(arg0, arg1, arg2);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_src_activate(void* fnptr, GstAggregator* arg0, GstPadMode arg1, gboolean arg2) {
//   return ((gboolean (*)(GstAggregator*, GstPadMode, gboolean))(fnptr))(arg0, arg1, arg2);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_src_event(void* fnptr, GstAggregator* arg0, GstEvent* arg1) {
//   return ((gboolean (*)(GstAggregator*, GstEvent*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_src_query(void* fnptr, GstAggregator* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstAggregator*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_start(void* fnptr, GstAggregator* arg0) {
//   return ((gboolean (*)(GstAggregator*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstbase1_Aggregator_virtual_stop(void* fnptr, GstAggregator* arg0) {
//   return ((gboolean (*)(GstAggregator*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstbase1_BaseParse_virtual_convert(void* fnptr, GstBaseParse* arg0, GstFormat arg1, gint64 arg2, GstFormat arg3, gint64* arg4) {
//   return ((gboolean (*)(GstBaseParse*, GstFormat, gint64, GstFormat, gint64*))(fnptr))(arg0, arg1, arg2, arg3, arg4);
// };
// gboolean _gotk4_gstbase1_BaseParse_virtual_set_sink_caps(void* fnptr, GstBaseParse* arg0, GstCaps* arg1) {
//   return ((gboolean (*)(GstBaseParse*, GstCaps*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_BaseParse_virtual_sink_event(void* fnptr, GstBaseParse* arg0, GstEvent* arg1) {
//   return ((gboolean (*)(GstBaseParse*, GstEvent*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_BaseParse_virtual_sink_query(void* fnptr, GstBaseParse* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstBaseParse*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_BaseParse_virtual_src_event(void* fnptr, GstBaseParse* arg0, GstEvent* arg1) {
//   return ((gboolean (*)(GstBaseParse*, GstEvent*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_BaseParse_virtual_src_query(void* fnptr, GstBaseParse* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstBaseParse*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_BaseParse_virtual_start(void* fnptr, GstBaseParse* arg0) {
//   return ((gboolean (*)(GstBaseParse*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstbase1_BaseParse_virtual_stop(void* fnptr, GstBaseParse* arg0) {
//   return ((gboolean (*)(GstBaseParse*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstbase1_BaseSink_virtual_activate_pull(void* fnptr, GstBaseSink* arg0, gboolean arg1) {
//   return ((gboolean (*)(GstBaseSink*, gboolean))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_BaseSink_virtual_event(void* fnptr, GstBaseSink* arg0, GstEvent* arg1) {
//   return ((gboolean (*)(GstBaseSink*, GstEvent*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_BaseSink_virtual_propose_allocation(void* fnptr, GstBaseSink* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstBaseSink*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_BaseSink_virtual_query(void* fnptr, GstBaseSink* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstBaseSink*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_BaseSink_virtual_set_caps(void* fnptr, GstBaseSink* arg0, GstCaps* arg1) {
//   return ((gboolean (*)(GstBaseSink*, GstCaps*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_BaseSink_virtual_start(void* fnptr, GstBaseSink* arg0) {
//   return ((gboolean (*)(GstBaseSink*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstbase1_BaseSink_virtual_stop(void* fnptr, GstBaseSink* arg0) {
//   return ((gboolean (*)(GstBaseSink*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstbase1_BaseSink_virtual_unlock(void* fnptr, GstBaseSink* arg0) {
//   return ((gboolean (*)(GstBaseSink*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstbase1_BaseSink_virtual_unlock_stop(void* fnptr, GstBaseSink* arg0) {
//   return ((gboolean (*)(GstBaseSink*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstbase1_BaseSrc_virtual_decide_allocation(void* fnptr, GstBaseSrc* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstBaseSrc*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_BaseSrc_virtual_do_seek(void* fnptr, GstBaseSrc* arg0, GstSegment* arg1) {
//   return ((gboolean (*)(GstBaseSrc*, GstSegment*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_BaseSrc_virtual_event(void* fnptr, GstBaseSrc* arg0, GstEvent* arg1) {
//   return ((gboolean (*)(GstBaseSrc*, GstEvent*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_BaseSrc_virtual_get_size(void* fnptr, GstBaseSrc* arg0, guint64* arg1) {
//   return ((gboolean (*)(GstBaseSrc*, guint64*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_BaseSrc_virtual_is_seekable(void* fnptr, GstBaseSrc* arg0) {
//   return ((gboolean (*)(GstBaseSrc*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstbase1_BaseSrc_virtual_negotiate(void* fnptr, GstBaseSrc* arg0) {
//   return ((gboolean (*)(GstBaseSrc*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstbase1_BaseSrc_virtual_prepare_seek_segment(void* fnptr, GstBaseSrc* arg0, GstEvent* arg1, GstSegment* arg2) {
//   return ((gboolean (*)(GstBaseSrc*, GstEvent*, GstSegment*))(fnptr))(arg0, arg1, arg2);
// };
// gboolean _gotk4_gstbase1_BaseSrc_virtual_query(void* fnptr, GstBaseSrc* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstBaseSrc*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_BaseSrc_virtual_set_caps(void* fnptr, GstBaseSrc* arg0, GstCaps* arg1) {
//   return ((gboolean (*)(GstBaseSrc*, GstCaps*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_BaseSrc_virtual_start(void* fnptr, GstBaseSrc* arg0) {
//   return ((gboolean (*)(GstBaseSrc*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstbase1_BaseSrc_virtual_stop(void* fnptr, GstBaseSrc* arg0) {
//   return ((gboolean (*)(GstBaseSrc*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstbase1_BaseSrc_virtual_unlock(void* fnptr, GstBaseSrc* arg0) {
//   return ((gboolean (*)(GstBaseSrc*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstbase1_BaseSrc_virtual_unlock_stop(void* fnptr, GstBaseSrc* arg0) {
//   return ((gboolean (*)(GstBaseSrc*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstbase1_BaseTransform_virtual_accept_caps(void* fnptr, GstBaseTransform* arg0, GstPadDirection arg1, GstCaps* arg2) {
//   return ((gboolean (*)(GstBaseTransform*, GstPadDirection, GstCaps*))(fnptr))(arg0, arg1, arg2);
// };
// gboolean _gotk4_gstbase1_BaseTransform_virtual_copy_metadata(void* fnptr, GstBaseTransform* arg0, GstBuffer* arg1, GstBuffer* arg2) {
//   return ((gboolean (*)(GstBaseTransform*, GstBuffer*, GstBuffer*))(fnptr))(arg0, arg1, arg2);
// };
// gboolean _gotk4_gstbase1_BaseTransform_virtual_decide_allocation(void* fnptr, GstBaseTransform* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstBaseTransform*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_BaseTransform_virtual_filter_meta(void* fnptr, GstBaseTransform* arg0, GstQuery* arg1, GType arg2, GstStructure* arg3) {
//   return ((gboolean (*)(GstBaseTransform*, GstQuery*, GType, GstStructure*))(fnptr))(arg0, arg1, arg2, arg3);
// };
// gboolean _gotk4_gstbase1_BaseTransform_virtual_get_unit_size(void* fnptr, GstBaseTransform* arg0, GstCaps* arg1, gsize* arg2) {
//   return ((gboolean (*)(GstBaseTransform*, GstCaps*, gsize*))(fnptr))(arg0, arg1, arg2);
// };
// gboolean _gotk4_gstbase1_BaseTransform_virtual_propose_allocation(void* fnptr, GstBaseTransform* arg0, GstQuery* arg1, GstQuery* arg2) {
//   return ((gboolean (*)(GstBaseTransform*, GstQuery*, GstQuery*))(fnptr))(arg0, arg1, arg2);
// };
// gboolean _gotk4_gstbase1_BaseTransform_virtual_query(void* fnptr, GstBaseTransform* arg0, GstPadDirection arg1, GstQuery* arg2) {
//   return ((gboolean (*)(GstBaseTransform*, GstPadDirection, GstQuery*))(fnptr))(arg0, arg1, arg2);
// };
// gboolean _gotk4_gstbase1_BaseTransform_virtual_set_caps(void* fnptr, GstBaseTransform* arg0, GstCaps* arg1, GstCaps* arg2) {
//   return ((gboolean (*)(GstBaseTransform*, GstCaps*, GstCaps*))(fnptr))(arg0, arg1, arg2);
// };
// gboolean _gotk4_gstbase1_BaseTransform_virtual_sink_event(void* fnptr, GstBaseTransform* arg0, GstEvent* arg1) {
//   return ((gboolean (*)(GstBaseTransform*, GstEvent*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_BaseTransform_virtual_src_event(void* fnptr, GstBaseTransform* arg0, GstEvent* arg1) {
//   return ((gboolean (*)(GstBaseTransform*, GstEvent*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstbase1_BaseTransform_virtual_start(void* fnptr, GstBaseTransform* arg0) {
//   return ((gboolean (*)(GstBaseTransform*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstbase1_BaseTransform_virtual_stop(void* fnptr, GstBaseTransform* arg0) {
//   return ((gboolean (*)(GstBaseTransform*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstbase1_BaseTransform_virtual_transform_meta(void* fnptr, GstBaseTransform* arg0, GstBuffer* arg1, GstMeta* arg2, GstBuffer* arg3) {
//   return ((gboolean (*)(GstBaseTransform*, GstBuffer*, GstMeta*, GstBuffer*))(fnptr))(arg0, arg1, arg2, arg3);
// };
// gboolean _gotk4_gstbase1_BaseTransform_virtual_transform_size(void* fnptr, GstBaseTransform* arg0, GstPadDirection arg1, GstCaps* arg2, gsize arg3, GstCaps* arg4, gsize* arg5) {
//   return ((gboolean (*)(GstBaseTransform*, GstPadDirection, GstCaps*, gsize, GstCaps*, gsize*))(fnptr))(arg0, arg1, arg2, arg3, arg4, arg5);
// };
// void _gotk4_gstbase1_BaseSink_virtual_get_times(void* fnptr, GstBaseSink* arg0, GstBuffer* arg1, GstClockTime* arg2, GstClockTime* arg3) {
//   ((void (*)(GstBaseSink*, GstBuffer*, GstClockTime*, GstClockTime*))(fnptr))(arg0, arg1, arg2, arg3);
// };
// void _gotk4_gstbase1_BaseSrc_virtual_get_times(void* fnptr, GstBaseSrc* arg0, GstBuffer* arg1, GstClockTime* arg2, GstClockTime* arg3) {
//   ((void (*)(GstBaseSrc*, GstBuffer*, GstClockTime*, GstClockTime*))(fnptr))(arg0, arg1, arg2, arg3);
// };
// void _gotk4_gstbase1_BaseTransform_virtual_before_transform(void* fnptr, GstBaseTransform* arg0, GstBuffer* arg1) {
//   ((void (*)(GstBaseTransform*, GstBuffer*))(fnptr))(arg0, arg1);
// };
// void _gotk4_gstbase1_DataQueue_virtual_empty(void* fnptr, GstDataQueue* arg0) {
//   ((void (*)(GstDataQueue*))(fnptr))(arg0);
// };
// void _gotk4_gstbase1_DataQueue_virtual_full(void* fnptr, GstDataQueue* arg0) {
//   ((void (*)(GstDataQueue*))(fnptr))(arg0);
// };
import "C"

// GType values.
var (
	GTypeAggregatorStartTimeSelection = coreglib.Type(C.gst_aggregator_start_time_selection_get_type())
	GTypeAdapter                      = coreglib.Type(C.gst_adapter_get_type())
	GTypeAggregator                   = coreglib.Type(C.gst_aggregator_get_type())
	GTypeAggregatorPad                = coreglib.Type(C.gst_aggregator_pad_get_type())
	GTypeBaseParse                    = coreglib.Type(C.gst_base_parse_get_type())
	GTypeBaseSink                     = coreglib.Type(C.gst_base_sink_get_type())
	GTypeBaseSrc                      = coreglib.Type(C.gst_base_src_get_type())
	GTypeBaseTransform                = coreglib.Type(C.gst_base_transform_get_type())
	GTypeCollectPads                  = coreglib.Type(C.gst_collect_pads_get_type())
	GTypeDataQueue                    = coreglib.Type(C.gst_data_queue_get_type())
	GTypePushSrc                      = coreglib.Type(C.gst_push_src_get_type())
	GTypeBaseParseFrame               = coreglib.Type(C.gst_base_parse_frame_get_type())
	GTypeFlowCombiner                 = coreglib.Type(C.gst_flow_combiner_get_type())
)

func init() {
	coreglib.RegisterGValueMarshalers([]coreglib.TypeMarshaler{
		coreglib.TypeMarshaler{T: GTypeAggregatorStartTimeSelection, F: marshalAggregatorStartTimeSelection},
		coreglib.TypeMarshaler{T: GTypeAdapter, F: marshalAdapter},
		coreglib.TypeMarshaler{T: GTypeAggregator, F: marshalAggregator},
		coreglib.TypeMarshaler{T: GTypeAggregatorPad, F: marshalAggregatorPad},
		coreglib.TypeMarshaler{T: GTypeBaseParse, F: marshalBaseParse},
		coreglib.TypeMarshaler{T: GTypeBaseSink, F: marshalBaseSink},
		coreglib.TypeMarshaler{T: GTypeBaseSrc, F: marshalBaseSrc},
		coreglib.TypeMarshaler{T: GTypeBaseTransform, F: marshalBaseTransform},
		coreglib.TypeMarshaler{T: GTypeCollectPads, F: marshalCollectPads},
		coreglib.TypeMarshaler{T: GTypeDataQueue, F: marshalDataQueue},
		coreglib.TypeMarshaler{T: GTypePushSrc, F: marshalPushSrc},
		coreglib.TypeMarshaler{T: GTypeBaseParseFrame, F: marshalBaseParseFrame},
		coreglib.TypeMarshaler{T: GTypeFlowCombiner, F: marshalFlowCombiner},
	})
}

const BASE_PARSE_FLAG_DRAINING = 2
const BASE_PARSE_FLAG_LOST_SYNC = 1

// BASE_TRANSFORM_SINK_NAME (GST_BASE_TRANSFORM_SINK_NAME): name of the
// templates for the sink pad.
const BASE_TRANSFORM_SINK_NAME = "sink"

// BASE_TRANSFORM_SRC_NAME (GST_BASE_TRANSFORM_SRC_NAME): name of the templates
// for the source pad.
const BASE_TRANSFORM_SRC_NAME = "src"

type AggregatorStartTimeSelection C.gint

const (
	// AggregatorStartTimeSelectionZero
	// (GST_AGGREGATOR_START_TIME_SELECTION_ZERO): start at running time 0.
	AggregatorStartTimeSelectionZero AggregatorStartTimeSelection = iota
	// AggregatorStartTimeSelectionFirst
	// (GST_AGGREGATOR_START_TIME_SELECTION_FIRST): start at the running time of
	// the first buffer that is received.
	AggregatorStartTimeSelectionFirst
	// AggregatorStartTimeSelectionSet
	// (GST_AGGREGATOR_START_TIME_SELECTION_SET): start at the running time
	// selected by the start-time property.
	AggregatorStartTimeSelectionSet
)

func marshalAggregatorStartTimeSelection(p uintptr) (interface{}, error) {
	return AggregatorStartTimeSelection(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for AggregatorStartTimeSelection.
func (a AggregatorStartTimeSelection) String() string {
	switch a {
	case AggregatorStartTimeSelectionZero:
		return "Zero"
	case AggregatorStartTimeSelectionFirst:
		return "First"
	case AggregatorStartTimeSelectionSet:
		return "Set"
	default:
		return fmt.Sprintf("AggregatorStartTimeSelection(%d)", a)
	}
}

// BaseParseFrameFlags (GstBaseParseFrameFlags) flags to be used in a
// BaseParseFrame.
type BaseParseFrameFlags C.guint

const (
	// BaseParseFrameFlagNone (GST_BASE_PARSE_FRAME_FLAG_NONE): no flag.
	BaseParseFrameFlagNone BaseParseFrameFlags = 0b0
	// BaseParseFrameFlagNewFrame (GST_BASE_PARSE_FRAME_FLAG_NEW_FRAME): set by
	// baseclass if current frame is passed for processing to the subclass for
	// the first time (and not set on subsequent calls with same data).
	BaseParseFrameFlagNewFrame BaseParseFrameFlags = 0b1
	// BaseParseFrameFlagNoFrame (GST_BASE_PARSE_FRAME_FLAG_NO_FRAME):
	// set to indicate this buffer should not be counted as frame, e.g. if this
	// frame is dependent on a previous one. As it is not counted as a frame,
	// bitrate increases but frame to time conversions are maintained.
	BaseParseFrameFlagNoFrame BaseParseFrameFlags = 0b10
	// BaseParseFrameFlagClip (GST_BASE_PARSE_FRAME_FLAG_CLIP): pre_push_frame
	// can set this to indicate that regular segment clipping can still be
	// performed (as opposed to any custom one having been done).
	BaseParseFrameFlagClip BaseParseFrameFlags = 0b100
	// BaseParseFrameFlagDrop (GST_BASE_PARSE_FRAME_FLAG_DROP) indicates to
	// finish_frame that the the frame should be dropped (and might be handled
	// internally by subclass).
	BaseParseFrameFlagDrop BaseParseFrameFlags = 0b1000
	// BaseParseFrameFlagQueue (GST_BASE_PARSE_FRAME_FLAG_QUEUE) indicates to
	// finish_frame that the the frame should be queued for now and processed
	// fully later when the first non-queued frame is finished.
	BaseParseFrameFlagQueue BaseParseFrameFlags = 0b10000
)

// String returns the names in string for BaseParseFrameFlags.
func (b BaseParseFrameFlags) String() string {
	if b == 0 {
		return "BaseParseFrameFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(145)

	for b != 0 {
		next := b & (b - 1)
		bit := b - next

		switch bit {
		case BaseParseFrameFlagNone:
			builder.WriteString("None|")
		case BaseParseFrameFlagNewFrame:
			builder.WriteString("NewFrame|")
		case BaseParseFrameFlagNoFrame:
			builder.WriteString("NoFrame|")
		case BaseParseFrameFlagClip:
			builder.WriteString("Clip|")
		case BaseParseFrameFlagDrop:
			builder.WriteString("Drop|")
		case BaseParseFrameFlagQueue:
			builder.WriteString("Queue|")
		default:
			builder.WriteString(fmt.Sprintf("BaseParseFrameFlags(0b%b)|", bit))
		}

		b = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if b contains other.
func (b BaseParseFrameFlags) Has(other BaseParseFrameFlags) bool {
	return (b & other) == other
}

// BaseSrcFlags (GstBaseSrcFlags) flags that a basesrc element may have.
type BaseSrcFlags C.guint

const (
	// BaseSrcFlagStarting (GST_BASE_SRC_FLAG_STARTING) has source is starting.
	BaseSrcFlagStarting BaseSrcFlags = 0b100000000000000
	// BaseSrcFlagStarted (GST_BASE_SRC_FLAG_STARTED) has source been started.
	BaseSrcFlagStarted BaseSrcFlags = 0b1000000000000000
	// BaseSrcFlagLast (GST_BASE_SRC_FLAG_LAST): offset to define more flags.
	BaseSrcFlagLast BaseSrcFlags = 0b100000000000000000000
)

// String returns the names in string for BaseSrcFlags.
func (b BaseSrcFlags) String() string {
	if b == 0 {
		return "BaseSrcFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(54)

	for b != 0 {
		next := b & (b - 1)
		bit := b - next

		switch bit {
		case BaseSrcFlagStarting:
			builder.WriteString("Starting|")
		case BaseSrcFlagStarted:
			builder.WriteString("Started|")
		case BaseSrcFlagLast:
			builder.WriteString("Last|")
		default:
			builder.WriteString(fmt.Sprintf("BaseSrcFlags(0b%b)|", bit))
		}

		b = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if b contains other.
func (b BaseSrcFlags) Has(other BaseSrcFlags) bool {
	return (b & other) == other
}

type CollectPadsStateFlags C.guint

const (
	// CollectPadsStateEos (GST_COLLECT_PADS_STATE_EOS): set if collectdata's
	// pad is EOS.
	CollectPadsStateEos CollectPadsStateFlags = 0b1
	// CollectPadsStateFlushing (GST_COLLECT_PADS_STATE_FLUSHING): set if
	// collectdata's pad is flushing.
	CollectPadsStateFlushing CollectPadsStateFlags = 0b10
	// CollectPadsStateNewSegment (GST_COLLECT_PADS_STATE_NEW_SEGMENT): set if
	// collectdata's pad received a new_segment event.
	CollectPadsStateNewSegment CollectPadsStateFlags = 0b100
	// CollectPadsStateWaiting (GST_COLLECT_PADS_STATE_WAITING): set if
	// collectdata's pad must be waited for when collecting.
	CollectPadsStateWaiting CollectPadsStateFlags = 0b1000
	// CollectPadsStateLocked (GST_COLLECT_PADS_STATE_LOCKED): set collectdata's
	// pad WAITING state must not be changed. CollectPadsStateFlags indicate
	// private state of a collectdata('s pad).
	CollectPadsStateLocked CollectPadsStateFlags = 0b10000
)

// String returns the names in string for CollectPadsStateFlags.
func (c CollectPadsStateFlags) String() string {
	if c == 0 {
		return "CollectPadsStateFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(118)

	for c != 0 {
		next := c & (c - 1)
		bit := c - next

		switch bit {
		case CollectPadsStateEos:
			builder.WriteString("Eos|")
		case CollectPadsStateFlushing:
			builder.WriteString("Flushing|")
		case CollectPadsStateNewSegment:
			builder.WriteString("NewSegment|")
		case CollectPadsStateWaiting:
			builder.WriteString("Waiting|")
		case CollectPadsStateLocked:
			builder.WriteString("Locked|")
		default:
			builder.WriteString(fmt.Sprintf("CollectPadsStateFlags(0b%b)|", bit))
		}

		c = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if c contains other.
func (c CollectPadsStateFlags) Has(other CollectPadsStateFlags) bool {
	return (c & other) == other
}

// CollectPadsBufferFunction: function that will be called when a (considered
// oldest) buffer can be muxed. If all pads have reached EOS, this function is
// called with NULL buffer and NULL data.
type CollectPadsBufferFunction func(pads *CollectPads, data *CollectData, buffer *gst.Buffer) (flowReturn gst.FlowReturn)

// CollectPadsClipFunction: function that will be called when inbuffer is
// received on the pad managed by data in the collectpad object pads.
//
// The function should use the segment of data and the negotiated media type on
// the pad to perform clipping of inbuffer.
//
// This function takes ownership of inbuffer and should output a buffer in
// outbuffer or return NULL in outbuffer if the buffer should be dropped.
type CollectPadsClipFunction func(pads *CollectPads, data *CollectData, inbuffer *gst.Buffer) (outbuffer *gst.Buffer, flowReturn gst.FlowReturn)

// CollectPadsCompareFunction: function for comparing two timestamps of buffers
// or newsegments collected on one pad.
type CollectPadsCompareFunction func(pads *CollectPads, data1 *CollectData, timestamp1 gst.ClockTime, data2 *CollectData, timestamp2 gst.ClockTime) (gint int)

// CollectPadsEventFunction: function that will be called while processing an
// event. It takes ownership of the event and is responsible for chaining up
// (to gst_collect_pads_event_default()) or dropping events (such typical cases
// being handled by the default handler).
type CollectPadsEventFunction func(pads *CollectPads, pad *CollectData, event *gst.Event) (ok bool)

// CollectPadsFlushFunction: function that will be called while processing a
// flushing seek event.
//
// The function should flush any internal state of the element and the state of
// all the pads. It should clear only the state not directly managed by the pads
// object. It is therefore not necessary to call gst_collect_pads_set_flushing
// nor gst_collect_pads_clear from this function.
type CollectPadsFlushFunction func(pads *CollectPads)

// CollectPadsFunction: function that will be called when all pads have received
// data.
type CollectPadsFunction func(pads *CollectPads) (flowReturn gst.FlowReturn)

// CollectPadsQueryFunction: function that will be called while processing a
// query. It takes ownership of the query and is responsible for chaining up (to
// events downstream (with gst_pad_event_default()).
type CollectPadsQueryFunction func(pads *CollectPads, pad *CollectData, query *gst.Query) (ok bool)

// TypeFindHelper (gst_type_find_helper) tries to find what type of data is
// flowing from the given source Pad.
//
// Free-function: gst_caps_unref.
//
// The function takes the following parameters:
//
//   - src: source Pad.
//   - size: length in bytes.
//
// The function returns the following values:
//
//   - caps (optional) corresponding to the data stream. Returns NULL if no Caps
//     matches the data stream.
func TypeFindHelper(src *gst.Pad, size uint64) *gst.Caps {
	var _arg1 *C.GstPad  // out
	var _arg2 C.guint64  // out
	var _cret *C.GstCaps // in

	_arg1 = (*C.GstPad)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg2 = C.guint64(size)

	_cret = C.gst_type_find_helper(_arg1, _arg2)
	runtime.KeepAlive(src)
	runtime.KeepAlive(size)

	var _caps *gst.Caps // out

	if _cret != nil {
		_caps = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_caps)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _caps
}

// TypeFindHelperForBuffer (gst_type_find_helper_for_buffer) tries to find what
// type of data is contained in the given Buffer, the assumption being that the
// buffer represents the beginning of the stream or file.
//
// All available typefinders will be called on the data in order of rank.
// If a typefinding function returns a probability of GST_TYPE_FIND_MAXIMUM,
// typefinding is stopped immediately and the found caps will be returned right
// away. Otherwise, all available typefind functions will the tried, and the
// caps with the highest probability will be returned, or NULL if the content of
// the buffer could not be identified.
//
// Free-function: gst_caps_unref.
//
// The function takes the following parameters:
//
//   - obj (optional): object doing the typefinding, or NULL (used for logging).
//   - buf with data to typefind.
//
// The function returns the following values:
//
//   - prob (optional): location to store the probability of the found caps,
//     or NULL.
//   - caps (optional) corresponding to the data, or NULL if no type could be
//     found. The caller should free the caps returned with gst_caps_unref().
func TypeFindHelperForBuffer(obj gst.GstObjector, buf *gst.Buffer) (gst.TypeFindProbability, *gst.Caps) {
	var _arg1 *C.GstObject             // out
	var _arg2 *C.GstBuffer             // out
	var _arg3 C.GstTypeFindProbability // in
	var _cret *C.GstCaps               // in

	if obj != nil {
		_arg1 = (*C.GstObject)(unsafe.Pointer(coreglib.BaseObject(obj).Native()))
	}
	_arg2 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buf)))

	_cret = C.gst_type_find_helper_for_buffer(_arg1, _arg2, &_arg3)
	runtime.KeepAlive(obj)
	runtime.KeepAlive(buf)

	var _prob gst.TypeFindProbability // out
	var _caps *gst.Caps               // out

	_prob = gst.TypeFindProbability(_arg3)
	if _cret != nil {
		_caps = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_caps)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _prob, _caps
}

// TypeFindHelperForBufferWithCaps (gst_type_find_helper_for_buffer_with_caps)
// tries to find if type of media contained in the given Buffer, matches caps
// specified, assumption being that the buffer represents the beginning of the
// stream or file.
//
// Tries to find what type of data is contained in the given data, the
// assumption being that the data represents the beginning of the stream or
// file.
//
// Only the typefinder matching the given caps will be called, if found. The
// caps with the highest probability will be returned, or NULL if the content of
// the data could not be identified.
//
// Free-function: gst_caps_unref.
//
// The function takes the following parameters:
//
//   - obj (optional): object doing the typefinding, or NULL (used for logging).
//   - buf with data to typefind.
//   - caps of the media.
//
// The function returns the following values:
//
//   - prob (optional): location to store the probability of the found caps,
//     or NULL.
//   - ret (optional) corresponding to the data, or NULL if no type could be
//     found. The caller should free the caps returned with gst_caps_unref().
func TypeFindHelperForBufferWithCaps(obj gst.GstObjector, buf *gst.Buffer, caps *gst.Caps) (gst.TypeFindProbability, *gst.Caps) {
	var _arg1 *C.GstObject             // out
	var _arg2 *C.GstBuffer             // out
	var _arg3 *C.GstCaps               // out
	var _arg4 C.GstTypeFindProbability // in
	var _cret *C.GstCaps               // in

	if obj != nil {
		_arg1 = (*C.GstObject)(unsafe.Pointer(coreglib.BaseObject(obj).Native()))
	}
	_arg2 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buf)))
	_arg3 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C.gst_type_find_helper_for_buffer_with_caps(_arg1, _arg2, _arg3, &_arg4)
	runtime.KeepAlive(obj)
	runtime.KeepAlive(buf)
	runtime.KeepAlive(caps)

	var _prob gst.TypeFindProbability // out
	var _ret *gst.Caps                // out

	_prob = gst.TypeFindProbability(_arg4)
	if _cret != nil {
		_ret = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_ret)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _prob, _ret
}

// TypeFindHelperForBufferWithExtension
// (gst_type_find_helper_for_buffer_with_extension) tries to find what type of
// data is contained in the given Buffer, the assumption being that the buffer
// represents the beginning of the stream or file.
//
// All available typefinders will be called on the data in order of rank.
// If a typefinding function returns a probability of GST_TYPE_FIND_MAXIMUM,
// typefinding is stopped immediately and the found caps will be returned right
// away. Otherwise, all available typefind functions will the tried, and the
// caps with the highest probability will be returned, or NULL if the content of
// the buffer could not be identified.
//
// When extension is not NULL, this function will first try the typefind
// functions for the given extension, which might speed up the typefinding in
// many cases.
//
// Free-function: gst_caps_unref.
//
// The function takes the following parameters:
//
//   - obj (optional): object doing the typefinding, or NULL (used for logging).
//   - buf with data to typefind.
//   - extension (optional) of the media, or NULL.
//
// The function returns the following values:
//
//   - prob (optional): location to store the probability of the found caps,
//     or NULL.
//   - caps (optional) corresponding to the data, or NULL if no type could be
//     found. The caller should free the caps returned with gst_caps_unref().
func TypeFindHelperForBufferWithExtension(obj gst.GstObjector, buf *gst.Buffer, extension string) (gst.TypeFindProbability, *gst.Caps) {
	var _arg1 *C.GstObject             // out
	var _arg2 *C.GstBuffer             // out
	var _arg3 *C.gchar                 // out
	var _arg4 C.GstTypeFindProbability // in
	var _cret *C.GstCaps               // in

	if obj != nil {
		_arg1 = (*C.GstObject)(unsafe.Pointer(coreglib.BaseObject(obj).Native()))
	}
	_arg2 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buf)))
	if extension != "" {
		_arg3 = (*C.gchar)(unsafe.Pointer(C.CString(extension)))
		defer C.free(unsafe.Pointer(_arg3))
	}

	_cret = C.gst_type_find_helper_for_buffer_with_extension(_arg1, _arg2, _arg3, &_arg4)
	runtime.KeepAlive(obj)
	runtime.KeepAlive(buf)
	runtime.KeepAlive(extension)

	var _prob gst.TypeFindProbability // out
	var _caps *gst.Caps               // out

	_prob = gst.TypeFindProbability(_arg4)
	if _cret != nil {
		_caps = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_caps)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _prob, _caps
}

// TypeFindHelperForData (gst_type_find_helper_for_data) tries to find what type
// of data is contained in the given data, the assumption being that the data
// represents the beginning of the stream or file.
//
// All available typefinders will be called on the data in order of rank.
// If a typefinding function returns a probability of GST_TYPE_FIND_MAXIMUM,
// typefinding is stopped immediately and the found caps will be returned right
// away. Otherwise, all available typefind functions will the tried, and the
// caps with the highest probability will be returned, or NULL if the content of
// data could not be identified.
//
// Free-function: gst_caps_unref.
//
// The function takes the following parameters:
//
//   - obj (optional): object doing the typefinding, or NULL (used for logging).
//   - data: * a pointer with data to typefind.
//
// The function returns the following values:
//
//   - prob (optional): location to store the probability of the found caps,
//     or NULL.
//   - caps (optional) corresponding to the data, or NULL if no type could be
//     found. The caller should free the caps returned with gst_caps_unref().
func TypeFindHelperForData(obj gst.GstObjector, data []byte) (gst.TypeFindProbability, *gst.Caps) {
	var _arg1 *C.GstObject // out
	var _arg2 *C.guint8    // out
	var _arg3 C.gsize
	var _arg4 C.GstTypeFindProbability // in
	var _cret *C.GstCaps               // in

	if obj != nil {
		_arg1 = (*C.GstObject)(unsafe.Pointer(coreglib.BaseObject(obj).Native()))
	}
	_arg3 = (C.gsize)(len(data))
	if len(data) > 0 {
		_arg2 = (*C.guint8)(unsafe.Pointer(&data[0]))
	}

	_cret = C.gst_type_find_helper_for_data(_arg1, _arg2, _arg3, &_arg4)
	runtime.KeepAlive(obj)
	runtime.KeepAlive(data)

	var _prob gst.TypeFindProbability // out
	var _caps *gst.Caps               // out

	_prob = gst.TypeFindProbability(_arg4)
	if _cret != nil {
		_caps = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_caps)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _prob, _caps
}

// TypeFindHelperForDataWithCaps (gst_type_find_helper_for_data_with_caps)
// tries to find if type of media contained in the given data, matches the caps
// specified, assumption being that the data represents the beginning of the
// stream or file.
//
// Only the typefinder matching the given caps will be called, if found. The
// caps with the highest probability will be returned, or NULL if the content of
// the data could not be identified.
//
// Free-function: gst_caps_unref.
//
// The function takes the following parameters:
//
//   - obj (optional): object doing the typefinding, or NULL (used for logging).
//   - data: pointer with data to typefind.
//   - caps of the media.
//
// The function returns the following values:
//
//   - prob (optional): location to store the probability of the found caps,
//     or NULL.
//   - ret (optional) corresponding to the data, or NULL if no type could be
//     found. The caller should free the caps returned with gst_caps_unref().
func TypeFindHelperForDataWithCaps(obj gst.GstObjector, data []byte, caps *gst.Caps) (gst.TypeFindProbability, *gst.Caps) {
	var _arg1 *C.GstObject // out
	var _arg2 *C.guint8    // out
	var _arg3 C.gsize
	var _arg4 *C.GstCaps               // out
	var _arg5 C.GstTypeFindProbability // in
	var _cret *C.GstCaps               // in

	if obj != nil {
		_arg1 = (*C.GstObject)(unsafe.Pointer(coreglib.BaseObject(obj).Native()))
	}
	_arg3 = (C.gsize)(len(data))
	if len(data) > 0 {
		_arg2 = (*C.guint8)(unsafe.Pointer(&data[0]))
	}
	_arg4 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C.gst_type_find_helper_for_data_with_caps(_arg1, _arg2, _arg3, _arg4, &_arg5)
	runtime.KeepAlive(obj)
	runtime.KeepAlive(data)
	runtime.KeepAlive(caps)

	var _prob gst.TypeFindProbability // out
	var _ret *gst.Caps                // out

	_prob = gst.TypeFindProbability(_arg5)
	if _cret != nil {
		_ret = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_ret)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _prob, _ret
}

// TypeFindHelperForDataWithExtension
// (gst_type_find_helper_for_data_with_extension) tries to find what type of
// data is contained in the given data, the assumption being that the data
// represents the beginning of the stream or file.
//
// All available typefinders will be called on the data in order of rank.
// If a typefinding function returns a probability of GST_TYPE_FIND_MAXIMUM,
// typefinding is stopped immediately and the found caps will be returned right
// away. Otherwise, all available typefind functions will the tried, and the
// caps with the highest probability will be returned, or NULL if the content of
// data could not be identified.
//
// When extension is not NULL, this function will first try the typefind
// functions for the given extension, which might speed up the typefinding in
// many cases.
//
// Free-function: gst_caps_unref.
//
// The function takes the following parameters:
//
//   - obj (optional): object doing the typefinding, or NULL (used for logging).
//   - data: * a pointer with data to typefind.
//   - extension (optional) of the media, or NULL.
//
// The function returns the following values:
//
//   - prob (optional): location to store the probability of the found caps,
//     or NULL.
//   - caps (optional) corresponding to the data, or NULL if no type could be
//     found. The caller should free the caps returned with gst_caps_unref().
func TypeFindHelperForDataWithExtension(obj gst.GstObjector, data []byte, extension string) (gst.TypeFindProbability, *gst.Caps) {
	var _arg1 *C.GstObject // out
	var _arg2 *C.guint8    // out
	var _arg3 C.gsize
	var _arg4 *C.gchar                 // out
	var _arg5 C.GstTypeFindProbability // in
	var _cret *C.GstCaps               // in

	if obj != nil {
		_arg1 = (*C.GstObject)(unsafe.Pointer(coreglib.BaseObject(obj).Native()))
	}
	_arg3 = (C.gsize)(len(data))
	if len(data) > 0 {
		_arg2 = (*C.guint8)(unsafe.Pointer(&data[0]))
	}
	if extension != "" {
		_arg4 = (*C.gchar)(unsafe.Pointer(C.CString(extension)))
		defer C.free(unsafe.Pointer(_arg4))
	}

	_cret = C.gst_type_find_helper_for_data_with_extension(_arg1, _arg2, _arg3, _arg4, &_arg5)
	runtime.KeepAlive(obj)
	runtime.KeepAlive(data)
	runtime.KeepAlive(extension)

	var _prob gst.TypeFindProbability // out
	var _caps *gst.Caps               // out

	_prob = gst.TypeFindProbability(_arg5)
	if _cret != nil {
		_caps = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_caps)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _prob, _caps
}

// TypeFindHelperForExtension (gst_type_find_helper_for_extension) tries to find
// the best Caps associated with extension.
//
// All available typefinders will be checked against the extension in order
// of rank. The caps of the first typefinder that can handle extension will be
// returned.
//
// Free-function: gst_caps_unref.
//
// The function takes the following parameters:
//
//   - obj (optional): object doing the typefinding, or NULL (used for logging).
//   - extension: extension.
//
// The function returns the following values:
//
//   - caps (optional) corresponding to extension, or NULL if no type could be
//     found. The caller should free the caps returned with gst_caps_unref().
func TypeFindHelperForExtension(obj gst.GstObjector, extension string) *gst.Caps {
	var _arg1 *C.GstObject // out
	var _arg2 *C.gchar     // out
	var _cret *C.GstCaps   // in

	if obj != nil {
		_arg1 = (*C.GstObject)(unsafe.Pointer(coreglib.BaseObject(obj).Native()))
	}
	_arg2 = (*C.gchar)(unsafe.Pointer(C.CString(extension)))
	defer C.free(unsafe.Pointer(_arg2))

	_cret = C.gst_type_find_helper_for_extension(_arg1, _arg2)
	runtime.KeepAlive(obj)
	runtime.KeepAlive(extension)

	var _caps *gst.Caps // out

	if _cret != nil {
		_caps = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_caps)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _caps
}

// TypeFindListFactoriesForCaps (gst_type_find_list_factories_for_caps) tries to
// find the best TypeFindFactory associated with caps.
//
// The typefinder that can handle caps will be returned.
//
// Free-function: g_list_free.
//
// The function takes the following parameters:
//
//   - obj (optional): object doing the typefinding, or NULL (used for logging).
//   - caps of the media.
//
// The function returns the following values:
//
//   - list (optional) of TypeFindFactory corresponding to caps, or NULL if
//     no typefinder could be found. Caller should free the returned list with
//     g_list_free() and list elements with gst_object_unref().
func TypeFindListFactoriesForCaps(obj gst.GstObjector, caps *gst.Caps) []*gst.TypeFindFactory {
	var _arg1 *C.GstObject // out
	var _arg2 *C.GstCaps   // out
	var _cret *C.GList     // in

	if obj != nil {
		_arg1 = (*C.GstObject)(unsafe.Pointer(coreglib.BaseObject(obj).Native()))
	}
	_arg2 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C.gst_type_find_list_factories_for_caps(_arg1, _arg2)
	runtime.KeepAlive(obj)
	runtime.KeepAlive(caps)

	var _list []*gst.TypeFindFactory // out

	if _cret != nil {
		_list = make([]*gst.TypeFindFactory, 0, gextras.ListSize(unsafe.Pointer(_cret)))
		gextras.MoveList(unsafe.Pointer(_cret), true, func(v unsafe.Pointer) {
			src := (*C.GstTypeFindFactory)(v)
			var dst *gst.TypeFindFactory // out
			{
				obj := coreglib.AssumeOwnership(unsafe.Pointer(src))
				dst = &gst.TypeFindFactory{
					PluginFeature: gst.PluginFeature{
						GstObject: gst.GstObject{
							InitiallyUnowned: coreglib.InitiallyUnowned{
								Object: obj,
							},
						},
					},
				}
			}
			_list = append(_list, dst)
		})
	}

	return _list
}

// Adapter (GstAdapter): this class is for elements that receive buffers in an
// undesired size. While for example raw video contains one image per buffer,
// the same is not true for a lot of other formats, especially those that come
// directly from a file. So if you have undefined buffer sizes and require a
// specific size, this object is for you.
//
// An adapter is created with gst_adapter_new(). It can be freed again with
// g_object_unref().
//
// The theory of operation is like this: All buffers received are put into the
// adapter using gst_adapter_push() and the data is then read back in chunks
// of the desired size using gst_adapter_map()/gst_adapter_unmap() and/or
// gst_adapter_copy(). After the data has been processed, it is freed using
// gst_adapter_unmap().
//
// Other methods such as gst_adapter_take() and gst_adapter_take_buffer()
// combine gst_adapter_map() and gst_adapter_unmap() in one method and are
// potentially more convenient for some use cases.
//
// For example, a sink pad's chain function that needs to pass data to a library
// in 512-byte chunks could be implemented like this:
//
//	static GstFlowReturn
//	sink_pad_chain (GstPad *pad, GstObject *parent, GstBuffer *buffer)
//	{
//	  MyElement *this;
//	  GstAdapter *adapter;
//	  GstFlowReturn ret = GST_FLOW_OK;
//
//	  this = MY_ELEMENT (parent);
//
//	  adapter = this->adapter;
//
//	  // put buffer into adapter
//	  gst_adapter_push (adapter, buffer);
//
//	  // while we can read out 512 bytes, process them
//	  while (gst_adapter_available (adapter) >= 512 && ret == GST_FLOW_OK) {
//	    const guint8 *data = gst_adapter_map (adapter, 512);
//	    // use flowreturn as an error value
//	    ret = my_library_foo (data);
//	    gst_adapter_unmap (adapter);
//	    gst_adapter_flush (adapter, 512);
//	  }
//	  return ret;
//	}
//
// For another example, a simple element inside GStreamer that uses Adapter is
// the libvisual element.
//
// An element using Adapter in its sink pad chain function should ensure that
// when the FLUSH_STOP event is received, that any queued data is cleared using
// gst_adapter_clear(). Data should also be cleared or processed on EOS and when
// changing state from GST_STATE_PAUSED to GST_STATE_READY.
//
// Also check the GST_BUFFER_FLAG_DISCONT flag on the buffer. Some elements
// might need to clear the adapter after a discontinuity.
//
// The adapter will keep track of the timestamps of the buffers that were
// pushed. The last seen timestamp before the current position can be queried
// with gst_adapter_prev_pts(). This function can optionally return the number
// of bytes between the start of the buffer that carried the timestamp and
// the current adapter position. The distance is useful when dealing with, for
// example, raw audio samples because it allows you to calculate the timestamp
// of the current adapter position by using the last seen timestamp and the
// amount of bytes since. Additionally, the gst_adapter_prev_pts_at_offset() can
// be used to determine the last seen timestamp at a particular offset in the
// adapter.
//
// The adapter will also keep track of the offset of the buffers
// (T_BUFFER_OFFSET) that were pushed. The last seen offset before the current
// position can be queried with gst_adapter_prev_offset(). This function can
// optionally return the number of bytes between the start of the buffer that
// carried the offset and the current adapter position.
//
// Additionally the adapter also keeps track of the PTS, DTS and
// buffer offset at the last discontinuity, which can be retrieved
// with gst_adapter_pts_at_discont(), gst_adapter_dts_at_discont() and
// gst_adapter_offset_at_discont(). The number of bytes that were consumed since
// then can be queried with gst_adapter_distance_from_discont().
//
// A last thing to note is that while Adapter is pretty optimized, merging
// buffers still might be an operation that requires a malloc() and memcpy()
// operation, and these operations are not the fastest. Because of this,
// some functions like gst_adapter_available_fast() are provided to help speed
// up such cases should you want to. To avoid repeated memory allocations,
// gst_adapter_copy() can be used to copy data into a (statically allocated)
// user provided buffer.
//
// Adapter is not MT safe. All operations on an adapter must be serialized
// by the caller. This is not normally a problem, however, as the normal use
// case of Adapter is inside one pad's chain function, in which case access is
// serialized via the pad's STREAM_LOCK.
//
// Note that gst_adapter_push() takes ownership of the buffer passed.
// Use gst_buffer_ref() before pushing it into the adapter if you still want to
// access the buffer later. The adapter will never modify the data in the buffer
// pushed in it.
type Adapter struct {
	_ [0]func() // equal guard
	*coreglib.Object
}

var (
	_ coreglib.Objector = (*Adapter)(nil)
)

// Adapterer describes types inherited from Adapter.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type Adapterer interface {
	coreglib.Objector

	// Available (gst_adapter_available) gets the maximum amount of bytes
	// available, that is it returns the maximum value that can be supplied to
	// gst_adapter_map() without that function returning NULL.
	Available() uint
	// AvailableFast (gst_adapter_available_fast) gets the maximum number of
	// bytes that are immediately available without requiring any expensive
	// operations (like copying the data into a temporary buffer).
	AvailableFast() uint
	// Clear (gst_adapter_clear) removes all buffers from adapter.
	Clear()
	// Copy (gst_adapter_copy_bytes): similar to gst_adapter_copy, but more
	// suitable for language bindings.
	Copy(offset, size uint) *glib.Bytes
	// DistanceFromDiscont (gst_adapter_distance_from_discont): get the distance
	// in bytes since the last buffer with the GST_BUFFER_FLAG_DISCONT flag.
	DistanceFromDiscont() uint64
	// DtsAtDiscont (gst_adapter_dts_at_discont): get the DTS that was
	// on the last buffer with the GST_BUFFER_FLAG_DISCONT flag, or
	// GST_CLOCK_TIME_NONE.
	DtsAtDiscont() gst.ClockTime
	// Flush (gst_adapter_flush) flushes the first flush bytes in the adapter.
	Flush(flush uint)
	// Buffer (gst_adapter_get_buffer) returns a Buffer containing the first
	// nbytes of the adapter, but does not flush them from the adapter.
	Buffer(nbytes uint) *gst.Buffer
	// BufferFast (gst_adapter_get_buffer_fast) returns a Buffer containing the
	// first nbytes of the adapter, but does not flush them from the adapter.
	BufferFast(nbytes uint) *gst.Buffer
	// BufferList (gst_adapter_get_buffer_list) returns a BufferList of buffers
	// containing the first nbytes bytes of the adapter but does not flush them
	// from the adapter.
	BufferList(nbytes uint) *gst.BufferList
	// List (gst_adapter_get_list) returns a #GList of buffers containing the
	// first nbytes bytes of the adapter, but does not flush them from the
	// adapter.
	List(nbytes uint) []*gst.Buffer
	// MaskedScanUint32 (gst_adapter_masked_scan_uint32): scan for pattern
	// pattern with applied mask mask in the adapter data, starting from offset
	// offset.
	MaskedScanUint32(mask, pattern uint32, offset, size uint) int
	// MaskedScanUint32Peek (gst_adapter_masked_scan_uint32_peek): scan for
	// pattern pattern with applied mask mask in the adapter data, starting from
	// offset offset.
	MaskedScanUint32Peek(mask, pattern uint32, offset, size uint) (uint32, int)
	// OffsetAtDiscont (gst_adapter_offset_at_discont): get the offset
	// that was on the last buffer with the GST_BUFFER_FLAG_DISCONT flag,
	// or GST_BUFFER_OFFSET_NONE.
	OffsetAtDiscont() uint64
	// PrevDts (gst_adapter_prev_dts): get the dts that was before the current
	// byte in the adapter.
	PrevDts() (uint64, gst.ClockTime)
	// PrevDtsAtOffset (gst_adapter_prev_dts_at_offset): get the dts that was
	// before the byte at offset offset in the adapter.
	PrevDtsAtOffset(offset uint) (uint64, gst.ClockTime)
	// PrevOffset (gst_adapter_prev_offset): get the offset that was before the
	// current byte in the adapter.
	PrevOffset() (distance, guint64 uint64)
	// PrevPts (gst_adapter_prev_pts): get the pts that was before the current
	// byte in the adapter.
	PrevPts() (uint64, gst.ClockTime)
	// PrevPtsAtOffset (gst_adapter_prev_pts_at_offset): get the pts that was
	// before the byte at offset offset in the adapter.
	PrevPtsAtOffset(offset uint) (uint64, gst.ClockTime)
	// PtsAtDiscont (gst_adapter_pts_at_discont): get the PTS that was
	// on the last buffer with the GST_BUFFER_FLAG_DISCONT flag, or
	// GST_CLOCK_TIME_NONE.
	PtsAtDiscont() gst.ClockTime
	// Push (gst_adapter_push) adds the data from buf to the data stored inside
	// adapter and takes ownership of the buffer.
	Push(buf *gst.Buffer)
	// TakeBuffer (gst_adapter_take_buffer) returns a Buffer containing the
	// first nbytes bytes of the adapter.
	TakeBuffer(nbytes uint) *gst.Buffer
	// TakeBufferFast (gst_adapter_take_buffer_fast) returns a Buffer containing
	// the first nbytes of the adapter.
	TakeBufferFast(nbytes uint) *gst.Buffer
	// TakeBufferList (gst_adapter_take_buffer_list) returns a BufferList of
	// buffers containing the first nbytes bytes of the adapter.
	TakeBufferList(nbytes uint) *gst.BufferList
	// TakeList (gst_adapter_take_list) returns a #GList of buffers containing
	// the first nbytes bytes of the adapter.
	TakeList(nbytes uint) []*gst.Buffer
	// Unmap (gst_adapter_unmap) releases the memory obtained with the last
	// gst_adapter_map().
	Unmap()

	baseAdapter() *Adapter
}

var _ Adapterer = (*Adapter)(nil)

func wrapAdapter(obj *coreglib.Object) *Adapter {
	return &Adapter{
		Object: obj,
	}
}

func marshalAdapter(p uintptr) (interface{}, error) {
	return wrapAdapter(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (adapter *Adapter) baseAdapter() *Adapter {
	return adapter
}

// BaseAdapter returns the underlying base object.
func BaseAdapter(obj Adapterer) *Adapter {
	return obj.baseAdapter()
}

// NewAdapter (gst_adapter_new) creates a new Adapter. Free with
// g_object_unref().
//
// The function returns the following values:
//
//   - adapter: new Adapter.
func NewAdapter() *Adapter {
	var _cret *C.GstAdapter // in

	_cret = C.gst_adapter_new()

	var _adapter *Adapter // out

	_adapter = wrapAdapter(coreglib.AssumeOwnership(unsafe.Pointer(_cret)))

	return _adapter
}

// Available (gst_adapter_available) gets the maximum amount of bytes
// available, that is it returns the maximum value that can be supplied to
// gst_adapter_map() without that function returning NULL.
//
// The function returns the following values:
//
//   - gsize: number of bytes available in adapter.
func (adapter *Adapter) Available() uint {
	var _arg0 *C.GstAdapter // out
	var _cret C.gsize       // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))

	_cret = C.gst_adapter_available(_arg0)
	runtime.KeepAlive(adapter)

	var _gsize uint // out

	_gsize = uint(_cret)

	return _gsize
}

// AvailableFast (gst_adapter_available_fast) gets the maximum number of bytes
// that are immediately available without requiring any expensive operations
// (like copying the data into a temporary buffer).
//
// The function returns the following values:
//
//   - gsize: number of bytes that are available in adapter without expensive
//     operations.
func (adapter *Adapter) AvailableFast() uint {
	var _arg0 *C.GstAdapter // out
	var _cret C.gsize       // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))

	_cret = C.gst_adapter_available_fast(_arg0)
	runtime.KeepAlive(adapter)

	var _gsize uint // out

	_gsize = uint(_cret)

	return _gsize
}

// Clear (gst_adapter_clear) removes all buffers from adapter.
func (adapter *Adapter) Clear() {
	var _arg0 *C.GstAdapter // out

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))

	C.gst_adapter_clear(_arg0)
	runtime.KeepAlive(adapter)
}

// Copy (gst_adapter_copy_bytes): similar to gst_adapter_copy, but more suitable
// for language bindings. size bytes of data starting at offset will be copied
// out of the buffers contained in adapter and into a new #GBytes structure
// which is returned. Depending on the value of the size argument an empty
// #GBytes structure may be returned.
//
// The function takes the following parameters:
//
//   - offset bytes offset in the adapter to start from.
//   - size: number of bytes to copy.
//
// The function returns the following values:
//
//   - bytes: new #GBytes structure containing the copied data.
func (adapter *Adapter) Copy(offset, size uint) *glib.Bytes {
	var _arg0 *C.GstAdapter // out
	var _arg1 C.gsize       // out
	var _arg2 C.gsize       // out
	var _cret *C.GBytes     // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))
	_arg1 = C.gsize(offset)
	_arg2 = C.gsize(size)

	_cret = C.gst_adapter_copy_bytes(_arg0, _arg1, _arg2)
	runtime.KeepAlive(adapter)
	runtime.KeepAlive(offset)
	runtime.KeepAlive(size)

	var _bytes *glib.Bytes // out

	_bytes = (*glib.Bytes)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_bytes)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.g_bytes_unref((*C.GBytes)(intern.C))
		},
	)

	return _bytes
}

// DistanceFromDiscont (gst_adapter_distance_from_discont): get the distance in
// bytes since the last buffer with the GST_BUFFER_FLAG_DISCONT flag.
//
// The distance will be reset to 0 for all buffers with GST_BUFFER_FLAG_DISCONT
// on them, and then calculated for all other following buffers based on their
// size.
//
// The function returns the following values:
//
//   - guint64: offset. Can be GST_BUFFER_OFFSET_NONE.
func (adapter *Adapter) DistanceFromDiscont() uint64 {
	var _arg0 *C.GstAdapter // out
	var _cret C.guint64     // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))

	_cret = C.gst_adapter_distance_from_discont(_arg0)
	runtime.KeepAlive(adapter)

	var _guint64 uint64 // out

	_guint64 = uint64(_cret)

	return _guint64
}

// DtsAtDiscont (gst_adapter_dts_at_discont): get the DTS that was on the last
// buffer with the GST_BUFFER_FLAG_DISCONT flag, or GST_CLOCK_TIME_NONE.
//
// The function returns the following values:
//
//   - clockTime: DTS at the last discont or GST_CLOCK_TIME_NONE.
func (adapter *Adapter) DtsAtDiscont() gst.ClockTime {
	var _arg0 *C.GstAdapter  // out
	var _cret C.GstClockTime // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))

	_cret = C.gst_adapter_dts_at_discont(_arg0)
	runtime.KeepAlive(adapter)

	var _clockTime gst.ClockTime // out

	_clockTime = gst.ClockTime(_cret)

	return _clockTime
}

// Flush (gst_adapter_flush) flushes the first flush bytes in the adapter.
// The caller must ensure that at least this many bytes are available.
//
// See also: gst_adapter_map(), gst_adapter_unmap().
//
// The function takes the following parameters:
//
//   - flush: number of bytes to flush.
func (adapter *Adapter) Flush(flush uint) {
	var _arg0 *C.GstAdapter // out
	var _arg1 C.gsize       // out

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))
	_arg1 = C.gsize(flush)

	C.gst_adapter_flush(_arg0, _arg1)
	runtime.KeepAlive(adapter)
	runtime.KeepAlive(flush)
}

// Buffer (gst_adapter_get_buffer) returns a Buffer containing the first
// nbytes of the adapter, but does not flush them from the adapter. See
// gst_adapter_take_buffer() for details.
//
// Caller owns a reference to the returned buffer. gst_buffer_unref() after
// usage.
//
// Free-function: gst_buffer_unref.
//
// The function takes the following parameters:
//
//   - nbytes: number of bytes to get.
//
// The function returns the following values:
//
//   - buffer (optional) containing the first nbytes of the adapter, or NULL if
//     nbytes bytes are not available. gst_buffer_unref() when no longer needed.
func (adapter *Adapter) Buffer(nbytes uint) *gst.Buffer {
	var _arg0 *C.GstAdapter // out
	var _arg1 C.gsize       // out
	var _cret *C.GstBuffer  // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))
	_arg1 = C.gsize(nbytes)

	_cret = C.gst_adapter_get_buffer(_arg0, _arg1)
	runtime.KeepAlive(adapter)
	runtime.KeepAlive(nbytes)

	var _buffer *gst.Buffer // out

	if _cret != nil {
		_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_buffer)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _buffer
}

// BufferFast (gst_adapter_get_buffer_fast) returns a Buffer containing the
// first nbytes of the adapter, but does not flush them from the adapter.
// See gst_adapter_take_buffer_fast() for details.
//
// Caller owns a reference to the returned buffer. gst_buffer_unref() after
// usage.
//
// Free-function: gst_buffer_unref.
//
// The function takes the following parameters:
//
//   - nbytes: number of bytes to get.
//
// The function returns the following values:
//
//   - buffer (optional) containing the first nbytes of the adapter, or NULL if
//     nbytes bytes are not available. gst_buffer_unref() when no longer needed.
func (adapter *Adapter) BufferFast(nbytes uint) *gst.Buffer {
	var _arg0 *C.GstAdapter // out
	var _arg1 C.gsize       // out
	var _cret *C.GstBuffer  // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))
	_arg1 = C.gsize(nbytes)

	_cret = C.gst_adapter_get_buffer_fast(_arg0, _arg1)
	runtime.KeepAlive(adapter)
	runtime.KeepAlive(nbytes)

	var _buffer *gst.Buffer // out

	if _cret != nil {
		_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_buffer)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _buffer
}

// BufferList (gst_adapter_get_buffer_list) returns a BufferList of buffers
// containing the first nbytes bytes of the adapter but does not flush them from
// the adapter. See gst_adapter_take_buffer_list() for details.
//
// Caller owns the returned list. Call gst_buffer_list_unref() to free the list
// after usage.
//
// The function takes the following parameters:
//
//   - nbytes: number of bytes to get.
//
// The function returns the following values:
//
//   - bufferList (optional) of buffers containing the first nbytes of the
//     adapter, or NULL if nbytes bytes are not available.
func (adapter *Adapter) BufferList(nbytes uint) *gst.BufferList {
	var _arg0 *C.GstAdapter    // out
	var _arg1 C.gsize          // out
	var _cret *C.GstBufferList // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))
	_arg1 = C.gsize(nbytes)

	_cret = C.gst_adapter_get_buffer_list(_arg0, _arg1)
	runtime.KeepAlive(adapter)
	runtime.KeepAlive(nbytes)

	var _bufferList *gst.BufferList // out

	if _cret != nil {
		_bufferList = (*gst.BufferList)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_bufferList)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _bufferList
}

// List (gst_adapter_get_list) returns a #GList of buffers containing the first
// nbytes bytes of the adapter, but does not flush them from the adapter.
// See gst_adapter_take_list() for details.
//
// Caller owns returned list and contained buffers. gst_buffer_unref() each
// buffer in the list before freeing the list after usage.
//
// The function takes the following parameters:
//
//   - nbytes: number of bytes to get.
//
// The function returns the following values:
//
//   - list (optional) of buffers containing the first nbytes of the adapter,
//     or NULL if nbytes bytes are not available.
func (adapter *Adapter) List(nbytes uint) []*gst.Buffer {
	var _arg0 *C.GstAdapter // out
	var _arg1 C.gsize       // out
	var _cret *C.GList      // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))
	_arg1 = C.gsize(nbytes)

	_cret = C.gst_adapter_get_list(_arg0, _arg1)
	runtime.KeepAlive(adapter)
	runtime.KeepAlive(nbytes)

	var _list []*gst.Buffer // out

	if _cret != nil {
		_list = make([]*gst.Buffer, 0, gextras.ListSize(unsafe.Pointer(_cret)))
		gextras.MoveList(unsafe.Pointer(_cret), true, func(v unsafe.Pointer) {
			src := (*C.GstBuffer)(v)
			var dst *gst.Buffer // out
			dst = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(src)))
			runtime.SetFinalizer(
				gextras.StructIntern(unsafe.Pointer(dst)),
				func(intern *struct{ C unsafe.Pointer }) {
					C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
				})
			_list = append(_list, dst)
		})
	}

	return _list
}

// MaskedScanUint32 (gst_adapter_masked_scan_uint32): scan for pattern pattern
// with applied mask mask in the adapter data, starting from offset offset.
//
// The bytes in pattern and mask are interpreted left-to-right, regardless of
// endianness. All four bytes of the pattern must be present in the adapter for
// it to match, even if the first or last bytes are masked out.
//
// It is an error to call this function without making sure that there is enough
// data (offset+size bytes) in the adapter.
//
// This function calls gst_adapter_masked_scan_uint32_peek() passing NULL for
// value.
//
// The function takes the following parameters:
//
//   - mask to apply to data before matching against pattern.
//   - pattern to match (after mask is applied).
//   - offset into the adapter data from which to start scanning, returns the
//     last scanned position.
//   - size: number of bytes to scan from offset.
//
// The function returns the following values:
//
//   - gssize: offset of the first match, or -1 if no match was found.
//
//     Example:
//
//     // Assume the adapter contains 0x00 0x01 0x02 ... 0xfe 0xff
//
//     gst_adapter_masked_scan_uint32 (adapter, 0xffffffff, 0x00010203, 0, 256);
//     // -> returns 0 gst_adapter_masked_scan_uint32 (adapter, 0xffffffff,
//     0x00010203, 1, 255); // -> returns -1 gst_adapter_masked_scan_uint32
//     (adapter, 0xffffffff, 0x01020304, 1, 255); // -> returns 1
//     gst_adapter_masked_scan_uint32 (adapter, 0xffff, 0x0001, 0, 256);
//     // -> returns -1 gst_adapter_masked_scan_uint32 (adapter, 0xffff,
//     0x0203, 0, 256); // -> returns 0 gst_adapter_masked_scan_uint32
//     (adapter, 0xffff0000, 0x02030000, 0, 256); // -> returns 2
//     gst_adapter_masked_scan_uint32 (adapter, 0xffff0000, 0x02030000, 0, 4);
//     // -> returns -1.
func (adapter *Adapter) MaskedScanUint32(mask, pattern uint32, offset, size uint) int {
	var _arg0 *C.GstAdapter // out
	var _arg1 C.guint32     // out
	var _arg2 C.guint32     // out
	var _arg3 C.gsize       // out
	var _arg4 C.gsize       // out
	var _cret C.gssize      // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))
	_arg1 = C.guint32(mask)
	_arg2 = C.guint32(pattern)
	_arg3 = C.gsize(offset)
	_arg4 = C.gsize(size)

	_cret = C.gst_adapter_masked_scan_uint32(_arg0, _arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(adapter)
	runtime.KeepAlive(mask)
	runtime.KeepAlive(pattern)
	runtime.KeepAlive(offset)
	runtime.KeepAlive(size)

	var _gssize int // out

	_gssize = int(_cret)

	return _gssize
}

// MaskedScanUint32Peek (gst_adapter_masked_scan_uint32_peek): scan for pattern
// pattern with applied mask mask in the adapter data, starting from offset
// offset. If a match is found, the value that matched is returned through
// value, otherwise value is left untouched.
//
// The bytes in pattern and mask are interpreted left-to-right, regardless of
// endianness. All four bytes of the pattern must be present in the adapter for
// it to match, even if the first or last bytes are masked out.
//
// It is an error to call this function without making sure that there is enough
// data (offset+size bytes) in the adapter.
//
// The function takes the following parameters:
//
//   - mask to apply to data before matching against pattern.
//   - pattern to match (after mask is applied).
//   - offset into the adapter data from which to start scanning, returns the
//     last scanned position.
//   - size: number of bytes to scan from offset.
//
// The function returns the following values:
//
//   - value (optional): pointer to uint32 to return matching data.
//   - gssize: offset of the first match, or -1 if no match was found.
func (adapter *Adapter) MaskedScanUint32Peek(mask, pattern uint32, offset, size uint) (uint32, int) {
	var _arg0 *C.GstAdapter // out
	var _arg1 C.guint32     // out
	var _arg2 C.guint32     // out
	var _arg3 C.gsize       // out
	var _arg4 C.gsize       // out
	var _arg5 C.guint32     // in
	var _cret C.gssize      // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))
	_arg1 = C.guint32(mask)
	_arg2 = C.guint32(pattern)
	_arg3 = C.gsize(offset)
	_arg4 = C.gsize(size)

	_cret = C.gst_adapter_masked_scan_uint32_peek(_arg0, _arg1, _arg2, _arg3, _arg4, &_arg5)
	runtime.KeepAlive(adapter)
	runtime.KeepAlive(mask)
	runtime.KeepAlive(pattern)
	runtime.KeepAlive(offset)
	runtime.KeepAlive(size)

	var _value uint32 // out
	var _gssize int   // out

	_value = uint32(_arg5)
	_gssize = int(_cret)

	return _value, _gssize
}

// OffsetAtDiscont (gst_adapter_offset_at_discont): get the offset that
// was on the last buffer with the GST_BUFFER_FLAG_DISCONT flag, or
// GST_BUFFER_OFFSET_NONE.
//
// The function returns the following values:
//
//   - guint64: offset at the last discont or GST_BUFFER_OFFSET_NONE.
func (adapter *Adapter) OffsetAtDiscont() uint64 {
	var _arg0 *C.GstAdapter // out
	var _cret C.guint64     // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))

	_cret = C.gst_adapter_offset_at_discont(_arg0)
	runtime.KeepAlive(adapter)

	var _guint64 uint64 // out

	_guint64 = uint64(_cret)

	return _guint64
}

// PrevDts (gst_adapter_prev_dts): get the dts that was before the current byte
// in the adapter. When distance is given, the amount of bytes between the dts
// and the current position is returned.
//
// The dts is reset to GST_CLOCK_TIME_NONE and the distance is set to 0 when the
// adapter is first created or when it is cleared. This also means that before
// the first byte with a dts is removed from the adapter, the dts and distance
// returned are GST_CLOCK_TIME_NONE and 0 respectively.
//
// The function returns the following values:
//
//   - distance (optional): pointer to location for distance, or NULL.
//   - clockTime: previously seen dts.
func (adapter *Adapter) PrevDts() (uint64, gst.ClockTime) {
	var _arg0 *C.GstAdapter  // out
	var _arg1 C.guint64      // in
	var _cret C.GstClockTime // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))

	_cret = C.gst_adapter_prev_dts(_arg0, &_arg1)
	runtime.KeepAlive(adapter)

	var _distance uint64         // out
	var _clockTime gst.ClockTime // out

	_distance = uint64(_arg1)
	_clockTime = gst.ClockTime(_cret)

	return _distance, _clockTime
}

// PrevDtsAtOffset (gst_adapter_prev_dts_at_offset): get the dts that was before
// the byte at offset offset in the adapter. When distance is given, the amount
// of bytes between the dts and the current position is returned.
//
// The dts is reset to GST_CLOCK_TIME_NONE and the distance is set to 0 when the
// adapter is first created or when it is cleared. This also means that before
// the first byte with a dts is removed from the adapter, the dts and distance
// returned are GST_CLOCK_TIME_NONE and 0 respectively.
//
// The function takes the following parameters:
//
//   - offset in the adapter at which to get timestamp.
//
// The function returns the following values:
//
//   - distance (optional): pointer to location for distance, or NULL.
//   - clockTime: previously seen dts at given offset.
func (adapter *Adapter) PrevDtsAtOffset(offset uint) (uint64, gst.ClockTime) {
	var _arg0 *C.GstAdapter  // out
	var _arg1 C.gsize        // out
	var _arg2 C.guint64      // in
	var _cret C.GstClockTime // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))
	_arg1 = C.gsize(offset)

	_cret = C.gst_adapter_prev_dts_at_offset(_arg0, _arg1, &_arg2)
	runtime.KeepAlive(adapter)
	runtime.KeepAlive(offset)

	var _distance uint64         // out
	var _clockTime gst.ClockTime // out

	_distance = uint64(_arg2)
	_clockTime = gst.ClockTime(_cret)

	return _distance, _clockTime
}

// PrevOffset (gst_adapter_prev_offset): get the offset that was before the
// current byte in the adapter. When distance is given, the amount of bytes
// between the offset and the current position is returned.
//
// The offset is reset to GST_BUFFER_OFFSET_NONE and the distance is set to 0
// when the adapter is first created or when it is cleared. This also means that
// before the first byte with an offset is removed from the adapter, the offset
// and distance returned are GST_BUFFER_OFFSET_NONE and 0 respectively.
//
// The function returns the following values:
//
//   - distance (optional): pointer to a location for distance, or NULL.
//   - guint64 previous seen offset.
func (adapter *Adapter) PrevOffset() (distance, guint64 uint64) {
	var _arg0 *C.GstAdapter // out
	var _arg1 C.guint64     // in
	var _cret C.guint64     // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))

	_cret = C.gst_adapter_prev_offset(_arg0, &_arg1)
	runtime.KeepAlive(adapter)

	var _distance uint64 // out
	var _guint64 uint64  // out

	_distance = uint64(_arg1)
	_guint64 = uint64(_cret)

	return _distance, _guint64
}

// PrevPts (gst_adapter_prev_pts): get the pts that was before the current byte
// in the adapter. When distance is given, the amount of bytes between the pts
// and the current position is returned.
//
// The pts is reset to GST_CLOCK_TIME_NONE and the distance is set to 0 when the
// adapter is first created or when it is cleared. This also means that before
// the first byte with a pts is removed from the adapter, the pts and distance
// returned are GST_CLOCK_TIME_NONE and 0 respectively.
//
// The function returns the following values:
//
//   - distance (optional): pointer to location for distance, or NULL.
//   - clockTime: previously seen pts.
func (adapter *Adapter) PrevPts() (uint64, gst.ClockTime) {
	var _arg0 *C.GstAdapter  // out
	var _arg1 C.guint64      // in
	var _cret C.GstClockTime // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))

	_cret = C.gst_adapter_prev_pts(_arg0, &_arg1)
	runtime.KeepAlive(adapter)

	var _distance uint64         // out
	var _clockTime gst.ClockTime // out

	_distance = uint64(_arg1)
	_clockTime = gst.ClockTime(_cret)

	return _distance, _clockTime
}

// PrevPtsAtOffset (gst_adapter_prev_pts_at_offset): get the pts that was before
// the byte at offset offset in the adapter. When distance is given, the amount
// of bytes between the pts and the current position is returned.
//
// The pts is reset to GST_CLOCK_TIME_NONE and the distance is set to 0 when the
// adapter is first created or when it is cleared. This also means that before
// the first byte with a pts is removed from the adapter, the pts and distance
// returned are GST_CLOCK_TIME_NONE and 0 respectively.
//
// The function takes the following parameters:
//
//   - offset in the adapter at which to get timestamp.
//
// The function returns the following values:
//
//   - distance (optional): pointer to location for distance, or NULL.
//   - clockTime: previously seen pts at given offset.
func (adapter *Adapter) PrevPtsAtOffset(offset uint) (uint64, gst.ClockTime) {
	var _arg0 *C.GstAdapter  // out
	var _arg1 C.gsize        // out
	var _arg2 C.guint64      // in
	var _cret C.GstClockTime // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))
	_arg1 = C.gsize(offset)

	_cret = C.gst_adapter_prev_pts_at_offset(_arg0, _arg1, &_arg2)
	runtime.KeepAlive(adapter)
	runtime.KeepAlive(offset)

	var _distance uint64         // out
	var _clockTime gst.ClockTime // out

	_distance = uint64(_arg2)
	_clockTime = gst.ClockTime(_cret)

	return _distance, _clockTime
}

// PtsAtDiscont (gst_adapter_pts_at_discont): get the PTS that was on the last
// buffer with the GST_BUFFER_FLAG_DISCONT flag, or GST_CLOCK_TIME_NONE.
//
// The function returns the following values:
//
//   - clockTime: PTS at the last discont or GST_CLOCK_TIME_NONE.
func (adapter *Adapter) PtsAtDiscont() gst.ClockTime {
	var _arg0 *C.GstAdapter  // out
	var _cret C.GstClockTime // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))

	_cret = C.gst_adapter_pts_at_discont(_arg0)
	runtime.KeepAlive(adapter)

	var _clockTime gst.ClockTime // out

	_clockTime = gst.ClockTime(_cret)

	return _clockTime
}

// Push (gst_adapter_push) adds the data from buf to the data stored inside
// adapter and takes ownership of the buffer.
//
// The function takes the following parameters:
//
//   - buf to add to queue in the adapter.
func (adapter *Adapter) Push(buf *gst.Buffer) {
	var _arg0 *C.GstAdapter // out
	var _arg1 *C.GstBuffer  // out

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buf)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(buf)), nil)

	C.gst_adapter_push(_arg0, _arg1)
	runtime.KeepAlive(adapter)
	runtime.KeepAlive(buf)
}

// TakeBuffer (gst_adapter_take_buffer) returns a Buffer containing the first
// nbytes bytes of the adapter. The returned bytes will be flushed from the
// adapter. This function is potentially more performant than gst_adapter_take()
// since it can reuse the memory in pushed buffers by subbuffering or merging.
// This function will always return a buffer with a single memory region.
//
// Note that no assumptions should be made as to whether certain buffer flags
// such as the DISCONT flag are set on the returned buffer, or not. The caller
// needs to explicitly set or unset flags that should be set or unset.
//
// Since 1.6 this will also copy over all GstMeta of the input buffers except
// for meta with the GST_META_FLAG_POOLED flag or with the "memory" tag.
//
// Caller owns a reference to the returned buffer. gst_buffer_unref() after
// usage.
//
// Free-function: gst_buffer_unref.
//
// The function takes the following parameters:
//
//   - nbytes: number of bytes to take.
//
// The function returns the following values:
//
//   - buffer (optional) containing the first nbytes of the adapter, or NULL if
//     nbytes bytes are not available. gst_buffer_unref() when no longer needed.
func (adapter *Adapter) TakeBuffer(nbytes uint) *gst.Buffer {
	var _arg0 *C.GstAdapter // out
	var _arg1 C.gsize       // out
	var _cret *C.GstBuffer  // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))
	_arg1 = C.gsize(nbytes)

	_cret = C.gst_adapter_take_buffer(_arg0, _arg1)
	runtime.KeepAlive(adapter)
	runtime.KeepAlive(nbytes)

	var _buffer *gst.Buffer // out

	if _cret != nil {
		_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_buffer)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _buffer
}

// TakeBufferFast (gst_adapter_take_buffer_fast) returns a Buffer containing
// the first nbytes of the adapter. The returned bytes will be flushed
// from the adapter. This function is potentially more performant than
// gst_adapter_take_buffer() since it can reuse the memory in pushed buffers
// by subbuffering or merging. Unlike gst_adapter_take_buffer(), the returned
// buffer may be composed of multiple non-contiguous Memory objects, no copies
// are made.
//
// Note that no assumptions should be made as to whether certain buffer flags
// such as the DISCONT flag are set on the returned buffer, or not. The caller
// needs to explicitly set or unset flags that should be set or unset.
//
// This will also copy over all GstMeta of the input buffers except for meta
// with the GST_META_FLAG_POOLED flag or with the "memory" tag.
//
// This function can return buffer up to the return value of
// gst_adapter_available() without making copies if possible.
//
// Caller owns a reference to the returned buffer. gst_buffer_unref() after
// usage.
//
// Free-function: gst_buffer_unref.
//
// The function takes the following parameters:
//
//   - nbytes: number of bytes to take.
//
// The function returns the following values:
//
//   - buffer (optional) containing the first nbytes of the adapter, or NULL if
//     nbytes bytes are not available. gst_buffer_unref() when no longer needed.
func (adapter *Adapter) TakeBufferFast(nbytes uint) *gst.Buffer {
	var _arg0 *C.GstAdapter // out
	var _arg1 C.gsize       // out
	var _cret *C.GstBuffer  // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))
	_arg1 = C.gsize(nbytes)

	_cret = C.gst_adapter_take_buffer_fast(_arg0, _arg1)
	runtime.KeepAlive(adapter)
	runtime.KeepAlive(nbytes)

	var _buffer *gst.Buffer // out

	if _cret != nil {
		_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_buffer)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _buffer
}

// TakeBufferList (gst_adapter_take_buffer_list) returns a BufferList of buffers
// containing the first nbytes bytes of the adapter. The returned bytes will be
// flushed from the adapter. When the caller can deal with individual buffers,
// this function is more performant because no memory should be copied.
//
// Caller owns the returned list. Call gst_buffer_list_unref() to free the list
// after usage.
//
// The function takes the following parameters:
//
//   - nbytes: number of bytes to take.
//
// The function returns the following values:
//
//   - bufferList (optional) of buffers containing the first nbytes of the
//     adapter, or NULL if nbytes bytes are not available.
func (adapter *Adapter) TakeBufferList(nbytes uint) *gst.BufferList {
	var _arg0 *C.GstAdapter    // out
	var _arg1 C.gsize          // out
	var _cret *C.GstBufferList // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))
	_arg1 = C.gsize(nbytes)

	_cret = C.gst_adapter_take_buffer_list(_arg0, _arg1)
	runtime.KeepAlive(adapter)
	runtime.KeepAlive(nbytes)

	var _bufferList *gst.BufferList // out

	if _cret != nil {
		_bufferList = (*gst.BufferList)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_bufferList)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _bufferList
}

// TakeList (gst_adapter_take_list) returns a #GList of buffers containing the
// first nbytes bytes of the adapter. The returned bytes will be flushed from
// the adapter. When the caller can deal with individual buffers, this function
// is more performant because no memory should be copied.
//
// Caller owns returned list and contained buffers. gst_buffer_unref() each
// buffer in the list before freeing the list after usage.
//
// The function takes the following parameters:
//
//   - nbytes: number of bytes to take.
//
// The function returns the following values:
//
//   - list (optional) of buffers containing the first nbytes of the adapter,
//     or NULL if nbytes bytes are not available.
func (adapter *Adapter) TakeList(nbytes uint) []*gst.Buffer {
	var _arg0 *C.GstAdapter // out
	var _arg1 C.gsize       // out
	var _cret *C.GList      // in

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))
	_arg1 = C.gsize(nbytes)

	_cret = C.gst_adapter_take_list(_arg0, _arg1)
	runtime.KeepAlive(adapter)
	runtime.KeepAlive(nbytes)

	var _list []*gst.Buffer // out

	if _cret != nil {
		_list = make([]*gst.Buffer, 0, gextras.ListSize(unsafe.Pointer(_cret)))
		gextras.MoveList(unsafe.Pointer(_cret), true, func(v unsafe.Pointer) {
			src := (*C.GstBuffer)(v)
			var dst *gst.Buffer // out
			dst = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(src)))
			runtime.SetFinalizer(
				gextras.StructIntern(unsafe.Pointer(dst)),
				func(intern *struct{ C unsafe.Pointer }) {
					C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
				})
			_list = append(_list, dst)
		})
	}

	return _list
}

// Unmap (gst_adapter_unmap) releases the memory obtained with the last
// gst_adapter_map().
func (adapter *Adapter) Unmap() {
	var _arg0 *C.GstAdapter // out

	_arg0 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))

	C.gst_adapter_unmap(_arg0)
	runtime.KeepAlive(adapter)
}

// AggregatorOverrides contains methods that are overridable.
type AggregatorOverrides struct {
	// Aggregate: mandatory. Called when buffers are queued on all sinkpads.
	// Classes should iterate the GstElement->sinkpads and peek or steal
	// buffers from the AggregatorPads. If the subclass returns GST_FLOW_EOS,
	// sending of the eos event will be taken care of. Once / if a buffer has
	// been constructed from the aggregated buffers, the subclass should call
	// _finish_buffer.
	Aggregate func(timeout bool) gst.FlowReturn
	// Clip: optional. Called when a buffer is received on a sink pad,
	// the task of clipping it and translating it to the current segment falls
	// on the subclass. The function should use the segment of data and the
	// negotiated media type on the pad to perform clipping of input buffer.
	// This function takes ownership of buf and should output a buffer or return
	// NULL in if the buffer should be dropped.
	//
	// The function takes the following parameters:
	//
	//   - aggregatorPad
	//   - buf
	Clip func(aggregatorPad *AggregatorPad, buf *gst.Buffer) *gst.Buffer
	// DecideAllocation: optional. Allows the subclass to influence the
	// allocation choices. Setup the allocation parameters for allocating
	// output buffers. The passed in query contains the result of the downstream
	// allocation query.
	DecideAllocation func(query *gst.Query) bool
	// FinishBuffer: this method will push the provided output buffer
	// downstream. If needed, mandatory events such as stream-start, caps,
	// and segment events will be sent before pushing the buffer.
	//
	// The function takes the following parameters:
	//
	//   - buffer to push.
	FinishBuffer func(buffer *gst.Buffer) gst.FlowReturn
	// FinishBufferList: this method will push the provided output buffer list
	// downstream. If needed, mandatory events such as stream-start, caps,
	// and segment events will be sent before pushing the buffer.
	//
	// The function takes the following parameters:
	//
	//   - bufferlist to push.
	FinishBufferList func(bufferlist *gst.BufferList) gst.FlowReturn
	// FixateSrcCaps: optional. Fixate and return the src pad caps provided. The
	// function takes ownership of caps and returns a fixated version of caps.
	// caps is not guaranteed to be writable.
	FixateSrcCaps func(caps *gst.Caps) *gst.Caps
	// Flush: optional. Called after a successful flushing seek, once all
	// the flush stops have been received. Flush pad-specific data in
	// AggregatorPad->flush.
	Flush func() gst.FlowReturn
	// NextTime: optional. Called when the element needs to know the running
	// time of the next rendered buffer for live pipelines. This causes deadline
	// based aggregation to occur. Defaults to returning GST_CLOCK_TIME_NONE
	// causing the element to wait for buffers on all sink pads before
	// aggregating.
	NextTime func() gst.ClockTime
	// Negotiate negotiates src pad caps with downstream elements. Unmarks
	// GST_PAD_FLAG_NEED_RECONFIGURE in any case. But marks it again if
	// AggregatorClass::negotiate fails.
	//
	// The function returns the following values:
	//
	//   - ok: TRUE if the negotiation succeeded, else FALSE.
	Negotiate func() bool
	// NegotiatedSrcCaps: optional. Notifies subclasses what caps format has
	// been negotiated.
	NegotiatedSrcCaps func(caps *gst.Caps) bool
	// PeekNextSample: use this function to determine what input buffers will be
	// aggregated to produce the next output buffer. This should only be called
	// from a Aggregator::samples-selected handler, and can be used to precisely
	// control aggregating parameters for a given set of input samples.
	//
	// The function returns the following values:
	//
	//   - sample (optional) that is about to be aggregated. It may hold
	//     a Buffer or a BufferList. The contents of its info structure is
	//     subclass-dependent, and documented on a subclass basis. The buffers
	//     held by the sample are not writable.
	PeekNextSample func(aggregatorPad *AggregatorPad) *gst.Sample
	// ProposeAllocation: optional. Allows the subclass to handle the allocation
	// query from upstream.
	//
	// The function takes the following parameters:
	//
	//   - pad
	//   - decideQuery
	//   - query
	ProposeAllocation func(pad *AggregatorPad, decideQuery, query *gst.Query) bool
	// SinkEvent: optional. Called when an event is received on a sink pad,
	// the subclass should always chain up.
	//
	// The function takes the following parameters:
	//
	//   - aggregatorPad
	//   - event
	SinkEvent func(aggregatorPad *AggregatorPad, event *gst.Event) bool
	// SinkEventPreQueue: optional. Called when an event is received on a sink
	// pad before queueing up serialized events. The subclass should always
	// chain up (Since: 1.18).
	//
	// The function takes the following parameters:
	//
	//   - aggregatorPad
	//   - event
	SinkEventPreQueue func(aggregatorPad *AggregatorPad, event *gst.Event) gst.FlowReturn
	// SinkQuery: optional. Called when a query is received on a sink pad,
	// the subclass should always chain up.
	//
	// The function takes the following parameters:
	//
	//   - aggregatorPad
	//   - query
	SinkQuery func(aggregatorPad *AggregatorPad, query *gst.Query) bool
	// SinkQueryPreQueue: optional. Called when a query is received on a sink
	// pad before queueing up serialized queries. The subclass should always
	// chain up (Since: 1.18).
	//
	// The function takes the following parameters:
	//
	//   - aggregatorPad
	//   - query
	SinkQueryPreQueue func(aggregatorPad *AggregatorPad, query *gst.Query) bool
	// SrcActivate: optional. Called when the src pad is activated, it will
	// start/stop its pad task right after that call.
	//
	// The function takes the following parameters:
	//
	//   - mode
	//   - active
	SrcActivate func(mode gst.PadMode, active bool) bool
	// SrcEvent: optional. Called when an event is received on the src pad,
	// the subclass should always chain up.
	SrcEvent func(event *gst.Event) bool
	// SrcQuery: optional. Called when a query is received on the src pad,
	// the subclass should always chain up.
	SrcQuery func(query *gst.Query) bool
	// Start: optional. Called when the element goes from READY to PAUSED.
	// The subclass should get ready to process aggregated buffers.
	Start func() bool
	// Stop: optional. Called when the element goes from PAUSED to READY.
	// The subclass should free all resources and reset its state.
	Stop func() bool
	// The function returns the following values:
	//
	//   - ret (optional)
	//   - flowReturn
	UpdateSrcCaps func(caps *gst.Caps) (*gst.Caps, gst.FlowReturn)
}

func defaultAggregatorOverrides(v *Aggregator) AggregatorOverrides {
	return AggregatorOverrides{
		Aggregate:         v.aggregate,
		Clip:              v.clip,
		DecideAllocation:  v.decideAllocation,
		FinishBuffer:      v.finishBuffer,
		FinishBufferList:  v.finishBufferList,
		FixateSrcCaps:     v.fixateSrcCaps,
		Flush:             v.flush,
		NextTime:          v.nextTime,
		Negotiate:         v.negotiate,
		NegotiatedSrcCaps: v.negotiatedSrcCaps,
		PeekNextSample:    v.peekNextSample,
		ProposeAllocation: v.proposeAllocation,
		SinkEvent:         v.sinkEvent,
		SinkEventPreQueue: v.sinkEventPreQueue,
		SinkQuery:         v.sinkQuery,
		SinkQueryPreQueue: v.sinkQueryPreQueue,
		SrcActivate:       v.srcActivate,
		SrcEvent:          v.srcEvent,
		SrcQuery:          v.srcQuery,
		Start:             v.start,
		Stop:              v.stop,
		UpdateSrcCaps:     v.updateSrcCaps,
	}
}

// Aggregator (GstAggregator) manages a set of pads with the purpose of
// aggregating their buffers. Control is given to the subclass when all pads
// have data.
//
//   - Base class for mixers and muxers. Subclasses should at least implement
//     the AggregatorClass::aggregate virtual method.
//
//   - Installs a PadChainFunction, a PadEventFullFunction and a
//     PadQueryFunction to queue all serialized data packets per sink pad.
//     Subclasses should not overwrite those, but instead implement
//     AggregatorClass::sink_event and AggregatorClass::sink_query as needed.
//
//   - When data is queued on all pads, the aggregate vmethod is called.
//
//   - One can peek at the data on any given GstAggregatorPad with the
//     gst_aggregator_pad_peek_buffer() method, and remove it from the pad with
//     the gst_aggregator_pad_pop_buffer () method. When a buffer has been taken
//     with pop_buffer (), a new buffer can be queued on that pad.
//
//   - When gst_aggregator_pad_peek_buffer() or gst_aggregator_pad_has_buffer()
//     are called, a reference is taken to the returned buffer, which stays
//     valid until either:
//
//   - gst_aggregator_pad_pop_buffer() is called, in which case the caller is
//     guaranteed that the buffer they receive is the same as the peeked buffer.
//
//   - gst_aggregator_pad_drop_buffer() is called, in which case the caller is
//     guaranteed that the dropped buffer is the one that was peeked.
//
//   - the subclass implementation of AggregatorClass.aggregate returns.
//
//     Subsequent calls to gst_aggregator_pad_peek_buffer() or
//     gst_aggregator_pad_has_buffer() return / check the same buffer that was
//     returned / checked, until one of the conditions listed above is met.
//
//     Subclasses are only allowed to call these methods from the aggregate
//     thread.
//
//   - If the subclass wishes to push a buffer downstream in
//     its aggregate implementation, it should do so through the
//     gst_aggregator_finish_buffer() method. This method will take care
//     of sending and ordering mandatory events such as stream start,
//     caps and segment. Buffer lists can also be pushed out with
//     gst_aggregator_finish_buffer_list().
//
//   - Same goes for EOS events, which should not be pushed directly by the
//     subclass, it should instead return GST_FLOW_EOS in its aggregate
//     implementation.
//
//   - Note that the aggregator logic regarding gap event handling is to turn
//     these into gap buffers with matching PTS and duration. It will also flag
//     these buffers with GST_BUFFER_FLAG_GAP and GST_BUFFER_FLAG_DROPPABLE
//     to ease their identification and subsequent processing. In addition,
//     if the gap event was flagged with GST_GAP_FLAG_MISSING_DATA, a custom
//     meta is added to the resulting gap buffer (GstAggregatorMissingDataMeta).
//
//   - Subclasses must use (a subclass of) AggregatorPad for both their sink and
//     source pads. See gst_element_class_add_static_pad_template_with_gtype().
//
// This class used to live in gst-plugins-bad and was moved to core.
type Aggregator struct {
	_ [0]func() // equal guard
	gst.Element
}

var (
	_ gst.Elementer = (*Aggregator)(nil)
)

// Aggregatorrer describes types inherited from Aggregator.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type Aggregatorrer interface {
	gst.Elementer

	// FinishBuffer (gst_aggregator_finish_buffer): this method will push the
	// provided output buffer downstream.
	FinishBuffer(buffer *gst.Buffer) gst.FlowReturn
	// FinishBufferList (gst_aggregator_finish_buffer_list): this method will
	// push the provided output buffer list downstream.
	FinishBufferList(bufferlist *gst.BufferList) gst.FlowReturn
	// Allocator (gst_aggregator_get_allocator) lets Aggregator sub-classes get
	// the memory allocator acquired by the base class and its params.
	Allocator() (gst.Allocatorrer, *gst.AllocationParams)
	BufferPool() *gst.BufferPool
	// ForceLive (gst_aggregator_get_force_live) subclasses may use the return
	// value to inform whether they should return GST_FLOW_EOS from their
	// aggregate implementation.
	ForceLive() bool
	IgnoreInactivePads() bool
	// Latency (gst_aggregator_get_latency) retrieves the latency values
	// reported by self in response to the latency query, or GST_CLOCK_TIME_NONE
	// if there is not live source connected and the element will not wait for
	// the clock.
	Latency() gst.ClockTime
	// Negotiate (gst_aggregator_negotiate) negotiates src pad caps with
	// downstream elements.
	Negotiate() bool
	// PeekNextSample (gst_aggregator_peek_next_sample): use this function
	// to determine what input buffers will be aggregated to produce the next
	// output buffer.
	PeekNextSample(pad *AggregatorPad) *gst.Sample
	// SelectedSamples (gst_aggregator_selected_samples) subclasses should call
	// this when they have prepared the buffers they will aggregate for each of
	// their sink pads, but before using any of the properties of the pads that
	// govern *how* aggregation should be performed, for example z-index for
	// video aggregators.
	SelectedSamples(pts, dts, duration gst.ClockTime, info *gst.Structure)
	// SetForceLive (gst_aggregator_set_force_live) subclasses should call this
	// at construction time in order for self to aggregate on a timeout even
	// when no live source is connected.
	SetForceLive(forceLive bool)
	// SetIgnoreInactivePads (gst_aggregator_set_ignore_inactive_pads)
	// subclasses should call this when they don't want to time out waiting for
	// a pad that hasn't yet received any buffers in live mode.
	SetIgnoreInactivePads(ignore bool)
	// SetLatency (gst_aggregator_set_latency) lets Aggregator sub-classes tell
	// the baseclass what their internal latency is.
	SetLatency(minLatency, maxLatency gst.ClockTime)
	// SetSrcCaps (gst_aggregator_set_src_caps) sets the caps to be used on the
	// src pad.
	SetSrcCaps(caps *gst.Caps)
	// SimpleGetNextTime (gst_aggregator_simple_get_next_time): this is a simple
	// AggregatorClass::get_next_time implementation that just looks at the
	// Segment on the srcpad of the aggregator and bases the next time on the
	// running time there.
	SimpleGetNextTime() gst.ClockTime
	// UpdateSegment (gst_aggregator_update_segment) subclasses should use this
	// to update the segment on their source pad, instead of directly pushing
	// new segment events downstream.
	UpdateSegment(segment *gst.Segment)

	// Samples-selected signals that the Aggregator subclass has selected the
	// next set of input samples it will aggregate.
	ConnectSamplesSelected(func(segment *gst.Segment, pts, dts, duration uint64, info *gst.Structure)) coreglib.SignalHandle

	baseAggregator() *Aggregator
}

var _ Aggregatorrer = (*Aggregator)(nil)

func init() {
	coreglib.RegisterClassInfo[*Aggregator, *AggregatorClass, AggregatorOverrides](
		GTypeAggregator,
		initAggregatorClass,
		wrapAggregator,
		defaultAggregatorOverrides,
	)
}

func initAggregatorClass(gclass unsafe.Pointer, overrides AggregatorOverrides, classInitFunc func(*AggregatorClass)) {
	pclass := (*C.GstAggregatorClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeAggregator))))

	if overrides.Aggregate != nil {
		pclass.aggregate = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_aggregate)
	}

	if overrides.Clip != nil {
		pclass.clip = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_clip)
	}

	if overrides.DecideAllocation != nil {
		pclass.decide_allocation = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_decide_allocation)
	}

	if overrides.FinishBuffer != nil {
		pclass.finish_buffer = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_finish_buffer)
	}

	if overrides.FinishBufferList != nil {
		pclass.finish_buffer_list = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_finish_buffer_list)
	}

	if overrides.FixateSrcCaps != nil {
		pclass.fixate_src_caps = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_fixate_src_caps)
	}

	if overrides.Flush != nil {
		pclass.flush = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_flush)
	}

	if overrides.NextTime != nil {
		pclass.get_next_time = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_get_next_time)
	}

	if overrides.Negotiate != nil {
		pclass.negotiate = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_negotiate)
	}

	if overrides.NegotiatedSrcCaps != nil {
		pclass.negotiated_src_caps = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_negotiated_src_caps)
	}

	if overrides.PeekNextSample != nil {
		pclass.peek_next_sample = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_peek_next_sample)
	}

	if overrides.ProposeAllocation != nil {
		pclass.propose_allocation = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_propose_allocation)
	}

	if overrides.SinkEvent != nil {
		pclass.sink_event = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_sink_event)
	}

	if overrides.SinkEventPreQueue != nil {
		pclass.sink_event_pre_queue = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_sink_event_pre_queue)
	}

	if overrides.SinkQuery != nil {
		pclass.sink_query = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_sink_query)
	}

	if overrides.SinkQueryPreQueue != nil {
		pclass.sink_query_pre_queue = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_sink_query_pre_queue)
	}

	if overrides.SrcActivate != nil {
		pclass.src_activate = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_src_activate)
	}

	if overrides.SrcEvent != nil {
		pclass.src_event = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_src_event)
	}

	if overrides.SrcQuery != nil {
		pclass.src_query = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_src_query)
	}

	if overrides.Start != nil {
		pclass.start = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_start)
	}

	if overrides.Stop != nil {
		pclass.stop = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_stop)
	}

	if overrides.UpdateSrcCaps != nil {
		pclass.update_src_caps = (*[0]byte)(C._gotk4_gstbase1_AggregatorClass_update_src_caps)
	}

	if classInitFunc != nil {
		class := (*AggregatorClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapAggregator(obj *coreglib.Object) *Aggregator {
	return &Aggregator{
		Element: gst.Element{
			GstObject: gst.GstObject{
				InitiallyUnowned: coreglib.InitiallyUnowned{
					Object: obj,
				},
			},
		},
	}
}

func marshalAggregator(p uintptr) (interface{}, error) {
	return wrapAggregator(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (aggregator *Aggregator) baseAggregator() *Aggregator {
	return aggregator
}

// BaseAggregator returns the underlying base object.
func BaseAggregator(obj Aggregatorrer) *Aggregator {
	return obj.baseAggregator()
}

// ConnectSamplesSelected signals that the Aggregator subclass has selected
// the next set of input samples it will aggregate. Handlers may call
// gst_aggregator_peek_next_sample() at that point.
func (aggregator *Aggregator) ConnectSamplesSelected(f func(segment *gst.Segment, pts, dts, duration uint64, info *gst.Structure)) coreglib.SignalHandle {
	return coreglib.ConnectGeneratedClosure(aggregator, "samples-selected", false, unsafe.Pointer(C._gotk4_gstbase1_Aggregator_ConnectSamplesSelected), f)
}

// FinishBuffer (gst_aggregator_finish_buffer): this method will push the
// provided output buffer downstream. If needed, mandatory events such as
// stream-start, caps, and segment events will be sent before pushing the
// buffer.
//
// The function takes the following parameters:
//
//   - buffer to push.
func (aggregator *Aggregator) FinishBuffer(buffer *gst.Buffer) gst.FlowReturn {
	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstBuffer     // out
	var _cret C.GstFlowReturn  // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(aggregator).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(buffer)), nil)

	_cret = C.gst_aggregator_finish_buffer(_arg0, _arg1)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(buffer)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// FinishBufferList (gst_aggregator_finish_buffer_list): this method will push
// the provided output buffer list downstream. If needed, mandatory events such
// as stream-start, caps, and segment events will be sent before pushing the
// buffer.
//
// The function takes the following parameters:
//
//   - bufferlist to push.
func (aggregator *Aggregator) FinishBufferList(bufferlist *gst.BufferList) gst.FlowReturn {
	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstBufferList // out
	var _cret C.GstFlowReturn  // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(aggregator).Native()))
	_arg1 = (*C.GstBufferList)(gextras.StructNative(unsafe.Pointer(bufferlist)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(bufferlist)), nil)

	_cret = C.gst_aggregator_finish_buffer_list(_arg0, _arg1)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(bufferlist)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// Allocator (gst_aggregator_get_allocator) lets Aggregator sub-classes get the
// memory allocator acquired by the base class and its params.
//
// Unref the allocator after use it.
//
// The function returns the following values:
//
//   - allocator (optional): Allocator used.
//   - params (optional) the AllocationParams of allocator.
func (self *Aggregator) Allocator() (gst.Allocatorrer, *gst.AllocationParams) {
	var _arg0 *C.GstAggregator      // out
	var _arg1 *C.GstAllocator       // in
	var _arg2 C.GstAllocationParams // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(self).Native()))

	C.gst_aggregator_get_allocator(_arg0, &_arg1, &_arg2)
	runtime.KeepAlive(self)

	var _allocator gst.Allocatorrer   // out
	var _params *gst.AllocationParams // out

	if _arg1 != nil {
		{
			objptr := unsafe.Pointer(_arg1)

			object := coreglib.AssumeOwnership(objptr)
			casted := object.WalkCast(func(obj coreglib.Objector) bool {
				_, ok := obj.(gst.Allocatorrer)
				return ok
			})
			rv, ok := casted.(gst.Allocatorrer)
			if !ok {
				panic("no marshaler for " + object.TypeFromInstance().String() + " matching gst.Allocatorrer")
			}
			_allocator = rv
		}
	}
	_params = (*gst.AllocationParams)(gextras.NewStructNative(unsafe.Pointer((&_arg2))))

	return _allocator, _params
}

// The function returns the following values:
//
//   - bufferPool (optional): instance of the BufferPool used by trans; free it
//     after use it.
func (self *Aggregator) BufferPool() *gst.BufferPool {
	var _arg0 *C.GstAggregator // out
	var _cret *C.GstBufferPool // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(self).Native()))

	_cret = C.gst_aggregator_get_buffer_pool(_arg0)
	runtime.KeepAlive(self)

	var _bufferPool *gst.BufferPool // out

	if _cret != nil {
		{
			obj := coreglib.AssumeOwnership(unsafe.Pointer(_cret))
			_bufferPool = &gst.BufferPool{
				GstObject: gst.GstObject{
					InitiallyUnowned: coreglib.InitiallyUnowned{
						Object: obj,
					},
				},
			}
		}
	}

	return _bufferPool
}

// ForceLive (gst_aggregator_get_force_live) subclasses may use the return
// value to inform whether they should return GST_FLOW_EOS from their aggregate
// implementation.
//
// The function returns the following values:
//
//   - ok: whether live status was forced on self.
func (self *Aggregator) ForceLive() bool {
	var _arg0 *C.GstAggregator // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(self).Native()))

	_cret = C.gst_aggregator_get_force_live(_arg0)
	runtime.KeepAlive(self)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function returns the following values:
//
//   - ok: whether inactive pads will not be waited on.
func (self *Aggregator) IgnoreInactivePads() bool {
	var _arg0 *C.GstAggregator // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(self).Native()))

	_cret = C.gst_aggregator_get_ignore_inactive_pads(_arg0)
	runtime.KeepAlive(self)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Latency (gst_aggregator_get_latency) retrieves the latency values reported by
// self in response to the latency query, or GST_CLOCK_TIME_NONE if there is not
// live source connected and the element will not wait for the clock.
//
// Typically only called by subclasses.
//
// The function returns the following values:
//
//   - clockTime: latency or GST_CLOCK_TIME_NONE if the element does not sync.
func (self *Aggregator) Latency() gst.ClockTime {
	var _arg0 *C.GstAggregator // out
	var _cret C.GstClockTime   // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(self).Native()))

	_cret = C.gst_aggregator_get_latency(_arg0)
	runtime.KeepAlive(self)

	var _clockTime gst.ClockTime // out

	_clockTime = gst.ClockTime(_cret)

	return _clockTime
}

// Negotiate (gst_aggregator_negotiate) negotiates src pad caps with downstream
// elements. Unmarks GST_PAD_FLAG_NEED_RECONFIGURE in any case. But marks it
// again if AggregatorClass::negotiate fails.
//
// The function returns the following values:
//
//   - ok: TRUE if the negotiation succeeded, else FALSE.
func (self *Aggregator) Negotiate() bool {
	var _arg0 *C.GstAggregator // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(self).Native()))

	_cret = C.gst_aggregator_negotiate(_arg0)
	runtime.KeepAlive(self)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PeekNextSample (gst_aggregator_peek_next_sample): use this function to
// determine what input buffers will be aggregated to produce the next output
// buffer. This should only be called from a Aggregator::samples-selected
// handler, and can be used to precisely control aggregating parameters for a
// given set of input samples.
//
// The function returns the following values:
//
//   - sample (optional) that is about to be aggregated. It may hold a Buffer or
//     a BufferList. The contents of its info structure is subclass-dependent,
//     and documented on a subclass basis. The buffers held by the sample are
//     not writable.
func (self *Aggregator) PeekNextSample(pad *AggregatorPad) *gst.Sample {
	var _arg0 *C.GstAggregator    // out
	var _arg1 *C.GstAggregatorPad // out
	var _cret *C.GstSample        // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(self).Native()))
	_arg1 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))

	_cret = C.gst_aggregator_peek_next_sample(_arg0, _arg1)
	runtime.KeepAlive(self)
	runtime.KeepAlive(pad)

	var _sample *gst.Sample // out

	if _cret != nil {
		_sample = (*gst.Sample)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_sample)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _sample
}

// SelectedSamples (gst_aggregator_selected_samples) subclasses should call
// this when they have prepared the buffers they will aggregate for each of
// their sink pads, but before using any of the properties of the pads that
// govern *how* aggregation should be performed, for example z-index for video
// aggregators.
//
// If gst_aggregator_update_segment() is used by the subclass, it MUST be called
// before gst_aggregator_selected_samples().
//
// This function MUST only be called from the AggregatorClass::aggregate()
// function.
//
// The function takes the following parameters:
//
//   - pts: presentation timestamp of the next output buffer.
//   - dts: decoding timestamp of the next output buffer.
//   - duration of the next output buffer.
//   - info (optional) containing additional information.
func (self *Aggregator) SelectedSamples(pts, dts, duration gst.ClockTime, info *gst.Structure) {
	var _arg0 *C.GstAggregator // out
	var _arg1 C.GstClockTime   // out
	var _arg2 C.GstClockTime   // out
	var _arg3 C.GstClockTime   // out
	var _arg4 *C.GstStructure  // out

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(self).Native()))
	_arg1 = C.GstClockTime(pts)
	_arg2 = C.GstClockTime(dts)
	_arg3 = C.GstClockTime(duration)
	if info != nil {
		_arg4 = (*C.GstStructure)(gextras.StructNative(unsafe.Pointer(info)))
	}

	C.gst_aggregator_selected_samples(_arg0, _arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(self)
	runtime.KeepAlive(pts)
	runtime.KeepAlive(dts)
	runtime.KeepAlive(duration)
	runtime.KeepAlive(info)
}

// SetForceLive (gst_aggregator_set_force_live) subclasses should call this at
// construction time in order for self to aggregate on a timeout even when no
// live source is connected.
func (self *Aggregator) SetForceLive(forceLive bool) {
	var _arg0 *C.GstAggregator // out
	var _arg1 C.gboolean       // out

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(self).Native()))
	if forceLive {
		_arg1 = C.TRUE
	}

	C.gst_aggregator_set_force_live(_arg0, _arg1)
	runtime.KeepAlive(self)
	runtime.KeepAlive(forceLive)
}

// SetIgnoreInactivePads (gst_aggregator_set_ignore_inactive_pads) subclasses
// should call this when they don't want to time out waiting for a pad that
// hasn't yet received any buffers in live mode.
//
// Aggregator will still wait once on each newly-added pad, making sure upstream
// has had a fair chance to start up.
//
// The function takes the following parameters:
//
//   - ignore: whether inactive pads should not be waited on.
func (self *Aggregator) SetIgnoreInactivePads(ignore bool) {
	var _arg0 *C.GstAggregator // out
	var _arg1 C.gboolean       // out

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(self).Native()))
	if ignore {
		_arg1 = C.TRUE
	}

	C.gst_aggregator_set_ignore_inactive_pads(_arg0, _arg1)
	runtime.KeepAlive(self)
	runtime.KeepAlive(ignore)
}

// SetLatency (gst_aggregator_set_latency) lets Aggregator sub-classes tell the
// baseclass what their internal latency is. Will also post a LATENCY message
// on the bus so the pipeline can reconfigure its global latency if the values
// changed.
//
// The function takes the following parameters:
//
//   - minLatency: minimum latency.
//   - maxLatency: maximum latency.
func (self *Aggregator) SetLatency(minLatency, maxLatency gst.ClockTime) {
	var _arg0 *C.GstAggregator // out
	var _arg1 C.GstClockTime   // out
	var _arg2 C.GstClockTime   // out

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(self).Native()))
	_arg1 = C.GstClockTime(minLatency)
	_arg2 = C.GstClockTime(maxLatency)

	C.gst_aggregator_set_latency(_arg0, _arg1, _arg2)
	runtime.KeepAlive(self)
	runtime.KeepAlive(minLatency)
	runtime.KeepAlive(maxLatency)
}

// SetSrcCaps (gst_aggregator_set_src_caps) sets the caps to be used on the src
// pad.
//
// The function takes the following parameters:
//
//   - caps to set on the src pad.
func (self *Aggregator) SetSrcCaps(caps *gst.Caps) {
	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstCaps       // out

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(self).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	C.gst_aggregator_set_src_caps(_arg0, _arg1)
	runtime.KeepAlive(self)
	runtime.KeepAlive(caps)
}

// SimpleGetNextTime (gst_aggregator_simple_get_next_time): this is a simple
// AggregatorClass::get_next_time implementation that just looks at the Segment
// on the srcpad of the aggregator and bases the next time on the running time
// there.
//
// This is the desired behaviour in most cases where you have a live source and
// you have a dead line based aggregator subclass.
//
// The function returns the following values:
//
//   - clockTime: running time based on the position.
func (self *Aggregator) SimpleGetNextTime() gst.ClockTime {
	var _arg0 *C.GstAggregator // out
	var _cret C.GstClockTime   // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(self).Native()))

	_cret = C.gst_aggregator_simple_get_next_time(_arg0)
	runtime.KeepAlive(self)

	var _clockTime gst.ClockTime // out

	_clockTime = gst.ClockTime(_cret)

	return _clockTime
}

// UpdateSegment (gst_aggregator_update_segment) subclasses should use this
// to update the segment on their source pad, instead of directly pushing new
// segment events downstream.
//
// Subclasses MUST call this before gst_aggregator_selected_samples(), if it is
// used at all.
func (self *Aggregator) UpdateSegment(segment *gst.Segment) {
	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstSegment    // out

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(self).Native()))
	_arg1 = (*C.GstSegment)(gextras.StructNative(unsafe.Pointer(segment)))

	C.gst_aggregator_update_segment(_arg0, _arg1)
	runtime.KeepAlive(self)
	runtime.KeepAlive(segment)
}

// Aggregate: mandatory. Called when buffers are queued on all sinkpads.
// Classes should iterate the GstElement->sinkpads and peek or steal buffers
// from the AggregatorPads. If the subclass returns GST_FLOW_EOS, sending of the
// eos event will be taken care of. Once / if a buffer has been constructed from
// the aggregated buffers, the subclass should call _finish_buffer.
func (aggregator *Aggregator) aggregate(timeout bool) gst.FlowReturn {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.aggregate

	var _arg0 *C.GstAggregator // out
	var _arg1 C.gboolean       // out
	var _cret C.GstFlowReturn  // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(aggregator).Native()))
	if timeout {
		_arg1 = C.TRUE
	}

	_cret = C._gotk4_gstbase1_Aggregator_virtual_aggregate(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(timeout)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// Clip: optional. Called when a buffer is received on a sink pad, the task of
// clipping it and translating it to the current segment falls on the subclass.
// The function should use the segment of data and the negotiated media type on
// the pad to perform clipping of input buffer. This function takes ownership
// of buf and should output a buffer or return NULL in if the buffer should be
// dropped.
//
// The function takes the following parameters:
//
//   - aggregatorPad
//   - buf
func (aggregator *Aggregator) clip(aggregatorPad *AggregatorPad, buf *gst.Buffer) *gst.Buffer {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.clip

	var _arg0 *C.GstAggregator    // out
	var _arg1 *C.GstAggregatorPad // out
	var _arg2 *C.GstBuffer        // out
	var _cret *C.GstBuffer        // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(aggregator).Native()))
	_arg1 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(aggregatorPad).Native()))
	_arg2 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buf)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_clip(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(aggregatorPad)
	runtime.KeepAlive(buf)

	var _buffer *gst.Buffer // out

	_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_buffer)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _buffer
}

// decideAllocation: optional. Allows the subclass to influence the allocation
// choices. Setup the allocation parameters for allocating output buffers.
// The passed in query contains the result of the downstream allocation query.
func (self *Aggregator) decideAllocation(query *gst.Query) bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(self))
	fnarg := gclass.decide_allocation

	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstQuery      // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(self).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_decide_allocation(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(self)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// finishBuffer: this method will push the provided output buffer downstream.
// If needed, mandatory events such as stream-start, caps, and segment events
// will be sent before pushing the buffer.
//
// The function takes the following parameters:
//
//   - buffer to push.
func (aggregator *Aggregator) finishBuffer(buffer *gst.Buffer) gst.FlowReturn {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.finish_buffer

	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstBuffer     // out
	var _cret C.GstFlowReturn  // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(aggregator).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(buffer)), nil)

	_cret = C._gotk4_gstbase1_Aggregator_virtual_finish_buffer(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(buffer)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// finishBufferList: this method will push the provided output buffer list
// downstream. If needed, mandatory events such as stream-start, caps, and
// segment events will be sent before pushing the buffer.
//
// The function takes the following parameters:
//
//   - bufferlist to push.
func (aggregator *Aggregator) finishBufferList(bufferlist *gst.BufferList) gst.FlowReturn {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.finish_buffer_list

	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstBufferList // out
	var _cret C.GstFlowReturn  // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(aggregator).Native()))
	_arg1 = (*C.GstBufferList)(gextras.StructNative(unsafe.Pointer(bufferlist)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(bufferlist)), nil)

	_cret = C._gotk4_gstbase1_Aggregator_virtual_finish_buffer_list(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(bufferlist)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// fixateSrcCaps: optional. Fixate and return the src pad caps provided.
// The function takes ownership of caps and returns a fixated version of caps.
// caps is not guaranteed to be writable.
func (self *Aggregator) fixateSrcCaps(caps *gst.Caps) *gst.Caps {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(self))
	fnarg := gclass.fixate_src_caps

	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstCaps       // out
	var _cret *C.GstCaps       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(self).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_fixate_src_caps(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(self)
	runtime.KeepAlive(caps)

	var _ret *gst.Caps // out

	_ret = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_ret)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _ret
}

// Flush: optional. Called after a successful flushing seek, once all the flush
// stops have been received. Flush pad-specific data in AggregatorPad->flush.
func (aggregator *Aggregator) flush() gst.FlowReturn {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.flush

	var _arg0 *C.GstAggregator // out
	var _cret C.GstFlowReturn  // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(aggregator).Native()))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_flush(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(aggregator)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// nextTime: optional. Called when the element needs to know the running time
// of the next rendered buffer for live pipelines. This causes deadline based
// aggregation to occur. Defaults to returning GST_CLOCK_TIME_NONE causing the
// element to wait for buffers on all sink pads before aggregating.
func (aggregator *Aggregator) nextTime() gst.ClockTime {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.get_next_time

	var _arg0 *C.GstAggregator // out
	var _cret C.GstClockTime   // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(aggregator).Native()))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_get_next_time(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(aggregator)

	var _clockTime gst.ClockTime // out

	_clockTime = gst.ClockTime(_cret)

	return _clockTime
}

// Negotiate negotiates src pad caps with downstream elements. Unmarks
// GST_PAD_FLAG_NEED_RECONFIGURE in any case. But marks it again if
// AggregatorClass::negotiate fails.
//
// The function returns the following values:
//
//   - ok: TRUE if the negotiation succeeded, else FALSE.
func (self *Aggregator) negotiate() bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(self))
	fnarg := gclass.negotiate

	var _arg0 *C.GstAggregator // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(self).Native()))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_negotiate(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(self)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// negotiatedSrcCaps: optional. Notifies subclasses what caps format has been
// negotiated.
func (self *Aggregator) negotiatedSrcCaps(caps *gst.Caps) bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(self))
	fnarg := gclass.negotiated_src_caps

	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstCaps       // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(self).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_negotiated_src_caps(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(self)
	runtime.KeepAlive(caps)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// peekNextSample: use this function to determine what input buffers will be
// aggregated to produce the next output buffer. This should only be called from
// a Aggregator::samples-selected handler, and can be used to precisely control
// aggregating parameters for a given set of input samples.
//
// The function returns the following values:
//
//   - sample (optional) that is about to be aggregated. It may hold a Buffer or
//     a BufferList. The contents of its info structure is subclass-dependent,
//     and documented on a subclass basis. The buffers held by the sample are
//     not writable.
func (aggregator *Aggregator) peekNextSample(aggregatorPad *AggregatorPad) *gst.Sample {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.peek_next_sample

	var _arg0 *C.GstAggregator    // out
	var _arg1 *C.GstAggregatorPad // out
	var _cret *C.GstSample        // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(aggregator).Native()))
	_arg1 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(aggregatorPad).Native()))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_peek_next_sample(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(aggregatorPad)

	var _sample *gst.Sample // out

	if _cret != nil {
		_sample = (*gst.Sample)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_sample)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _sample
}

// proposeAllocation: optional. Allows the subclass to handle the allocation
// query from upstream.
//
// The function takes the following parameters:
//
//   - pad
//   - decideQuery
//   - query
func (self *Aggregator) proposeAllocation(pad *AggregatorPad, decideQuery, query *gst.Query) bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(self))
	fnarg := gclass.propose_allocation

	var _arg0 *C.GstAggregator    // out
	var _arg1 *C.GstAggregatorPad // out
	var _arg2 *C.GstQuery         // out
	var _arg3 *C.GstQuery         // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(self).Native()))
	_arg1 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))
	_arg2 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(decideQuery)))
	_arg3 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_propose_allocation(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(self)
	runtime.KeepAlive(pad)
	runtime.KeepAlive(decideQuery)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// sinkEvent: optional. Called when an event is received on a sink pad,
// the subclass should always chain up.
//
// The function takes the following parameters:
//
//   - aggregatorPad
//   - event
func (aggregator *Aggregator) sinkEvent(aggregatorPad *AggregatorPad, event *gst.Event) bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.sink_event

	var _arg0 *C.GstAggregator    // out
	var _arg1 *C.GstAggregatorPad // out
	var _arg2 *C.GstEvent         // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(aggregator).Native()))
	_arg1 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(aggregatorPad).Native()))
	_arg2 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_sink_event(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(aggregatorPad)
	runtime.KeepAlive(event)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// sinkEventPreQueue: optional. Called when an event is received on a sink pad
// before queueing up serialized events. The subclass should always chain up
// (Since: 1.18).
//
// The function takes the following parameters:
//
//   - aggregatorPad
//   - event
func (aggregator *Aggregator) sinkEventPreQueue(aggregatorPad *AggregatorPad, event *gst.Event) gst.FlowReturn {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.sink_event_pre_queue

	var _arg0 *C.GstAggregator    // out
	var _arg1 *C.GstAggregatorPad // out
	var _arg2 *C.GstEvent         // out
	var _cret C.GstFlowReturn     // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(aggregator).Native()))
	_arg1 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(aggregatorPad).Native()))
	_arg2 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_sink_event_pre_queue(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(aggregatorPad)
	runtime.KeepAlive(event)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// sinkQuery: optional. Called when a query is received on a sink pad, the
// subclass should always chain up.
//
// The function takes the following parameters:
//
//   - aggregatorPad
//   - query
func (aggregator *Aggregator) sinkQuery(aggregatorPad *AggregatorPad, query *gst.Query) bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.sink_query

	var _arg0 *C.GstAggregator    // out
	var _arg1 *C.GstAggregatorPad // out
	var _arg2 *C.GstQuery         // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(aggregator).Native()))
	_arg1 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(aggregatorPad).Native()))
	_arg2 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_sink_query(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(aggregatorPad)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// sinkQueryPreQueue: optional. Called when a query is received on a sink pad
// before queueing up serialized queries. The subclass should always chain up
// (Since: 1.18).
//
// The function takes the following parameters:
//
//   - aggregatorPad
//   - query
func (aggregator *Aggregator) sinkQueryPreQueue(aggregatorPad *AggregatorPad, query *gst.Query) bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.sink_query_pre_queue

	var _arg0 *C.GstAggregator    // out
	var _arg1 *C.GstAggregatorPad // out
	var _arg2 *C.GstQuery         // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(aggregator).Native()))
	_arg1 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(aggregatorPad).Native()))
	_arg2 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_sink_query_pre_queue(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(aggregatorPad)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// srcActivate: optional. Called when the src pad is activated, it will
// start/stop its pad task right after that call.
//
// The function takes the following parameters:
//
//   - mode
//   - active
func (aggregator *Aggregator) srcActivate(mode gst.PadMode, active bool) bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.src_activate

	var _arg0 *C.GstAggregator // out
	var _arg1 C.GstPadMode     // out
	var _arg2 C.gboolean       // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(aggregator).Native()))
	_arg1 = C.GstPadMode(mode)
	if active {
		_arg2 = C.TRUE
	}

	_cret = C._gotk4_gstbase1_Aggregator_virtual_src_activate(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(mode)
	runtime.KeepAlive(active)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// srcEvent: optional. Called when an event is received on the src pad,
// the subclass should always chain up.
func (aggregator *Aggregator) srcEvent(event *gst.Event) bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.src_event

	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstEvent      // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(aggregator).Native()))
	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_src_event(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(event)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// srcQuery: optional. Called when a query is received on the src pad, the
// subclass should always chain up.
func (aggregator *Aggregator) srcQuery(query *gst.Query) bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.src_query

	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstQuery      // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(aggregator).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_src_query(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Start: optional. Called when the element goes from READY to PAUSED. The
// subclass should get ready to process aggregated buffers.
func (aggregator *Aggregator) start() bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.start

	var _arg0 *C.GstAggregator // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(aggregator).Native()))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_start(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(aggregator)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Stop: optional. Called when the element goes from PAUSED to READY. The
// subclass should free all resources and reset its state.
func (aggregator *Aggregator) stop() bool {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(aggregator))
	fnarg := gclass.stop

	var _arg0 *C.GstAggregator // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(aggregator).Native()))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_stop(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(aggregator)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function returns the following values:
//
//   - ret (optional)
//   - flowReturn
func (self *Aggregator) updateSrcCaps(caps *gst.Caps) (*gst.Caps, gst.FlowReturn) {
	gclass := (*C.GstAggregatorClass)(coreglib.PeekParentClass(self))
	fnarg := gclass.update_src_caps

	var _arg0 *C.GstAggregator // out
	var _arg1 *C.GstCaps       // out
	var _arg2 *C.GstCaps       // in
	var _cret C.GstFlowReturn  // in

	_arg0 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(self).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C._gotk4_gstbase1_Aggregator_virtual_update_src_caps(unsafe.Pointer(fnarg), _arg0, _arg1, &_arg2)
	runtime.KeepAlive(self)
	runtime.KeepAlive(caps)

	var _ret *gst.Caps             // out
	var _flowReturn gst.FlowReturn // out

	if _arg2 != nil {
		_ret = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_arg2)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_ret)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}
	_flowReturn = gst.FlowReturn(_cret)

	return _ret, _flowReturn
}

// AggregatorPadOverrides contains methods that are overridable.
type AggregatorPadOverrides struct {
	// Flush: optional Called when the pad has received a flush stop, this is
	// the place to flush any information specific to the pad, it allows for
	// individual pads to be flushed while others might not be.
	Flush func(aggregator Aggregatorrer) gst.FlowReturn
	// SkipBuffer: optional Called before input buffers are queued in the pad,
	// return TRUE if the buffer should be skipped.
	//
	// The function takes the following parameters:
	//
	//   - aggregator
	//   - buffer
	SkipBuffer func(aggregator Aggregatorrer, buffer *gst.Buffer) bool
}

func defaultAggregatorPadOverrides(v *AggregatorPad) AggregatorPadOverrides {
	return AggregatorPadOverrides{
		Flush:      v.flush,
		SkipBuffer: v.skipBuffer,
	}
}

// AggregatorPad (GstAggregatorPad) pads managed by a Aggregator subclass.
//
// This class used to live in gst-plugins-bad and was moved to core.
type AggregatorPad struct {
	_ [0]func() // equal guard
	gst.Pad
}

var (
	_ gst.GstObjector = (*AggregatorPad)(nil)
)

// AggregatorPadder describes types inherited from AggregatorPad.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type AggregatorPadder interface {
	gst.Padder

	// DropBuffer (gst_aggregator_pad_drop_buffer): drop the buffer currently
	// queued in pad.
	DropBuffer() bool
	// HasBuffer (gst_aggregator_pad_has_buffer): this checks if a
	// pad has a buffer available that will be returned by a call to
	// gst_aggregator_pad_peek_buffer() or gst_aggregator_pad_pop_buffer().
	HasBuffer() bool
	IsEos() bool
	// IsInactive (gst_aggregator_pad_is_inactive): it is only valid to call
	// this method from AggregatorClass::aggregate().
	IsInactive() bool
	PeekBuffer() *gst.Buffer
	// PopBuffer (gst_aggregator_pad_pop_buffer): steal the ref to the buffer
	// currently queued in pad.
	PopBuffer() *gst.Buffer

	ConnectBufferConsumed(func(object *gst.Buffer)) coreglib.SignalHandle

	baseAggregatorPad() *AggregatorPad
}

var _ AggregatorPadder = (*AggregatorPad)(nil)

func init() {
	coreglib.RegisterClassInfo[*AggregatorPad, *AggregatorPadClass, AggregatorPadOverrides](
		GTypeAggregatorPad,
		initAggregatorPadClass,
		wrapAggregatorPad,
		defaultAggregatorPadOverrides,
	)
}

func initAggregatorPadClass(gclass unsafe.Pointer, overrides AggregatorPadOverrides, classInitFunc func(*AggregatorPadClass)) {
	pclass := (*C.GstAggregatorPadClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeAggregatorPad))))

	if overrides.Flush != nil {
		pclass.flush = (*[0]byte)(C._gotk4_gstbase1_AggregatorPadClass_flush)
	}

	if overrides.SkipBuffer != nil {
		pclass.skip_buffer = (*[0]byte)(C._gotk4_gstbase1_AggregatorPadClass_skip_buffer)
	}

	if classInitFunc != nil {
		class := (*AggregatorPadClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapAggregatorPad(obj *coreglib.Object) *AggregatorPad {
	return &AggregatorPad{
		Pad: gst.Pad{
			GstObject: gst.GstObject{
				InitiallyUnowned: coreglib.InitiallyUnowned{
					Object: obj,
				},
			},
		},
	}
}

func marshalAggregatorPad(p uintptr) (interface{}, error) {
	return wrapAggregatorPad(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (pad *AggregatorPad) baseAggregatorPad() *AggregatorPad {
	return pad
}

// BaseAggregatorPad returns the underlying base object.
func BaseAggregatorPad(obj AggregatorPadder) *AggregatorPad {
	return obj.baseAggregatorPad()
}

func (pad *AggregatorPad) ConnectBufferConsumed(f func(object *gst.Buffer)) coreglib.SignalHandle {
	return coreglib.ConnectGeneratedClosure(pad, "buffer-consumed", false, unsafe.Pointer(C._gotk4_gstbase1_AggregatorPad_ConnectBufferConsumed), f)
}

// DropBuffer (gst_aggregator_pad_drop_buffer): drop the buffer currently queued
// in pad.
//
// The function returns the following values:
//
//   - ok: TRUE if there was a buffer queued in pad, or FALSE if not.
func (pad *AggregatorPad) DropBuffer() bool {
	var _arg0 *C.GstAggregatorPad // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))

	_cret = C.gst_aggregator_pad_drop_buffer(_arg0)
	runtime.KeepAlive(pad)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// HasBuffer (gst_aggregator_pad_has_buffer): this checks if a pad has a buffer
// available that will be returned by a call to gst_aggregator_pad_peek_buffer()
// or gst_aggregator_pad_pop_buffer().
//
// The function returns the following values:
//
//   - ok: TRUE if the pad has a buffer available as the next thing.
func (pad *AggregatorPad) HasBuffer() bool {
	var _arg0 *C.GstAggregatorPad // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))

	_cret = C.gst_aggregator_pad_has_buffer(_arg0)
	runtime.KeepAlive(pad)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function returns the following values:
//
//   - ok: TRUE if the pad is EOS, otherwise FALSE.
func (pad *AggregatorPad) IsEos() bool {
	var _arg0 *C.GstAggregatorPad // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))

	_cret = C.gst_aggregator_pad_is_eos(_arg0)
	runtime.KeepAlive(pad)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// IsInactive (gst_aggregator_pad_is_inactive): it is only valid to call this
// method from AggregatorClass::aggregate().
//
// The function returns the following values:
//
//   - ok: TRUE if the pad is inactive, FALSE otherwise. See
//     gst_aggregator_ignore_inactive_pads() for more info.
func (pad *AggregatorPad) IsInactive() bool {
	var _arg0 *C.GstAggregatorPad // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))

	_cret = C.gst_aggregator_pad_is_inactive(_arg0)
	runtime.KeepAlive(pad)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function returns the following values:
//
//   - buffer (optional): reference to the buffer in pad or NULL if no buffer
//     was queued. You should unref the buffer after usage.
func (pad *AggregatorPad) PeekBuffer() *gst.Buffer {
	var _arg0 *C.GstAggregatorPad // out
	var _cret *C.GstBuffer        // in

	_arg0 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))

	_cret = C.gst_aggregator_pad_peek_buffer(_arg0)
	runtime.KeepAlive(pad)

	var _buffer *gst.Buffer // out

	if _cret != nil {
		_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_buffer)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _buffer
}

// PopBuffer (gst_aggregator_pad_pop_buffer): steal the ref to the buffer
// currently queued in pad.
//
// The function returns the following values:
//
//   - buffer (optional) in pad or NULL if no buffer was queued. You should
//     unref the buffer after usage.
func (pad *AggregatorPad) PopBuffer() *gst.Buffer {
	var _arg0 *C.GstAggregatorPad // out
	var _cret *C.GstBuffer        // in

	_arg0 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))

	_cret = C.gst_aggregator_pad_pop_buffer(_arg0)
	runtime.KeepAlive(pad)

	var _buffer *gst.Buffer // out

	if _cret != nil {
		_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_buffer)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _buffer
}

// Flush: optional Called when the pad has received a flush stop, this is the
// place to flush any information specific to the pad, it allows for individual
// pads to be flushed while others might not be.
func (aggpad *AggregatorPad) flush(aggregator Aggregatorrer) gst.FlowReturn {
	gclass := (*C.GstAggregatorPadClass)(coreglib.PeekParentClass(aggpad))
	fnarg := gclass.flush

	var _arg0 *C.GstAggregatorPad // out
	var _arg1 *C.GstAggregator    // out
	var _cret C.GstFlowReturn     // in

	_arg0 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(aggpad).Native()))
	_arg1 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(aggregator).Native()))

	_cret = C._gotk4_gstbase1_AggregatorPad_virtual_flush(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(aggpad)
	runtime.KeepAlive(aggregator)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// skipBuffer: optional Called before input buffers are queued in the pad,
// return TRUE if the buffer should be skipped.
//
// The function takes the following parameters:
//
//   - aggregator
//   - buffer
func (aggpad *AggregatorPad) skipBuffer(aggregator Aggregatorrer, buffer *gst.Buffer) bool {
	gclass := (*C.GstAggregatorPadClass)(coreglib.PeekParentClass(aggpad))
	fnarg := gclass.skip_buffer

	var _arg0 *C.GstAggregatorPad // out
	var _arg1 *C.GstAggregator    // out
	var _arg2 *C.GstBuffer        // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(aggpad).Native()))
	_arg1 = (*C.GstAggregator)(unsafe.Pointer(coreglib.BaseObject(aggregator).Native()))
	_arg2 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))

	_cret = C._gotk4_gstbase1_AggregatorPad_virtual_skip_buffer(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(aggpad)
	runtime.KeepAlive(aggregator)
	runtime.KeepAlive(buffer)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// BaseParseOverrides contains methods that are overridable.
type BaseParseOverrides struct {
	// Convert: optional. Convert between formats.
	//
	// The function takes the following parameters:
	//
	//   - srcFormat
	//   - srcValue
	//   - destFormat
	//   - destValue
	Convert func(srcFormat gst.Format, srcValue int64, destFormat gst.Format, destValue *int64) bool
	// Detect: optional. Called until it doesn't return GST_FLOW_OK anymore
	// for the first buffers. Can be used by the subclass to detect the stream
	// format.
	Detect func(buffer *gst.Buffer) gst.FlowReturn
	// SinkCaps: optional. Allows the subclass to do its own sink get caps if
	// needed.
	SinkCaps func(filter *gst.Caps) *gst.Caps
	// HandleFrame parses the input data into valid frames as defined by
	// subclass which should be passed to gst_base_parse_finish_frame().
	// The frame's input buffer is guaranteed writable, whereas the input frame
	// ownership is held by caller (so subclass should make a copy if it needs
	// to hang on). Input buffer (data) is provided by baseclass with as much
	// metadata set as possible by baseclass according to upstream information
	// and/or subclass settings, though subclass may still set buffer timestamp
	// and duration if desired.
	//
	// The function returns the following values:
	//
	//   - skipsize
	//   - flowReturn
	HandleFrame func(frame *BaseParseFrame) (int, gst.FlowReturn)
	// PrePushFrame: optional. Called just prior to pushing a frame (after
	// any pending events have been sent) to give subclass a chance to perform
	// additional actions at this time (e.g. tag sending) or to decide whether
	// this buffer should be dropped or not (e.g. custom segment clipping).
	PrePushFrame func(frame *BaseParseFrame) gst.FlowReturn
	// SetSinkCaps: optional. Allows the subclass to be notified of the actual
	// caps set.
	SetSinkCaps func(caps *gst.Caps) bool
	// SinkEvent: optional. Event handler on the sink pad. This function should
	// chain up to the parent implementation to let the default handler run.
	SinkEvent func(event *gst.Event) bool
	// SinkQuery: optional. Query handler on the sink pad. This function should
	// chain up to the parent implementation to let the default handler run
	// (Since: 1.2).
	SinkQuery func(query *gst.Query) bool
	// SrcEvent: optional. Event handler on the source pad. Should chain up to
	// the parent to let the default handler run.
	SrcEvent func(event *gst.Event) bool
	// SrcQuery: optional. Query handler on the source pad. Should chain up to
	// the parent to let the default handler run (Since: 1.2).
	SrcQuery func(query *gst.Query) bool
	// Start: optional. Called when the element starts processing. Allows
	// opening external resources.
	Start func() bool
	// Stop: optional. Called when the element stops processing. Allows closing
	// external resources.
	Stop func() bool
}

func defaultBaseParseOverrides(v *BaseParse) BaseParseOverrides {
	return BaseParseOverrides{
		Convert:      v.convert,
		Detect:       v.detect,
		SinkCaps:     v.sinkCaps,
		HandleFrame:  v.handleFrame,
		PrePushFrame: v.prePushFrame,
		SetSinkCaps:  v.setSinkCaps,
		SinkEvent:    v.sinkEvent,
		SinkQuery:    v.sinkQuery,
		SrcEvent:     v.srcEvent,
		SrcQuery:     v.srcQuery,
		Start:        v.start,
		Stop:         v.stop,
	}
}

// BaseParse (GstBaseParse): this base class is for parser elements that process
// data and splits it into separate audio/video/whatever frames.
//
// It provides for:
//
//   - provides one sink pad and one source pad
//   - handles state changes
//   - can operate in pull mode or push mode
//   - handles seeking in both modes
//   - handles events (SEGMENT/EOS/FLUSH)
//   - handles queries (POSITION/DURATION/SEEKING/FORMAT/CONVERT)
//   - handles flushing
//
// The purpose of this base class is to provide the basic functionality of a
// parser and share a lot of rather complex code.
//
// Description of the parsing mechanism:
//
// Set-up phase
//
//   - BaseParse calls BaseParseClass::start to inform subclass that data
//     processing is about to start now.
//
//   - BaseParse class calls BaseParseClass::set_sink_caps to inform the
//     subclass about incoming sinkpad caps. Subclass could already set the
//     srcpad caps accordingly, but this might be delayed until calling
//     gst_base_parse_finish_frame() with a non-queued frame.
//
//   - At least at this point subclass needs to tell the BaseParse class how
//     big data chunks it wants to receive (minimum frame size ). It can do this
//     with gst_base_parse_set_min_frame_size().
//
//   - BaseParse class sets up appropriate data passing mode (pull/push) and
//     starts to process the data.
//
// Parsing phase
//
//   - BaseParse gathers at least min_frame_size bytes of data either by pulling
//     it from upstream or collecting buffers in an internal Adapter.
//
//   - A buffer of (at least) min_frame_size bytes is passed to subclass
//     with BaseParseClass::handle_frame. Subclass checks the contents and
//     can optionally return T_FLOW_OK along with an amount of data to be
//     skipped to find a valid frame (which will result in a subsequent
//     DISCONT). If, otherwise, the buffer does not hold a complete frame,
//     BaseParseClass::handle_frame can merely return and will be called again
//     when additional data is available. In push mode this amounts to an
//     additional input buffer (thus minimal additional latency), in pull mode
//     this amounts to some arbitrary reasonable buffer size increase.
//
//     Of course, gst_base_parse_set_min_frame_size() could also be used if a
//     very specific known amount of additional data is required. If, however,
//     the buffer holds a complete valid frame, it can pass the size of this
//     frame to gst_base_parse_finish_frame().
//
//     If acting as a converter, it can also merely indicate consumed input data
//     while simultaneously providing custom output data. Note that baseclass
//     performs some processing (such as tracking overall consumed data rate
//     versus duration) for each finished frame, but other state is only updated
//     upon each call to BaseParseClass::handle_frame (such as tracking upstream
//     input timestamp).
//
//     Subclass is also responsible for setting the buffer metadata (e.g.
//     buffer timestamp and duration, or keyframe if applicable). (although the
//     latter can also be done by BaseParse if it is appropriately configured,
//     see below). Frame is provided with timestamp derived from upstream (as
//     much as generally possible), duration obtained from configuration (see
//     below), and offset if meaningful (in pull mode).
//
//     Note that BaseParseClass::handle_frame might receive any small amount of
//     input data when leftover data is being drained (e.g. at EOS).
//
//   - As part of finish frame processing, just prior to actually pushing the
//     buffer in question, it is passed to BaseParseClass::pre_push_frame which
//     gives subclass yet one last chance to examine buffer metadata, or to send
//     some custom (tag) events, or to perform custom (segment) filtering.
//
//   - During the parsing process BaseParseClass will handle both
//     srcpad and sinkpad events. They will be passed to subclass if
//     BaseParseClass::sink_event or BaseParseClass::src_event implementations
//     have been provided.
//
// # Shutdown phase
//
// * BaseParse class calls BaseParseClass::stop to inform the subclass that data
// parsing will be stopped.
//
// Subclass is responsible for providing pad template caps for source and sink
// pads. The pads need to be named "sink" and "src". It also needs to set the
// fixed caps on srcpad, when the format is ensured (e.g. when base class calls
// subclass' BaseParseClass::set_sink_caps function).
//
// This base class uses GST_FORMAT_DEFAULT as a meaning of frames. So, subclass
// conversion routine needs to know that conversion from GST_FORMAT_TIME to
// GST_FORMAT_DEFAULT must return the frame number that can be found from the
// given byte position.
//
// BaseParse uses subclasses conversion methods also for seeking (or otherwise
// uses its own default one, see also below).
//
// Subclass start and stop functions will be called to inform the beginning and
// end of data processing.
//
// Things that subclass need to take care of:
//
// * Provide pad templates * Fixate the source pad caps when appropriate *
// Inform base class how big data chunks should be retrieved. This is done
// with gst_base_parse_set_min_frame_size() function. * Examine data chunks
// passed to subclass with BaseParseClass::handle_frame and pass proper
// frame(s) to gst_base_parse_finish_frame(), and setting src pad caps and
// timestamps on frame. * Provide conversion functions * Update the duration
// information with gst_base_parse_set_duration() * Optionally passthrough using
// gst_base_parse_set_passthrough() * Configure various baseparse parameters
// using gst_base_parse_set_average_bitrate(), gst_base_parse_set_syncable() and
// gst_base_parse_set_frame_rate().
//
// * In particular, if subclass is unable to determine a duration, but parsing
// (or specs) yields a frames per seconds rate, then this can be provided to
// BaseParse to enable it to cater for buffer time metadata (which will be
// taken from upstream as much as possible). Internally keeping track of frame
// durations and respective sizes that have been pushed provides BaseParse
// with an estimated bitrate. A default BaseParseClass::convert (used if not
// overridden) will then use these rates to perform obvious conversions.
// These rates are also used to update (estimated) duration at regular frame
// intervals.
type BaseParse struct {
	_ [0]func() // equal guard
	gst.Element
}

var (
	_ gst.Elementer = (*BaseParse)(nil)
)

// BaseParser describes types inherited from BaseParse.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type BaseParser interface {
	gst.Elementer

	// AddIndexEntry (gst_base_parse_add_index_entry) adds an entry to the index
	// associating offset to ts.
	AddIndexEntry(offset uint64, ts gst.ClockTime, key, force bool) bool
	// ConvertDefault (gst_base_parse_convert_default): default implementation
	// of BaseParseClass::convert.
	ConvertDefault(srcFormat gst.Format, srcValue int64, destFormat gst.Format) (int64, bool)
	// Drain (gst_base_parse_drain) drains the adapter until it is empty.
	Drain()
	// FinishFrame (gst_base_parse_finish_frame) collects parsed data and pushes
	// it downstream.
	FinishFrame(frame *BaseParseFrame, size int) gst.FlowReturn
	// MergeTags (gst_base_parse_merge_tags) sets the parser subclass's tags and
	// how they should be merged with any upstream stream tags.
	MergeTags(tags *gst.TagList, mode gst.TagMergeMode)
	// PushFrame (gst_base_parse_push_frame) pushes the frame's buffer
	// downstream, sends any pending events and does some timestamp and segment
	// handling.
	PushFrame(frame *BaseParseFrame) gst.FlowReturn
	// SetAverageBitrate (gst_base_parse_set_average_bitrate): optionally sets
	// the average bitrate detected in media (if non-zero), e.g.
	SetAverageBitrate(bitrate uint)
	// SetDuration (gst_base_parse_set_duration) sets the duration of the
	// currently playing media.
	SetDuration(fmt gst.Format, duration int64, interval int)
	// SetFrameRate (gst_base_parse_set_frame_rate): if frames per second is
	// configured, parser can take care of buffer duration and timestamping.
	SetFrameRate(fpsNum, fpsDen, leadIn, leadOut uint)
	// SetHasTimingInfo (gst_base_parse_set_has_timing_info): set if frames
	// carry timing information which the subclass can (generally) parse and
	// provide.
	SetHasTimingInfo(hasTiming bool)
	// SetInferTs (gst_base_parse_set_infer_ts): by default, the base class
	// might try to infer PTS from DTS and vice versa.
	SetInferTs(inferTs bool)
	// SetLatency (gst_base_parse_set_latency) sets the minimum and maximum
	// (which may likely be equal) latency introduced by the parsing process.
	SetLatency(minLatency, maxLatency gst.ClockTime)
	// SetMinFrameSize (gst_base_parse_set_min_frame_size) subclass can use this
	// function to tell the base class that it needs to be given buffers of at
	// least min_size bytes.
	SetMinFrameSize(minSize uint)
	// SetPassthrough (gst_base_parse_set_passthrough): set if the nature of the
	// format or configuration does not allow (much) parsing, and the parser
	// should operate in passthrough mode (which only applies when operating in
	// push mode).
	SetPassthrough(passthrough bool)
	// SetPtsInterpolation (gst_base_parse_set_pts_interpolation): by default,
	// the base class will guess PTS timestamps using a simple interpolation
	// (previous timestamp + duration), which is incorrect for data streams with
	// reordering, where PTS can go backward.
	SetPtsInterpolation(ptsInterpolate bool)
	// SetSyncable (gst_base_parse_set_syncable): set if frame starts can be
	// identified.
	SetSyncable(syncable bool)
	// SetTsAtOffset (gst_base_parse_set_ts_at_offset): this function should
	// only be called from a handle_frame implementation.
	SetTsAtOffset(offset uint)

	baseBaseParse() *BaseParse
}

var _ BaseParser = (*BaseParse)(nil)

func init() {
	coreglib.RegisterClassInfo[*BaseParse, *BaseParseClass, BaseParseOverrides](
		GTypeBaseParse,
		initBaseParseClass,
		wrapBaseParse,
		defaultBaseParseOverrides,
	)
}

func initBaseParseClass(gclass unsafe.Pointer, overrides BaseParseOverrides, classInitFunc func(*BaseParseClass)) {
	pclass := (*C.GstBaseParseClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeBaseParse))))

	if overrides.Convert != nil {
		pclass.convert = (*[0]byte)(C._gotk4_gstbase1_BaseParseClass_convert)
	}

	if overrides.Detect != nil {
		pclass.detect = (*[0]byte)(C._gotk4_gstbase1_BaseParseClass_detect)
	}

	if overrides.SinkCaps != nil {
		pclass.get_sink_caps = (*[0]byte)(C._gotk4_gstbase1_BaseParseClass_get_sink_caps)
	}

	if overrides.HandleFrame != nil {
		pclass.handle_frame = (*[0]byte)(C._gotk4_gstbase1_BaseParseClass_handle_frame)
	}

	if overrides.PrePushFrame != nil {
		pclass.pre_push_frame = (*[0]byte)(C._gotk4_gstbase1_BaseParseClass_pre_push_frame)
	}

	if overrides.SetSinkCaps != nil {
		pclass.set_sink_caps = (*[0]byte)(C._gotk4_gstbase1_BaseParseClass_set_sink_caps)
	}

	if overrides.SinkEvent != nil {
		pclass.sink_event = (*[0]byte)(C._gotk4_gstbase1_BaseParseClass_sink_event)
	}

	if overrides.SinkQuery != nil {
		pclass.sink_query = (*[0]byte)(C._gotk4_gstbase1_BaseParseClass_sink_query)
	}

	if overrides.SrcEvent != nil {
		pclass.src_event = (*[0]byte)(C._gotk4_gstbase1_BaseParseClass_src_event)
	}

	if overrides.SrcQuery != nil {
		pclass.src_query = (*[0]byte)(C._gotk4_gstbase1_BaseParseClass_src_query)
	}

	if overrides.Start != nil {
		pclass.start = (*[0]byte)(C._gotk4_gstbase1_BaseParseClass_start)
	}

	if overrides.Stop != nil {
		pclass.stop = (*[0]byte)(C._gotk4_gstbase1_BaseParseClass_stop)
	}

	if classInitFunc != nil {
		class := (*BaseParseClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapBaseParse(obj *coreglib.Object) *BaseParse {
	return &BaseParse{
		Element: gst.Element{
			GstObject: gst.GstObject{
				InitiallyUnowned: coreglib.InitiallyUnowned{
					Object: obj,
				},
			},
		},
	}
}

func marshalBaseParse(p uintptr) (interface{}, error) {
	return wrapBaseParse(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (parse *BaseParse) baseBaseParse() *BaseParse {
	return parse
}

// BaseBaseParse returns the underlying base object.
func BaseBaseParse(obj BaseParser) *BaseParse {
	return obj.baseBaseParse()
}

// AddIndexEntry (gst_base_parse_add_index_entry) adds an entry to the index
// associating offset to ts. It is recommended to only add keyframe entries.
// force allows to bypass checks, such as whether the stream is (upstream)
// seekable, another entry is already "close" to the new entry, etc.
//
// The function takes the following parameters:
//
//   - offset of entry.
//   - ts: timestamp associated with offset.
//   - key: whether entry refers to keyframe.
//   - force: add entry disregarding sanity checks.
//
// The function returns the following values:
//
//   - ok indicating whether entry was added.
func (parse *BaseParse) AddIndexEntry(offset uint64, ts gst.ClockTime, key, force bool) bool {
	var _arg0 *C.GstBaseParse // out
	var _arg1 C.guint64       // out
	var _arg2 C.GstClockTime  // out
	var _arg3 C.gboolean      // out
	var _arg4 C.gboolean      // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	_arg1 = C.guint64(offset)
	_arg2 = C.GstClockTime(ts)
	if key {
		_arg3 = C.TRUE
	}
	if force {
		_arg4 = C.TRUE
	}

	_cret = C.gst_base_parse_add_index_entry(_arg0, _arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(offset)
	runtime.KeepAlive(ts)
	runtime.KeepAlive(key)
	runtime.KeepAlive(force)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// ConvertDefault (gst_base_parse_convert_default): default implementation of
// BaseParseClass::convert.
//
// The function takes the following parameters:
//
//   - srcFormat describing the source format.
//   - srcValue: source value to be converted.
//   - destFormat defining the converted format.
//
// The function returns the following values:
//
//   - destValue: pointer where the conversion result will be put.
//   - ok: TRUE if conversion was successful.
func (parse *BaseParse) ConvertDefault(srcFormat gst.Format, srcValue int64, destFormat gst.Format) (int64, bool) {
	var _arg0 *C.GstBaseParse // out
	var _arg1 C.GstFormat     // out
	var _arg2 C.gint64        // out
	var _arg3 C.GstFormat     // out
	var _arg4 C.gint64        // in
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	_arg1 = C.GstFormat(srcFormat)
	_arg2 = C.gint64(srcValue)
	_arg3 = C.GstFormat(destFormat)

	_cret = C.gst_base_parse_convert_default(_arg0, _arg1, _arg2, _arg3, &_arg4)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(srcFormat)
	runtime.KeepAlive(srcValue)
	runtime.KeepAlive(destFormat)

	var _destValue int64 // out
	var _ok bool         // out

	_destValue = int64(_arg4)
	if _cret != 0 {
		_ok = true
	}

	return _destValue, _ok
}

// Drain (gst_base_parse_drain) drains the adapter until it is empty.
// It decreases the min_frame_size to match the current adapter size and calls
// chain method until the adapter is emptied or chain returns with error.
func (parse *BaseParse) Drain() {
	var _arg0 *C.GstBaseParse // out

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))

	C.gst_base_parse_drain(_arg0)
	runtime.KeepAlive(parse)
}

// FinishFrame (gst_base_parse_finish_frame) collects parsed data and pushes it
// downstream. Source pad caps must be set when this is called.
//
// If frame's out_buffer is set, that will be used as subsequent frame data,
// and size amount will be flushed from the input data. The output_buffer size
// can differ from the consumed size indicated by size.
//
// Otherwise, size samples will be taken from the input and used for output,
// and the output's metadata (timestamps etc) will be taken as (optionally) set
// by the subclass on frame's (input) buffer (which is otherwise ignored for any
// but the above purpose/information).
//
// Note that the latter buffer is invalidated by this call, whereas the caller
// retains ownership of frame.
//
// The function takes the following parameters:
//
//   - frame: BaseParseFrame.
//   - size: consumed input data represented by frame.
//
// The function returns the following values:
//
//   - flowReturn that should be escalated to caller (of caller).
func (parse *BaseParse) FinishFrame(frame *BaseParseFrame, size int) gst.FlowReturn {
	var _arg0 *C.GstBaseParse      // out
	var _arg1 *C.GstBaseParseFrame // out
	var _arg2 C.gint               // out
	var _cret C.GstFlowReturn      // in

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	_arg1 = (*C.GstBaseParseFrame)(gextras.StructNative(unsafe.Pointer(frame)))
	_arg2 = C.gint(size)

	_cret = C.gst_base_parse_finish_frame(_arg0, _arg1, _arg2)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(frame)
	runtime.KeepAlive(size)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// MergeTags (gst_base_parse_merge_tags) sets the parser subclass's tags and how
// they should be merged with any upstream stream tags. This will override any
// tags previously-set with gst_base_parse_merge_tags().
//
// Note that this is provided for convenience, and the subclass is not required
// to use this and can still do tag handling on its own.
//
// The function takes the following parameters:
//
//   - tags (optional) to merge, or NULL to unset previously-set tags.
//   - mode to use, usually T_TAG_MERGE_REPLACE.
func (parse *BaseParse) MergeTags(tags *gst.TagList, mode gst.TagMergeMode) {
	var _arg0 *C.GstBaseParse   // out
	var _arg1 *C.GstTagList     // out
	var _arg2 C.GstTagMergeMode // out

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	if tags != nil {
		_arg1 = (*C.GstTagList)(gextras.StructNative(unsafe.Pointer(tags)))
	}
	_arg2 = C.GstTagMergeMode(mode)

	C.gst_base_parse_merge_tags(_arg0, _arg1, _arg2)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(tags)
	runtime.KeepAlive(mode)
}

// PushFrame (gst_base_parse_push_frame) pushes the frame's buffer downstream,
// sends any pending events and does some timestamp and segment handling.
// Takes ownership of frame's buffer, though caller retains ownership of frame.
//
// This must be called with sinkpad STREAM_LOCK held.
//
// The function takes the following parameters:
//
//   - frame: BaseParseFrame.
//
// The function returns the following values:
//
//   - flowReturn: FlowReturn.
func (parse *BaseParse) PushFrame(frame *BaseParseFrame) gst.FlowReturn {
	var _arg0 *C.GstBaseParse      // out
	var _arg1 *C.GstBaseParseFrame // out
	var _cret C.GstFlowReturn      // in

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	_arg1 = (*C.GstBaseParseFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	_cret = C.gst_base_parse_push_frame(_arg0, _arg1)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(frame)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// SetAverageBitrate (gst_base_parse_set_average_bitrate): optionally sets the
// average bitrate detected in media (if non-zero), e.g. based on metadata,
// as it will be posted to the application.
//
// By default, announced average bitrate is estimated. The average bitrate
// is used to estimate the total duration of the stream and to estimate
// a seek position, if there's no index and the format is syncable (see
// gst_base_parse_set_syncable()).
//
// The function takes the following parameters:
//
//   - bitrate: average bitrate in bits/second.
func (parse *BaseParse) SetAverageBitrate(bitrate uint) {
	var _arg0 *C.GstBaseParse // out
	var _arg1 C.guint         // out

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	_arg1 = C.guint(bitrate)

	C.gst_base_parse_set_average_bitrate(_arg0, _arg1)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(bitrate)
}

// SetDuration (gst_base_parse_set_duration) sets the duration of the currently
// playing media. Subclass can use this when it is able to determine duration
// and/or notices a change in the media duration. Alternatively, if interval is
// non-zero (default), then stream duration is determined based on estimated
// bitrate, and updated every interval frames.
//
// The function takes the following parameters:
//
//   - fmt: Format.
//   - duration value.
//   - interval: how often to update the duration estimate based on bitrate,
//     or 0.
func (parse *BaseParse) SetDuration(fmt gst.Format, duration int64, interval int) {
	var _arg0 *C.GstBaseParse // out
	var _arg1 C.GstFormat     // out
	var _arg2 C.gint64        // out
	var _arg3 C.gint          // out

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	_arg1 = C.GstFormat(fmt)
	_arg2 = C.gint64(duration)
	_arg3 = C.gint(interval)

	C.gst_base_parse_set_duration(_arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(fmt)
	runtime.KeepAlive(duration)
	runtime.KeepAlive(interval)
}

// SetFrameRate (gst_base_parse_set_frame_rate): if frames per second is
// configured, parser can take care of buffer duration and timestamping.
// When performing segment clipping, or seeking to a specific location,
// a corresponding decoder might need an initial lead_in and a following
// lead_out number of frames to ensure the desired segment is entirely filled
// upon decoding.
//
// The function takes the following parameters:
//
//   - fpsNum frames per second (numerator).
//   - fpsDen frames per second (denominator).
//   - leadIn frames needed before a segment for subsequent decode.
//   - leadOut frames needed after a segment.
func (parse *BaseParse) SetFrameRate(fpsNum, fpsDen, leadIn, leadOut uint) {
	var _arg0 *C.GstBaseParse // out
	var _arg1 C.guint         // out
	var _arg2 C.guint         // out
	var _arg3 C.guint         // out
	var _arg4 C.guint         // out

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	_arg1 = C.guint(fpsNum)
	_arg2 = C.guint(fpsDen)
	_arg3 = C.guint(leadIn)
	_arg4 = C.guint(leadOut)

	C.gst_base_parse_set_frame_rate(_arg0, _arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(fpsNum)
	runtime.KeepAlive(fpsDen)
	runtime.KeepAlive(leadIn)
	runtime.KeepAlive(leadOut)
}

// SetHasTimingInfo (gst_base_parse_set_has_timing_info): set if frames carry
// timing information which the subclass can (generally) parse and provide. In
// particular, intrinsic (rather than estimated) time can be obtained following
// a seek.
//
// The function takes the following parameters:
//
//   - hasTiming: whether frames carry timing information.
func (parse *BaseParse) SetHasTimingInfo(hasTiming bool) {
	var _arg0 *C.GstBaseParse // out
	var _arg1 C.gboolean      // out

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	if hasTiming {
		_arg1 = C.TRUE
	}

	C.gst_base_parse_set_has_timing_info(_arg0, _arg1)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(hasTiming)
}

// SetInferTs (gst_base_parse_set_infer_ts): by default, the base class might
// try to infer PTS from DTS and vice versa. While this is generally correct for
// audio data, it may not be otherwise. Sub-classes implementing such formats
// should disable timestamp inferring.
//
// The function takes the following parameters:
//
//   - inferTs: TRUE if parser should infer DTS/PTS from each other.
func (parse *BaseParse) SetInferTs(inferTs bool) {
	var _arg0 *C.GstBaseParse // out
	var _arg1 C.gboolean      // out

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	if inferTs {
		_arg1 = C.TRUE
	}

	C.gst_base_parse_set_infer_ts(_arg0, _arg1)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(inferTs)
}

// SetLatency (gst_base_parse_set_latency) sets the minimum and maximum (which
// may likely be equal) latency introduced by the parsing process. If there
// is such a latency, which depends on the particular parsing of the format,
// it typically corresponds to 1 frame duration.
//
// If the provided values changed from previously provided ones, this will also
// post a LATENCY message on the bus so the pipeline can reconfigure its global
// latency.
//
// The function takes the following parameters:
//
//   - minLatency: minimum parse latency.
//   - maxLatency: maximum parse latency.
func (parse *BaseParse) SetLatency(minLatency, maxLatency gst.ClockTime) {
	var _arg0 *C.GstBaseParse // out
	var _arg1 C.GstClockTime  // out
	var _arg2 C.GstClockTime  // out

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	_arg1 = C.GstClockTime(minLatency)
	_arg2 = C.GstClockTime(maxLatency)

	C.gst_base_parse_set_latency(_arg0, _arg1, _arg2)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(minLatency)
	runtime.KeepAlive(maxLatency)
}

// SetMinFrameSize (gst_base_parse_set_min_frame_size) subclass can use this
// function to tell the base class that it needs to be given buffers of at least
// min_size bytes.
//
// The function takes the following parameters:
//
//   - minSize: minimum size in bytes of the data that this base class should
//     give to subclass.
func (parse *BaseParse) SetMinFrameSize(minSize uint) {
	var _arg0 *C.GstBaseParse // out
	var _arg1 C.guint         // out

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	_arg1 = C.guint(minSize)

	C.gst_base_parse_set_min_frame_size(_arg0, _arg1)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(minSize)
}

// SetPassthrough (gst_base_parse_set_passthrough): set if the nature
// of the format or configuration does not allow (much) parsing, and the
// parser should operate in passthrough mode (which only applies when
// operating in push mode). That is, incoming buffers are pushed through
// unmodified, i.e. no BaseParseClass::handle_frame will be invoked,
// but BaseParseClass::pre_push_frame will still be invoked, so subclass can
// perform as much or as little is appropriate for passthrough semantics in
// BaseParseClass::pre_push_frame.
//
// The function takes the following parameters:
//
//   - passthrough: TRUE if parser should run in passthrough mode.
func (parse *BaseParse) SetPassthrough(passthrough bool) {
	var _arg0 *C.GstBaseParse // out
	var _arg1 C.gboolean      // out

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	if passthrough {
		_arg1 = C.TRUE
	}

	C.gst_base_parse_set_passthrough(_arg0, _arg1)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(passthrough)
}

// SetPtsInterpolation (gst_base_parse_set_pts_interpolation): by default, the
// base class will guess PTS timestamps using a simple interpolation (previous
// timestamp + duration), which is incorrect for data streams with reordering,
// where PTS can go backward. Sub-classes implementing such formats should
// disable PTS interpolation.
//
// The function takes the following parameters:
//
//   - ptsInterpolate: TRUE if parser should interpolate PTS timestamps.
func (parse *BaseParse) SetPtsInterpolation(ptsInterpolate bool) {
	var _arg0 *C.GstBaseParse // out
	var _arg1 C.gboolean      // out

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	if ptsInterpolate {
		_arg1 = C.TRUE
	}

	C.gst_base_parse_set_pts_interpolation(_arg0, _arg1)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(ptsInterpolate)
}

// SetSyncable (gst_base_parse_set_syncable): set if frame starts can be
// identified. This is set by default and determines whether seeking based on
// bitrate averages is possible for a format/stream.
//
// The function takes the following parameters:
//
//   - syncable: set if frame starts can be identified.
func (parse *BaseParse) SetSyncable(syncable bool) {
	var _arg0 *C.GstBaseParse // out
	var _arg1 C.gboolean      // out

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	if syncable {
		_arg1 = C.TRUE
	}

	C.gst_base_parse_set_syncable(_arg0, _arg1)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(syncable)
}

// SetTsAtOffset (gst_base_parse_set_ts_at_offset): this function should only be
// called from a handle_frame implementation.
//
// BaseParse creates initial timestamps for frames by using the last timestamp
// seen in the stream before the frame starts. In certain cases, the correct
// timestamps will occur in the stream after the start of the frame, but before
// the start of the actual picture data. This function can be used to set the
// timestamps based on the offset into the frame data that the picture starts.
//
// The function takes the following parameters:
//
//   - offset into current buffer.
func (parse *BaseParse) SetTsAtOffset(offset uint) {
	var _arg0 *C.GstBaseParse // out
	var _arg1 C.gsize         // out

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	_arg1 = C.gsize(offset)

	C.gst_base_parse_set_ts_at_offset(_arg0, _arg1)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(offset)
}

// Convert: optional. Convert between formats.
//
// The function takes the following parameters:
//
//   - srcFormat
//   - srcValue
//   - destFormat
//   - destValue
func (parse *BaseParse) convert(srcFormat gst.Format, srcValue int64, destFormat gst.Format, destValue *int64) bool {
	gclass := (*C.GstBaseParseClass)(coreglib.PeekParentClass(parse))
	fnarg := gclass.convert

	var _arg0 *C.GstBaseParse // out
	var _arg1 C.GstFormat     // out
	var _arg2 C.gint64        // out
	var _arg3 C.GstFormat     // out
	var _arg4 *C.gint64       // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	_arg1 = C.GstFormat(srcFormat)
	_arg2 = C.gint64(srcValue)
	_arg3 = C.GstFormat(destFormat)
	_arg4 = (*C.gint64)(unsafe.Pointer(destValue))

	_cret = C._gotk4_gstbase1_BaseParse_virtual_convert(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(srcFormat)
	runtime.KeepAlive(srcValue)
	runtime.KeepAlive(destFormat)
	runtime.KeepAlive(destValue)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Detect: optional. Called until it doesn't return GST_FLOW_OK anymore for the
// first buffers. Can be used by the subclass to detect the stream format.
func (parse *BaseParse) detect(buffer *gst.Buffer) gst.FlowReturn {
	gclass := (*C.GstBaseParseClass)(coreglib.PeekParentClass(parse))
	fnarg := gclass.detect

	var _arg0 *C.GstBaseParse // out
	var _arg1 *C.GstBuffer    // out
	var _cret C.GstFlowReturn // in

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))

	_cret = C._gotk4_gstbase1_BaseParse_virtual_detect(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(buffer)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// sinkCaps: optional. Allows the subclass to do its own sink get caps if
// needed.
func (parse *BaseParse) sinkCaps(filter *gst.Caps) *gst.Caps {
	gclass := (*C.GstBaseParseClass)(coreglib.PeekParentClass(parse))
	fnarg := gclass.get_sink_caps

	var _arg0 *C.GstBaseParse // out
	var _arg1 *C.GstCaps      // out
	var _cret *C.GstCaps      // in

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(filter)))

	_cret = C._gotk4_gstbase1_BaseParse_virtual_get_sink_caps(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(filter)

	var _caps *gst.Caps // out

	_caps = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_caps)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _caps
}

// handleFrame parses the input data into valid frames as defined by subclass
// which should be passed to gst_base_parse_finish_frame(). The frame's input
// buffer is guaranteed writable, whereas the input frame ownership is held
// by caller (so subclass should make a copy if it needs to hang on). Input
// buffer (data) is provided by baseclass with as much metadata set as possible
// by baseclass according to upstream information and/or subclass settings,
// though subclass may still set buffer timestamp and duration if desired.
//
// The function returns the following values:
//
//   - skipsize
//   - flowReturn
func (parse *BaseParse) handleFrame(frame *BaseParseFrame) (int, gst.FlowReturn) {
	gclass := (*C.GstBaseParseClass)(coreglib.PeekParentClass(parse))
	fnarg := gclass.handle_frame

	var _arg0 *C.GstBaseParse      // out
	var _arg1 *C.GstBaseParseFrame // out
	var _arg2 C.gint               // in
	var _cret C.GstFlowReturn      // in

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	_arg1 = (*C.GstBaseParseFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	_cret = C._gotk4_gstbase1_BaseParse_virtual_handle_frame(unsafe.Pointer(fnarg), _arg0, _arg1, &_arg2)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(frame)

	var _skipsize int              // out
	var _flowReturn gst.FlowReturn // out

	_skipsize = int(_arg2)
	_flowReturn = gst.FlowReturn(_cret)

	return _skipsize, _flowReturn
}

// prePushFrame: optional. Called just prior to pushing a frame (after
// any pending events have been sent) to give subclass a chance to perform
// additional actions at this time (e.g. tag sending) or to decide whether this
// buffer should be dropped or not (e.g. custom segment clipping).
func (parse *BaseParse) prePushFrame(frame *BaseParseFrame) gst.FlowReturn {
	gclass := (*C.GstBaseParseClass)(coreglib.PeekParentClass(parse))
	fnarg := gclass.pre_push_frame

	var _arg0 *C.GstBaseParse      // out
	var _arg1 *C.GstBaseParseFrame // out
	var _cret C.GstFlowReturn      // in

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	_arg1 = (*C.GstBaseParseFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	_cret = C._gotk4_gstbase1_BaseParse_virtual_pre_push_frame(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(frame)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// setSinkCaps: optional. Allows the subclass to be notified of the actual caps
// set.
func (parse *BaseParse) setSinkCaps(caps *gst.Caps) bool {
	gclass := (*C.GstBaseParseClass)(coreglib.PeekParentClass(parse))
	fnarg := gclass.set_sink_caps

	var _arg0 *C.GstBaseParse // out
	var _arg1 *C.GstCaps      // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C._gotk4_gstbase1_BaseParse_virtual_set_sink_caps(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(caps)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// sinkEvent: optional. Event handler on the sink pad. This function should
// chain up to the parent implementation to let the default handler run.
func (parse *BaseParse) sinkEvent(event *gst.Event) bool {
	gclass := (*C.GstBaseParseClass)(coreglib.PeekParentClass(parse))
	fnarg := gclass.sink_event

	var _arg0 *C.GstBaseParse // out
	var _arg1 *C.GstEvent     // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C._gotk4_gstbase1_BaseParse_virtual_sink_event(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(event)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// sinkQuery: optional. Query handler on the sink pad. This function should
// chain up to the parent implementation to let the default handler run (Since:
// 1.2).
func (parse *BaseParse) sinkQuery(query *gst.Query) bool {
	gclass := (*C.GstBaseParseClass)(coreglib.PeekParentClass(parse))
	fnarg := gclass.sink_query

	var _arg0 *C.GstBaseParse // out
	var _arg1 *C.GstQuery     // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstbase1_BaseParse_virtual_sink_query(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// srcEvent: optional. Event handler on the source pad. Should chain up to the
// parent to let the default handler run.
func (parse *BaseParse) srcEvent(event *gst.Event) bool {
	gclass := (*C.GstBaseParseClass)(coreglib.PeekParentClass(parse))
	fnarg := gclass.src_event

	var _arg0 *C.GstBaseParse // out
	var _arg1 *C.GstEvent     // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C._gotk4_gstbase1_BaseParse_virtual_src_event(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(event)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// srcQuery: optional. Query handler on the source pad. Should chain up to the
// parent to let the default handler run (Since: 1.2).
func (parse *BaseParse) srcQuery(query *gst.Query) bool {
	gclass := (*C.GstBaseParseClass)(coreglib.PeekParentClass(parse))
	fnarg := gclass.src_query

	var _arg0 *C.GstBaseParse // out
	var _arg1 *C.GstQuery     // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstbase1_BaseParse_virtual_src_query(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(parse)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Start: optional. Called when the element starts processing. Allows opening
// external resources.
func (parse *BaseParse) start() bool {
	gclass := (*C.GstBaseParseClass)(coreglib.PeekParentClass(parse))
	fnarg := gclass.start

	var _arg0 *C.GstBaseParse // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))

	_cret = C._gotk4_gstbase1_BaseParse_virtual_start(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(parse)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Stop: optional. Called when the element stops processing. Allows closing
// external resources.
func (parse *BaseParse) stop() bool {
	gclass := (*C.GstBaseParseClass)(coreglib.PeekParentClass(parse))
	fnarg := gclass.stop

	var _arg0 *C.GstBaseParse // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBaseParse)(unsafe.Pointer(coreglib.BaseObject(parse).Native()))

	_cret = C._gotk4_gstbase1_BaseParse_virtual_stop(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(parse)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// BaseSinkOverrides contains methods that are overridable.
type BaseSinkOverrides struct {
	// ActivatePull subclasses should override this when they can provide an
	// alternate method of spawning a thread to drive the pipeline in pull mode.
	// Should start or stop the pulling thread, depending on the value of the
	// "active" argument. Called after actually activating the sink pad in pull
	// mode. The default implementation starts a task on the sink pad.
	ActivatePull func(active bool) bool
	// Event: override this to handle events arriving on the sink pad.
	Event func(event *gst.Event) bool
	// Fixate: only useful in pull mode. Implement if you have ideas about what
	// should be the default values for the caps you support.
	Fixate func(caps *gst.Caps) *gst.Caps
	// Caps: called to get sink pad caps from the subclass.
	Caps func(filter *gst.Caps) *gst.Caps
	// Times: get the start and end times for syncing on this buffer.
	//
	// The function returns the following values:
	//
	//   - start ClockTime.
	//   - end ClockTime.
	Times func(buffer *gst.Buffer) (start, end gst.ClockTime)
	// Prepare: called to prepare the buffer for render and preroll. This
	// function is called before synchronisation is performed.
	Prepare func(buffer *gst.Buffer) gst.FlowReturn
	// PrepareList: called to prepare the buffer list for render_list. This
	// function is called before synchronisation is performed.
	PrepareList func(bufferList *gst.BufferList) gst.FlowReturn
	// Preroll: called to present the preroll buffer if desired.
	Preroll func(buffer *gst.Buffer) gst.FlowReturn
	// ProposeAllocation: configure the allocation query.
	ProposeAllocation func(query *gst.Query) bool
	// Query: perform a Query on the element.
	Query func(query *gst.Query) bool
	// Render: called when a buffer should be presented or output, at the
	// correct moment if the BaseSink has been set to sync to the clock.
	Render func(buffer *gst.Buffer) gst.FlowReturn
	// RenderList: same as render but used with buffer lists instead of buffers.
	RenderList func(bufferList *gst.BufferList) gst.FlowReturn
	// SetCaps: notify subclass of changed caps.
	SetCaps func(caps *gst.Caps) bool
	// Start processing. Ideal for opening resources in the subclass.
	Start func() bool
	// Stop processing. Subclasses should use this to close resources.
	Stop func() bool
	// Unlock any pending access to the resource. Subclasses should unblock any
	// blocked function ASAP and call gst_base_sink_wait_preroll().
	Unlock func() bool
	// UnlockStop: clear the previous unlock request. Subclasses should
	// clear any state they set during BaseSinkClass::unlock, and be ready
	// to continue where they left off after gst_base_sink_wait_preroll(),
	// gst_base_sink_wait() or gst_wait_sink_wait_clock() return or
	// BaseSinkClass::render is called again.
	UnlockStop func() bool
	// WaitEvent: override this to implement custom logic to wait for the event
	// time (for events like EOS and GAP). Subclasses should always first chain
	// up to the default implementation.
	WaitEvent func(event *gst.Event) gst.FlowReturn
}

func defaultBaseSinkOverrides(v *BaseSink) BaseSinkOverrides {
	return BaseSinkOverrides{
		ActivatePull:      v.activatePull,
		Event:             v.event,
		Fixate:            v.fixate,
		Caps:              v.caps,
		Times:             v.times,
		Prepare:           v.prepare,
		PrepareList:       v.prepareList,
		Preroll:           v.preroll,
		ProposeAllocation: v.proposeAllocation,
		Query:             v.query,
		Render:            v.render,
		RenderList:        v.renderList,
		SetCaps:           v.setCaps,
		Start:             v.start,
		Stop:              v.stop,
		Unlock:            v.unlock,
		UnlockStop:        v.unlockStop,
		WaitEvent:         v.waitEvent,
	}
}

// BaseSink (GstBaseSink) is the base class for sink elements in GStreamer,
// such as xvimagesink or filesink. It is a layer on top of Element that
// provides a simplified interface to plugin writers. BaseSink handles many
// details for you, for example: preroll, clock synchronization, state changes,
// activation in push or pull mode, and queries.
//
// In most cases, when writing sink elements, there is no need to implement
// class methods from Element or to set functions on pads, because the BaseSink
// infrastructure should be sufficient.
//
// BaseSink provides support for exactly one sink pad, which should be named
// "sink". A sink implementation (subclass of BaseSink) should install a pad
// template in its class_init function, like so:
//
//	static void
//	my_element_class_init (GstMyElementClass *klass)
//	{
//	  GstElementClass *gstelement_class = GST_ELEMENT_CLASS (klass);
//
//	  // sinktemplate should be a StaticPadTemplate with direction
//	  // GST_PAD_SINK and name "sink"
//	  gst_element_class_add_static_pad_template (gstelement_class, &sinktemplate);
//
//	  gst_element_class_set_static_metadata (gstelement_class,
//	      "Sink name",
//	      "Sink",
//	      "My Sink element",
//	      "The author <my.sinkmy.email>");
//	}
//
// BaseSink will handle the prerolling correctly. This means that it will return
// GST_STATE_CHANGE_ASYNC from a state change to PAUSED until the first buffer
// arrives in this element. The base class will call the BaseSinkClass::preroll
// vmethod with this preroll buffer and will then commit the state change to the
// next asynchronously pending state.
//
// When the element is set to PLAYING, BaseSink will synchronise on the clock
// using the times returned from BaseSinkClass::get_times. If this function
// returns GST_CLOCK_TIME_NONE for the start time, no synchronisation will
// be done. Synchronisation can be disabled entirely by setting the object
// BaseSink:sync property to FALSE.
//
// After synchronisation the virtual method BaseSinkClass::render will be
// called. Subclasses should minimally implement this method.
//
// Subclasses that synchronise on the clock in the BaseSinkClass::render
// method are supported as well. These classes typically receive a buffer
// in the render method and can then potentially block on the clock while
// rendering. A typical example is an audiosink. These subclasses can use
// gst_base_sink_wait_preroll() to perform the blocking wait.
//
// Upon receiving the EOS event in the PLAYING state, BaseSink will wait
// for the clock to reach the time indicated by the stop time of the last
// BaseSinkClass::get_times call before posting an EOS message. When the element
// receives EOS in PAUSED, preroll completes, the event is queued and an EOS
// message is posted when going to PLAYING.
//
// BaseSink will internally use the GST_EVENT_SEGMENT events to schedule
// synchronisation and clipping of buffers. Buffers that fall completely outside
// of the current segment are dropped. Buffers that fall partially in the
// segment are rendered (and prerolled). Subclasses should do any subbuffer
// clipping themselves when needed.
//
// BaseSink will by default report the current playback position in
// GST_FORMAT_TIME based on the current clock time and segment information. If
// no clock has been set on the element, the query will be forwarded upstream.
//
// The BaseSinkClass::set_caps function will be called when the subclass should
// configure itself to process a specific media type.
//
// The BaseSinkClass::start and BaseSinkClass::stop virtual methods will be
// called when resources should be allocated. Any BaseSinkClass::preroll,
// BaseSinkClass::render and BaseSinkClass::set_caps function will be called
// between the BaseSinkClass::start and BaseSinkClass::stop calls.
//
// The BaseSinkClass::event virtual method will be called when an event is
// received by BaseSink. Normally this method should only be overridden by very
// specific elements (such as file sinks) which need to handle the newsegment
// event specially.
//
// The BaseSinkClass::unlock method is called when the elements should unblock
// any blocking operations they perform in the BaseSinkClass::render method.
// This is mostly useful when the BaseSinkClass::render method performs a
// blocking write on a file descriptor, for example.
//
// The BaseSink:max-lateness property affects how the sink deals with buffers
// that arrive too late in the sink. A buffer arrives too late in the sink when
// the presentation time (as a combination of the last segment, buffer timestamp
// and element base_time) plus the duration is before the current time of the
// clock. If the frame is later than max-lateness, the sink will drop the
// buffer without calling the render method. This feature is disabled if sync
// is disabled, the BaseSinkClass::get_times method does not return a valid
// start time or max-lateness is set to -1 (the default). Subclasses can use
// gst_base_sink_set_max_lateness() to configure the max-lateness value.
//
// The BaseSink:qos property will enable the quality-of-service features of
// the basesink which gather statistics about the real-time performance of the
// clock synchronisation. For each buffer received in the sink, statistics
// are gathered and a QOS event is sent upstream with these numbers. This
// information can then be used by upstream elements to reduce their processing
// rate, for example.
//
// The BaseSink:async property can be used to instruct the sink to never perform
// an ASYNC state change. This feature is mostly usable when dealing with
// non-synchronized streams or sparse streams.
type BaseSink struct {
	_ [0]func() // equal guard
	gst.Element
}

var (
	_ gst.Elementer = (*BaseSink)(nil)
)

// BaseSinker describes types inherited from BaseSink.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type BaseSinker interface {
	gst.Elementer

	// DoPreroll (gst_base_sink_do_preroll): if the sink spawns its own thread
	// for pulling buffers from upstream it should call this method after it has
	// pulled a buffer.
	DoPreroll(obj *gst.MiniObject) gst.FlowReturn
	// Blocksize (gst_base_sink_get_blocksize): get the number of bytes that the
	// sink will pull when it is operating in pull mode.
	Blocksize() uint
	// DropOutOfSegment (gst_base_sink_get_drop_out_of_segment) checks if sink
	// is currently configured to drop buffers which are outside the current
	// segment.
	DropOutOfSegment() bool
	// LastSample (gst_base_sink_get_last_sample): get the last sample that
	// arrived in the sink and was used for preroll or for rendering.
	LastSample() *gst.Sample
	// Latency (gst_base_sink_get_latency): get the currently configured
	// latency.
	Latency() gst.ClockTime
	// MaxBitrate (gst_base_sink_get_max_bitrate): get the maximum amount of
	// bits per second that the sink will render.
	MaxBitrate() uint64
	// MaxLateness (gst_base_sink_get_max_lateness) gets the max lateness value.
	MaxLateness() int64
	// ProcessingDeadline (gst_base_sink_get_processing_deadline): get the
	// processing deadline of sink.
	ProcessingDeadline() gst.ClockTime
	// RenderDelay (gst_base_sink_get_render_delay): get the render delay of
	// sink.
	RenderDelay() gst.ClockTime
	// Stats (gst_base_sink_get_stats): return various BaseSink statistics.
	Stats() *gst.Structure
	// Sync (gst_base_sink_get_sync) checks if sink is currently configured to
	// synchronize against the clock.
	Sync() bool
	// ThrottleTime (gst_base_sink_get_throttle_time): get the time that will be
	// inserted between frames to control the maximum buffers per second.
	ThrottleTime() uint64
	// TsOffset (gst_base_sink_get_ts_offset): get the synchronisation offset of
	// sink.
	TsOffset() gst.ClockTimeDiff
	// IsAsyncEnabled (gst_base_sink_is_async_enabled) checks if sink is
	// currently configured to perform asynchronous state changes to PAUSED.
	IsAsyncEnabled() bool
	// IsLastSampleEnabled (gst_base_sink_is_last_sample_enabled) checks if
	// sink is currently configured to store the last received sample in the
	// last-sample property.
	IsLastSampleEnabled() bool
	// IsQosEnabled (gst_base_sink_is_qos_enabled) checks if sink is currently
	// configured to send Quality-of-Service events upstream.
	IsQosEnabled() bool
	// QueryLatency (gst_base_sink_query_latency): query the sink for the
	// latency parameters.
	QueryLatency() (live, upstreamLive bool, minLatency, maxLatency gst.ClockTime, ok bool)
	// SetAsyncEnabled (gst_base_sink_set_async_enabled) configures sink to
	// perform all state changes asynchronously.
	SetAsyncEnabled(enabled bool)
	// SetBlocksize (gst_base_sink_set_blocksize): set the number of bytes that
	// the sink will pull when it is operating in pull mode.
	SetBlocksize(blocksize uint)
	// SetDropOutOfSegment (gst_base_sink_set_drop_out_of_segment): configure
	// sink to drop buffers which are outside the current segment.
	SetDropOutOfSegment(dropOutOfSegment bool)
	// SetLastSampleEnabled (gst_base_sink_set_last_sample_enabled) configures
	// sink to store the last received sample in the last-sample property.
	SetLastSampleEnabled(enabled bool)
	// SetMaxBitrate (gst_base_sink_set_max_bitrate): set the maximum amount of
	// bits per second that the sink will render.
	SetMaxBitrate(maxBitrate uint64)
	// SetMaxLateness (gst_base_sink_set_max_lateness) sets the new max lateness
	// value to max_lateness.
	SetMaxLateness(maxLateness int64)
	// SetProcessingDeadline (gst_base_sink_set_processing_deadline): maximum
	// amount of time (in nanoseconds) that the pipeline can take for processing
	// the buffer.
	SetProcessingDeadline(processingDeadline gst.ClockTime)
	// SetQosEnabled (gst_base_sink_set_qos_enabled) configures sink to send
	// Quality-of-Service events upstream.
	SetQosEnabled(enabled bool)
	// SetRenderDelay (gst_base_sink_set_render_delay): set the render delay in
	// sink to delay.
	SetRenderDelay(delay gst.ClockTime)
	// SetSync (gst_base_sink_set_sync) configures sink to synchronize on the
	// clock or not.
	SetSync(sync bool)
	// SetThrottleTime (gst_base_sink_set_throttle_time): set the time that will
	// be inserted between rendered buffers.
	SetThrottleTime(throttle uint64)
	// SetTsOffset (gst_base_sink_set_ts_offset): adjust the synchronisation of
	// sink with offset.
	SetTsOffset(offset gst.ClockTimeDiff)
	// Wait (gst_base_sink_wait): this function will wait for preroll to
	// complete and will then block until time is reached.
	Wait(time gst.ClockTime) (gst.ClockTimeDiff, gst.FlowReturn)
	// WaitClock (gst_base_sink_wait_clock): this function will block until time
	// is reached.
	WaitClock(time gst.ClockTime) (gst.ClockTimeDiff, gst.ClockReturn)
	// WaitPreroll (gst_base_sink_wait_preroll): if the BaseSinkClass::render
	// method performs its own synchronisation against the clock it must unblock
	// when going from PLAYING to the PAUSED state and call this method before
	// continuing to render the remaining data.
	WaitPreroll() gst.FlowReturn

	baseBaseSink() *BaseSink
}

var _ BaseSinker = (*BaseSink)(nil)

func init() {
	coreglib.RegisterClassInfo[*BaseSink, *BaseSinkClass, BaseSinkOverrides](
		GTypeBaseSink,
		initBaseSinkClass,
		wrapBaseSink,
		defaultBaseSinkOverrides,
	)
}

func initBaseSinkClass(gclass unsafe.Pointer, overrides BaseSinkOverrides, classInitFunc func(*BaseSinkClass)) {
	pclass := (*C.GstBaseSinkClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeBaseSink))))

	if overrides.ActivatePull != nil {
		pclass.activate_pull = (*[0]byte)(C._gotk4_gstbase1_BaseSinkClass_activate_pull)
	}

	if overrides.Event != nil {
		pclass.event = (*[0]byte)(C._gotk4_gstbase1_BaseSinkClass_event)
	}

	if overrides.Fixate != nil {
		pclass.fixate = (*[0]byte)(C._gotk4_gstbase1_BaseSinkClass_fixate)
	}

	if overrides.Caps != nil {
		pclass.get_caps = (*[0]byte)(C._gotk4_gstbase1_BaseSinkClass_get_caps)
	}

	if overrides.Times != nil {
		pclass.get_times = (*[0]byte)(C._gotk4_gstbase1_BaseSinkClass_get_times)
	}

	if overrides.Prepare != nil {
		pclass.prepare = (*[0]byte)(C._gotk4_gstbase1_BaseSinkClass_prepare)
	}

	if overrides.PrepareList != nil {
		pclass.prepare_list = (*[0]byte)(C._gotk4_gstbase1_BaseSinkClass_prepare_list)
	}

	if overrides.Preroll != nil {
		pclass.preroll = (*[0]byte)(C._gotk4_gstbase1_BaseSinkClass_preroll)
	}

	if overrides.ProposeAllocation != nil {
		pclass.propose_allocation = (*[0]byte)(C._gotk4_gstbase1_BaseSinkClass_propose_allocation)
	}

	if overrides.Query != nil {
		pclass.query = (*[0]byte)(C._gotk4_gstbase1_BaseSinkClass_query)
	}

	if overrides.Render != nil {
		pclass.render = (*[0]byte)(C._gotk4_gstbase1_BaseSinkClass_render)
	}

	if overrides.RenderList != nil {
		pclass.render_list = (*[0]byte)(C._gotk4_gstbase1_BaseSinkClass_render_list)
	}

	if overrides.SetCaps != nil {
		pclass.set_caps = (*[0]byte)(C._gotk4_gstbase1_BaseSinkClass_set_caps)
	}

	if overrides.Start != nil {
		pclass.start = (*[0]byte)(C._gotk4_gstbase1_BaseSinkClass_start)
	}

	if overrides.Stop != nil {
		pclass.stop = (*[0]byte)(C._gotk4_gstbase1_BaseSinkClass_stop)
	}

	if overrides.Unlock != nil {
		pclass.unlock = (*[0]byte)(C._gotk4_gstbase1_BaseSinkClass_unlock)
	}

	if overrides.UnlockStop != nil {
		pclass.unlock_stop = (*[0]byte)(C._gotk4_gstbase1_BaseSinkClass_unlock_stop)
	}

	if overrides.WaitEvent != nil {
		pclass.wait_event = (*[0]byte)(C._gotk4_gstbase1_BaseSinkClass_wait_event)
	}

	if classInitFunc != nil {
		class := (*BaseSinkClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapBaseSink(obj *coreglib.Object) *BaseSink {
	return &BaseSink{
		Element: gst.Element{
			GstObject: gst.GstObject{
				InitiallyUnowned: coreglib.InitiallyUnowned{
					Object: obj,
				},
			},
		},
	}
}

func marshalBaseSink(p uintptr) (interface{}, error) {
	return wrapBaseSink(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (sink *BaseSink) baseBaseSink() *BaseSink {
	return sink
}

// BaseBaseSink returns the underlying base object.
func BaseBaseSink(obj BaseSinker) *BaseSink {
	return obj.baseBaseSink()
}

// DoPreroll (gst_base_sink_do_preroll): if the sink spawns its own thread for
// pulling buffers from upstream it should call this method after it has pulled
// a buffer. If the element needed to preroll, this function will perform the
// preroll and will then block until the element state is changed.
//
// This function should be called with the PREROLL_LOCK held.
//
// The function takes the following parameters:
//
//   - obj: mini object that caused the preroll.
//
// The function returns the following values:
//
//   - flowReturn: GST_FLOW_OK if the preroll completed and processing can
//     continue. Any other return value should be returned from the render
//     vmethod.
func (sink *BaseSink) DoPreroll(obj *gst.MiniObject) gst.FlowReturn {
	var _arg0 *C.GstBaseSink   // out
	var _arg1 *C.GstMiniObject // out
	var _cret C.GstFlowReturn  // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = (*C.GstMiniObject)(gextras.StructNative(unsafe.Pointer(obj)))

	_cret = C.gst_base_sink_do_preroll(_arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(obj)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// Blocksize (gst_base_sink_get_blocksize): get the number of bytes that the
// sink will pull when it is operating in pull mode.
//
// The function returns the following values:
//
//   - guint: number of bytes sink will pull in pull mode.
func (sink *BaseSink) Blocksize() uint {
	var _arg0 *C.GstBaseSink // out
	var _cret C.guint        // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_base_sink_get_blocksize(_arg0)
	runtime.KeepAlive(sink)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// DropOutOfSegment (gst_base_sink_get_drop_out_of_segment) checks if sink is
// currently configured to drop buffers which are outside the current segment.
//
// The function returns the following values:
//
//   - ok: TRUE if the sink is configured to drop buffers outside the current
//     segment.
func (sink *BaseSink) DropOutOfSegment() bool {
	var _arg0 *C.GstBaseSink // out
	var _cret C.gboolean     // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_base_sink_get_drop_out_of_segment(_arg0)
	runtime.KeepAlive(sink)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// LastSample (gst_base_sink_get_last_sample): get the last sample that arrived
// in the sink and was used for preroll or for rendering. This property can be
// used to generate thumbnails.
//
// The Caps on the sample can be used to determine the type of the buffer.
//
// Free-function: gst_sample_unref.
//
// The function returns the following values:
//
//   - sample (optional) gst_sample_unref() after usage. This function returns
//     NULL when no buffer has arrived in the sink yet or when the sink is not
//     in PAUSED or PLAYING.
func (sink *BaseSink) LastSample() *gst.Sample {
	var _arg0 *C.GstBaseSink // out
	var _cret *C.GstSample   // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_base_sink_get_last_sample(_arg0)
	runtime.KeepAlive(sink)

	var _sample *gst.Sample // out

	if _cret != nil {
		_sample = (*gst.Sample)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_sample)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _sample
}

// Latency (gst_base_sink_get_latency): get the currently configured latency.
//
// The function returns the following values:
//
//   - clockTime: configured latency.
func (sink *BaseSink) Latency() gst.ClockTime {
	var _arg0 *C.GstBaseSink // out
	var _cret C.GstClockTime // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_base_sink_get_latency(_arg0)
	runtime.KeepAlive(sink)

	var _clockTime gst.ClockTime // out

	_clockTime = gst.ClockTime(_cret)

	return _clockTime
}

// MaxBitrate (gst_base_sink_get_max_bitrate): get the maximum amount of bits
// per second that the sink will render.
//
// The function returns the following values:
//
//   - guint64: maximum number of bits per second sink will render.
func (sink *BaseSink) MaxBitrate() uint64 {
	var _arg0 *C.GstBaseSink // out
	var _cret C.guint64      // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_base_sink_get_max_bitrate(_arg0)
	runtime.KeepAlive(sink)

	var _guint64 uint64 // out

	_guint64 = uint64(_cret)

	return _guint64
}

// MaxLateness (gst_base_sink_get_max_lateness) gets the max lateness value.
// See gst_base_sink_set_max_lateness() for more details.
//
// The function returns the following values:
//
//   - gint64: maximum time in nanoseconds that a buffer can be late before it
//     is dropped and not rendered. A value of -1 means an unlimited time.
func (sink *BaseSink) MaxLateness() int64 {
	var _arg0 *C.GstBaseSink // out
	var _cret C.gint64       // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_base_sink_get_max_lateness(_arg0)
	runtime.KeepAlive(sink)

	var _gint64 int64 // out

	_gint64 = int64(_cret)

	return _gint64
}

// ProcessingDeadline (gst_base_sink_get_processing_deadline): get the
// processing deadline of sink. see gst_base_sink_set_processing_deadline() for
// more information about the processing deadline.
//
// The function returns the following values:
//
//   - clockTime: processing deadline.
func (sink *BaseSink) ProcessingDeadline() gst.ClockTime {
	var _arg0 *C.GstBaseSink // out
	var _cret C.GstClockTime // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_base_sink_get_processing_deadline(_arg0)
	runtime.KeepAlive(sink)

	var _clockTime gst.ClockTime // out

	_clockTime = gst.ClockTime(_cret)

	return _clockTime
}

// RenderDelay (gst_base_sink_get_render_delay): get the render delay of sink.
// see gst_base_sink_set_render_delay() for more information about the render
// delay.
//
// The function returns the following values:
//
//   - clockTime: render delay of sink.
func (sink *BaseSink) RenderDelay() gst.ClockTime {
	var _arg0 *C.GstBaseSink // out
	var _cret C.GstClockTime // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_base_sink_get_render_delay(_arg0)
	runtime.KeepAlive(sink)

	var _clockTime gst.ClockTime // out

	_clockTime = gst.ClockTime(_cret)

	return _clockTime
}

// Stats (gst_base_sink_get_stats): return various BaseSink statistics. This
// function returns a Structure with name application/x-gst-base-sink-stats with
// the following fields:
//
// - "average-rate" G_TYPE_DOUBLE average frame rate
//
// - "dropped" G_TYPE_UINT64 Number of dropped frames
//
// - "rendered" G_TYPE_UINT64 Number of rendered frames.
//
// The function returns the following values:
//
//   - structure: pointer to Structure.
func (sink *BaseSink) Stats() *gst.Structure {
	var _arg0 *C.GstBaseSink  // out
	var _cret *C.GstStructure // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_base_sink_get_stats(_arg0)
	runtime.KeepAlive(sink)

	var _structure *gst.Structure // out

	_structure = (*gst.Structure)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_structure)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _structure
}

// Sync (gst_base_sink_get_sync) checks if sink is currently configured to
// synchronize against the clock.
//
// The function returns the following values:
//
//   - ok: TRUE if the sink is configured to synchronize against the clock.
func (sink *BaseSink) Sync() bool {
	var _arg0 *C.GstBaseSink // out
	var _cret C.gboolean     // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_base_sink_get_sync(_arg0)
	runtime.KeepAlive(sink)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// ThrottleTime (gst_base_sink_get_throttle_time): get the time that will be
// inserted between frames to control the maximum buffers per second.
//
// The function returns the following values:
//
//   - guint64: number of nanoseconds sink will put between frames.
func (sink *BaseSink) ThrottleTime() uint64 {
	var _arg0 *C.GstBaseSink // out
	var _cret C.guint64      // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_base_sink_get_throttle_time(_arg0)
	runtime.KeepAlive(sink)

	var _guint64 uint64 // out

	_guint64 = uint64(_cret)

	return _guint64
}

// TsOffset (gst_base_sink_get_ts_offset): get the synchronisation offset of
// sink.
//
// The function returns the following values:
//
//   - clockTimeDiff: synchronisation offset.
func (sink *BaseSink) TsOffset() gst.ClockTimeDiff {
	var _arg0 *C.GstBaseSink     // out
	var _cret C.GstClockTimeDiff // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_base_sink_get_ts_offset(_arg0)
	runtime.KeepAlive(sink)

	var _clockTimeDiff gst.ClockTimeDiff // out

	_clockTimeDiff = gst.ClockTimeDiff(_cret)

	return _clockTimeDiff
}

// IsAsyncEnabled (gst_base_sink_is_async_enabled) checks if sink is currently
// configured to perform asynchronous state changes to PAUSED.
//
// The function returns the following values:
//
//   - ok: TRUE if the sink is configured to perform asynchronous state changes.
func (sink *BaseSink) IsAsyncEnabled() bool {
	var _arg0 *C.GstBaseSink // out
	var _cret C.gboolean     // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_base_sink_is_async_enabled(_arg0)
	runtime.KeepAlive(sink)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// IsLastSampleEnabled (gst_base_sink_is_last_sample_enabled) checks if sink is
// currently configured to store the last received sample in the last-sample
// property.
//
// The function returns the following values:
//
//   - ok: TRUE if the sink is configured to store the last received sample.
func (sink *BaseSink) IsLastSampleEnabled() bool {
	var _arg0 *C.GstBaseSink // out
	var _cret C.gboolean     // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_base_sink_is_last_sample_enabled(_arg0)
	runtime.KeepAlive(sink)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// IsQosEnabled (gst_base_sink_is_qos_enabled) checks if sink is currently
// configured to send Quality-of-Service events upstream.
//
// The function returns the following values:
//
//   - ok: TRUE if the sink is configured to perform Quality-of-Service.
func (sink *BaseSink) IsQosEnabled() bool {
	var _arg0 *C.GstBaseSink // out
	var _cret C.gboolean     // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_base_sink_is_qos_enabled(_arg0)
	runtime.KeepAlive(sink)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// QueryLatency (gst_base_sink_query_latency): query the sink for the latency
// parameters. The latency will be queried from the upstream elements.
// live will be TRUE if sink is configured to synchronize against the clock.
// upstream_live will be TRUE if an upstream element is live.
//
// If both live and upstream_live are TRUE, the sink will want to compensate for
// the latency introduced by the upstream elements by setting the min_latency to
// a strictly positive value.
//
// This function is mostly used by subclasses.
//
// The function returns the following values:
//
//   - live (optional): if the sink is live.
//   - upstreamLive (optional): if an upstream element is live.
//   - minLatency (optional): min latency of the upstream elements.
//   - maxLatency (optional): max latency of the upstream elements.
//   - ok: TRUE if the query succeeded.
func (sink *BaseSink) QueryLatency() (live, upstreamLive bool, minLatency, maxLatency gst.ClockTime, ok bool) {
	var _arg0 *C.GstBaseSink // out
	var _arg1 C.gboolean     // in
	var _arg2 C.gboolean     // in
	var _arg3 C.GstClockTime // in
	var _arg4 C.GstClockTime // in
	var _cret C.gboolean     // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_base_sink_query_latency(_arg0, &_arg1, &_arg2, &_arg3, &_arg4)
	runtime.KeepAlive(sink)

	var _live bool                // out
	var _upstreamLive bool        // out
	var _minLatency gst.ClockTime // out
	var _maxLatency gst.ClockTime // out
	var _ok bool                  // out

	if _arg1 != 0 {
		_live = true
	}
	if _arg2 != 0 {
		_upstreamLive = true
	}
	_minLatency = gst.ClockTime(_arg3)
	_maxLatency = gst.ClockTime(_arg4)
	if _cret != 0 {
		_ok = true
	}

	return _live, _upstreamLive, _minLatency, _maxLatency, _ok
}

// SetAsyncEnabled (gst_base_sink_set_async_enabled) configures sink to
// perform all state changes asynchronously. When async is disabled, the sink
// will immediately go to PAUSED instead of waiting for a preroll buffer.
// This feature is useful if the sink does not synchronize against the clock or
// when it is dealing with sparse streams.
//
// The function takes the following parameters:
//
//   - enabled: new async value.
func (sink *BaseSink) SetAsyncEnabled(enabled bool) {
	var _arg0 *C.GstBaseSink // out
	var _arg1 C.gboolean     // out

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	if enabled {
		_arg1 = C.TRUE
	}

	C.gst_base_sink_set_async_enabled(_arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(enabled)
}

// SetBlocksize (gst_base_sink_set_blocksize): set the number of bytes that the
// sink will pull when it is operating in pull mode.
//
// The function takes the following parameters:
//
//   - blocksize in bytes.
func (sink *BaseSink) SetBlocksize(blocksize uint) {
	var _arg0 *C.GstBaseSink // out
	var _arg1 C.guint        // out

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = C.guint(blocksize)

	C.gst_base_sink_set_blocksize(_arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(blocksize)
}

// SetDropOutOfSegment (gst_base_sink_set_drop_out_of_segment): configure sink
// to drop buffers which are outside the current segment.
//
// The function takes the following parameters:
//
//   - dropOutOfSegment: drop buffers outside the segment.
func (sink *BaseSink) SetDropOutOfSegment(dropOutOfSegment bool) {
	var _arg0 *C.GstBaseSink // out
	var _arg1 C.gboolean     // out

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	if dropOutOfSegment {
		_arg1 = C.TRUE
	}

	C.gst_base_sink_set_drop_out_of_segment(_arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(dropOutOfSegment)
}

// SetLastSampleEnabled (gst_base_sink_set_last_sample_enabled) configures sink
// to store the last received sample in the last-sample property.
//
// The function takes the following parameters:
//
//   - enabled: new enable-last-sample value.
func (sink *BaseSink) SetLastSampleEnabled(enabled bool) {
	var _arg0 *C.GstBaseSink // out
	var _arg1 C.gboolean     // out

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	if enabled {
		_arg1 = C.TRUE
	}

	C.gst_base_sink_set_last_sample_enabled(_arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(enabled)
}

// SetMaxBitrate (gst_base_sink_set_max_bitrate): set the maximum amount of bits
// per second that the sink will render.
//
// The function takes the following parameters:
//
//   - maxBitrate: max_bitrate in bits per second.
func (sink *BaseSink) SetMaxBitrate(maxBitrate uint64) {
	var _arg0 *C.GstBaseSink // out
	var _arg1 C.guint64      // out

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = C.guint64(maxBitrate)

	C.gst_base_sink_set_max_bitrate(_arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(maxBitrate)
}

// SetMaxLateness (gst_base_sink_set_max_lateness) sets the new max lateness
// value to max_lateness. This value is used to decide if a buffer should be
// dropped or not based on the buffer timestamp and the current clock time.
// A value of -1 means an unlimited time.
//
// The function takes the following parameters:
//
//   - maxLateness: new max lateness value.
func (sink *BaseSink) SetMaxLateness(maxLateness int64) {
	var _arg0 *C.GstBaseSink // out
	var _arg1 C.gint64       // out

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = C.gint64(maxLateness)

	C.gst_base_sink_set_max_lateness(_arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(maxLateness)
}

// SetProcessingDeadline (gst_base_sink_set_processing_deadline): maximum
// amount of time (in nanoseconds) that the pipeline can take for processing the
// buffer. This is added to the latency of live pipelines.
//
// This function is usually called by subclasses.
//
// The function takes the following parameters:
//
//   - processingDeadline: new processing deadline in nanoseconds.
func (sink *BaseSink) SetProcessingDeadline(processingDeadline gst.ClockTime) {
	var _arg0 *C.GstBaseSink // out
	var _arg1 C.GstClockTime // out

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = C.GstClockTime(processingDeadline)

	C.gst_base_sink_set_processing_deadline(_arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(processingDeadline)
}

// SetQosEnabled (gst_base_sink_set_qos_enabled) configures sink to send
// Quality-of-Service events upstream.
//
// The function takes the following parameters:
//
//   - enabled: new qos value.
func (sink *BaseSink) SetQosEnabled(enabled bool) {
	var _arg0 *C.GstBaseSink // out
	var _arg1 C.gboolean     // out

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	if enabled {
		_arg1 = C.TRUE
	}

	C.gst_base_sink_set_qos_enabled(_arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(enabled)
}

// SetRenderDelay (gst_base_sink_set_render_delay): set the render delay in sink
// to delay. The render delay is the time between actual rendering of a buffer
// and its synchronisation time. Some devices might delay media rendering which
// can be compensated for with this function.
//
// After calling this function, this sink will report additional latency and
// other sinks will adjust their latency to delay the rendering of their media.
//
// This function is usually called by subclasses.
//
// The function takes the following parameters:
//
//   - delay: new delay.
func (sink *BaseSink) SetRenderDelay(delay gst.ClockTime) {
	var _arg0 *C.GstBaseSink // out
	var _arg1 C.GstClockTime // out

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = C.GstClockTime(delay)

	C.gst_base_sink_set_render_delay(_arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(delay)
}

// SetSync (gst_base_sink_set_sync) configures sink to synchronize on the
// clock or not. When sync is FALSE, incoming samples will be played as fast
// as possible. If sync is TRUE, the timestamps of the incoming buffers will be
// used to schedule the exact render time of its contents.
//
// The function takes the following parameters:
//
//   - sync: new sync value.
func (sink *BaseSink) SetSync(sync bool) {
	var _arg0 *C.GstBaseSink // out
	var _arg1 C.gboolean     // out

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	if sync {
		_arg1 = C.TRUE
	}

	C.gst_base_sink_set_sync(_arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(sync)
}

// SetThrottleTime (gst_base_sink_set_throttle_time): set the time that will be
// inserted between rendered buffers. This can be used to control the maximum
// buffers per second that the sink will render.
//
// The function takes the following parameters:
//
//   - throttle time in nanoseconds.
func (sink *BaseSink) SetThrottleTime(throttle uint64) {
	var _arg0 *C.GstBaseSink // out
	var _arg1 C.guint64      // out

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = C.guint64(throttle)

	C.gst_base_sink_set_throttle_time(_arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(throttle)
}

// SetTsOffset (gst_base_sink_set_ts_offset): adjust the synchronisation of
// sink with offset. A negative value will render buffers earlier than their
// timestamp. A positive value will delay rendering. This function can be used
// to fix playback of badly timestamped buffers.
//
// The function takes the following parameters:
//
//   - offset: new offset.
func (sink *BaseSink) SetTsOffset(offset gst.ClockTimeDiff) {
	var _arg0 *C.GstBaseSink     // out
	var _arg1 C.GstClockTimeDiff // out

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = C.GstClockTimeDiff(offset)

	C.gst_base_sink_set_ts_offset(_arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(offset)
}

// Wait (gst_base_sink_wait): this function will wait for preroll to complete
// and will then block until time is reached. It is usually called by
// subclasses that use their own internal synchronisation but want to let some
// synchronization (like EOS) be handled by the base class.
//
// This function should only be called with the PREROLL_LOCK held (like when
// receiving an EOS event in the ::event vmethod or when handling buffers in
// ::render).
//
// The time argument should be the running_time of when the timeout should
// happen and will be adjusted with any latency and offset configured in the
// sink.
//
// The function takes the following parameters:
//
//   - time to be reached.
//
// The function returns the following values:
//
//   - jitter (optional) to be filled with time diff, or NULL.
//   - flowReturn: FlowReturn.
func (sink *BaseSink) Wait(time gst.ClockTime) (gst.ClockTimeDiff, gst.FlowReturn) {
	var _arg0 *C.GstBaseSink     // out
	var _arg1 C.GstClockTime     // out
	var _arg2 C.GstClockTimeDiff // in
	var _cret C.GstFlowReturn    // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = C.GstClockTime(time)

	_cret = C.gst_base_sink_wait(_arg0, _arg1, &_arg2)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(time)

	var _jitter gst.ClockTimeDiff  // out
	var _flowReturn gst.FlowReturn // out

	_jitter = gst.ClockTimeDiff(_arg2)
	_flowReturn = gst.FlowReturn(_cret)

	return _jitter, _flowReturn
}

// WaitClock (gst_base_sink_wait_clock): this function will block until time
// is reached. It is usually called by subclasses that use their own internal
// synchronisation.
//
// If time is not valid, no synchronisation is done and GST_CLOCK_BADTIME is
// returned. Likewise, if synchronisation is disabled in the element or there is
// no clock, no synchronisation is done and GST_CLOCK_BADTIME is returned.
//
// This function should only be called with the PREROLL_LOCK held, like when
// receiving an EOS event in the BaseSinkClass::event vmethod or when receiving
// a buffer in the BaseSinkClass::render vmethod.
//
// The time argument should be the running_time of when this method should
// return and is not adjusted with any latency or offset configured in the sink.
//
// The function takes the following parameters:
//
//   - time to be reached.
//
// The function returns the following values:
//
//   - jitter (optional) to be filled with time diff, or NULL.
//   - clockReturn: ClockReturn.
func (sink *BaseSink) WaitClock(time gst.ClockTime) (gst.ClockTimeDiff, gst.ClockReturn) {
	var _arg0 *C.GstBaseSink     // out
	var _arg1 C.GstClockTime     // out
	var _arg2 C.GstClockTimeDiff // in
	var _cret C.GstClockReturn   // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = C.GstClockTime(time)

	_cret = C.gst_base_sink_wait_clock(_arg0, _arg1, &_arg2)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(time)

	var _jitter gst.ClockTimeDiff    // out
	var _clockReturn gst.ClockReturn // out

	_jitter = gst.ClockTimeDiff(_arg2)
	_clockReturn = gst.ClockReturn(_cret)

	return _jitter, _clockReturn
}

// WaitPreroll (gst_base_sink_wait_preroll): if the BaseSinkClass::render method
// performs its own synchronisation against the clock it must unblock when going
// from PLAYING to the PAUSED state and call this method before continuing to
// render the remaining data.
//
// If the BaseSinkClass::render method can block on something else
// than the clock, it must also be ready to unblock immediately on the
// BaseSinkClass::unlock method and cause the BaseSinkClass::render method to
// immediately call this function. In this case, the subclass must be prepared
// to continue rendering where it left off if this function returns GST_FLOW_OK.
//
// This function will block until a state change to PLAYING happens (in which
// case this function returns GST_FLOW_OK) or the processing must be stopped
// due to a state change to READY or a FLUSH event (in which case this function
// returns GST_FLOW_FLUSHING).
//
// This function should only be called with the PREROLL_LOCK held, like in the
// render function.
//
// The function returns the following values:
//
//   - flowReturn: GST_FLOW_OK if the preroll completed and processing can
//     continue. Any other return value should be returned from the render
//     vmethod.
func (sink *BaseSink) WaitPreroll() gst.FlowReturn {
	var _arg0 *C.GstBaseSink  // out
	var _cret C.GstFlowReturn // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_base_sink_wait_preroll(_arg0)
	runtime.KeepAlive(sink)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// activatePull subclasses should override this when they can provide an
// alternate method of spawning a thread to drive the pipeline in pull mode.
// Should start or stop the pulling thread, depending on the value of the
// "active" argument. Called after actually activating the sink pad in pull
// mode. The default implementation starts a task on the sink pad.
func (sink *BaseSink) activatePull(active bool) bool {
	gclass := (*C.GstBaseSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.activate_pull

	var _arg0 *C.GstBaseSink // out
	var _arg1 C.gboolean     // out
	var _cret C.gboolean     // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	if active {
		_arg1 = C.TRUE
	}

	_cret = C._gotk4_gstbase1_BaseSink_virtual_activate_pull(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(active)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Event: override this to handle events arriving on the sink pad.
func (sink *BaseSink) event(event *gst.Event) bool {
	gclass := (*C.GstBaseSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.event

	var _arg0 *C.GstBaseSink // out
	var _arg1 *C.GstEvent    // out
	var _cret C.gboolean     // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C._gotk4_gstbase1_BaseSink_virtual_event(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(event)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Fixate: only useful in pull mode. Implement if you have ideas about what
// should be the default values for the caps you support.
func (sink *BaseSink) fixate(caps *gst.Caps) *gst.Caps {
	gclass := (*C.GstBaseSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.fixate

	var _arg0 *C.GstBaseSink // out
	var _arg1 *C.GstCaps     // out
	var _cret *C.GstCaps     // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C._gotk4_gstbase1_BaseSink_virtual_fixate(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(caps)

	var _ret *gst.Caps // out

	_ret = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_ret)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _ret
}

// Caps: called to get sink pad caps from the subclass.
func (sink *BaseSink) caps(filter *gst.Caps) *gst.Caps {
	gclass := (*C.GstBaseSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.get_caps

	var _arg0 *C.GstBaseSink // out
	var _arg1 *C.GstCaps     // out
	var _cret *C.GstCaps     // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	if filter != nil {
		_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(filter)))
	}

	_cret = C._gotk4_gstbase1_BaseSink_virtual_get_caps(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(filter)

	var _caps *gst.Caps // out

	_caps = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_caps)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _caps
}

// Times: get the start and end times for syncing on this buffer.
//
// The function returns the following values:
//
//   - start ClockTime.
//   - end ClockTime.
func (sink *BaseSink) times(buffer *gst.Buffer) (start, end gst.ClockTime) {
	gclass := (*C.GstBaseSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.get_times

	var _arg0 *C.GstBaseSink // out
	var _arg1 *C.GstBuffer   // out
	var _arg2 C.GstClockTime // in
	var _arg3 C.GstClockTime // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))

	C._gotk4_gstbase1_BaseSink_virtual_get_times(unsafe.Pointer(fnarg), _arg0, _arg1, &_arg2, &_arg3)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(buffer)

	var _start gst.ClockTime // out
	var _end gst.ClockTime   // out

	_start = gst.ClockTime(_arg2)
	_end = gst.ClockTime(_arg3)

	return _start, _end
}

// Prepare: called to prepare the buffer for render and preroll. This function
// is called before synchronisation is performed.
func (sink *BaseSink) prepare(buffer *gst.Buffer) gst.FlowReturn {
	gclass := (*C.GstBaseSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.prepare

	var _arg0 *C.GstBaseSink  // out
	var _arg1 *C.GstBuffer    // out
	var _cret C.GstFlowReturn // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))

	_cret = C._gotk4_gstbase1_BaseSink_virtual_prepare(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(buffer)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// prepareList: called to prepare the buffer list for render_list. This function
// is called before synchronisation is performed.
func (sink *BaseSink) prepareList(bufferList *gst.BufferList) gst.FlowReturn {
	gclass := (*C.GstBaseSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.prepare_list

	var _arg0 *C.GstBaseSink   // out
	var _arg1 *C.GstBufferList // out
	var _cret C.GstFlowReturn  // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = (*C.GstBufferList)(gextras.StructNative(unsafe.Pointer(bufferList)))

	_cret = C._gotk4_gstbase1_BaseSink_virtual_prepare_list(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(bufferList)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// Preroll: called to present the preroll buffer if desired.
func (sink *BaseSink) preroll(buffer *gst.Buffer) gst.FlowReturn {
	gclass := (*C.GstBaseSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.preroll

	var _arg0 *C.GstBaseSink  // out
	var _arg1 *C.GstBuffer    // out
	var _cret C.GstFlowReturn // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))

	_cret = C._gotk4_gstbase1_BaseSink_virtual_preroll(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(buffer)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// proposeAllocation: configure the allocation query.
func (sink *BaseSink) proposeAllocation(query *gst.Query) bool {
	gclass := (*C.GstBaseSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.propose_allocation

	var _arg0 *C.GstBaseSink // out
	var _arg1 *C.GstQuery    // out
	var _cret C.gboolean     // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstbase1_BaseSink_virtual_propose_allocation(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Query: perform a Query on the element.
func (sink *BaseSink) query(query *gst.Query) bool {
	gclass := (*C.GstBaseSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.query

	var _arg0 *C.GstBaseSink // out
	var _arg1 *C.GstQuery    // out
	var _cret C.gboolean     // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstbase1_BaseSink_virtual_query(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Render: called when a buffer should be presented or output, at the correct
// moment if the BaseSink has been set to sync to the clock.
func (sink *BaseSink) render(buffer *gst.Buffer) gst.FlowReturn {
	gclass := (*C.GstBaseSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.render

	var _arg0 *C.GstBaseSink  // out
	var _arg1 *C.GstBuffer    // out
	var _cret C.GstFlowReturn // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))

	_cret = C._gotk4_gstbase1_BaseSink_virtual_render(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(buffer)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// renderList: same as render but used with buffer lists instead of buffers.
func (sink *BaseSink) renderList(bufferList *gst.BufferList) gst.FlowReturn {
	gclass := (*C.GstBaseSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.render_list

	var _arg0 *C.GstBaseSink   // out
	var _arg1 *C.GstBufferList // out
	var _cret C.GstFlowReturn  // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = (*C.GstBufferList)(gextras.StructNative(unsafe.Pointer(bufferList)))

	_cret = C._gotk4_gstbase1_BaseSink_virtual_render_list(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(bufferList)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// setCaps: notify subclass of changed caps.
func (sink *BaseSink) setCaps(caps *gst.Caps) bool {
	gclass := (*C.GstBaseSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.set_caps

	var _arg0 *C.GstBaseSink // out
	var _arg1 *C.GstCaps     // out
	var _cret C.gboolean     // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C._gotk4_gstbase1_BaseSink_virtual_set_caps(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(caps)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Start: start processing. Ideal for opening resources in the subclass.
func (sink *BaseSink) start() bool {
	gclass := (*C.GstBaseSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.start

	var _arg0 *C.GstBaseSink // out
	var _cret C.gboolean     // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C._gotk4_gstbase1_BaseSink_virtual_start(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(sink)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Stop: stop processing. Subclasses should use this to close resources.
func (sink *BaseSink) stop() bool {
	gclass := (*C.GstBaseSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.stop

	var _arg0 *C.GstBaseSink // out
	var _cret C.gboolean     // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C._gotk4_gstbase1_BaseSink_virtual_stop(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(sink)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Unlock: unlock any pending access to the resource. Subclasses should unblock
// any blocked function ASAP and call gst_base_sink_wait_preroll().
func (sink *BaseSink) unlock() bool {
	gclass := (*C.GstBaseSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.unlock

	var _arg0 *C.GstBaseSink // out
	var _cret C.gboolean     // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C._gotk4_gstbase1_BaseSink_virtual_unlock(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(sink)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// unlockStop: clear the previous unlock request. Subclasses should clear any
// state they set during BaseSinkClass::unlock, and be ready to continue where
// they left off after gst_base_sink_wait_preroll(), gst_base_sink_wait() or
// gst_wait_sink_wait_clock() return or BaseSinkClass::render is called again.
func (sink *BaseSink) unlockStop() bool {
	gclass := (*C.GstBaseSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.unlock_stop

	var _arg0 *C.GstBaseSink // out
	var _cret C.gboolean     // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C._gotk4_gstbase1_BaseSink_virtual_unlock_stop(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(sink)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// waitEvent: override this to implement custom logic to wait for the event time
// (for events like EOS and GAP). Subclasses should always first chain up to the
// default implementation.
func (sink *BaseSink) waitEvent(event *gst.Event) gst.FlowReturn {
	gclass := (*C.GstBaseSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.wait_event

	var _arg0 *C.GstBaseSink  // out
	var _arg1 *C.GstEvent     // out
	var _cret C.GstFlowReturn // in

	_arg0 = (*C.GstBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C._gotk4_gstbase1_BaseSink_virtual_wait_event(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(event)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// BaseSrcOverrides contains methods that are overridable.
type BaseSrcOverrides struct {
	// Alloc: ask the subclass to allocate an output buffer with offset and
	// size, the default implementation will use the negotiated allocator.
	//
	// The function takes the following parameters:
	//
	//   - offset
	//   - size
	//
	// The function returns the following values:
	//
	//   - buf (optional)
	//   - flowReturn
	Alloc func(offset uint64, size uint) (*gst.Buffer, gst.FlowReturn)
	// DecideAllocation: configure the allocation query.
	DecideAllocation func(query *gst.Query) bool
	// DoSeek: perform seeking on the resource to the indicated segment.
	DoSeek func(segment *gst.Segment) bool
	// Event: override this to implement custom event handling.
	Event func(event *gst.Event) bool
	// Fill: ask the subclass to fill the buffer with data for offset and size.
	// The passed buffer is guaranteed to hold the requested amount of bytes.
	//
	// The function takes the following parameters:
	//
	//   - offset
	//   - size
	//   - buf
	Fill func(offset uint64, size uint, buf *gst.Buffer) gst.FlowReturn
	// Fixate: called if, in negotiation, caps need fixating.
	//
	// The function returns the following values:
	//
	//   - ret: fixated caps.
	Fixate func(caps *gst.Caps) *gst.Caps
	// Caps: called to get the caps to report.
	Caps func(filter *gst.Caps) *gst.Caps
	// Size: get the total size of the resource in the format set by
	// gst_base_src_set_format().
	//
	// The function returns the following values:
	//
	//   - size
	//   - ok: TRUE if the size is available and has been set.
	Size func() (uint64, bool)
	// Times: given buffer, return start and end time when it should be pushed
	// out. The base class will sync on the clock using these times.
	//
	// The function returns the following values:
	//
	//   - start
	//   - end
	Times func(buffer *gst.Buffer) (start, end gst.ClockTime)
	// IsSeekable: check if the source can seek.
	IsSeekable func() bool
	// Negotiate negotiates src pad caps with downstream elements. Unmarks
	// GST_PAD_FLAG_NEED_RECONFIGURE in any case. But marks it again if
	// BaseSrcClass::negotiate fails.
	//
	// Do not call this in the BaseSrcClass::fill vmethod. Call this in
	// BaseSrcClass::create or in BaseSrcClass::alloc, _before_ any buffer is
	// allocated.
	//
	// The function returns the following values:
	//
	//   - ok: TRUE if the negotiation succeeded, else FALSE.
	Negotiate func() bool
	// PrepareSeekSegment: prepare the Segment that will be passed to the
	// BaseSrcClass::do_seek vmethod for executing a seek request. Sub-classes
	// should override this if they support seeking in formats other than
	// the configured native format. By default, it tries to convert the seek
	// arguments to the configured native format and prepare a segment in that
	// format.
	//
	// The function takes the following parameters:
	//
	//   - seek
	//   - segment
	PrepareSeekSegment func(seek *gst.Event, segment *gst.Segment) bool
	// Query: handle a requested query.
	Query func(query *gst.Query) bool
	// SetCaps: set new caps on the basesrc source pad.
	//
	// The function takes the following parameters:
	//
	//   - caps: Caps.
	//
	// The function returns the following values:
	//
	//   - ok: TRUE if the caps could be set.
	SetCaps func(caps *gst.Caps) bool
	// Start processing. Subclasses should open resources and prepare to produce
	// data. Implementation should call gst_base_src_start_complete() when the
	// operation completes, either from the current thread or any other thread
	// that finishes the start operation asynchronously.
	Start func() bool
	// Stop processing. Subclasses should use this to close resources.
	Stop func() bool
	// Unlock any pending access to the resource. Subclasses should unblock any
	// blocked function ASAP. In particular, any create() function in progress
	// should be unblocked and should return GST_FLOW_FLUSHING. Any future
	// BaseSrcClass::create function call should also return GST_FLOW_FLUSHING
	// until the BaseSrcClass::unlock_stop function has been called.
	Unlock func() bool
	// UnlockStop: clear the previous unlock request. Subclasses should clear
	// any state they set during BaseSrcClass::unlock, such as clearing command
	// queues.
	UnlockStop func() bool
}

func defaultBaseSrcOverrides(v *BaseSrc) BaseSrcOverrides {
	return BaseSrcOverrides{
		Alloc:              v.alloc,
		DecideAllocation:   v.decideAllocation,
		DoSeek:             v.doSeek,
		Event:              v.event,
		Fill:               v.fill,
		Fixate:             v.fixate,
		Caps:               v.caps,
		Size:               v.size,
		Times:              v.times,
		IsSeekable:         v.isSeekable,
		Negotiate:          v.negotiate,
		PrepareSeekSegment: v.prepareSeekSegment,
		Query:              v.query,
		SetCaps:            v.setCaps,
		Start:              v.start,
		Stop:               v.stop,
		Unlock:             v.unlock,
		UnlockStop:         v.unlockStop,
	}
}

// BaseSrc (GstBaseSrc): this is a generic base class for source elements.
// The following types of sources are supported:
//
//   - random access sources like files
//   - seekable sources
//   - live sources
//
// The source can be configured to operate in any Format with the
// gst_base_src_set_format() method. The currently set format determines the
// format of the internal Segment and any GST_EVENT_SEGMENT events. The default
// format for BaseSrc is GST_FORMAT_BYTES.
//
// BaseSrc always supports push mode scheduling. If the following conditions are
// met, it also supports pull mode scheduling:
//
//   - The format is set to GST_FORMAT_BYTES (default).
//   - BaseSrcClass::is_seekable returns TRUE.
//
// If all the conditions are met for operating in pull mode, BaseSrc is
// automatically seekable in push mode as well. The following conditions must
// be met to make the element seekable in push mode when the format is not
// GST_FORMAT_BYTES:
//
// * BaseSrcClass::is_seekable returns TRUE. * BaseSrcClass::query can
// convert all supported seek formats to the internal format as set with
// gst_base_src_set_format(). * BaseSrcClass::do_seek is implemented, performs
// the seek and returns TRUE.
//
// When the element does not meet the requirements to operate in pull mode,
// the offset and length in the BaseSrcClass::create method should be ignored.
// It is recommended to subclass PushSrc instead, in this situation. If the
// element can operate in pull mode but only with specific offsets and lengths,
// it is allowed to generate an error when the wrong values are passed to the
// BaseSrcClass::create function.
//
// BaseSrc has support for live sources. Live sources are sources that when
// paused discard data, such as audio or video capture devices. A typical
// live source also produces data at a fixed rate and thus provides a clock to
// publish this rate. Use gst_base_src_set_live() to activate the live source
// mode.
//
// A live source does not produce data in the PAUSED state. This means that the
// BaseSrcClass::create method will not be called in PAUSED but only in PLAYING.
// To signal the pipeline that the element will not produce data, the return
// value from the READY to PAUSED state will be GST_STATE_CHANGE_NO_PREROLL.
//
// A typical live source will timestamp the buffers it creates with the current
// running time of the pipeline. This is one reason why a live source can only
// produce data in the PLAYING state, when the clock is actually distributed and
// running.
//
// Live sources that synchronize and block on the clock (an audio source, for
// example) can use gst_base_src_wait_playing() when the BaseSrcClass::create
// function was interrupted by a state change to PAUSED.
//
// The BaseSrcClass::get_times method can be used to implement pseudo-live
// sources. It only makes sense to implement the BaseSrcClass::get_times
// function if the source is a live source. The BaseSrcClass::get_times function
// should return timestamps starting from 0, as if it were a non-live source.
// The base class will make sure that the timestamps are transformed into the
// current running_time. The base source will then wait for the calculated
// running_time before pushing out the buffer.
//
// For live sources, the base class will by default report a latency of 0. For
// pseudo live sources, the base class will by default measure the difference
// between the first buffer timestamp and the start time of get_times and will
// report this value as the latency. Subclasses should override the query
// function when this behaviour is not acceptable.
//
// There is only support in BaseSrc for exactly one source pad, which should be
// named "src". A source implementation (subclass of BaseSrc) should install a
// pad template in its class_init function, like so:
//
//	static void
//	my_element_class_init (GstMyElementClass *klass)
//	{
//	  GstElementClass *gstelement_class = GST_ELEMENT_CLASS (klass);
//	  // srctemplate should be a StaticPadTemplate with direction
//	  // GST_PAD_SRC and name "src"
//	  gst_element_class_add_static_pad_template (gstelement_class, &srctemplate);
//
//	  gst_element_class_set_static_metadata (gstelement_class,
//	     "Source name",
//	     "Source",
//	     "My Source element",
//	     "The author <my.sinkmy.email>");
//	}
//
// # Controlled shutdown of live sources in applications
//
// Applications that record from a live source may want to stop recording in a
// controlled way, so that the recording is stopped, but the data already in
// the pipeline is processed to the end (remember that many live sources would
// go on recording forever otherwise). For that to happen the application needs
// to make the source stop recording and send an EOS event down the pipeline.
// The application would then wait for an EOS message posted on the pipeline's
// bus to know when all data has been processed and the pipeline can safely be
// stopped.
//
// An application may send an EOS event to a source element to make it perform
// the EOS logic (send EOS event downstream or post a GST_MESSAGE_SEGMENT_DONE
// on the bus). This can typically be done with the gst_element_send_event()
// function on the element or its parent bin.
//
// After the EOS has been sent to the element, the application should wait for
// an EOS message to be posted on the pipeline's bus. Once this EOS message is
// received, it may safely shut down the entire pipeline.
type BaseSrc struct {
	_ [0]func() // equal guard
	gst.Element
}

var (
	_ gst.Elementer = (*BaseSrc)(nil)
)

// BaseSrcer describes types inherited from BaseSrc.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type BaseSrcer interface {
	gst.Elementer

	// Allocator (gst_base_src_get_allocator) lets BaseSrc sub-classes to know
	// the memory allocator used by the base class and its params.
	Allocator() (gst.Allocatorrer, *gst.AllocationParams)
	// Blocksize (gst_base_src_get_blocksize): get the number of bytes that src
	// will push out with each buffer.
	Blocksize() uint
	BufferPool() *gst.BufferPool
	// DoTimestamp (gst_base_src_get_do_timestamp): query if src timestamps
	// outgoing buffers based on the current running_time.
	DoTimestamp() bool
	// IsAsync (gst_base_src_is_async): get the current async behaviour of src.
	IsAsync() bool
	// IsLive (gst_base_src_is_live): check if an element is in live mode.
	IsLive() bool
	// Negotiate (gst_base_src_negotiate) negotiates src pad caps with
	// downstream elements.
	Negotiate() bool
	// NewSeamlessSegment (gst_base_src_new_seamless_segment): prepare a new
	// seamless segment for emission downstream.
	NewSeamlessSegment(start, stop, time int64) bool
	// NewSegment (gst_base_src_new_segment): prepare a new segment for emission
	// downstream.
	NewSegment(segment *gst.Segment) bool
	// PushSegment (gst_base_src_push_segment): send a new segment downstream.
	PushSegment(segment *gst.Segment) bool
	// QueryLatency (gst_base_src_query_latency): query the source for the
	// latency parameters.
	QueryLatency() (live bool, minLatency, maxLatency gst.ClockTime, ok bool)
	// SetAsync (gst_base_src_set_async): configure async behaviour in src,
	// no state change will block.
	SetAsync(async bool)
	// SetAutomaticEos (gst_base_src_set_automatic_eos): if automatic_eos is
	// TRUE, src will automatically go EOS if a buffer after the total size is
	// returned.
	SetAutomaticEos(automaticEos bool)
	// SetBlocksize (gst_base_src_set_blocksize): set the number of bytes that
	// src will push out with each buffer.
	SetBlocksize(blocksize uint)
	// SetCaps (gst_base_src_set_caps): set new caps on the basesrc source pad.
	SetCaps(caps *gst.Caps) bool
	// SetDoTimestamp (gst_base_src_set_do_timestamp): configure src to
	// automatically timestamp outgoing buffers based on the current
	// running_time of the pipeline.
	SetDoTimestamp(timestamp bool)
	// SetDynamicSize (gst_base_src_set_dynamic_size): if not dynamic, size
	// is only updated when needed, such as when trying to read past current
	// tracked size.
	SetDynamicSize(dynamic bool)
	// SetFormat (gst_base_src_set_format) sets the default format of the
	// source.
	SetFormat(format gst.Format)
	// SetLive (gst_base_src_set_live): if the element listens to a live source,
	// live should be set to TRUE.
	SetLive(live bool)
	// StartComplete (gst_base_src_start_complete): complete an asynchronous
	// start operation.
	StartComplete(ret gst.FlowReturn)
	// StartWait (gst_base_src_start_wait): wait until the start operation
	// completes.
	StartWait() gst.FlowReturn
	// SubmitBufferList (gst_base_src_submit_buffer_list) subclasses can call
	// this from their create virtual method implementation to submit a buffer
	// list to be pushed out later.
	SubmitBufferList(bufferList *gst.BufferList)
	// WaitPlaying (gst_base_src_wait_playing): if the BaseSrcClass::create
	// method performs its own synchronisation against the clock it must unblock
	// when going from PLAYING to the PAUSED state and call this method before
	// continuing to produce the remaining data.
	WaitPlaying() gst.FlowReturn

	baseBaseSrc() *BaseSrc
}

var _ BaseSrcer = (*BaseSrc)(nil)

func init() {
	coreglib.RegisterClassInfo[*BaseSrc, *BaseSrcClass, BaseSrcOverrides](
		GTypeBaseSrc,
		initBaseSrcClass,
		wrapBaseSrc,
		defaultBaseSrcOverrides,
	)
}

func initBaseSrcClass(gclass unsafe.Pointer, overrides BaseSrcOverrides, classInitFunc func(*BaseSrcClass)) {
	pclass := (*C.GstBaseSrcClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeBaseSrc))))

	if overrides.Alloc != nil {
		pclass.alloc = (*[0]byte)(C._gotk4_gstbase1_BaseSrcClass_alloc)
	}

	if overrides.DecideAllocation != nil {
		pclass.decide_allocation = (*[0]byte)(C._gotk4_gstbase1_BaseSrcClass_decide_allocation)
	}

	if overrides.DoSeek != nil {
		pclass.do_seek = (*[0]byte)(C._gotk4_gstbase1_BaseSrcClass_do_seek)
	}

	if overrides.Event != nil {
		pclass.event = (*[0]byte)(C._gotk4_gstbase1_BaseSrcClass_event)
	}

	if overrides.Fill != nil {
		pclass.fill = (*[0]byte)(C._gotk4_gstbase1_BaseSrcClass_fill)
	}

	if overrides.Fixate != nil {
		pclass.fixate = (*[0]byte)(C._gotk4_gstbase1_BaseSrcClass_fixate)
	}

	if overrides.Caps != nil {
		pclass.get_caps = (*[0]byte)(C._gotk4_gstbase1_BaseSrcClass_get_caps)
	}

	if overrides.Size != nil {
		pclass.get_size = (*[0]byte)(C._gotk4_gstbase1_BaseSrcClass_get_size)
	}

	if overrides.Times != nil {
		pclass.get_times = (*[0]byte)(C._gotk4_gstbase1_BaseSrcClass_get_times)
	}

	if overrides.IsSeekable != nil {
		pclass.is_seekable = (*[0]byte)(C._gotk4_gstbase1_BaseSrcClass_is_seekable)
	}

	if overrides.Negotiate != nil {
		pclass.negotiate = (*[0]byte)(C._gotk4_gstbase1_BaseSrcClass_negotiate)
	}

	if overrides.PrepareSeekSegment != nil {
		pclass.prepare_seek_segment = (*[0]byte)(C._gotk4_gstbase1_BaseSrcClass_prepare_seek_segment)
	}

	if overrides.Query != nil {
		pclass.query = (*[0]byte)(C._gotk4_gstbase1_BaseSrcClass_query)
	}

	if overrides.SetCaps != nil {
		pclass.set_caps = (*[0]byte)(C._gotk4_gstbase1_BaseSrcClass_set_caps)
	}

	if overrides.Start != nil {
		pclass.start = (*[0]byte)(C._gotk4_gstbase1_BaseSrcClass_start)
	}

	if overrides.Stop != nil {
		pclass.stop = (*[0]byte)(C._gotk4_gstbase1_BaseSrcClass_stop)
	}

	if overrides.Unlock != nil {
		pclass.unlock = (*[0]byte)(C._gotk4_gstbase1_BaseSrcClass_unlock)
	}

	if overrides.UnlockStop != nil {
		pclass.unlock_stop = (*[0]byte)(C._gotk4_gstbase1_BaseSrcClass_unlock_stop)
	}

	if classInitFunc != nil {
		class := (*BaseSrcClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapBaseSrc(obj *coreglib.Object) *BaseSrc {
	return &BaseSrc{
		Element: gst.Element{
			GstObject: gst.GstObject{
				InitiallyUnowned: coreglib.InitiallyUnowned{
					Object: obj,
				},
			},
		},
	}
}

func marshalBaseSrc(p uintptr) (interface{}, error) {
	return wrapBaseSrc(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (src *BaseSrc) baseBaseSrc() *BaseSrc {
	return src
}

// BaseBaseSrc returns the underlying base object.
func BaseBaseSrc(obj BaseSrcer) *BaseSrc {
	return obj.baseBaseSrc()
}

// Allocator (gst_base_src_get_allocator) lets BaseSrc sub-classes to know the
// memory allocator used by the base class and its params.
//
// Unref the allocator after usage.
//
// The function returns the following values:
//
//   - allocator (optional): Allocator used.
//   - params (optional) of allocator.
func (src *BaseSrc) Allocator() (gst.Allocatorrer, *gst.AllocationParams) {
	var _arg0 *C.GstBaseSrc         // out
	var _arg1 *C.GstAllocator       // in
	var _arg2 C.GstAllocationParams // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	C.gst_base_src_get_allocator(_arg0, &_arg1, &_arg2)
	runtime.KeepAlive(src)

	var _allocator gst.Allocatorrer   // out
	var _params *gst.AllocationParams // out

	if _arg1 != nil {
		{
			objptr := unsafe.Pointer(_arg1)

			object := coreglib.AssumeOwnership(objptr)
			casted := object.WalkCast(func(obj coreglib.Objector) bool {
				_, ok := obj.(gst.Allocatorrer)
				return ok
			})
			rv, ok := casted.(gst.Allocatorrer)
			if !ok {
				panic("no marshaler for " + object.TypeFromInstance().String() + " matching gst.Allocatorrer")
			}
			_allocator = rv
		}
	}
	_params = (*gst.AllocationParams)(gextras.NewStructNative(unsafe.Pointer((&_arg2))))

	return _allocator, _params
}

// Blocksize (gst_base_src_get_blocksize): get the number of bytes that src will
// push out with each buffer.
//
// The function returns the following values:
//
//   - guint: number of bytes pushed with each buffer.
func (src *BaseSrc) Blocksize() uint {
	var _arg0 *C.GstBaseSrc // out
	var _cret C.guint       // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C.gst_base_src_get_blocksize(_arg0)
	runtime.KeepAlive(src)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// The function returns the following values:
//
//   - bufferPool (optional): instance of the BufferPool used by the src;
//     unref it after usage.
func (src *BaseSrc) BufferPool() *gst.BufferPool {
	var _arg0 *C.GstBaseSrc    // out
	var _cret *C.GstBufferPool // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C.gst_base_src_get_buffer_pool(_arg0)
	runtime.KeepAlive(src)

	var _bufferPool *gst.BufferPool // out

	if _cret != nil {
		{
			obj := coreglib.AssumeOwnership(unsafe.Pointer(_cret))
			_bufferPool = &gst.BufferPool{
				GstObject: gst.GstObject{
					InitiallyUnowned: coreglib.InitiallyUnowned{
						Object: obj,
					},
				},
			}
		}
	}

	return _bufferPool
}

// DoTimestamp (gst_base_src_get_do_timestamp): query if src timestamps outgoing
// buffers based on the current running_time.
//
// The function returns the following values:
//
//   - ok: TRUE if the base class will automatically timestamp outgoing buffers.
func (src *BaseSrc) DoTimestamp() bool {
	var _arg0 *C.GstBaseSrc // out
	var _cret C.gboolean    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C.gst_base_src_get_do_timestamp(_arg0)
	runtime.KeepAlive(src)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// IsAsync (gst_base_src_is_async): get the current async behaviour of src.
// See also gst_base_src_set_async().
//
// The function returns the following values:
//
//   - ok: TRUE if src is operating in async mode.
func (src *BaseSrc) IsAsync() bool {
	var _arg0 *C.GstBaseSrc // out
	var _cret C.gboolean    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C.gst_base_src_is_async(_arg0)
	runtime.KeepAlive(src)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// IsLive (gst_base_src_is_live): check if an element is in live mode.
//
// The function returns the following values:
//
//   - ok: TRUE if element is in live mode.
func (src *BaseSrc) IsLive() bool {
	var _arg0 *C.GstBaseSrc // out
	var _cret C.gboolean    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C.gst_base_src_is_live(_arg0)
	runtime.KeepAlive(src)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Negotiate (gst_base_src_negotiate) negotiates src pad caps with downstream
// elements. Unmarks GST_PAD_FLAG_NEED_RECONFIGURE in any case. But marks it
// again if BaseSrcClass::negotiate fails.
//
// Do not call this in the BaseSrcClass::fill vmethod. Call this in
// BaseSrcClass::create or in BaseSrcClass::alloc, _before_ any buffer is
// allocated.
//
// The function returns the following values:
//
//   - ok: TRUE if the negotiation succeeded, else FALSE.
func (src *BaseSrc) Negotiate() bool {
	var _arg0 *C.GstBaseSrc // out
	var _cret C.gboolean    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C.gst_base_src_negotiate(_arg0)
	runtime.KeepAlive(src)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// NewSeamlessSegment (gst_base_src_new_seamless_segment): prepare a new
// seamless segment for emission downstream. This function must only be called
// by derived sub-classes, and only from the BaseSrcClass::create function,
// as the stream-lock needs to be held.
//
// The format for the new segment will be the current format of the source,
// as configured with gst_base_src_set_format()
//
// Deprecated: Use gst_base_src_new_segment().
//
// The function takes the following parameters:
//
//   - start: new start value for the segment.
//   - stop: stop value for the new segment.
//   - time: new time value for the start of the new segment.
//
// The function returns the following values:
//
//   - ok: TRUE if preparation of the seamless segment succeeded.
func (src *BaseSrc) NewSeamlessSegment(start, stop, time int64) bool {
	var _arg0 *C.GstBaseSrc // out
	var _arg1 C.gint64      // out
	var _arg2 C.gint64      // out
	var _arg3 C.gint64      // out
	var _cret C.gboolean    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = C.gint64(start)
	_arg2 = C.gint64(stop)
	_arg3 = C.gint64(time)

	_cret = C.gst_base_src_new_seamless_segment(_arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(src)
	runtime.KeepAlive(start)
	runtime.KeepAlive(stop)
	runtime.KeepAlive(time)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// NewSegment (gst_base_src_new_segment): prepare a new segment for emission
// downstream. This function must only be called by derived sub-classes,
// and only from the BaseSrcClass::create function, as the stream-lock needs to
// be held.
//
// The format for the segment must be identical with the current format of the
// source, as configured with gst_base_src_set_format().
//
// The format of src must not be GST_FORMAT_UNDEFINED and the format should be
// configured via gst_base_src_set_format() before calling this method.
//
// The function takes the following parameters:
//
//   - segment: pointer to a Segment.
//
// The function returns the following values:
//
//   - ok: TRUE if preparation of new segment succeeded.
func (src *BaseSrc) NewSegment(segment *gst.Segment) bool {
	var _arg0 *C.GstBaseSrc // out
	var _arg1 *C.GstSegment // out
	var _cret C.gboolean    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = (*C.GstSegment)(gextras.StructNative(unsafe.Pointer(segment)))

	_cret = C.gst_base_src_new_segment(_arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(segment)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PushSegment (gst_base_src_push_segment): send a new segment downstream.
// This function must only be called by derived sub-classes, and only from
// the BaseSrcClass::create function, as the stream-lock needs to be held.
// This method also requires that an out caps has been configured, so
// gst_base_src_set_caps() needs to have been called before.
//
// The format for the segment must be identical with the current format of the
// source, as configured with gst_base_src_set_format().
//
// The format of src must not be GST_FORMAT_UNDEFINED and the format should be
// configured via gst_base_src_set_format() before calling this method.
//
// This is a variant of gst_base_src_new_segment() sending the segment right
// away, which can be useful to ensure events ordering.
//
// The function takes the following parameters:
//
//   - segment: pointer to a Segment.
//
// The function returns the following values:
//
//   - ok: TRUE if sending of new segment succeeded.
func (src *BaseSrc) PushSegment(segment *gst.Segment) bool {
	var _arg0 *C.GstBaseSrc // out
	var _arg1 *C.GstSegment // out
	var _cret C.gboolean    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = (*C.GstSegment)(gextras.StructNative(unsafe.Pointer(segment)))

	_cret = C.gst_base_src_push_segment(_arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(segment)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// QueryLatency (gst_base_src_query_latency): query the source for the latency
// parameters. live will be TRUE when src is configured as a live source.
// min_latency and max_latency will be set to the difference between the running
// time and the timestamp of the first buffer.
//
// This function is mostly used by subclasses.
//
// The function returns the following values:
//
//   - live (optional): if the source is live.
//   - minLatency (optional): min latency of the source.
//   - maxLatency (optional): max latency of the source.
//   - ok: TRUE if the query succeeded.
func (src *BaseSrc) QueryLatency() (live bool, minLatency, maxLatency gst.ClockTime, ok bool) {
	var _arg0 *C.GstBaseSrc  // out
	var _arg1 C.gboolean     // in
	var _arg2 C.GstClockTime // in
	var _arg3 C.GstClockTime // in
	var _cret C.gboolean     // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C.gst_base_src_query_latency(_arg0, &_arg1, &_arg2, &_arg3)
	runtime.KeepAlive(src)

	var _live bool                // out
	var _minLatency gst.ClockTime // out
	var _maxLatency gst.ClockTime // out
	var _ok bool                  // out

	if _arg1 != 0 {
		_live = true
	}
	_minLatency = gst.ClockTime(_arg2)
	_maxLatency = gst.ClockTime(_arg3)
	if _cret != 0 {
		_ok = true
	}

	return _live, _minLatency, _maxLatency, _ok
}

// SetAsync (gst_base_src_set_async): configure async behaviour in src,
// no state change will block. The open, close, start, stop, play and pause
// virtual methods will be executed in a different thread and are thus allowed
// to perform blocking operations. Any blocking operation should be unblocked
// with the unlock vmethod.
//
// The function takes the following parameters:
//
//   - async: new async mode.
func (src *BaseSrc) SetAsync(async bool) {
	var _arg0 *C.GstBaseSrc // out
	var _arg1 C.gboolean    // out

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	if async {
		_arg1 = C.TRUE
	}

	C.gst_base_src_set_async(_arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(async)
}

// SetAutomaticEos (gst_base_src_set_automatic_eos): if automatic_eos is TRUE,
// src will automatically go EOS if a buffer after the total size is returned.
// By default this is TRUE but sources that can't return an authoritative size
// and only know that they're EOS when trying to read more should set this to
// FALSE.
//
// When src operates in GST_FORMAT_TIME, BaseSrc will send an EOS when a buffer
// outside of the currently configured segment is pushed if automatic_eos is
// TRUE. Since 1.16, if automatic_eos is FALSE an EOS will be pushed only when
// the BaseSrcClass::create implementation returns GST_FLOW_EOS.
//
// The function takes the following parameters:
//
//   - automaticEos: automatic eos.
func (src *BaseSrc) SetAutomaticEos(automaticEos bool) {
	var _arg0 *C.GstBaseSrc // out
	var _arg1 C.gboolean    // out

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	if automaticEos {
		_arg1 = C.TRUE
	}

	C.gst_base_src_set_automatic_eos(_arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(automaticEos)
}

// SetBlocksize (gst_base_src_set_blocksize): set the number of bytes that src
// will push out with each buffer. When blocksize is set to -1, a default length
// will be used.
//
// The function takes the following parameters:
//
//   - blocksize: new blocksize in bytes.
func (src *BaseSrc) SetBlocksize(blocksize uint) {
	var _arg0 *C.GstBaseSrc // out
	var _arg1 C.guint       // out

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = C.guint(blocksize)

	C.gst_base_src_set_blocksize(_arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(blocksize)
}

// SetCaps (gst_base_src_set_caps): set new caps on the basesrc source pad.
//
// The function takes the following parameters:
//
//   - caps: Caps.
//
// The function returns the following values:
//
//   - ok: TRUE if the caps could be set.
func (src *BaseSrc) SetCaps(caps *gst.Caps) bool {
	var _arg0 *C.GstBaseSrc // out
	var _arg1 *C.GstCaps    // out
	var _cret C.gboolean    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C.gst_base_src_set_caps(_arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(caps)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SetDoTimestamp (gst_base_src_set_do_timestamp): configure src to
// automatically timestamp outgoing buffers based on the current running_time of
// the pipeline. This property is mostly useful for live sources.
//
// The function takes the following parameters:
//
//   - timestamp: enable or disable timestamping.
func (src *BaseSrc) SetDoTimestamp(timestamp bool) {
	var _arg0 *C.GstBaseSrc // out
	var _arg1 C.gboolean    // out

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	if timestamp {
		_arg1 = C.TRUE
	}

	C.gst_base_src_set_do_timestamp(_arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(timestamp)
}

// SetDynamicSize (gst_base_src_set_dynamic_size): if not dynamic, size is only
// updated when needed, such as when trying to read past current tracked size.
// Otherwise, size is checked for upon each read.
//
// The function takes the following parameters:
//
//   - dynamic: new dynamic size mode.
func (src *BaseSrc) SetDynamicSize(dynamic bool) {
	var _arg0 *C.GstBaseSrc // out
	var _arg1 C.gboolean    // out

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	if dynamic {
		_arg1 = C.TRUE
	}

	C.gst_base_src_set_dynamic_size(_arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(dynamic)
}

// SetFormat (gst_base_src_set_format) sets the default format of the source.
// This will be the format used for sending SEGMENT events and for performing
// seeks.
//
// If a format of GST_FORMAT_BYTES is set, the element will be able to operate
// in pull mode if the BaseSrcClass::is_seekable returns TRUE.
//
// This function must only be called in states < GST_STATE_PAUSED.
//
// The function takes the following parameters:
//
//   - format to use.
func (src *BaseSrc) SetFormat(format gst.Format) {
	var _arg0 *C.GstBaseSrc // out
	var _arg1 C.GstFormat   // out

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = C.GstFormat(format)

	C.gst_base_src_set_format(_arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(format)
}

// SetLive (gst_base_src_set_live): if the element listens to a live source,
// live should be set to TRUE.
//
// A live source will not produce data in the PAUSED state and will therefore
// not be able to participate in the PREROLL phase of a pipeline. To signal this
// fact to the application and the pipeline, the state change return value of
// the live source will be GST_STATE_CHANGE_NO_PREROLL.
//
// The function takes the following parameters:
//
//   - live: new live-mode.
func (src *BaseSrc) SetLive(live bool) {
	var _arg0 *C.GstBaseSrc // out
	var _arg1 C.gboolean    // out

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	if live {
		_arg1 = C.TRUE
	}

	C.gst_base_src_set_live(_arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(live)
}

// StartComplete (gst_base_src_start_complete): complete an asynchronous start
// operation. When the subclass overrides the start method, it should call
// gst_base_src_start_complete() when the start operation completes either from
// the same thread or from an asynchronous helper thread.
//
// The function takes the following parameters:
//
//   - ret: FlowReturn.
func (basesrc *BaseSrc) StartComplete(ret gst.FlowReturn) {
	var _arg0 *C.GstBaseSrc   // out
	var _arg1 C.GstFlowReturn // out

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(basesrc).Native()))
	_arg1 = C.GstFlowReturn(ret)

	C.gst_base_src_start_complete(_arg0, _arg1)
	runtime.KeepAlive(basesrc)
	runtime.KeepAlive(ret)
}

// StartWait (gst_base_src_start_wait): wait until the start operation
// completes.
//
// The function returns the following values:
//
//   - flowReturn: FlowReturn.
func (basesrc *BaseSrc) StartWait() gst.FlowReturn {
	var _arg0 *C.GstBaseSrc   // out
	var _cret C.GstFlowReturn // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(basesrc).Native()))

	_cret = C.gst_base_src_start_wait(_arg0)
	runtime.KeepAlive(basesrc)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// SubmitBufferList (gst_base_src_submit_buffer_list) subclasses can call this
// from their create virtual method implementation to submit a buffer list to be
// pushed out later. This is useful in cases where the create function wants to
// produce multiple buffers to be pushed out in one go in form of a BufferList,
// which can reduce overhead drastically, especially for packetised inputs (for
// data streams where the packetisation/chunking is not important it is usually
// more efficient to return larger buffers instead).
//
// Subclasses that use this function from their create function must return
// GST_FLOW_OK and no buffer from their create virtual method implementation.
// If a buffer is returned after a buffer list has also been submitted via this
// function the behaviour is undefined.
//
// Subclasses must only call this function once per create function call and
// subclasses must only call this function when the source operates in push
// mode.
//
// The function takes the following parameters:
//
//   - bufferList: BufferList.
func (src *BaseSrc) SubmitBufferList(bufferList *gst.BufferList) {
	var _arg0 *C.GstBaseSrc    // out
	var _arg1 *C.GstBufferList // out

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = (*C.GstBufferList)(gextras.StructNative(unsafe.Pointer(bufferList)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(bufferList)), nil)

	C.gst_base_src_submit_buffer_list(_arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(bufferList)
}

// WaitPlaying (gst_base_src_wait_playing): if the BaseSrcClass::create method
// performs its own synchronisation against the clock it must unblock when going
// from PLAYING to the PAUSED state and call this method before continuing to
// produce the remaining data.
//
// This function will block until a state change to PLAYING happens (in which
// case this function returns GST_FLOW_OK) or the processing must be stopped
// due to a state change to READY or a FLUSH event (in which case this function
// returns GST_FLOW_FLUSHING).
//
// The function returns the following values:
//
//   - flowReturn: GST_FLOW_OK if src is PLAYING and processing can continue.
//     Any other return value should be returned from the create vmethod.
func (src *BaseSrc) WaitPlaying() gst.FlowReturn {
	var _arg0 *C.GstBaseSrc   // out
	var _cret C.GstFlowReturn // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C.gst_base_src_wait_playing(_arg0)
	runtime.KeepAlive(src)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// Alloc: ask the subclass to allocate an output buffer with offset and size,
// the default implementation will use the negotiated allocator.
//
// The function takes the following parameters:
//
//   - offset
//   - size
//
// The function returns the following values:
//
//   - buf (optional)
//   - flowReturn
func (src *BaseSrc) alloc(offset uint64, size uint) (*gst.Buffer, gst.FlowReturn) {
	gclass := (*C.GstBaseSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.alloc

	var _arg0 *C.GstBaseSrc   // out
	var _arg1 C.guint64       // out
	var _arg2 C.guint         // out
	var _arg3 *C.GstBuffer    // in
	var _cret C.GstFlowReturn // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = C.guint64(offset)
	_arg2 = C.guint(size)

	_cret = C._gotk4_gstbase1_BaseSrc_virtual_alloc(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2, &_arg3)
	runtime.KeepAlive(src)
	runtime.KeepAlive(offset)
	runtime.KeepAlive(size)

	var _buf *gst.Buffer           // out
	var _flowReturn gst.FlowReturn // out

	if _arg3 != nil {
		_buf = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_arg3)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_buf)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}
	_flowReturn = gst.FlowReturn(_cret)

	return _buf, _flowReturn
}

// decideAllocation: configure the allocation query.
func (src *BaseSrc) decideAllocation(query *gst.Query) bool {
	gclass := (*C.GstBaseSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.decide_allocation

	var _arg0 *C.GstBaseSrc // out
	var _arg1 *C.GstQuery   // out
	var _cret C.gboolean    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstbase1_BaseSrc_virtual_decide_allocation(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// doSeek: perform seeking on the resource to the indicated segment.
func (src *BaseSrc) doSeek(segment *gst.Segment) bool {
	gclass := (*C.GstBaseSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.do_seek

	var _arg0 *C.GstBaseSrc // out
	var _arg1 *C.GstSegment // out
	var _cret C.gboolean    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = (*C.GstSegment)(gextras.StructNative(unsafe.Pointer(segment)))

	_cret = C._gotk4_gstbase1_BaseSrc_virtual_do_seek(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(segment)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Event: override this to implement custom event handling.
func (src *BaseSrc) event(event *gst.Event) bool {
	gclass := (*C.GstBaseSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.event

	var _arg0 *C.GstBaseSrc // out
	var _arg1 *C.GstEvent   // out
	var _cret C.gboolean    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C._gotk4_gstbase1_BaseSrc_virtual_event(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(event)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Fill: ask the subclass to fill the buffer with data for offset and size.
// The passed buffer is guaranteed to hold the requested amount of bytes.
//
// The function takes the following parameters:
//
//   - offset
//   - size
//   - buf
func (src *BaseSrc) fill(offset uint64, size uint, buf *gst.Buffer) gst.FlowReturn {
	gclass := (*C.GstBaseSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.fill

	var _arg0 *C.GstBaseSrc   // out
	var _arg1 C.guint64       // out
	var _arg2 C.guint         // out
	var _arg3 *C.GstBuffer    // out
	var _cret C.GstFlowReturn // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = C.guint64(offset)
	_arg2 = C.guint(size)
	_arg3 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buf)))

	_cret = C._gotk4_gstbase1_BaseSrc_virtual_fill(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(src)
	runtime.KeepAlive(offset)
	runtime.KeepAlive(size)
	runtime.KeepAlive(buf)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// Fixate: called if, in negotiation, caps need fixating.
//
// The function returns the following values:
//
//   - ret: fixated caps.
func (src *BaseSrc) fixate(caps *gst.Caps) *gst.Caps {
	gclass := (*C.GstBaseSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.fixate

	var _arg0 *C.GstBaseSrc // out
	var _arg1 *C.GstCaps    // out
	var _cret *C.GstCaps    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(caps)), nil)

	_cret = C._gotk4_gstbase1_BaseSrc_virtual_fixate(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(caps)

	var _ret *gst.Caps // out

	_ret = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_ret)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _ret
}

// Caps: called to get the caps to report.
func (src *BaseSrc) caps(filter *gst.Caps) *gst.Caps {
	gclass := (*C.GstBaseSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.get_caps

	var _arg0 *C.GstBaseSrc // out
	var _arg1 *C.GstCaps    // out
	var _cret *C.GstCaps    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	if filter != nil {
		_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(filter)))
	}

	_cret = C._gotk4_gstbase1_BaseSrc_virtual_get_caps(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(filter)

	var _caps *gst.Caps // out

	_caps = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_caps)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _caps
}

// Size: get the total size of the resource in the format set by
// gst_base_src_set_format().
//
// The function returns the following values:
//
//   - size
//   - ok: TRUE if the size is available and has been set.
func (src *BaseSrc) size() (uint64, bool) {
	gclass := (*C.GstBaseSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.get_size

	var _arg0 *C.GstBaseSrc // out
	var _arg1 C.guint64     // in
	var _cret C.gboolean    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C._gotk4_gstbase1_BaseSrc_virtual_get_size(unsafe.Pointer(fnarg), _arg0, &_arg1)
	runtime.KeepAlive(src)

	var _size uint64 // out
	var _ok bool     // out

	_size = uint64(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _size, _ok
}

// Times: given buffer, return start and end time when it should be pushed out.
// The base class will sync on the clock using these times.
//
// The function returns the following values:
//
//   - start
//   - end
func (src *BaseSrc) times(buffer *gst.Buffer) (start, end gst.ClockTime) {
	gclass := (*C.GstBaseSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.get_times

	var _arg0 *C.GstBaseSrc  // out
	var _arg1 *C.GstBuffer   // out
	var _arg2 C.GstClockTime // in
	var _arg3 C.GstClockTime // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))

	C._gotk4_gstbase1_BaseSrc_virtual_get_times(unsafe.Pointer(fnarg), _arg0, _arg1, &_arg2, &_arg3)
	runtime.KeepAlive(src)
	runtime.KeepAlive(buffer)

	var _start gst.ClockTime // out
	var _end gst.ClockTime   // out

	_start = gst.ClockTime(_arg2)
	_end = gst.ClockTime(_arg3)

	return _start, _end
}

// isSeekable: check if the source can seek.
func (src *BaseSrc) isSeekable() bool {
	gclass := (*C.GstBaseSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.is_seekable

	var _arg0 *C.GstBaseSrc // out
	var _cret C.gboolean    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C._gotk4_gstbase1_BaseSrc_virtual_is_seekable(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(src)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Negotiate negotiates src pad caps with downstream elements. Unmarks
// GST_PAD_FLAG_NEED_RECONFIGURE in any case. But marks it again if
// BaseSrcClass::negotiate fails.
//
// Do not call this in the BaseSrcClass::fill vmethod. Call this in
// BaseSrcClass::create or in BaseSrcClass::alloc, _before_ any buffer is
// allocated.
//
// The function returns the following values:
//
//   - ok: TRUE if the negotiation succeeded, else FALSE.
func (src *BaseSrc) negotiate() bool {
	gclass := (*C.GstBaseSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.negotiate

	var _arg0 *C.GstBaseSrc // out
	var _cret C.gboolean    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C._gotk4_gstbase1_BaseSrc_virtual_negotiate(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(src)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// prepareSeekSegment: prepare the Segment that will be passed to the
// BaseSrcClass::do_seek vmethod for executing a seek request. Sub-classes
// should override this if they support seeking in formats other than the
// configured native format. By default, it tries to convert the seek arguments
// to the configured native format and prepare a segment in that format.
//
// The function takes the following parameters:
//
//   - seek
//   - segment
func (src *BaseSrc) prepareSeekSegment(seek *gst.Event, segment *gst.Segment) bool {
	gclass := (*C.GstBaseSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.prepare_seek_segment

	var _arg0 *C.GstBaseSrc // out
	var _arg1 *C.GstEvent   // out
	var _arg2 *C.GstSegment // out
	var _cret C.gboolean    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(seek)))
	_arg2 = (*C.GstSegment)(gextras.StructNative(unsafe.Pointer(segment)))

	_cret = C._gotk4_gstbase1_BaseSrc_virtual_prepare_seek_segment(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(src)
	runtime.KeepAlive(seek)
	runtime.KeepAlive(segment)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Query: handle a requested query.
func (src *BaseSrc) query(query *gst.Query) bool {
	gclass := (*C.GstBaseSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.query

	var _arg0 *C.GstBaseSrc // out
	var _arg1 *C.GstQuery   // out
	var _cret C.gboolean    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstbase1_BaseSrc_virtual_query(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// setCaps: set new caps on the basesrc source pad.
//
// The function takes the following parameters:
//
//   - caps: Caps.
//
// The function returns the following values:
//
//   - ok: TRUE if the caps could be set.
func (src *BaseSrc) setCaps(caps *gst.Caps) bool {
	gclass := (*C.GstBaseSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.set_caps

	var _arg0 *C.GstBaseSrc // out
	var _arg1 *C.GstCaps    // out
	var _cret C.gboolean    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C._gotk4_gstbase1_BaseSrc_virtual_set_caps(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(caps)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Start: start processing. Subclasses should open resources and prepare to
// produce data. Implementation should call gst_base_src_start_complete() when
// the operation completes, either from the current thread or any other thread
// that finishes the start operation asynchronously.
func (src *BaseSrc) start() bool {
	gclass := (*C.GstBaseSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.start

	var _arg0 *C.GstBaseSrc // out
	var _cret C.gboolean    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C._gotk4_gstbase1_BaseSrc_virtual_start(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(src)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Stop: stop processing. Subclasses should use this to close resources.
func (src *BaseSrc) stop() bool {
	gclass := (*C.GstBaseSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.stop

	var _arg0 *C.GstBaseSrc // out
	var _cret C.gboolean    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C._gotk4_gstbase1_BaseSrc_virtual_stop(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(src)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Unlock: unlock any pending access to the resource. Subclasses should
// unblock any blocked function ASAP. In particular, any create() function in
// progress should be unblocked and should return GST_FLOW_FLUSHING. Any future
// BaseSrcClass::create function call should also return GST_FLOW_FLUSHING until
// the BaseSrcClass::unlock_stop function has been called.
func (src *BaseSrc) unlock() bool {
	gclass := (*C.GstBaseSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.unlock

	var _arg0 *C.GstBaseSrc // out
	var _cret C.gboolean    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C._gotk4_gstbase1_BaseSrc_virtual_unlock(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(src)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// unlockStop: clear the previous unlock request. Subclasses should clear any
// state they set during BaseSrcClass::unlock, such as clearing command queues.
func (src *BaseSrc) unlockStop() bool {
	gclass := (*C.GstBaseSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.unlock_stop

	var _arg0 *C.GstBaseSrc // out
	var _cret C.gboolean    // in

	_arg0 = (*C.GstBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C._gotk4_gstbase1_BaseSrc_virtual_unlock_stop(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(src)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// BaseTransformOverrides contains methods that are overridable.
type BaseTransformOverrides struct {
	// AcceptCaps: optional. Subclasses can override this method to check if
	// caps can be handled by the element. The default implementation might not
	// be the most optimal way to check this in all cases.
	//
	// The function takes the following parameters:
	//
	//   - direction
	//   - caps
	AcceptCaps func(direction gst.PadDirection, caps *gst.Caps) bool
	// BeforeTransform: optional. This method is called right before the
	// base class will start processing. Dynamic properties or other delayed
	// configuration could be performed in this method.
	BeforeTransform func(buffer *gst.Buffer)
	// CopyMetadata: optional. Copy the metadata from the input buffer to the
	// output buffer. The default implementation will copy the flags, timestamps
	// and offsets of the buffer.
	//
	// The function takes the following parameters:
	//
	//   - input
	//   - outbuf
	CopyMetadata func(input, outbuf *gst.Buffer) bool
	// DecideAllocation: setup the allocation parameters for allocating output
	// buffers. The passed in query contains the result of the downstream
	// allocation query. This function is only called when not operating in
	// passthrough mode. The default implementation will remove all memory
	// dependent metadata. If there is a filter_meta method implementation,
	// it will be called for all metadata API in the downstream query, otherwise
	// the metadata API is removed.
	DecideAllocation func(query *gst.Query) bool
	// FilterMeta: return TRUE if the metadata API should be proposed in the
	// upstream allocation query. The default implementation is NULL and will
	// cause all metadata to be removed.
	//
	// The function takes the following parameters:
	//
	//   - query
	//   - api
	//   - params
	FilterMeta func(query *gst.Query, api coreglib.Type, params *gst.Structure) bool
	// The function takes the following parameters:
	//
	//   - direction
	//   - caps
	//   - othercaps
	FixateCaps func(direction gst.PadDirection, caps, othercaps *gst.Caps) *gst.Caps
	// The function returns the following values:
	//
	//   - outbuf
	//   - flowReturn
	GenerateOutput func() (*gst.Buffer, gst.FlowReturn)
	// The function returns the following values:
	//
	//   - size
	//   - ok
	UnitSize func(caps *gst.Caps) (uint, bool)
	// The function returns the following values:
	//
	//   - outbuf
	//   - flowReturn
	PrepareOutputBuffer func(input *gst.Buffer) (*gst.Buffer, gst.FlowReturn)
	// ProposeAllocation: propose buffer allocation parameters for upstream
	// elements. This function must be implemented if the element reads
	// or writes the buffer content. The query that was passed to the
	// decide_allocation is passed in this method (or NULL when the element
	// is in passthrough mode). The default implementation will pass the query
	// downstream when in passthrough mode and will copy all the filtered
	// metadata API in non-passthrough mode.
	//
	// The function takes the following parameters:
	//
	//   - decideQuery
	//   - query
	ProposeAllocation func(decideQuery, query *gst.Query) bool
	// Query: optional. Handle a requested query. Subclasses that implement this
	// must chain up to the parent if they didn't handle the query.
	//
	// The function takes the following parameters:
	//
	//   - direction
	//   - query
	Query func(direction gst.PadDirection, query *gst.Query) bool
	// SetCaps allows the subclass to be notified of the actual caps set.
	//
	// The function takes the following parameters:
	//
	//   - incaps
	//   - outcaps
	SetCaps   func(incaps, outcaps *gst.Caps) bool
	SinkEvent func(event *gst.Event) bool
	SrcEvent  func(event *gst.Event) bool
	// Start: optional. Called when the element starts processing. Allows
	// opening external resources.
	Start func() bool
	// Stop: optional. Called when the element stops processing. Allows closing
	// external resources.
	Stop func() bool
	// SubmitInputBuffer: function which accepts a new input buffer
	// and pre-processes it. The default implementation performs caps
	// (re)negotiation, then QoS if needed, and places the input buffer into
	// the queued_buf member variable. If the buffer is dropped due to QoS,
	// it returns GST_BASE_TRANSFORM_FLOW_DROPPED. If this input buffer is not
	// contiguous with any previous input buffer, then is_discont is set to
	// TRUE. (Since: 1.6).
	//
	// The function takes the following parameters:
	//
	//   - isDiscont
	//   - input
	SubmitInputBuffer func(isDiscont bool, input *gst.Buffer) gst.FlowReturn
	// Transform: required if the element does not operate in-place. Transforms
	// one incoming buffer to one outgoing buffer. The function is allowed to
	// change size/timestamp/duration of the outgoing buffer.
	//
	// The function takes the following parameters:
	//
	//   - inbuf
	//   - outbuf
	Transform func(inbuf, outbuf *gst.Buffer) gst.FlowReturn
	// TransformCaps: optional. Given the pad in this direction and the given
	// caps, what caps are allowed on the other pad in this element ?.
	//
	// The function takes the following parameters:
	//
	//   - direction
	//   - caps
	//   - filter
	TransformCaps func(direction gst.PadDirection, caps, filter *gst.Caps) *gst.Caps
	// TransformIP: required if the element operates in-place. Transform the
	// incoming buffer in-place.
	TransformIP func(buf *gst.Buffer) gst.FlowReturn
	// TransformMeta: optional. Transform the metadata on the input buffer to
	// the output buffer. By default this method copies all meta without tags.
	// Subclasses can implement this method and return TRUE if the metadata is
	// to be copied.
	//
	// The function takes the following parameters:
	//
	//   - outbuf
	//   - meta
	//   - inbuf
	TransformMeta func(outbuf *gst.Buffer, meta *gst.Meta, inbuf *gst.Buffer) bool
	// The function takes the following parameters:
	//
	//   - direction
	//   - caps
	//   - size
	//   - othercaps
	//
	// The function returns the following values:
	//
	//   - othersize
	//   - ok
	TransformSize func(direction gst.PadDirection, caps *gst.Caps, size uint, othercaps *gst.Caps) (uint, bool)
}

func defaultBaseTransformOverrides(v *BaseTransform) BaseTransformOverrides {
	return BaseTransformOverrides{
		AcceptCaps:          v.acceptCaps,
		BeforeTransform:     v.beforeTransform,
		CopyMetadata:        v.copyMetadata,
		DecideAllocation:    v.decideAllocation,
		FilterMeta:          v.filterMeta,
		FixateCaps:          v.fixateCaps,
		GenerateOutput:      v.generateOutput,
		UnitSize:            v.unitSize,
		PrepareOutputBuffer: v.prepareOutputBuffer,
		ProposeAllocation:   v.proposeAllocation,
		Query:               v.query,
		SetCaps:             v.setCaps,
		SinkEvent:           v.sinkEvent,
		SrcEvent:            v.srcEvent,
		Start:               v.start,
		Stop:                v.stop,
		SubmitInputBuffer:   v.submitInputBuffer,
		Transform:           v.transform,
		TransformCaps:       v.transformCaps,
		TransformIP:         v.transformIP,
		TransformMeta:       v.transformMeta,
		TransformSize:       v.transformSize,
	}
}

// BaseTransform (GstBaseTransform): this base class is for filter elements
// that process data. Elements that are suitable for implementation using
// BaseTransform are ones where the size and caps of the output is known
// entirely from the input caps and buffer sizes. These include elements that
// directly transform one buffer into another, modify the contents of a buffer
// in-place, as well as elements that collate multiple input buffers into one
// output buffer, or that expand one input buffer into multiple output buffers.
// See below for more concrete use cases.
//
// It provides for:
//
// * one sinkpad and one srcpad * Possible formats on sink and source pad
// implemented with custom transform_caps function. By default uses same format
// on sink and source.
//
// * Handles state changes * Does flushing * Push mode * Pull mode if the
// sub-class transform can operate on arbitrary data
//
// # Use Cases
//
// Passthrough mode
//
//   - Element has no interest in modifying the buffer. It may want to inspect
//     it, in which case the element should have a transform_ip function.
//     If there is no transform_ip function in passthrough mode, the buffer is
//     pushed intact.
//
//   - The BaseTransformClass.passthrough_on_same_caps variable will
//     automatically set/unset passthrough based on whether the element
//     negotiates the same caps on both pads.
//
//   - BaseTransformClass.passthrough_on_same_caps on an element that doesn't
//     implement a transform_caps function is useful for elements that only
//     inspect data (such as level)
//
//   - Example elements
//
//   - Level
//
//   - Videoscale, audioconvert, videoconvert, audioresample in certain modes.
//
// Modifications in-place - input buffer and output buffer are the same thing.
//
// * The element must implement a transform_ip function. * Output buffer size
// must <= input buffer size * If the always_in_place flag is set, non-writable
// buffers will be copied and passed to the transform_ip function, otherwise a
// new buffer will be created and the transform function called.
//
// * Incoming writable buffers will be passed to the transform_ip function
// immediately. * only implementing transform_ip and not transform implies
// always_in_place = TRUE
//
//   - Example elements:
//   - Volume
//   - Audioconvert in certain modes (signed/unsigned conversion)
//   - videoconvert in certain modes (endianness swapping)
//
// Modifications only to the caps/metadata of a buffer
//
// * The element does not require writable data, but non-writable buffers should
// be subbuffered so that the meta-information can be replaced.
//
// * Elements wishing to operate in this mode should replace the
// prepare_output_buffer method to create subbuffers of the input buffer and set
// always_in_place to TRUE
//
// * Example elements * Capsfilter when setting caps on outgoing buffers that
// have none. * identity when it is going to re-timestamp buffers by datarate.
//
// Normal mode
//
//   - always_in_place flag is not set, or there is no transform_ip function
//   - Element will receive an input buffer and output buffer to operate on.
//   - Output buffer is allocated by calling the prepare_output_buffer function.
//   - Example elements:
//   - Videoscale, videoconvert, audioconvert when doing scaling/conversions
//
// Special output buffer allocations
//
//   - Elements which need to do special allocation of their output buffers
//     beyond allocating output buffers via the negotiated allocator or buffer
//     pool should implement the prepare_output_buffer method.
//
//   - Example elements:
//
//   - efence
//
// # Sub-class settable flags on GstBaseTransform
//
// * passthrough
//
//   - Implies that in the current configuration, the sub-class is not
//     interested in modifying the buffers.
//   - Elements which are always in passthrough mode whenever the same
//     caps has been negotiated on both pads can set the class variable
//     passthrough_on_same_caps to have this behaviour automatically.
//
// * always_in_place * Determines whether a non-writable buffer will be copied
// before passing to the transform_ip function.
//
//   - Implied TRUE if no transform function is implemented.
//   - Implied FALSE if ONLY transform function is implemented.
type BaseTransform struct {
	_ [0]func() // equal guard
	gst.Element
}

var (
	_ gst.Elementer = (*BaseTransform)(nil)
)

// BaseTransformer describes types inherited from BaseTransform.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type BaseTransformer interface {
	gst.Elementer

	// Allocator (gst_base_transform_get_allocator) lets BaseTransform
	// sub-classes know the memory allocator used by the base class and its
	// params.
	Allocator() (gst.Allocatorrer, *gst.AllocationParams)
	BufferPool() *gst.BufferPool
	// IsInPlace (gst_base_transform_is_in_place): see if trans is configured as
	// a in_place transform.
	IsInPlace() bool
	// IsPassthrough (gst_base_transform_is_passthrough): see if trans is
	// configured as a passthrough transform.
	IsPassthrough() bool
	// IsQosEnabled (gst_base_transform_is_qos_enabled) queries if the transform
	// will handle QoS.
	IsQosEnabled() bool
	// Reconfigure (gst_base_transform_reconfigure) negotiates src pad caps with
	// downstream elements if the source pad is marked as needing reconfiguring.
	Reconfigure() bool
	// ReconfigureSink (gst_base_transform_reconfigure_sink) instructs trans to
	// request renegotiation upstream.
	ReconfigureSink()
	// ReconfigureSrc (gst_base_transform_reconfigure_src) instructs trans to
	// renegotiate a new downstream transform on the next buffer.
	ReconfigureSrc()
	// SetGapAware (gst_base_transform_set_gap_aware): if gap_aware is FALSE
	// (the default), output buffers will have the GST_BUFFER_FLAG_GAP flag
	// unset.
	SetGapAware(gapAware bool)
	// SetInPlace (gst_base_transform_set_in_place) determines whether a
	// non-writable buffer will be copied before passing to the transform_ip
	// function.
	SetInPlace(inPlace bool)
	// SetPassthrough (gst_base_transform_set_passthrough): set passthrough mode
	// for this filter by default.
	SetPassthrough(passthrough bool)
	// SetPreferPassthrough (gst_base_transform_set_prefer_passthrough):
	// if prefer_passthrough is TRUE (the default), trans will check and prefer
	// passthrough caps from the list of caps returned by the transform_caps
	// vmethod.
	SetPreferPassthrough(preferPassthrough bool)
	// SetQosEnabled (gst_base_transform_set_qos_enabled): enable or disable QoS
	// handling in the transform.
	SetQosEnabled(enabled bool)
	// UpdateQos (gst_base_transform_update_qos): set the QoS parameters in the
	// transform.
	UpdateQos(proportion float64, diff gst.ClockTimeDiff, timestamp gst.ClockTime)
	// UpdateSrcCaps (gst_base_transform_update_src_caps) updates the srcpad
	// caps and sends the caps downstream.
	UpdateSrcCaps(updatedCaps *gst.Caps) bool

	baseBaseTransform() *BaseTransform
}

var _ BaseTransformer = (*BaseTransform)(nil)

func init() {
	coreglib.RegisterClassInfo[*BaseTransform, *BaseTransformClass, BaseTransformOverrides](
		GTypeBaseTransform,
		initBaseTransformClass,
		wrapBaseTransform,
		defaultBaseTransformOverrides,
	)
}

func initBaseTransformClass(gclass unsafe.Pointer, overrides BaseTransformOverrides, classInitFunc func(*BaseTransformClass)) {
	pclass := (*C.GstBaseTransformClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeBaseTransform))))

	if overrides.AcceptCaps != nil {
		pclass.accept_caps = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_accept_caps)
	}

	if overrides.BeforeTransform != nil {
		pclass.before_transform = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_before_transform)
	}

	if overrides.CopyMetadata != nil {
		pclass.copy_metadata = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_copy_metadata)
	}

	if overrides.DecideAllocation != nil {
		pclass.decide_allocation = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_decide_allocation)
	}

	if overrides.FilterMeta != nil {
		pclass.filter_meta = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_filter_meta)
	}

	if overrides.FixateCaps != nil {
		pclass.fixate_caps = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_fixate_caps)
	}

	if overrides.GenerateOutput != nil {
		pclass.generate_output = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_generate_output)
	}

	if overrides.UnitSize != nil {
		pclass.get_unit_size = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_get_unit_size)
	}

	if overrides.PrepareOutputBuffer != nil {
		pclass.prepare_output_buffer = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_prepare_output_buffer)
	}

	if overrides.ProposeAllocation != nil {
		pclass.propose_allocation = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_propose_allocation)
	}

	if overrides.Query != nil {
		pclass.query = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_query)
	}

	if overrides.SetCaps != nil {
		pclass.set_caps = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_set_caps)
	}

	if overrides.SinkEvent != nil {
		pclass.sink_event = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_sink_event)
	}

	if overrides.SrcEvent != nil {
		pclass.src_event = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_src_event)
	}

	if overrides.Start != nil {
		pclass.start = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_start)
	}

	if overrides.Stop != nil {
		pclass.stop = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_stop)
	}

	if overrides.SubmitInputBuffer != nil {
		pclass.submit_input_buffer = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_submit_input_buffer)
	}

	if overrides.Transform != nil {
		pclass.transform = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_transform)
	}

	if overrides.TransformCaps != nil {
		pclass.transform_caps = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_transform_caps)
	}

	if overrides.TransformIP != nil {
		pclass.transform_ip = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_transform_ip)
	}

	if overrides.TransformMeta != nil {
		pclass.transform_meta = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_transform_meta)
	}

	if overrides.TransformSize != nil {
		pclass.transform_size = (*[0]byte)(C._gotk4_gstbase1_BaseTransformClass_transform_size)
	}

	if classInitFunc != nil {
		class := (*BaseTransformClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapBaseTransform(obj *coreglib.Object) *BaseTransform {
	return &BaseTransform{
		Element: gst.Element{
			GstObject: gst.GstObject{
				InitiallyUnowned: coreglib.InitiallyUnowned{
					Object: obj,
				},
			},
		},
	}
}

func marshalBaseTransform(p uintptr) (interface{}, error) {
	return wrapBaseTransform(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (trans *BaseTransform) baseBaseTransform() *BaseTransform {
	return trans
}

// BaseBaseTransform returns the underlying base object.
func BaseBaseTransform(obj BaseTransformer) *BaseTransform {
	return obj.baseBaseTransform()
}

// Allocator (gst_base_transform_get_allocator) lets BaseTransform sub-classes
// know the memory allocator used by the base class and its params.
//
// Unref the allocator after use.
//
// The function returns the following values:
//
//   - allocator (optional): Allocator used.
//   - params (optional) of allocator.
func (trans *BaseTransform) Allocator() (gst.Allocatorrer, *gst.AllocationParams) {
	var _arg0 *C.GstBaseTransform   // out
	var _arg1 *C.GstAllocator       // in
	var _arg2 C.GstAllocationParams // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))

	C.gst_base_transform_get_allocator(_arg0, &_arg1, &_arg2)
	runtime.KeepAlive(trans)

	var _allocator gst.Allocatorrer   // out
	var _params *gst.AllocationParams // out

	if _arg1 != nil {
		{
			objptr := unsafe.Pointer(_arg1)

			object := coreglib.AssumeOwnership(objptr)
			casted := object.WalkCast(func(obj coreglib.Objector) bool {
				_, ok := obj.(gst.Allocatorrer)
				return ok
			})
			rv, ok := casted.(gst.Allocatorrer)
			if !ok {
				panic("no marshaler for " + object.TypeFromInstance().String() + " matching gst.Allocatorrer")
			}
			_allocator = rv
		}
	}
	_params = (*gst.AllocationParams)(gextras.NewStructNative(unsafe.Pointer((&_arg2))))

	return _allocator, _params
}

// The function returns the following values:
//
//   - bufferPool (optional): instance of the BufferPool used by trans; free it
//     after use.
func (trans *BaseTransform) BufferPool() *gst.BufferPool {
	var _arg0 *C.GstBaseTransform // out
	var _cret *C.GstBufferPool    // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))

	_cret = C.gst_base_transform_get_buffer_pool(_arg0)
	runtime.KeepAlive(trans)

	var _bufferPool *gst.BufferPool // out

	if _cret != nil {
		{
			obj := coreglib.AssumeOwnership(unsafe.Pointer(_cret))
			_bufferPool = &gst.BufferPool{
				GstObject: gst.GstObject{
					InitiallyUnowned: coreglib.InitiallyUnowned{
						Object: obj,
					},
				},
			}
		}
	}

	return _bufferPool
}

// IsInPlace (gst_base_transform_is_in_place): see if trans is configured as a
// in_place transform.
//
// The function returns the following values:
//
//   - ok: TRUE if the transform is configured in in_place mode.
//
//     MT safe.
func (trans *BaseTransform) IsInPlace() bool {
	var _arg0 *C.GstBaseTransform // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))

	_cret = C.gst_base_transform_is_in_place(_arg0)
	runtime.KeepAlive(trans)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// IsPassthrough (gst_base_transform_is_passthrough): see if trans is configured
// as a passthrough transform.
//
// The function returns the following values:
//
//   - ok: TRUE if the transform is configured in passthrough mode.
//
//     MT safe.
func (trans *BaseTransform) IsPassthrough() bool {
	var _arg0 *C.GstBaseTransform // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))

	_cret = C.gst_base_transform_is_passthrough(_arg0)
	runtime.KeepAlive(trans)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// IsQosEnabled (gst_base_transform_is_qos_enabled) queries if the transform
// will handle QoS.
//
// The function returns the following values:
//
//   - ok: TRUE if QoS is enabled.
//
//     MT safe.
func (trans *BaseTransform) IsQosEnabled() bool {
	var _arg0 *C.GstBaseTransform // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))

	_cret = C.gst_base_transform_is_qos_enabled(_arg0)
	runtime.KeepAlive(trans)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Reconfigure (gst_base_transform_reconfigure) negotiates src pad caps with
// downstream elements if the source pad is marked as needing reconfiguring.
// Unmarks GST_PAD_FLAG_NEED_RECONFIGURE in any case. But marks it again if
// negotiation fails.
//
// Do not call this in the BaseTransformClass::transform
// or BaseTransformClass::transform_ip vmethod.
// Call this in BaseTransformClass::submit_input_buffer,
// BaseTransformClass::prepare_output_buffer or in
// BaseTransformClass::generate_output _before_ any output buffer is allocated.
//
// It will be default be called when handling an ALLOCATION query or at the
// very beginning of the default BaseTransformClass::submit_input_buffer
// implementation.
//
// The function returns the following values:
//
//   - ok: TRUE if the negotiation succeeded, else FALSE.
func (trans *BaseTransform) Reconfigure() bool {
	var _arg0 *C.GstBaseTransform // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))

	_cret = C.gst_base_transform_reconfigure(_arg0)
	runtime.KeepAlive(trans)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// ReconfigureSink (gst_base_transform_reconfigure_sink) instructs trans to
// request renegotiation upstream. This function is typically called after
// properties on the transform were set that influence the input format.
func (trans *BaseTransform) ReconfigureSink() {
	var _arg0 *C.GstBaseTransform // out

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))

	C.gst_base_transform_reconfigure_sink(_arg0)
	runtime.KeepAlive(trans)
}

// ReconfigureSrc (gst_base_transform_reconfigure_src) instructs trans to
// renegotiate a new downstream transform on the next buffer. This function is
// typically called after properties on the transform were set that influence
// the output format.
func (trans *BaseTransform) ReconfigureSrc() {
	var _arg0 *C.GstBaseTransform // out

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))

	C.gst_base_transform_reconfigure_src(_arg0)
	runtime.KeepAlive(trans)
}

// SetGapAware (gst_base_transform_set_gap_aware): if gap_aware is FALSE (the
// default), output buffers will have the GST_BUFFER_FLAG_GAP flag unset.
//
// If set to TRUE, the element must handle output buffers with this flag set
// correctly, i.e. it can assume that the buffer contains neutral data but must
// unset the flag if the output is no neutral data.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - gapAware: new state.
func (trans *BaseTransform) SetGapAware(gapAware bool) {
	var _arg0 *C.GstBaseTransform // out
	var _arg1 C.gboolean          // out

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	if gapAware {
		_arg1 = C.TRUE
	}

	C.gst_base_transform_set_gap_aware(_arg0, _arg1)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(gapAware)
}

// SetInPlace (gst_base_transform_set_in_place) determines whether a
// non-writable buffer will be copied before passing to the transform_ip
// function.
//
//   - Always TRUE if no transform function is implemented.
//   - Always FALSE if ONLY transform function is implemented.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - inPlace: boolean value indicating that we would like to operate on
//     in_place buffers.
func (trans *BaseTransform) SetInPlace(inPlace bool) {
	var _arg0 *C.GstBaseTransform // out
	var _arg1 C.gboolean          // out

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	if inPlace {
		_arg1 = C.TRUE
	}

	C.gst_base_transform_set_in_place(_arg0, _arg1)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(inPlace)
}

// SetPassthrough (gst_base_transform_set_passthrough): set passthrough mode for
// this filter by default. This is mostly useful for filters that do not care
// about negotiation.
//
// Always TRUE for filters which don't implement either a transform or
// transform_ip or generate_output method.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - passthrough: boolean indicating passthrough mode.
func (trans *BaseTransform) SetPassthrough(passthrough bool) {
	var _arg0 *C.GstBaseTransform // out
	var _arg1 C.gboolean          // out

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	if passthrough {
		_arg1 = C.TRUE
	}

	C.gst_base_transform_set_passthrough(_arg0, _arg1)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(passthrough)
}

// SetPreferPassthrough (gst_base_transform_set_prefer_passthrough):
// if prefer_passthrough is TRUE (the default), trans will check and prefer
// passthrough caps from the list of caps returned by the transform_caps
// vmethod.
//
// If set to FALSE, the element must order the caps returned from the
// transform_caps function in such a way that the preferred format is first in
// the list. This can be interesting for transforms that can do passthrough
// transforms but prefer to do something else, like a capsfilter.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - preferPassthrough: new state.
func (trans *BaseTransform) SetPreferPassthrough(preferPassthrough bool) {
	var _arg0 *C.GstBaseTransform // out
	var _arg1 C.gboolean          // out

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	if preferPassthrough {
		_arg1 = C.TRUE
	}

	C.gst_base_transform_set_prefer_passthrough(_arg0, _arg1)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(preferPassthrough)
}

// SetQosEnabled (gst_base_transform_set_qos_enabled): enable or disable QoS
// handling in the transform.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - enabled: new state.
func (trans *BaseTransform) SetQosEnabled(enabled bool) {
	var _arg0 *C.GstBaseTransform // out
	var _arg1 C.gboolean          // out

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	if enabled {
		_arg1 = C.TRUE
	}

	C.gst_base_transform_set_qos_enabled(_arg0, _arg1)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(enabled)
}

// UpdateQos (gst_base_transform_update_qos): set the QoS parameters in the
// transform. This function is called internally when a QOS event is received
// but subclasses can provide custom information when needed.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - proportion: proportion.
//   - diff against the clock.
//   - timestamp of the buffer generating the QoS expressed in running_time.
func (trans *BaseTransform) UpdateQos(proportion float64, diff gst.ClockTimeDiff, timestamp gst.ClockTime) {
	var _arg0 *C.GstBaseTransform // out
	var _arg1 C.gdouble           // out
	var _arg2 C.GstClockTimeDiff  // out
	var _arg3 C.GstClockTime      // out

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	_arg1 = C.gdouble(proportion)
	_arg2 = C.GstClockTimeDiff(diff)
	_arg3 = C.GstClockTime(timestamp)

	C.gst_base_transform_update_qos(_arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(proportion)
	runtime.KeepAlive(diff)
	runtime.KeepAlive(timestamp)
}

// UpdateSrcCaps (gst_base_transform_update_src_caps) updates the srcpad caps
// and sends the caps downstream. This function can be used by subclasses
// when they have already negotiated their caps but found a change in them (or
// computed new information). This way, they can notify downstream about that
// change without losing any buffer.
//
// The function takes the following parameters:
//
//   - updatedCaps: updated version of the srcpad caps to be pushed downstream.
//
// The function returns the following values:
//
//   - ok: TRUE if the caps could be sent downstream FALSE otherwise.
func (trans *BaseTransform) UpdateSrcCaps(updatedCaps *gst.Caps) bool {
	var _arg0 *C.GstBaseTransform // out
	var _arg1 *C.GstCaps          // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(updatedCaps)))

	_cret = C.gst_base_transform_update_src_caps(_arg0, _arg1)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(updatedCaps)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// acceptCaps: optional. Subclasses can override this method to check if caps
// can be handled by the element. The default implementation might not be the
// most optimal way to check this in all cases.
//
// The function takes the following parameters:
//
//   - direction
//   - caps
func (trans *BaseTransform) acceptCaps(direction gst.PadDirection, caps *gst.Caps) bool {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.accept_caps

	var _arg0 *C.GstBaseTransform // out
	var _arg1 C.GstPadDirection   // out
	var _arg2 *C.GstCaps          // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	_arg1 = C.GstPadDirection(direction)
	_arg2 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C._gotk4_gstbase1_BaseTransform_virtual_accept_caps(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(direction)
	runtime.KeepAlive(caps)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// beforeTransform: optional. This method is called right before the base class
// will start processing. Dynamic properties or other delayed configuration
// could be performed in this method.
func (trans *BaseTransform) beforeTransform(buffer *gst.Buffer) {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.before_transform

	var _arg0 *C.GstBaseTransform // out
	var _arg1 *C.GstBuffer        // out

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))

	C._gotk4_gstbase1_BaseTransform_virtual_before_transform(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(buffer)
}

// copyMetadata: optional. Copy the metadata from the input buffer to the
// output buffer. The default implementation will copy the flags, timestamps and
// offsets of the buffer.
//
// The function takes the following parameters:
//
//   - input
//   - outbuf
func (trans *BaseTransform) copyMetadata(input, outbuf *gst.Buffer) bool {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.copy_metadata

	var _arg0 *C.GstBaseTransform // out
	var _arg1 *C.GstBuffer        // out
	var _arg2 *C.GstBuffer        // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(input)))
	_arg2 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(outbuf)))

	_cret = C._gotk4_gstbase1_BaseTransform_virtual_copy_metadata(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(input)
	runtime.KeepAlive(outbuf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// decideAllocation: setup the allocation parameters for allocating output
// buffers. The passed in query contains the result of the downstream allocation
// query. This function is only called when not operating in passthrough mode.
// The default implementation will remove all memory dependent metadata.
// If there is a filter_meta method implementation, it will be called for all
// metadata API in the downstream query, otherwise the metadata API is removed.
func (trans *BaseTransform) decideAllocation(query *gst.Query) bool {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.decide_allocation

	var _arg0 *C.GstBaseTransform // out
	var _arg1 *C.GstQuery         // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstbase1_BaseTransform_virtual_decide_allocation(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// filterMeta: return TRUE if the metadata API should be proposed in the
// upstream allocation query. The default implementation is NULL and will cause
// all metadata to be removed.
//
// The function takes the following parameters:
//
//   - query
//   - api
//   - params
func (trans *BaseTransform) filterMeta(query *gst.Query, api coreglib.Type, params *gst.Structure) bool {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.filter_meta

	var _arg0 *C.GstBaseTransform // out
	var _arg1 *C.GstQuery         // out
	var _arg2 C.GType             // out
	var _arg3 *C.GstStructure     // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))
	_arg2 = C.GType(api)
	_arg3 = (*C.GstStructure)(gextras.StructNative(unsafe.Pointer(params)))

	_cret = C._gotk4_gstbase1_BaseTransform_virtual_filter_meta(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(query)
	runtime.KeepAlive(api)
	runtime.KeepAlive(params)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function takes the following parameters:
//
//   - direction
//   - caps
//   - othercaps
func (trans *BaseTransform) fixateCaps(direction gst.PadDirection, caps, othercaps *gst.Caps) *gst.Caps {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.fixate_caps

	var _arg0 *C.GstBaseTransform // out
	var _arg1 C.GstPadDirection   // out
	var _arg2 *C.GstCaps          // out
	var _arg3 *C.GstCaps          // out
	var _cret *C.GstCaps          // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	_arg1 = C.GstPadDirection(direction)
	_arg2 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))
	_arg3 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(othercaps)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(othercaps)), nil)

	_cret = C._gotk4_gstbase1_BaseTransform_virtual_fixate_caps(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(direction)
	runtime.KeepAlive(caps)
	runtime.KeepAlive(othercaps)

	var _ret *gst.Caps // out

	_ret = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_ret)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _ret
}

// The function returns the following values:
//
//   - outbuf
//   - flowReturn
func (trans *BaseTransform) generateOutput() (*gst.Buffer, gst.FlowReturn) {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.generate_output

	var _arg0 *C.GstBaseTransform // out
	var _arg1 *C.GstBuffer        // in
	var _cret C.GstFlowReturn     // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))

	_cret = C._gotk4_gstbase1_BaseTransform_virtual_generate_output(unsafe.Pointer(fnarg), _arg0, &_arg1)
	runtime.KeepAlive(trans)

	var _outbuf *gst.Buffer        // out
	var _flowReturn gst.FlowReturn // out

	_outbuf = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_arg1)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_outbuf)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})
	_flowReturn = gst.FlowReturn(_cret)

	return _outbuf, _flowReturn
}

// The function returns the following values:
//
//   - size
//   - ok
func (trans *BaseTransform) unitSize(caps *gst.Caps) (uint, bool) {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.get_unit_size

	var _arg0 *C.GstBaseTransform // out
	var _arg1 *C.GstCaps          // out
	var _arg2 C.gsize             // in
	var _cret C.gboolean          // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C._gotk4_gstbase1_BaseTransform_virtual_get_unit_size(unsafe.Pointer(fnarg), _arg0, _arg1, &_arg2)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(caps)

	var _size uint // out
	var _ok bool   // out

	_size = uint(_arg2)
	if _cret != 0 {
		_ok = true
	}

	return _size, _ok
}

// The function returns the following values:
//
//   - outbuf
//   - flowReturn
func (trans *BaseTransform) prepareOutputBuffer(input *gst.Buffer) (*gst.Buffer, gst.FlowReturn) {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.prepare_output_buffer

	var _arg0 *C.GstBaseTransform // out
	var _arg1 *C.GstBuffer        // out
	var _arg2 *C.GstBuffer        // in
	var _cret C.GstFlowReturn     // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(input)))

	_cret = C._gotk4_gstbase1_BaseTransform_virtual_prepare_output_buffer(unsafe.Pointer(fnarg), _arg0, _arg1, &_arg2)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(input)

	var _outbuf *gst.Buffer        // out
	var _flowReturn gst.FlowReturn // out

	_outbuf = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_arg2)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_outbuf)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})
	_flowReturn = gst.FlowReturn(_cret)

	return _outbuf, _flowReturn
}

// proposeAllocation: propose buffer allocation parameters for upstream
// elements. This function must be implemented if the element reads or writes
// the buffer content. The query that was passed to the decide_allocation is
// passed in this method (or NULL when the element is in passthrough mode).
// The default implementation will pass the query downstream when in passthrough
// mode and will copy all the filtered metadata API in non-passthrough mode.
//
// The function takes the following parameters:
//
//   - decideQuery
//   - query
func (trans *BaseTransform) proposeAllocation(decideQuery, query *gst.Query) bool {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.propose_allocation

	var _arg0 *C.GstBaseTransform // out
	var _arg1 *C.GstQuery         // out
	var _arg2 *C.GstQuery         // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(decideQuery)))
	_arg2 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstbase1_BaseTransform_virtual_propose_allocation(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(decideQuery)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Query: optional. Handle a requested query. Subclasses that implement this
// must chain up to the parent if they didn't handle the query.
//
// The function takes the following parameters:
//
//   - direction
//   - query
func (trans *BaseTransform) query(direction gst.PadDirection, query *gst.Query) bool {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.query

	var _arg0 *C.GstBaseTransform // out
	var _arg1 C.GstPadDirection   // out
	var _arg2 *C.GstQuery         // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	_arg1 = C.GstPadDirection(direction)
	_arg2 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstbase1_BaseTransform_virtual_query(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(direction)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// setCaps allows the subclass to be notified of the actual caps set.
//
// The function takes the following parameters:
//
//   - incaps
//   - outcaps
func (trans *BaseTransform) setCaps(incaps, outcaps *gst.Caps) bool {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.set_caps

	var _arg0 *C.GstBaseTransform // out
	var _arg1 *C.GstCaps          // out
	var _arg2 *C.GstCaps          // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(incaps)))
	_arg2 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(outcaps)))

	_cret = C._gotk4_gstbase1_BaseTransform_virtual_set_caps(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(incaps)
	runtime.KeepAlive(outcaps)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

func (trans *BaseTransform) sinkEvent(event *gst.Event) bool {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.sink_event

	var _arg0 *C.GstBaseTransform // out
	var _arg1 *C.GstEvent         // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(event)), nil)

	_cret = C._gotk4_gstbase1_BaseTransform_virtual_sink_event(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(event)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

func (trans *BaseTransform) srcEvent(event *gst.Event) bool {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.src_event

	var _arg0 *C.GstBaseTransform // out
	var _arg1 *C.GstEvent         // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(event)), nil)

	_cret = C._gotk4_gstbase1_BaseTransform_virtual_src_event(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(event)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Start: optional. Called when the element starts processing. Allows opening
// external resources.
func (trans *BaseTransform) start() bool {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.start

	var _arg0 *C.GstBaseTransform // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))

	_cret = C._gotk4_gstbase1_BaseTransform_virtual_start(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(trans)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Stop: optional. Called when the element stops processing. Allows closing
// external resources.
func (trans *BaseTransform) stop() bool {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.stop

	var _arg0 *C.GstBaseTransform // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))

	_cret = C._gotk4_gstbase1_BaseTransform_virtual_stop(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(trans)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// submitInputBuffer: function which accepts a new input buffer and
// pre-processes it. The default implementation performs caps (re)negotiation,
// then QoS if needed, and places the input buffer into the queued_buf
// member variable. If the buffer is dropped due to QoS, it returns
// GST_BASE_TRANSFORM_FLOW_DROPPED. If this input buffer is not contiguous with
// any previous input buffer, then is_discont is set to TRUE. (Since: 1.6).
//
// The function takes the following parameters:
//
//   - isDiscont
//   - input
func (trans *BaseTransform) submitInputBuffer(isDiscont bool, input *gst.Buffer) gst.FlowReturn {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.submit_input_buffer

	var _arg0 *C.GstBaseTransform // out
	var _arg1 C.gboolean          // out
	var _arg2 *C.GstBuffer        // out
	var _cret C.GstFlowReturn     // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	if isDiscont {
		_arg1 = C.TRUE
	}
	_arg2 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(input)))

	_cret = C._gotk4_gstbase1_BaseTransform_virtual_submit_input_buffer(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(isDiscont)
	runtime.KeepAlive(input)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// Transform: required if the element does not operate in-place. Transforms one
// incoming buffer to one outgoing buffer. The function is allowed to change
// size/timestamp/duration of the outgoing buffer.
//
// The function takes the following parameters:
//
//   - inbuf
//   - outbuf
func (trans *BaseTransform) transform(inbuf, outbuf *gst.Buffer) gst.FlowReturn {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.transform

	var _arg0 *C.GstBaseTransform // out
	var _arg1 *C.GstBuffer        // out
	var _arg2 *C.GstBuffer        // out
	var _cret C.GstFlowReturn     // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(inbuf)))
	_arg2 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(outbuf)))

	_cret = C._gotk4_gstbase1_BaseTransform_virtual_transform(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(inbuf)
	runtime.KeepAlive(outbuf)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// transformCaps: optional. Given the pad in this direction and the given caps,
// what caps are allowed on the other pad in this element ?.
//
// The function takes the following parameters:
//
//   - direction
//   - caps
//   - filter
func (trans *BaseTransform) transformCaps(direction gst.PadDirection, caps, filter *gst.Caps) *gst.Caps {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.transform_caps

	var _arg0 *C.GstBaseTransform // out
	var _arg1 C.GstPadDirection   // out
	var _arg2 *C.GstCaps          // out
	var _arg3 *C.GstCaps          // out
	var _cret *C.GstCaps          // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	_arg1 = C.GstPadDirection(direction)
	_arg2 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))
	_arg3 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(filter)))

	_cret = C._gotk4_gstbase1_BaseTransform_virtual_transform_caps(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(direction)
	runtime.KeepAlive(caps)
	runtime.KeepAlive(filter)

	var _ret *gst.Caps // out

	_ret = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_ret)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _ret
}

// transformIP: required if the element operates in-place. Transform the
// incoming buffer in-place.
func (trans *BaseTransform) transformIP(buf *gst.Buffer) gst.FlowReturn {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.transform_ip

	var _arg0 *C.GstBaseTransform // out
	var _arg1 *C.GstBuffer        // out
	var _cret C.GstFlowReturn     // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buf)))

	_cret = C._gotk4_gstbase1_BaseTransform_virtual_transform_ip(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(buf)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// transformMeta: optional. Transform the metadata on the input buffer to
// the output buffer. By default this method copies all meta without tags.
// Subclasses can implement this method and return TRUE if the metadata is to be
// copied.
//
// The function takes the following parameters:
//
//   - outbuf
//   - meta
//   - inbuf
func (trans *BaseTransform) transformMeta(outbuf *gst.Buffer, meta *gst.Meta, inbuf *gst.Buffer) bool {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.transform_meta

	var _arg0 *C.GstBaseTransform // out
	var _arg1 *C.GstBuffer        // out
	var _arg2 *C.GstMeta          // out
	var _arg3 *C.GstBuffer        // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(outbuf)))
	_arg2 = (*C.GstMeta)(gextras.StructNative(unsafe.Pointer(meta)))
	_arg3 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(inbuf)))

	_cret = C._gotk4_gstbase1_BaseTransform_virtual_transform_meta(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(outbuf)
	runtime.KeepAlive(meta)
	runtime.KeepAlive(inbuf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function takes the following parameters:
//
//   - direction
//   - caps
//   - size
//   - othercaps
//
// The function returns the following values:
//
//   - othersize
//   - ok
func (trans *BaseTransform) transformSize(direction gst.PadDirection, caps *gst.Caps, size uint, othercaps *gst.Caps) (uint, bool) {
	gclass := (*C.GstBaseTransformClass)(coreglib.PeekParentClass(trans))
	fnarg := gclass.transform_size

	var _arg0 *C.GstBaseTransform // out
	var _arg1 C.GstPadDirection   // out
	var _arg2 *C.GstCaps          // out
	var _arg3 C.gsize             // out
	var _arg4 *C.GstCaps          // out
	var _arg5 C.gsize             // in
	var _cret C.gboolean          // in

	_arg0 = (*C.GstBaseTransform)(unsafe.Pointer(coreglib.BaseObject(trans).Native()))
	_arg1 = C.GstPadDirection(direction)
	_arg2 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))
	_arg3 = C.gsize(size)
	_arg4 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(othercaps)))

	_cret = C._gotk4_gstbase1_BaseTransform_virtual_transform_size(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2, _arg3, _arg4, &_arg5)
	runtime.KeepAlive(trans)
	runtime.KeepAlive(direction)
	runtime.KeepAlive(caps)
	runtime.KeepAlive(size)
	runtime.KeepAlive(othercaps)

	var _othersize uint // out
	var _ok bool        // out

	_othersize = uint(_arg5)
	if _cret != 0 {
		_ok = true
	}

	return _othersize, _ok
}

// CollectPadsOverrides contains methods that are overridable.
type CollectPadsOverrides struct {
}

func defaultCollectPadsOverrides(v *CollectPads) CollectPadsOverrides {
	return CollectPadsOverrides{}
}

// CollectPads (GstCollectPads) manages a set of pads that operate in collect
// mode. This means that control is given to the manager of this object when all
// pads have data.
//
//   - Collectpads are created with gst_collect_pads_new(). A callback should
//     then be installed with gst_collect_pads_set_function ().
//
//   - Pads are added to the collection with gst_collect_pads_add_pad()/
//     gst_collect_pads_remove_pad(). The pad has to be a sinkpad. When added,
//     the chain, event and query functions of the pad are overridden.
//     The element_private of the pad is used to store private information for
//     the collectpads.
//
//   - For each pad, data is queued in the _chain function or by performing a
//     pull_range.
//
//   - When data is queued on all pads in waiting mode, the callback function is
//     called.
//
//   - Data can be dequeued from the pad with the gst_collect_pads_pop() method.
//     One can peek at the data with the gst_collect_pads_peek() function.
//     These functions will return NULL if the pad received an EOS event.
//     When all pads return NULL from a gst_collect_pads_peek(), the element can
//     emit an EOS event itself.
//
//   - Data can also be dequeued in byte units using the
//     gst_collect_pads_available(), gst_collect_pads_read_buffer() and
//     gst_collect_pads_flush() calls.
//
//   - Elements should call gst_collect_pads_start() and gst_collect_pads_stop()
//     in their state change functions to start and stop the processing of the
//     collectpads. The gst_collect_pads_stop() call should be called before
//     calling the parent element state change function in the PAUSED_TO_READY
//     state change to ensure no pad is blocked and the element can finish
//     streaming.
//
//   - gst_collect_pads_set_waiting() sets a pad to waiting or non-waiting mode.
//     CollectPads element is not waiting for data to be collected on
//     non-waiting pads. Thus these pads may but need not have data when the
//     callback is called. All pads are in waiting mode by default.
type CollectPads struct {
	_ [0]func() // equal guard
	gst.GstObject
}

var (
	_ gst.GstObjector = (*CollectPads)(nil)
)

// CollectPadser describes types inherited from CollectPads.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type CollectPadser interface {
	gst.GstObjector

	// Available (gst_collect_pads_available): query how much bytes can be read
	// from each queued buffer.
	Available() uint
	// ClipRunningTime (gst_collect_pads_clip_running_time): convenience
	// clipping function that converts incoming buffer's timestamp to running
	// time, or clips the buffer if outside configured segment.
	ClipRunningTime(cdata *CollectData, buf *gst.Buffer, userData unsafe.Pointer) (*gst.Buffer, gst.FlowReturn)
	// EventDefault (gst_collect_pads_event_default): default CollectPads
	// event handling that elements should always chain up to to ensure proper
	// operation.
	EventDefault(data *CollectData, event *gst.Event, discard bool) bool
	// Flush (gst_collect_pads_flush) size bytes from the pad data.
	Flush(data *CollectData, size uint) uint
	// Peek (gst_collect_pads_peek) at the buffer currently queued in data.
	Peek(data *CollectData) *gst.Buffer
	// Pop (gst_collect_pads_pop) the buffer currently queued in data.
	Pop(data *CollectData) *gst.Buffer
	// QueryDefault (gst_collect_pads_query_default): default CollectPads
	// query handling that elements should always chain up to to ensure proper
	// operation.
	QueryDefault(data *CollectData, query *gst.Query, discard bool) bool
	// ReadBuffer (gst_collect_pads_read_buffer): get a subbuffer of size bytes
	// from the given pad data.
	ReadBuffer(data *CollectData, size uint) *gst.Buffer
	// RemovePad (gst_collect_pads_remove_pad): remove a pad from the collection
	// of collect pads.
	RemovePad(pad *gst.Pad) bool
	// SetBufferFunction (gst_collect_pads_set_buffer_function): set the
	// callback function and user data that will be called with the oldest
	// buffer when all pads have been collected, or NULL on EOS.
	SetBufferFunction(fn CollectPadsBufferFunction)
	// SetClipFunction (gst_collect_pads_set_clip_function): install a clipping
	// function that is called right after a buffer is received on a pad managed
	// by pads.
	SetClipFunction(clipfunc CollectPadsClipFunction)
	// SetCompareFunction (gst_collect_pads_set_compare_function): set the
	// timestamp comparison function.
	SetCompareFunction(fn CollectPadsCompareFunction)
	// SetEventFunction (gst_collect_pads_set_event_function): set the event
	// callback function and user data that will be called when collectpads has
	// received an event originating from one of the collected pads.
	SetEventFunction(fn CollectPadsEventFunction)
	// SetFlushFunction (gst_collect_pads_set_flush_function): install a flush
	// function that is called when the internal state of all pads should be
	// flushed as part of flushing seek handling.
	SetFlushFunction(fn CollectPadsFlushFunction)
	// SetFlushing (gst_collect_pads_set_flushing): change the flushing state of
	// all the pads in the collection.
	SetFlushing(flushing bool)
	// SetFunction (gst_collect_pads_set_function) collectPads provides a
	// default collection algorithm that will determine the oldest buffer
	// available on all of its pads, and then delegate to a configured callback.
	SetFunction(fn CollectPadsFunction)
	// SetQueryFunction (gst_collect_pads_set_query_function): set the query
	// callback function and user data that will be called after collectpads has
	// received a query originating from one of the collected pads.
	SetQueryFunction(fn CollectPadsQueryFunction)
	// SetWaiting (gst_collect_pads_set_waiting) sets a pad to waiting or
	// non-waiting mode, if at least this pad has not been created with locked
	// waiting state, in which case nothing happens.
	SetWaiting(data *CollectData, waiting bool)
	// SrcEventDefault (gst_collect_pads_src_event_default): default CollectPads
	// event handling for the src pad of elements.
	SrcEventDefault(pad *gst.Pad, event *gst.Event) bool
	// Start (gst_collect_pads_start) starts the processing of data in the
	// collect_pads.
	Start()
	// Stop (gst_collect_pads_stop) stops the processing of data in the
	// collect_pads.
	Stop()
	// TakeBuffer (gst_collect_pads_take_buffer): get a subbuffer of size bytes
	// from the given pad data.
	TakeBuffer(data *CollectData, size uint) *gst.Buffer

	baseCollectPads() *CollectPads
}

var _ CollectPadser = (*CollectPads)(nil)

func init() {
	coreglib.RegisterClassInfo[*CollectPads, *CollectPadsClass, CollectPadsOverrides](
		GTypeCollectPads,
		initCollectPadsClass,
		wrapCollectPads,
		defaultCollectPadsOverrides,
	)
}

func initCollectPadsClass(gclass unsafe.Pointer, overrides CollectPadsOverrides, classInitFunc func(*CollectPadsClass)) {
	if classInitFunc != nil {
		class := (*CollectPadsClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapCollectPads(obj *coreglib.Object) *CollectPads {
	return &CollectPads{
		GstObject: gst.GstObject{
			InitiallyUnowned: coreglib.InitiallyUnowned{
				Object: obj,
			},
		},
	}
}

func marshalCollectPads(p uintptr) (interface{}, error) {
	return wrapCollectPads(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (pads *CollectPads) baseCollectPads() *CollectPads {
	return pads
}

// BaseCollectPads returns the underlying base object.
func BaseCollectPads(obj CollectPadser) *CollectPads {
	return obj.baseCollectPads()
}

// NewCollectPads (gst_collect_pads_new): create a new instance of CollectPads.
//
// MT safe.
//
// The function returns the following values:
//
//   - collectPads: new CollectPads, or NULL in case of an error.
func NewCollectPads() *CollectPads {
	var _cret *C.GstCollectPads // in

	_cret = C.gst_collect_pads_new()

	var _collectPads *CollectPads // out

	_collectPads = wrapCollectPads(coreglib.AssumeOwnership(unsafe.Pointer(_cret)))

	return _collectPads
}

// Available (gst_collect_pads_available): query how much bytes can be read from
// each queued buffer. This means that the result of this call is the maximum
// number of bytes that can be read from each of the pads.
//
// This function should be called with pads STREAM_LOCK held, such as in the
// callback.
//
// MT safe.
//
// The function returns the following values:
//
//   - guint: maximum number of bytes queued on all pads. This function returns
//     0 if a pad has no queued buffer.
func (pads *CollectPads) Available() uint {
	var _arg0 *C.GstCollectPads // out
	var _cret C.guint           // in

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))

	_cret = C.gst_collect_pads_available(_arg0)
	runtime.KeepAlive(pads)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// ClipRunningTime (gst_collect_pads_clip_running_time): convenience clipping
// function that converts incoming buffer's timestamp to running time, or clips
// the buffer if outside configured segment.
//
// Since 1.6, this clipping function also sets the DTS parameter of the
// GstCollectData structure. This version of the running time DTS can be
// negative. G_MININT64 is used to indicate invalid value.
//
// The function takes the following parameters:
//
//   - cdata: collect data of corresponding pad.
//   - buf: buffer being clipped.
//   - userData (optional): user data (unused).
//
// The function returns the following values:
//
//   - outbuf (optional): output buffer with running time, or NULL if clipped.
//   - flowReturn
func (pads *CollectPads) ClipRunningTime(cdata *CollectData, buf *gst.Buffer, userData unsafe.Pointer) (*gst.Buffer, gst.FlowReturn) {
	var _arg0 *C.GstCollectPads // out
	var _arg1 *C.GstCollectData // out
	var _arg2 *C.GstBuffer      // out
	var _arg3 *C.GstBuffer      // in
	var _arg4 C.gpointer        // out
	var _cret C.GstFlowReturn   // in

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))
	_arg1 = (*C.GstCollectData)(gextras.StructNative(unsafe.Pointer(cdata)))
	_arg2 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buf)))
	_arg4 = (C.gpointer)(unsafe.Pointer(userData))

	_cret = C.gst_collect_pads_clip_running_time(_arg0, _arg1, _arg2, &_arg3, _arg4)
	runtime.KeepAlive(pads)
	runtime.KeepAlive(cdata)
	runtime.KeepAlive(buf)
	runtime.KeepAlive(userData)

	var _outbuf *gst.Buffer        // out
	var _flowReturn gst.FlowReturn // out

	if _arg3 != nil {
		_outbuf = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_arg3)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_outbuf)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}
	_flowReturn = gst.FlowReturn(_cret)

	return _outbuf, _flowReturn
}

// EventDefault (gst_collect_pads_event_default): default CollectPads event
// handling that elements should always chain up to to ensure proper operation.
// Element might however indicate event should not be forwarded downstream.
//
// The function takes the following parameters:
//
//   - data: collect data of corresponding pad.
//   - event being processed.
//   - discard process but do not send event downstream.
func (pads *CollectPads) EventDefault(data *CollectData, event *gst.Event, discard bool) bool {
	var _arg0 *C.GstCollectPads // out
	var _arg1 *C.GstCollectData // out
	var _arg2 *C.GstEvent       // out
	var _arg3 C.gboolean        // out
	var _cret C.gboolean        // in

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))
	_arg1 = (*C.GstCollectData)(gextras.StructNative(unsafe.Pointer(data)))
	_arg2 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))
	if discard {
		_arg3 = C.TRUE
	}

	_cret = C.gst_collect_pads_event_default(_arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(pads)
	runtime.KeepAlive(data)
	runtime.KeepAlive(event)
	runtime.KeepAlive(discard)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Flush (gst_collect_pads_flush) size bytes from the pad data.
//
// This function should be called with pads STREAM_LOCK held, such as in the
// callback.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - data to use.
//   - size: number of bytes to flush.
//
// The function returns the following values:
//
//   - guint: number of bytes flushed This can be less than size and is 0 if the
//     pad was end-of-stream.
func (pads *CollectPads) Flush(data *CollectData, size uint) uint {
	var _arg0 *C.GstCollectPads // out
	var _arg1 *C.GstCollectData // out
	var _arg2 C.guint           // out
	var _cret C.guint           // in

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))
	_arg1 = (*C.GstCollectData)(gextras.StructNative(unsafe.Pointer(data)))
	_arg2 = C.guint(size)

	_cret = C.gst_collect_pads_flush(_arg0, _arg1, _arg2)
	runtime.KeepAlive(pads)
	runtime.KeepAlive(data)
	runtime.KeepAlive(size)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// Peek (gst_collect_pads_peek) at the buffer currently queued in data.
// This function should be called with the pads STREAM_LOCK held, such as in the
// callback handler.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - data to use.
//
// The function returns the following values:
//
//   - buffer (optional) in data or NULL if no buffer is queued. should unref
//     the buffer after usage.
func (pads *CollectPads) Peek(data *CollectData) *gst.Buffer {
	var _arg0 *C.GstCollectPads // out
	var _arg1 *C.GstCollectData // out
	var _cret *C.GstBuffer      // in

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))
	_arg1 = (*C.GstCollectData)(gextras.StructNative(unsafe.Pointer(data)))

	_cret = C.gst_collect_pads_peek(_arg0, _arg1)
	runtime.KeepAlive(pads)
	runtime.KeepAlive(data)

	var _buffer *gst.Buffer // out

	if _cret != nil {
		_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_buffer)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _buffer
}

// Pop (gst_collect_pads_pop) the buffer currently queued in data. This function
// should be called with the pads STREAM_LOCK held, such as in the callback
// handler.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - data to use.
//
// The function returns the following values:
//
//   - buffer (optional) in data or NULL if no buffer was queued. You should
//     unref the buffer after usage.
func (pads *CollectPads) Pop(data *CollectData) *gst.Buffer {
	var _arg0 *C.GstCollectPads // out
	var _arg1 *C.GstCollectData // out
	var _cret *C.GstBuffer      // in

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))
	_arg1 = (*C.GstCollectData)(gextras.StructNative(unsafe.Pointer(data)))

	_cret = C.gst_collect_pads_pop(_arg0, _arg1)
	runtime.KeepAlive(pads)
	runtime.KeepAlive(data)

	var _buffer *gst.Buffer // out

	if _cret != nil {
		_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_buffer)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _buffer
}

// QueryDefault (gst_collect_pads_query_default): default CollectPads query
// handling that elements should always chain up to to ensure proper operation.
// Element might however indicate query should not be forwarded downstream.
//
// The function takes the following parameters:
//
//   - data: collect data of corresponding pad.
//   - query being processed.
//   - discard process but do not send event downstream.
func (pads *CollectPads) QueryDefault(data *CollectData, query *gst.Query, discard bool) bool {
	var _arg0 *C.GstCollectPads // out
	var _arg1 *C.GstCollectData // out
	var _arg2 *C.GstQuery       // out
	var _arg3 C.gboolean        // out
	var _cret C.gboolean        // in

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))
	_arg1 = (*C.GstCollectData)(gextras.StructNative(unsafe.Pointer(data)))
	_arg2 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))
	if discard {
		_arg3 = C.TRUE
	}

	_cret = C.gst_collect_pads_query_default(_arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(pads)
	runtime.KeepAlive(data)
	runtime.KeepAlive(query)
	runtime.KeepAlive(discard)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// ReadBuffer (gst_collect_pads_read_buffer): get a subbuffer of size bytes from
// the given pad data.
//
// This function should be called with pads STREAM_LOCK held, such as in the
// callback.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - data to use.
//   - size: number of bytes to read.
//
// The function returns the following values:
//
//   - buffer (optional): sub buffer. The size of the buffer can be less that
//     requested. A return of NULL signals that the pad is end-of-stream.
//     Unref the buffer after use.
func (pads *CollectPads) ReadBuffer(data *CollectData, size uint) *gst.Buffer {
	var _arg0 *C.GstCollectPads // out
	var _arg1 *C.GstCollectData // out
	var _arg2 C.guint           // out
	var _cret *C.GstBuffer      // in

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))
	_arg1 = (*C.GstCollectData)(gextras.StructNative(unsafe.Pointer(data)))
	_arg2 = C.guint(size)

	_cret = C.gst_collect_pads_read_buffer(_arg0, _arg1, _arg2)
	runtime.KeepAlive(pads)
	runtime.KeepAlive(data)
	runtime.KeepAlive(size)

	var _buffer *gst.Buffer // out

	if _cret != nil {
		_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_buffer)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _buffer
}

// RemovePad (gst_collect_pads_remove_pad): remove a pad from the collection
// of collect pads. This function will also free the CollectData and all the
// resources that were allocated with gst_collect_pads_add_pad().
//
// The pad will be deactivated automatically when pads is stopped.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - pad to remove.
//
// The function returns the following values:
//
//   - ok: TRUE if the pad could be removed.
func (pads *CollectPads) RemovePad(pad *gst.Pad) bool {
	var _arg0 *C.GstCollectPads // out
	var _arg1 *C.GstPad         // out
	var _cret C.gboolean        // in

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))
	_arg1 = (*C.GstPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))

	_cret = C.gst_collect_pads_remove_pad(_arg0, _arg1)
	runtime.KeepAlive(pads)
	runtime.KeepAlive(pad)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SetBufferFunction (gst_collect_pads_set_buffer_function): set the callback
// function and user data that will be called with the oldest buffer when all
// pads have been collected, or NULL on EOS. If a buffer is passed, the callback
// owns a reference and must unref it.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - fn: function to set.
func (pads *CollectPads) SetBufferFunction(fn CollectPadsBufferFunction) {
	var _arg0 *C.GstCollectPads              // out
	var _arg1 C.GstCollectPadsBufferFunction // out
	var _arg2 C.gpointer

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))
	_arg1 = (*[0]byte)(C._gotk4_gstbase1_CollectPadsBufferFunction)
	_arg2 = C.gpointer(gbox.Assign(fn))
	defer gbox.Delete(uintptr(_arg2))

	C.gst_collect_pads_set_buffer_function(_arg0, _arg1, _arg2)
	runtime.KeepAlive(pads)
	runtime.KeepAlive(fn)
}

// SetClipFunction (gst_collect_pads_set_clip_function): install a clipping
// function that is called right after a buffer is received on a pad managed by
// pads. See CollectPadsClipFunction for more info.
//
// The function takes the following parameters:
//
//   - clipfunc: clip function to install.
func (pads *CollectPads) SetClipFunction(clipfunc CollectPadsClipFunction) {
	var _arg0 *C.GstCollectPads            // out
	var _arg1 C.GstCollectPadsClipFunction // out
	var _arg2 C.gpointer

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))
	_arg1 = (*[0]byte)(C._gotk4_gstbase1_CollectPadsClipFunction)
	_arg2 = C.gpointer(gbox.Assign(clipfunc))
	defer gbox.Delete(uintptr(_arg2))

	C.gst_collect_pads_set_clip_function(_arg0, _arg1, _arg2)
	runtime.KeepAlive(pads)
	runtime.KeepAlive(clipfunc)
}

// SetCompareFunction (gst_collect_pads_set_compare_function): set the timestamp
// comparison function.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - fn: function to set.
func (pads *CollectPads) SetCompareFunction(fn CollectPadsCompareFunction) {
	var _arg0 *C.GstCollectPads               // out
	var _arg1 C.GstCollectPadsCompareFunction // out
	var _arg2 C.gpointer

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))
	_arg1 = (*[0]byte)(C._gotk4_gstbase1_CollectPadsCompareFunction)
	_arg2 = C.gpointer(gbox.Assign(fn))
	defer gbox.Delete(uintptr(_arg2))

	C.gst_collect_pads_set_compare_function(_arg0, _arg1, _arg2)
	runtime.KeepAlive(pads)
	runtime.KeepAlive(fn)
}

// SetEventFunction (gst_collect_pads_set_event_function): set the event
// callback function and user data that will be called when collectpads has
// received an event originating from one of the collected pads. If the event
// being processed is a serialized one, this callback is called with pads
// STREAM_LOCK held, otherwise not. As this lock should be held when calling
// a number of CollectPads functions, it should be acquired if so (unusually)
// needed.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - fn: function to set.
func (pads *CollectPads) SetEventFunction(fn CollectPadsEventFunction) {
	var _arg0 *C.GstCollectPads             // out
	var _arg1 C.GstCollectPadsEventFunction // out
	var _arg2 C.gpointer

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))
	_arg1 = (*[0]byte)(C._gotk4_gstbase1_CollectPadsEventFunction)
	_arg2 = C.gpointer(gbox.Assign(fn))
	defer gbox.Delete(uintptr(_arg2))

	C.gst_collect_pads_set_event_function(_arg0, _arg1, _arg2)
	runtime.KeepAlive(pads)
	runtime.KeepAlive(fn)
}

// SetFlushFunction (gst_collect_pads_set_flush_function): install a flush
// function that is called when the internal state of all pads should be flushed
// as part of flushing seek handling. See CollectPadsFlushFunction for more
// info.
//
// The function takes the following parameters:
//
//   - fn: flush function to install.
func (pads *CollectPads) SetFlushFunction(fn CollectPadsFlushFunction) {
	var _arg0 *C.GstCollectPads             // out
	var _arg1 C.GstCollectPadsFlushFunction // out
	var _arg2 C.gpointer

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))
	_arg1 = (*[0]byte)(C._gotk4_gstbase1_CollectPadsFlushFunction)
	_arg2 = C.gpointer(gbox.Assign(fn))
	defer gbox.Delete(uintptr(_arg2))

	C.gst_collect_pads_set_flush_function(_arg0, _arg1, _arg2)
	runtime.KeepAlive(pads)
	runtime.KeepAlive(fn)
}

// SetFlushing (gst_collect_pads_set_flushing): change the flushing state of
// all the pads in the collection. No pad is able to accept anymore data when
// flushing is TRUE. Calling this function with flushing FALSE makes pads accept
// data again. Caller must ensure that downstream streaming (thread) is not
// blocked, e.g. by sending a FLUSH_START downstream.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - flushing: desired state of the pads.
func (pads *CollectPads) SetFlushing(flushing bool) {
	var _arg0 *C.GstCollectPads // out
	var _arg1 C.gboolean        // out

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))
	if flushing {
		_arg1 = C.TRUE
	}

	C.gst_collect_pads_set_flushing(_arg0, _arg1)
	runtime.KeepAlive(pads)
	runtime.KeepAlive(flushing)
}

// SetFunction (gst_collect_pads_set_function) collectPads provides a default
// collection algorithm that will determine the oldest buffer available on
// all of its pads, and then delegate to a configured callback. However,
// if circumstances are more complicated and/or more control is desired, this
// sets a callback that will be invoked instead when all the pads added to the
// collection have buffers queued. Evidently, this callback is not compatible
// with gst_collect_pads_set_buffer_function() callback. If this callback is
// set, the former will be unset.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - fn: function to set.
func (pads *CollectPads) SetFunction(fn CollectPadsFunction) {
	var _arg0 *C.GstCollectPads        // out
	var _arg1 C.GstCollectPadsFunction // out
	var _arg2 C.gpointer

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))
	_arg1 = (*[0]byte)(C._gotk4_gstbase1_CollectPadsFunction)
	_arg2 = C.gpointer(gbox.Assign(fn))
	defer gbox.Delete(uintptr(_arg2))

	C.gst_collect_pads_set_function(_arg0, _arg1, _arg2)
	runtime.KeepAlive(pads)
	runtime.KeepAlive(fn)
}

// SetQueryFunction (gst_collect_pads_set_query_function): set the query
// callback function and user data that will be called after collectpads has
// received a query originating from one of the collected pads. If the query
// being processed is a serialized one, this callback is called with pads
// STREAM_LOCK held, otherwise not. As this lock should be held when calling
// a number of CollectPads functions, it should be acquired if so (unusually)
// needed.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - fn: function to set.
func (pads *CollectPads) SetQueryFunction(fn CollectPadsQueryFunction) {
	var _arg0 *C.GstCollectPads             // out
	var _arg1 C.GstCollectPadsQueryFunction // out
	var _arg2 C.gpointer

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))
	_arg1 = (*[0]byte)(C._gotk4_gstbase1_CollectPadsQueryFunction)
	_arg2 = C.gpointer(gbox.Assign(fn))
	defer gbox.Delete(uintptr(_arg2))

	C.gst_collect_pads_set_query_function(_arg0, _arg1, _arg2)
	runtime.KeepAlive(pads)
	runtime.KeepAlive(fn)
}

// SetWaiting (gst_collect_pads_set_waiting) sets a pad to waiting or
// non-waiting mode, if at least this pad has not been created with locked
// waiting state, in which case nothing happens.
//
// This function should be called with pads STREAM_LOCK held, such as in the
// callback.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - data to use.
//   - waiting: boolean indicating whether this pad should operate in waiting or
//     non-waiting mode.
func (pads *CollectPads) SetWaiting(data *CollectData, waiting bool) {
	var _arg0 *C.GstCollectPads // out
	var _arg1 *C.GstCollectData // out
	var _arg2 C.gboolean        // out

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))
	_arg1 = (*C.GstCollectData)(gextras.StructNative(unsafe.Pointer(data)))
	if waiting {
		_arg2 = C.TRUE
	}

	C.gst_collect_pads_set_waiting(_arg0, _arg1, _arg2)
	runtime.KeepAlive(pads)
	runtime.KeepAlive(data)
	runtime.KeepAlive(waiting)
}

// SrcEventDefault (gst_collect_pads_src_event_default): default CollectPads
// event handling for the src pad of elements. Elements can chain up to this to
// let flushing seek event handling be done by CollectPads.
//
// The function takes the following parameters:
//
//   - pad: src Pad that received the event.
//   - event being processed.
func (pads *CollectPads) SrcEventDefault(pad *gst.Pad, event *gst.Event) bool {
	var _arg0 *C.GstCollectPads // out
	var _arg1 *C.GstPad         // out
	var _arg2 *C.GstEvent       // out
	var _cret C.gboolean        // in

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))
	_arg1 = (*C.GstPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))
	_arg2 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C.gst_collect_pads_src_event_default(_arg0, _arg1, _arg2)
	runtime.KeepAlive(pads)
	runtime.KeepAlive(pad)
	runtime.KeepAlive(event)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Start (gst_collect_pads_start) starts the processing of data in the
// collect_pads.
//
// MT safe.
func (pads *CollectPads) Start() {
	var _arg0 *C.GstCollectPads // out

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))

	C.gst_collect_pads_start(_arg0)
	runtime.KeepAlive(pads)
}

// Stop (gst_collect_pads_stop) stops the processing of data in the
// collect_pads. this function will also unblock any blocking operations.
//
// MT safe.
func (pads *CollectPads) Stop() {
	var _arg0 *C.GstCollectPads // out

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))

	C.gst_collect_pads_stop(_arg0)
	runtime.KeepAlive(pads)
}

// TakeBuffer (gst_collect_pads_take_buffer): get a subbuffer of size bytes from
// the given pad data. Flushes the amount of read bytes.
//
// This function should be called with pads STREAM_LOCK held, such as in the
// callback.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - data to use.
//   - size: number of bytes to read.
//
// The function returns the following values:
//
//   - buffer (optional): sub buffer. The size of the buffer can be less that
//     requested. A return of NULL signals that the pad is end-of-stream.
//     Unref the buffer after use.
func (pads *CollectPads) TakeBuffer(data *CollectData, size uint) *gst.Buffer {
	var _arg0 *C.GstCollectPads // out
	var _arg1 *C.GstCollectData // out
	var _arg2 C.guint           // out
	var _cret *C.GstBuffer      // in

	_arg0 = (*C.GstCollectPads)(unsafe.Pointer(coreglib.BaseObject(pads).Native()))
	_arg1 = (*C.GstCollectData)(gextras.StructNative(unsafe.Pointer(data)))
	_arg2 = C.guint(size)

	_cret = C.gst_collect_pads_take_buffer(_arg0, _arg1, _arg2)
	runtime.KeepAlive(pads)
	runtime.KeepAlive(data)
	runtime.KeepAlive(size)

	var _buffer *gst.Buffer // out

	if _cret != nil {
		_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_buffer)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _buffer
}

// DataQueueOverrides contains methods that are overridable.
type DataQueueOverrides struct {
	Empty func()
	Full  func()
}

func defaultDataQueueOverrides(v *DataQueue) DataQueueOverrides {
	return DataQueueOverrides{
		Empty: v.empty,
		Full:  v.full,
	}
}

// DataQueue (GstDataQueue) is an object that handles threadsafe queueing of
// objects. It also provides size-related functionality. This object should
// be used for any Element that wishes to provide some sort of queueing
// functionality.
type DataQueue struct {
	_ [0]func() // equal guard
	*coreglib.Object
}

var (
	_ coreglib.Objector = (*DataQueue)(nil)
)

// DataQueueer describes types inherited from DataQueue.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type DataQueueer interface {
	coreglib.Objector

	baseDataQueue() *DataQueue
}

var _ DataQueueer = (*DataQueue)(nil)

func init() {
	coreglib.RegisterClassInfo[*DataQueue, *DataQueueClass, DataQueueOverrides](
		GTypeDataQueue,
		initDataQueueClass,
		wrapDataQueue,
		defaultDataQueueOverrides,
	)
}

func initDataQueueClass(gclass unsafe.Pointer, overrides DataQueueOverrides, classInitFunc func(*DataQueueClass)) {
	pclass := (*C.GstDataQueueClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeDataQueue))))

	if overrides.Empty != nil {
		pclass.empty = (*[0]byte)(C._gotk4_gstbase1_DataQueueClass_empty)
	}

	if overrides.Full != nil {
		pclass.full = (*[0]byte)(C._gotk4_gstbase1_DataQueueClass_full)
	}

	if classInitFunc != nil {
		class := (*DataQueueClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapDataQueue(obj *coreglib.Object) *DataQueue {
	return &DataQueue{
		Object: obj,
	}
}

func marshalDataQueue(p uintptr) (interface{}, error) {
	return wrapDataQueue(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (v *DataQueue) baseDataQueue() *DataQueue {
	return v
}

// BaseDataQueue returns the underlying base object.
func BaseDataQueue(obj DataQueueer) *DataQueue {
	return obj.baseDataQueue()
}

// ConnectEmpty reports that the queue became empty (empty). A queue is
// empty if the total amount of visible items inside it (num-visible, time,
// size) is lower than the boundary values which can be set through the GObject
// properties.
func (v *DataQueue) ConnectEmpty(f func()) coreglib.SignalHandle {
	return coreglib.ConnectGeneratedClosure(v, "empty", false, unsafe.Pointer(C._gotk4_gstbase1_DataQueue_ConnectEmpty), f)
}

// ConnectFull reports that the queue became full (full). A queue is full if the
// total amount of data inside it (num-visible, time, size) is higher than the
// boundary values which can be set through the GObject properties.
func (v *DataQueue) ConnectFull(f func()) coreglib.SignalHandle {
	return coreglib.ConnectGeneratedClosure(v, "full", false, unsafe.Pointer(C._gotk4_gstbase1_DataQueue_ConnectFull), f)
}

func (queue *DataQueue) empty() {
	gclass := (*C.GstDataQueueClass)(coreglib.PeekParentClass(queue))
	fnarg := gclass.empty

	var _arg0 *C.GstDataQueue // out

	_arg0 = (*C.GstDataQueue)(unsafe.Pointer(coreglib.BaseObject(queue).Native()))

	C._gotk4_gstbase1_DataQueue_virtual_empty(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(queue)
}

func (queue *DataQueue) full() {
	gclass := (*C.GstDataQueueClass)(coreglib.PeekParentClass(queue))
	fnarg := gclass.full

	var _arg0 *C.GstDataQueue // out

	_arg0 = (*C.GstDataQueue)(unsafe.Pointer(coreglib.BaseObject(queue).Native()))

	C._gotk4_gstbase1_DataQueue_virtual_full(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(queue)
}

// PushSrcOverrides contains methods that are overridable.
type PushSrcOverrides struct {
	// Alloc: allocate memory for a buffer.
	//
	// The function returns the following values:
	//
	//   - buf (optional)
	//   - flowReturn
	Alloc func() (*gst.Buffer, gst.FlowReturn)
	// Fill: ask the subclass to fill the buffer with data.
	Fill func(buf *gst.Buffer) gst.FlowReturn
}

func defaultPushSrcOverrides(v *PushSrc) PushSrcOverrides {
	return PushSrcOverrides{
		Alloc: v.alloc,
		Fill:  v.fill,
	}
}

// PushSrc (GstPushSrc): this class is mostly useful for elements that cannot
// do random access, or at least very slowly. The source usually prefers to push
// out a fixed size buffer.
//
// Subclasses usually operate in a format that is different from the default
// GST_FORMAT_BYTES format of BaseSrc.
//
// Classes extending this base class will usually be scheduled in a push based
// mode. If the peer accepts to operate without offsets and within the limits
// of the allowed block size, this class can operate in getrange based mode
// automatically. To make this possible, the subclass should implement and
// override the SCHEDULING query.
//
// The subclass should extend the methods from the baseclass in addition to the
// ::create method.
//
// Seeking, flushing, scheduling and sync is all handled by this base class.
type PushSrc struct {
	_ [0]func() // equal guard
	BaseSrc
}

var (
	_ BaseSrcer = (*PushSrc)(nil)
)

// PushSrcer describes types inherited from PushSrc.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type PushSrcer interface {
	BaseSrcer

	basePushSrc() *PushSrc
}

var _ PushSrcer = (*PushSrc)(nil)

func init() {
	coreglib.RegisterClassInfo[*PushSrc, *PushSrcClass, PushSrcOverrides](
		GTypePushSrc,
		initPushSrcClass,
		wrapPushSrc,
		defaultPushSrcOverrides,
	)
}

func initPushSrcClass(gclass unsafe.Pointer, overrides PushSrcOverrides, classInitFunc func(*PushSrcClass)) {
	pclass := (*C.GstPushSrcClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypePushSrc))))

	if overrides.Alloc != nil {
		pclass.alloc = (*[0]byte)(C._gotk4_gstbase1_PushSrcClass_alloc)
	}

	if overrides.Fill != nil {
		pclass.fill = (*[0]byte)(C._gotk4_gstbase1_PushSrcClass_fill)
	}

	if classInitFunc != nil {
		class := (*PushSrcClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapPushSrc(obj *coreglib.Object) *PushSrc {
	return &PushSrc{
		BaseSrc: BaseSrc{
			Element: gst.Element{
				GstObject: gst.GstObject{
					InitiallyUnowned: coreglib.InitiallyUnowned{
						Object: obj,
					},
				},
			},
		},
	}
}

func marshalPushSrc(p uintptr) (interface{}, error) {
	return wrapPushSrc(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (v *PushSrc) basePushSrc() *PushSrc {
	return v
}

// BasePushSrc returns the underlying base object.
func BasePushSrc(obj PushSrcer) *PushSrc {
	return obj.basePushSrc()
}

// Alloc: allocate memory for a buffer.
//
// The function returns the following values:
//
//   - buf (optional)
//   - flowReturn
func (src *PushSrc) alloc() (*gst.Buffer, gst.FlowReturn) {
	gclass := (*C.GstPushSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.alloc

	var _arg0 *C.GstPushSrc   // out
	var _arg1 *C.GstBuffer    // in
	var _cret C.GstFlowReturn // in

	_arg0 = (*C.GstPushSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C._gotk4_gstbase1_PushSrc_virtual_alloc(unsafe.Pointer(fnarg), _arg0, &_arg1)
	runtime.KeepAlive(src)

	var _buf *gst.Buffer           // out
	var _flowReturn gst.FlowReturn // out

	if _arg1 != nil {
		_buf = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_arg1)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_buf)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}
	_flowReturn = gst.FlowReturn(_cret)

	return _buf, _flowReturn
}

// Fill: ask the subclass to fill the buffer with data.
func (src *PushSrc) fill(buf *gst.Buffer) gst.FlowReturn {
	gclass := (*C.GstPushSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.fill

	var _arg0 *C.GstPushSrc   // out
	var _arg1 *C.GstBuffer    // out
	var _cret C.GstFlowReturn // in

	_arg0 = (*C.GstPushSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buf)))

	_cret = C._gotk4_gstbase1_PushSrc_virtual_fill(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(buf)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// AggregatorClass (GstAggregatorClass): aggregator base class will handle in a
// thread-safe way all manners of concurrent flushes, seeks, pad additions and
// removals, leaving to the subclass the responsibility of clipping buffers,
// and aggregating buffers in the way the implementor sees fit.
//
// It will also take care of event ordering (stream-start, segment, eos).
//
// Basically, a simple implementation will override aggregate, and call
// _finish_buffer from inside that function.
//
// An instance of this type is always passed by reference.
type AggregatorClass struct {
	*aggregatorClass
}

// aggregatorClass is the struct that's finalized.
type aggregatorClass struct {
	native *C.GstAggregatorClass
}

func (a *AggregatorClass) ParentClass() *gst.ElementClass {
	valptr := &a.native.parent_class
	var _v *gst.ElementClass // out
	_v = (*gst.ElementClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// AggregatorPadClass (GstAggregatorPadClass): instance of this type is always
// passed by reference.
type AggregatorPadClass struct {
	*aggregatorPadClass
}

// aggregatorPadClass is the struct that's finalized.
type aggregatorPadClass struct {
	native *C.GstAggregatorPadClass
}

func (a *AggregatorPadClass) ParentClass() *gst.PadClass {
	valptr := &a.native.parent_class
	var _v *gst.PadClass // out
	_v = (*gst.PadClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// BaseParseClass (GstBaseParseClass) subclasses can override any of the
// available virtual methods or not, as needed. At minimum handle_frame needs to
// be overridden.
//
// An instance of this type is always passed by reference.
type BaseParseClass struct {
	*baseParseClass
}

// baseParseClass is the struct that's finalized.
type baseParseClass struct {
	native *C.GstBaseParseClass
}

// ParentClass: parent class.
func (b *BaseParseClass) ParentClass() *gst.ElementClass {
	valptr := &b.native.parent_class
	var _v *gst.ElementClass // out
	_v = (*gst.ElementClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// BaseParseFrame (GstBaseParseFrame): frame (context) data passed to each
// frame parsing virtual methods. In addition to providing the data to be
// checked for a valid frame or an already identified frame, it conveys
// additional metadata or control information from and to the subclass w.r.t.
// the particular frame in question (rather than global parameters). Some of
// these may apply to each parsing stage, others only to some a particular one.
// These parameters are effectively zeroed at start of each frame's processing,
// i.e. parsing virtual method invocation sequence.
//
// An instance of this type is always passed by reference.
type BaseParseFrame struct {
	*baseParseFrame
}

// baseParseFrame is the struct that's finalized.
type baseParseFrame struct {
	native *C.GstBaseParseFrame
}

func marshalBaseParseFrame(p uintptr) (interface{}, error) {
	b := coreglib.ValueFromNative(unsafe.Pointer(p)).Boxed()
	return &BaseParseFrame{&baseParseFrame{(*C.GstBaseParseFrame)(b)}}, nil
}

// NewBaseParseFrame constructs a struct BaseParseFrame.
func NewBaseParseFrame(buffer *gst.Buffer, flags BaseParseFrameFlags, overhead int) *BaseParseFrame {
	var _arg1 *C.GstBuffer             // out
	var _arg2 C.GstBaseParseFrameFlags // out
	var _arg3 C.gint                   // out
	var _cret *C.GstBaseParseFrame     // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg2 = C.GstBaseParseFrameFlags(flags)
	_arg3 = C.gint(overhead)

	_cret = C.gst_base_parse_frame_new(_arg1, _arg2, _arg3)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(flags)
	runtime.KeepAlive(overhead)

	var _baseParseFrame *BaseParseFrame // out

	_baseParseFrame = (*BaseParseFrame)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_baseParseFrame)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_base_parse_frame_free((*C.GstBaseParseFrame)(intern.C))
		},
	)

	return _baseParseFrame
}

// Buffer: input data to be parsed for frames.
func (b *BaseParseFrame) Buffer() *gst.Buffer {
	valptr := &b.native.buffer
	var _v *gst.Buffer // out
	_v = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_v)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})
	return _v
}

// OutBuffer: output data.
func (b *BaseParseFrame) OutBuffer() *gst.Buffer {
	valptr := &b.native.out_buffer
	var _v *gst.Buffer // out
	_v = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_v)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})
	return _v
}

// Flags: combination of input and output BaseParseFrameFlags that convey
// additional context to subclass or allow subclass to tune subsequent BaseParse
// actions.
func (b *BaseParseFrame) Flags() uint {
	valptr := &b.native.flags
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Offset: media specific offset of input frame Note that a converter may have a
// different one on the frame's buffer.
func (b *BaseParseFrame) Offset() uint64 {
	valptr := &b.native.offset
	var _v uint64 // out
	_v = uint64(*valptr)
	return _v
}

// Overhead subclass can set this to indicates the metadata overhead for the
// given frame, which is then used to enable more accurate bitrate computations.
// If this is -1, it is assumed that this frame should be skipped in bitrate
// calculation.
func (b *BaseParseFrame) Overhead() int {
	valptr := &b.native.overhead
	var _v int // out
	_v = int(*valptr)
	return _v
}

// Flags: combination of input and output BaseParseFrameFlags that convey
// additional context to subclass or allow subclass to tune subsequent BaseParse
// actions.
func (b *BaseParseFrame) SetFlags(flags uint) {
	valptr := &b.native.flags
	*valptr = C.guint(flags)
}

// Offset: media specific offset of input frame Note that a converter may have a
// different one on the frame's buffer.
func (b *BaseParseFrame) SetOffset(offset uint64) {
	valptr := &b.native.offset
	*valptr = C.guint64(offset)
}

// Overhead subclass can set this to indicates the metadata overhead for the
// given frame, which is then used to enable more accurate bitrate computations.
// If this is -1, it is assumed that this frame should be skipped in bitrate
// calculation.
func (b *BaseParseFrame) SetOverhead(overhead int) {
	valptr := &b.native.overhead
	*valptr = C.gint(overhead)
}

// Copy (gst_base_parse_frame_copy) copies a BaseParseFrame.
//
// The function returns the following values:
//
//   - baseParseFrame: copy of frame.
func (frame *BaseParseFrame) Copy() *BaseParseFrame {
	var _arg0 *C.GstBaseParseFrame // out
	var _cret *C.GstBaseParseFrame // in

	_arg0 = (*C.GstBaseParseFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	_cret = C.gst_base_parse_frame_copy(_arg0)
	runtime.KeepAlive(frame)

	var _baseParseFrame *BaseParseFrame // out

	_baseParseFrame = (*BaseParseFrame)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_baseParseFrame)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_base_parse_frame_free((*C.GstBaseParseFrame)(intern.C))
		},
	)

	return _baseParseFrame
}

// Init (gst_base_parse_frame_init) sets a BaseParseFrame to initial state.
// Currently this means all public fields are zero-ed and a private flag is set
// to make sure gst_base_parse_frame_free() only frees the contents but not the
// actual frame. Use this function to initialise a BaseParseFrame allocated on
// the stack.
func (frame *BaseParseFrame) Init() {
	var _arg0 *C.GstBaseParseFrame // out

	_arg0 = (*C.GstBaseParseFrame)(gextras.StructNative(unsafe.Pointer(frame)))

	C.gst_base_parse_frame_init(_arg0)
	runtime.KeepAlive(frame)
}

// BaseSinkClass (GstBaseSinkClass) subclasses can override any of the available
// virtual methods or not, as needed. At the minimum, the render method should
// be overridden to output/present buffers.
//
// An instance of this type is always passed by reference.
type BaseSinkClass struct {
	*baseSinkClass
}

// baseSinkClass is the struct that's finalized.
type baseSinkClass struct {
	native *C.GstBaseSinkClass
}

// ParentClass: element parent class.
func (b *BaseSinkClass) ParentClass() *gst.ElementClass {
	valptr := &b.native.parent_class
	var _v *gst.ElementClass // out
	_v = (*gst.ElementClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// BaseSrcClass (GstBaseSrcClass) subclasses can override any of the available
// virtual methods or not, as needed. At the minimum, the create method should
// be overridden to produce buffers.
//
// An instance of this type is always passed by reference.
type BaseSrcClass struct {
	*baseSrcClass
}

// baseSrcClass is the struct that's finalized.
type baseSrcClass struct {
	native *C.GstBaseSrcClass
}

// ParentClass: element parent class.
func (b *BaseSrcClass) ParentClass() *gst.ElementClass {
	valptr := &b.native.parent_class
	var _v *gst.ElementClass // out
	_v = (*gst.ElementClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// BaseTransformClass (GstBaseTransformClass) subclasses can override any of the
// available virtual methods or not, as needed. At minimum either transform or
// transform_ip need to be overridden. If the element can overwrite the input
// data with the results (data is of the same type and quantity) it should
// provide transform_ip.
//
// An instance of this type is always passed by reference.
type BaseTransformClass struct {
	*baseTransformClass
}

// baseTransformClass is the struct that's finalized.
type baseTransformClass struct {
	native *C.GstBaseTransformClass
}

// ParentClass: element parent class.
func (b *BaseTransformClass) ParentClass() *gst.ElementClass {
	valptr := &b.native.parent_class
	var _v *gst.ElementClass // out
	_v = (*gst.ElementClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// PassthroughOnSameCaps: if set to TRUE, passthrough mode will be automatically
// enabled if the caps are the same. Set to FALSE by default.
func (b *BaseTransformClass) PassthroughOnSameCaps() bool {
	valptr := &b.native.passthrough_on_same_caps
	var _v bool // out
	if *valptr != 0 {
		_v = true
	}
	return _v
}

// TransformIPOnPassthrough: if set to TRUE, transform_ip will be called in
// passthrough mode. The passed buffer might not be writable. When FALSE,
// neither transform nor transform_ip will be called in passthrough mode.
// Set to TRUE by default.
func (b *BaseTransformClass) TransformIPOnPassthrough() bool {
	valptr := &b.native.transform_ip_on_passthrough
	var _v bool // out
	if *valptr != 0 {
		_v = true
	}
	return _v
}

// BitReader (GstBitReader) provides a bit reader that can read any number of
// bits from a memory buffer. It provides functions for reading any number of
// bits into 8, 16, 32 and 64 bit variables.
//
// An instance of this type is always passed by reference.
type BitReader struct {
	*bitReader
}

// bitReader is the struct that's finalized.
type bitReader struct {
	native *C.GstBitReader
}

// BitsUint16 (gst_bit_reader_get_bits_uint16): read nbits bits into val and
// update the current position.
//
// The function takes the following parameters:
//
//   - nbits: number of bits to read.
//
// The function returns the following values:
//
//   - val: pointer to a #guint16 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *BitReader) BitsUint16(nbits uint) (uint16, bool) {
	var _arg0 *C.GstBitReader // out
	var _arg1 C.guint16       // in
	var _arg2 C.guint         // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBitReader)(gextras.StructNative(unsafe.Pointer(reader)))
	_arg2 = C.guint(nbits)

	_cret = C.gst_bit_reader_get_bits_uint16(_arg0, &_arg1, _arg2)
	runtime.KeepAlive(reader)
	runtime.KeepAlive(nbits)

	var _val uint16 // out
	var _ok bool    // out

	_val = uint16(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// BitsUint32 (gst_bit_reader_get_bits_uint32): read nbits bits into val and
// update the current position.
//
// The function takes the following parameters:
//
//   - nbits: number of bits to read.
//
// The function returns the following values:
//
//   - val: pointer to a #guint32 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *BitReader) BitsUint32(nbits uint) (uint32, bool) {
	var _arg0 *C.GstBitReader // out
	var _arg1 C.guint32       // in
	var _arg2 C.guint         // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBitReader)(gextras.StructNative(unsafe.Pointer(reader)))
	_arg2 = C.guint(nbits)

	_cret = C.gst_bit_reader_get_bits_uint32(_arg0, &_arg1, _arg2)
	runtime.KeepAlive(reader)
	runtime.KeepAlive(nbits)

	var _val uint32 // out
	var _ok bool    // out

	_val = uint32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// BitsUint64 (gst_bit_reader_get_bits_uint64): read nbits bits into val and
// update the current position.
//
// The function takes the following parameters:
//
//   - nbits: number of bits to read.
//
// The function returns the following values:
//
//   - val: pointer to a #guint64 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *BitReader) BitsUint64(nbits uint) (uint64, bool) {
	var _arg0 *C.GstBitReader // out
	var _arg1 C.guint64       // in
	var _arg2 C.guint         // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBitReader)(gextras.StructNative(unsafe.Pointer(reader)))
	_arg2 = C.guint(nbits)

	_cret = C.gst_bit_reader_get_bits_uint64(_arg0, &_arg1, _arg2)
	runtime.KeepAlive(reader)
	runtime.KeepAlive(nbits)

	var _val uint64 // out
	var _ok bool    // out

	_val = uint64(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// BitsUint8 (gst_bit_reader_get_bits_uint8): read nbits bits into val and
// update the current position.
//
// The function takes the following parameters:
//
//   - nbits: number of bits to read.
//
// The function returns the following values:
//
//   - val: pointer to a #guint8 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *BitReader) BitsUint8(nbits uint) (byte, bool) {
	var _arg0 *C.GstBitReader // out
	var _arg1 C.guint8        // in
	var _arg2 C.guint         // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBitReader)(gextras.StructNative(unsafe.Pointer(reader)))
	_arg2 = C.guint(nbits)

	_cret = C.gst_bit_reader_get_bits_uint8(_arg0, &_arg1, _arg2)
	runtime.KeepAlive(reader)
	runtime.KeepAlive(nbits)

	var _val byte // out
	var _ok bool  // out

	_val = byte(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Pos (gst_bit_reader_get_pos) returns the current position of a BitReader
// instance in bits.
//
// The function returns the following values:
//
//   - guint: current position of reader in bits.
func (reader *BitReader) Pos() uint {
	var _arg0 *C.GstBitReader // out
	var _cret C.guint         // in

	_arg0 = (*C.GstBitReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_bit_reader_get_pos(_arg0)
	runtime.KeepAlive(reader)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// Remaining (gst_bit_reader_get_remaining) returns the remaining number of bits
// of a BitReader instance.
//
// The function returns the following values:
//
//   - guint: remaining number of bits of reader instance.
func (reader *BitReader) Remaining() uint {
	var _arg0 *C.GstBitReader // out
	var _cret C.guint         // in

	_arg0 = (*C.GstBitReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_bit_reader_get_remaining(_arg0)
	runtime.KeepAlive(reader)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// Size (gst_bit_reader_get_size) returns the total number of bits of a
// BitReader instance.
//
// The function returns the following values:
//
//   - guint: total number of bits of reader instance.
func (reader *BitReader) Size() uint {
	var _arg0 *C.GstBitReader // out
	var _cret C.guint         // in

	_arg0 = (*C.GstBitReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_bit_reader_get_size(_arg0)
	runtime.KeepAlive(reader)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// Init (gst_bit_reader_init) initializes a BitReader instance to read from
// data. This function can be called on already initialized instances.
//
// The function takes the following parameters:
//
//   - data from which the bit reader should read.
func (reader *BitReader) Init(data []byte) {
	var _arg0 *C.GstBitReader // out
	var _arg1 *C.guint8       // out
	var _arg2 C.guint

	_arg0 = (*C.GstBitReader)(gextras.StructNative(unsafe.Pointer(reader)))
	_arg2 = (C.guint)(len(data))
	if len(data) > 0 {
		_arg1 = (*C.guint8)(unsafe.Pointer(&data[0]))
	}

	C.gst_bit_reader_init(_arg0, _arg1, _arg2)
	runtime.KeepAlive(reader)
	runtime.KeepAlive(data)
}

// PeekBitsUint16 (gst_bit_reader_peek_bits_uint16): read nbits bits into val
// but keep the current position.
//
// The function takes the following parameters:
//
//   - nbits: number of bits to read.
//
// The function returns the following values:
//
//   - val: pointer to a #guint16 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *BitReader) PeekBitsUint16(nbits uint) (uint16, bool) {
	var _arg0 *C.GstBitReader // out
	var _arg1 C.guint16       // in
	var _arg2 C.guint         // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBitReader)(gextras.StructNative(unsafe.Pointer(reader)))
	_arg2 = C.guint(nbits)

	_cret = C.gst_bit_reader_peek_bits_uint16(_arg0, &_arg1, _arg2)
	runtime.KeepAlive(reader)
	runtime.KeepAlive(nbits)

	var _val uint16 // out
	var _ok bool    // out

	_val = uint16(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekBitsUint32 (gst_bit_reader_peek_bits_uint32): read nbits bits into val
// but keep the current position.
//
// The function takes the following parameters:
//
//   - nbits: number of bits to read.
//
// The function returns the following values:
//
//   - val: pointer to a #guint32 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *BitReader) PeekBitsUint32(nbits uint) (uint32, bool) {
	var _arg0 *C.GstBitReader // out
	var _arg1 C.guint32       // in
	var _arg2 C.guint         // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBitReader)(gextras.StructNative(unsafe.Pointer(reader)))
	_arg2 = C.guint(nbits)

	_cret = C.gst_bit_reader_peek_bits_uint32(_arg0, &_arg1, _arg2)
	runtime.KeepAlive(reader)
	runtime.KeepAlive(nbits)

	var _val uint32 // out
	var _ok bool    // out

	_val = uint32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekBitsUint64 (gst_bit_reader_peek_bits_uint64): read nbits bits into val
// but keep the current position.
//
// The function takes the following parameters:
//
//   - nbits: number of bits to read.
//
// The function returns the following values:
//
//   - val: pointer to a #guint64 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *BitReader) PeekBitsUint64(nbits uint) (uint64, bool) {
	var _arg0 *C.GstBitReader // out
	var _arg1 C.guint64       // in
	var _arg2 C.guint         // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBitReader)(gextras.StructNative(unsafe.Pointer(reader)))
	_arg2 = C.guint(nbits)

	_cret = C.gst_bit_reader_peek_bits_uint64(_arg0, &_arg1, _arg2)
	runtime.KeepAlive(reader)
	runtime.KeepAlive(nbits)

	var _val uint64 // out
	var _ok bool    // out

	_val = uint64(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekBitsUint8 (gst_bit_reader_peek_bits_uint8): read nbits bits into val but
// keep the current position.
//
// The function takes the following parameters:
//
//   - nbits: number of bits to read.
//
// The function returns the following values:
//
//   - val: pointer to a #guint8 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *BitReader) PeekBitsUint8(nbits uint) (byte, bool) {
	var _arg0 *C.GstBitReader // out
	var _arg1 C.guint8        // in
	var _arg2 C.guint         // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBitReader)(gextras.StructNative(unsafe.Pointer(reader)))
	_arg2 = C.guint(nbits)

	_cret = C.gst_bit_reader_peek_bits_uint8(_arg0, &_arg1, _arg2)
	runtime.KeepAlive(reader)
	runtime.KeepAlive(nbits)

	var _val byte // out
	var _ok bool  // out

	_val = byte(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// SetPos (gst_bit_reader_set_pos) sets the new position of a BitReader instance
// to pos in bits.
//
// The function takes the following parameters:
//
//   - pos: new position in bits.
//
// The function returns the following values:
//
//   - ok: TRUE if the position could be set successfully, FALSE otherwise.
func (reader *BitReader) SetPos(pos uint) bool {
	var _arg0 *C.GstBitReader // out
	var _arg1 C.guint         // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBitReader)(gextras.StructNative(unsafe.Pointer(reader)))
	_arg1 = C.guint(pos)

	_cret = C.gst_bit_reader_set_pos(_arg0, _arg1)
	runtime.KeepAlive(reader)
	runtime.KeepAlive(pos)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Skip (gst_bit_reader_skip) skips nbits bits of the BitReader instance.
//
// The function takes the following parameters:
//
//   - nbits: number of bits to skip.
//
// The function returns the following values:
//
//   - ok: TRUE if nbits bits could be skipped, FALSE otherwise.
func (reader *BitReader) Skip(nbits uint) bool {
	var _arg0 *C.GstBitReader // out
	var _arg1 C.guint         // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBitReader)(gextras.StructNative(unsafe.Pointer(reader)))
	_arg1 = C.guint(nbits)

	_cret = C.gst_bit_reader_skip(_arg0, _arg1)
	runtime.KeepAlive(reader)
	runtime.KeepAlive(nbits)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SkipToByte (gst_bit_reader_skip_to_byte) skips until the next byte.
//
// The function returns the following values:
//
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *BitReader) SkipToByte() bool {
	var _arg0 *C.GstBitReader // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBitReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_bit_reader_skip_to_byte(_arg0)
	runtime.KeepAlive(reader)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// BitWriter (GstBitWriter) provides a bit writer that can write any number of
// bits into a memory buffer. It provides functions for writing any number of
// bits into 8, 16, 32 and 64 bit variables.
//
// An instance of this type is always passed by reference.
type BitWriter struct {
	*bitWriter
}

// bitWriter is the struct that's finalized.
type bitWriter struct {
	native *C.GstBitWriter
}

// Data: allocated data for bit writer to write.
func (b *BitWriter) Data() *byte {
	valptr := &b.native.data
	var _v *byte // out
	_v = (*byte)(unsafe.Pointer(*valptr))
	return _v
}

// BitSize: size of written data in bits.
func (b *BitWriter) BitSize() uint {
	valptr := &b.native.bit_size
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// BitSize: size of written data in bits.
func (b *BitWriter) SetBitSize(bitSize uint) {
	valptr := &b.native.bit_size
	*valptr = C.guint(bitSize)
}

// AlignBytes (gst_bit_writer_align_bytes): write trailing bit to align last
// byte of data. trailing_bit can only be 1 or 0.
//
// The function takes the following parameters:
//
//   - trailingBit: trailing bits of last byte, 0 or 1.
//
// The function returns the following values:
//
//   - ok: TRUE if successful, FALSE otherwise.
func (bitwriter *BitWriter) AlignBytes(trailingBit byte) bool {
	var _arg0 *C.GstBitWriter // out
	var _arg1 C.guint8        // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBitWriter)(gextras.StructNative(unsafe.Pointer(bitwriter)))
	_arg1 = C.guint8(trailingBit)

	_cret = C.gst_bit_writer_align_bytes(_arg0, _arg1)
	runtime.KeepAlive(bitwriter)
	runtime.KeepAlive(trailingBit)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// FreeAndGetBuffer (gst_bit_writer_free_and_get_buffer) frees bitwriter without
// destroying the internal data, which is returned as Buffer.
//
// Free-function: gst_buffer_unref.
//
// The function returns the following values:
//
//   - buffer: new allocated Buffer wrapping the data inside. gst_buffer_unref()
//     after usage.
func (bitwriter *BitWriter) FreeAndGetBuffer() *gst.Buffer {
	var _arg0 *C.GstBitWriter // out
	var _cret *C.GstBuffer    // in

	_arg0 = (*C.GstBitWriter)(gextras.StructNative(unsafe.Pointer(bitwriter)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(bitwriter)), nil)

	_cret = C.gst_bit_writer_free_and_get_buffer(_arg0)
	runtime.KeepAlive(bitwriter)

	var _buffer *gst.Buffer // out

	_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_buffer)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _buffer
}

func (bitwriter *BitWriter) Remaining() uint {
	var _arg0 *C.GstBitWriter // out
	var _cret C.guint         // in

	_arg0 = (*C.GstBitWriter)(gextras.StructNative(unsafe.Pointer(bitwriter)))

	_cret = C.gst_bit_writer_get_remaining(_arg0)
	runtime.KeepAlive(bitwriter)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// Size (gst_bit_writer_get_size): get size of written data.
//
// The function returns the following values:
//
//   - guint: size of bits written in data.
func (bitwriter *BitWriter) Size() uint {
	var _arg0 *C.GstBitWriter // out
	var _cret C.guint         // in

	_arg0 = (*C.GstBitWriter)(gextras.StructNative(unsafe.Pointer(bitwriter)))

	_cret = C.gst_bit_writer_get_size(_arg0)
	runtime.KeepAlive(bitwriter)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// PutBitsUint16 (gst_bit_writer_put_bits_uint16): write nbits bits of value to
// BitWriter.
//
// The function takes the following parameters:
//
//   - value of #guint16 to write.
//   - nbits: number of bits to write.
//
// The function returns the following values:
//
//   - ok: TRUE if successful, FALSE otherwise.
func (bitwriter *BitWriter) PutBitsUint16(value uint16, nbits uint) bool {
	var _arg0 *C.GstBitWriter // out
	var _arg1 C.guint16       // out
	var _arg2 C.guint         // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBitWriter)(gextras.StructNative(unsafe.Pointer(bitwriter)))
	_arg1 = C.guint16(value)
	_arg2 = C.guint(nbits)

	_cret = C.gst_bit_writer_put_bits_uint16(_arg0, _arg1, _arg2)
	runtime.KeepAlive(bitwriter)
	runtime.KeepAlive(value)
	runtime.KeepAlive(nbits)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutBitsUint32 (gst_bit_writer_put_bits_uint32): write nbits bits of value to
// BitWriter.
//
// The function takes the following parameters:
//
//   - value of #guint32 to write.
//   - nbits: number of bits to write.
//
// The function returns the following values:
//
//   - ok: TRUE if successful, FALSE otherwise.
func (bitwriter *BitWriter) PutBitsUint32(value uint32, nbits uint) bool {
	var _arg0 *C.GstBitWriter // out
	var _arg1 C.guint32       // out
	var _arg2 C.guint         // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBitWriter)(gextras.StructNative(unsafe.Pointer(bitwriter)))
	_arg1 = C.guint32(value)
	_arg2 = C.guint(nbits)

	_cret = C.gst_bit_writer_put_bits_uint32(_arg0, _arg1, _arg2)
	runtime.KeepAlive(bitwriter)
	runtime.KeepAlive(value)
	runtime.KeepAlive(nbits)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutBitsUint64 (gst_bit_writer_put_bits_uint64): write nbits bits of value to
// BitWriter.
//
// The function takes the following parameters:
//
//   - value of #guint64 to write.
//   - nbits: number of bits to write.
//
// The function returns the following values:
//
//   - ok: TRUE if successful, FALSE otherwise.
func (bitwriter *BitWriter) PutBitsUint64(value uint64, nbits uint) bool {
	var _arg0 *C.GstBitWriter // out
	var _arg1 C.guint64       // out
	var _arg2 C.guint         // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBitWriter)(gextras.StructNative(unsafe.Pointer(bitwriter)))
	_arg1 = C.guint64(value)
	_arg2 = C.guint(nbits)

	_cret = C.gst_bit_writer_put_bits_uint64(_arg0, _arg1, _arg2)
	runtime.KeepAlive(bitwriter)
	runtime.KeepAlive(value)
	runtime.KeepAlive(nbits)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutBitsUint8 (gst_bit_writer_put_bits_uint8): write nbits bits of value to
// BitWriter.
//
// The function takes the following parameters:
//
//   - value of #guint8 to write.
//   - nbits: number of bits to write.
//
// The function returns the following values:
//
//   - ok: TRUE if successful, FALSE otherwise.
func (bitwriter *BitWriter) PutBitsUint8(value byte, nbits uint) bool {
	var _arg0 *C.GstBitWriter // out
	var _arg1 C.guint8        // out
	var _arg2 C.guint         // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBitWriter)(gextras.StructNative(unsafe.Pointer(bitwriter)))
	_arg1 = C.guint8(value)
	_arg2 = C.guint(nbits)

	_cret = C.gst_bit_writer_put_bits_uint8(_arg0, _arg1, _arg2)
	runtime.KeepAlive(bitwriter)
	runtime.KeepAlive(value)
	runtime.KeepAlive(nbits)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Reset (gst_bit_writer_reset) resets bitwriter and frees the data if it's
// owned by bitwriter.
func (bitwriter *BitWriter) Reset() {
	var _arg0 *C.GstBitWriter // out

	_arg0 = (*C.GstBitWriter)(gextras.StructNative(unsafe.Pointer(bitwriter)))

	C.gst_bit_writer_reset(_arg0)
	runtime.KeepAlive(bitwriter)
}

// ResetAndGetBuffer (gst_bit_writer_reset_and_get_buffer) resets bitwriter and
// returns the current data as Buffer.
//
// Free-function: gst_buffer_unref.
//
// The function returns the following values:
//
//   - buffer: new allocated Buffer wrapping the current data.
//     gst_buffer_unref() after usage.
func (bitwriter *BitWriter) ResetAndGetBuffer() *gst.Buffer {
	var _arg0 *C.GstBitWriter // out
	var _cret *C.GstBuffer    // in

	_arg0 = (*C.GstBitWriter)(gextras.StructNative(unsafe.Pointer(bitwriter)))

	_cret = C.gst_bit_writer_reset_and_get_buffer(_arg0)
	runtime.KeepAlive(bitwriter)

	var _buffer *gst.Buffer // out

	_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_buffer)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _buffer
}

func (bitwriter *BitWriter) SetPos(pos uint) bool {
	var _arg0 *C.GstBitWriter // out
	var _arg1 C.guint         // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstBitWriter)(gextras.StructNative(unsafe.Pointer(bitwriter)))
	_arg1 = C.guint(pos)

	_cret = C.gst_bit_writer_set_pos(_arg0, _arg1)
	runtime.KeepAlive(bitwriter)
	runtime.KeepAlive(pos)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// ByteReader (GstByteReader) provides a byte reader that can read different
// integer and floating point types from a memory buffer. It provides functions
// for reading signed/unsigned, little/big endian integers of 8, 16, 24, 32 and
// 64 bits and functions for reading little/big endian floating points numbers
// of 32 and 64 bits. It also provides functions to read NUL-terminated strings
// in various character encodings.
//
// An instance of this type is always passed by reference.
type ByteReader struct {
	*byteReader
}

// byteReader is the struct that's finalized.
type byteReader struct {
	native *C.GstByteReader
}

// DupStringUTF16 (gst_byte_reader_dup_string_utf16): free-function: g_free
//
// Returns a newly-allocated copy of the current data position if there is a
// NUL-terminated UTF-16 string in the data (this could be an empty string as
// well), and advances the current position.
//
// No input checking for valid UTF-16 is done. This function is endianness
// agnostic - you should not assume the UTF-16 characters are in host
// endianness.
//
// This function will fail if no NUL-terminator was found in in the data.
//
// Note: there is no peek or get variant of this function to ensure correct byte
// alignment of the UTF-16 string.
//
// The function returns the following values:
//
//   - str address of a #guint16 pointer variable in which to store the result.
//   - ok: TRUE if a string could be read, FALSE otherwise. The string put into
//     str must be freed with g_free() when no longer needed.
func (reader *ByteReader) DupStringUTF16() ([]uint16, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 *C.guint16       // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_dup_string_utf16(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _str []uint16 // out
	var _ok bool      // out

	defer C.free(unsafe.Pointer(_arg1))
	{
		var i int
		var z C.guint16
		for p := _arg1; *p != z; p = &unsafe.Slice(p, 2)[1] {
			i++
		}

		src := unsafe.Slice(_arg1, i)
		_str = make([]uint16, i)
		for i := range src {
			_str[i] = uint16(src[i])
		}
	}
	if _cret != 0 {
		_ok = true
	}

	return _str, _ok
}

// DupStringUTF32 (gst_byte_reader_dup_string_utf32): free-function: g_free
//
// Returns a newly-allocated copy of the current data position if there is a
// NUL-terminated UTF-32 string in the data (this could be an empty string as
// well), and advances the current position.
//
// No input checking for valid UTF-32 is done. This function is endianness
// agnostic - you should not assume the UTF-32 characters are in host
// endianness.
//
// This function will fail if no NUL-terminator was found in in the data.
//
// Note: there is no peek or get variant of this function to ensure correct byte
// alignment of the UTF-32 string.
//
// The function returns the following values:
//
//   - str address of a #guint32 pointer variable in which to store the result.
//   - ok: TRUE if a string could be read, FALSE otherwise. The string put into
//     str must be freed with g_free() when no longer needed.
func (reader *ByteReader) DupStringUTF32() ([]uint32, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 *C.guint32       // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_dup_string_utf32(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _str []uint32 // out
	var _ok bool      // out

	defer C.free(unsafe.Pointer(_arg1))
	{
		var i int
		var z C.guint32
		for p := _arg1; *p != z; p = &unsafe.Slice(p, 2)[1] {
			i++
		}

		src := unsafe.Slice(_arg1, i)
		_str = make([]uint32, i)
		for i := range src {
			_str[i] = uint32(src[i])
		}
	}
	if _cret != 0 {
		_ok = true
	}

	return _str, _ok
}

// Float32Be (gst_byte_reader_get_float32_be): read a 32 bit big endian floating
// point value into val and update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gfloat to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Float32Be() (float32, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gfloat         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_float32_be(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val float32 // out
	var _ok bool     // out

	_val = float32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Float32LE (gst_byte_reader_get_float32_le): read a 32 bit little endian
// floating point value into val and update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gfloat to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Float32LE() (float32, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gfloat         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_float32_le(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val float32 // out
	var _ok bool     // out

	_val = float32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Float64Be (gst_byte_reader_get_float64_be): read a 64 bit big endian floating
// point value into val and update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gdouble to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Float64Be() (float64, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gdouble        // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_float64_be(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val float64 // out
	var _ok bool     // out

	_val = float64(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Float64LE (gst_byte_reader_get_float64_le): read a 64 bit little endian
// floating point value into val and update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gdouble to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Float64LE() (float64, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gdouble        // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_float64_le(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val float64 // out
	var _ok bool     // out

	_val = float64(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Int16Be (gst_byte_reader_get_int16_be): read a signed 16 bit big endian
// integer into val and update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gint16 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Int16Be() (int16, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gint16         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_int16_be(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val int16 // out
	var _ok bool   // out

	_val = int16(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Int16LE (gst_byte_reader_get_int16_le): read a signed 16 bit little endian
// integer into val and update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gint16 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Int16LE() (int16, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gint16         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_int16_le(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val int16 // out
	var _ok bool   // out

	_val = int16(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Int24Be (gst_byte_reader_get_int24_be): read a signed 24 bit big endian
// integer into val and update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gint32 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Int24Be() (int32, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gint32         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_int24_be(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val int32 // out
	var _ok bool   // out

	_val = int32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Int24LE (gst_byte_reader_get_int24_le): read a signed 24 bit little endian
// integer into val and update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gint32 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Int24LE() (int32, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gint32         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_int24_le(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val int32 // out
	var _ok bool   // out

	_val = int32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Int32Be (gst_byte_reader_get_int32_be): read a signed 32 bit big endian
// integer into val and update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gint32 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Int32Be() (int32, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gint32         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_int32_be(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val int32 // out
	var _ok bool   // out

	_val = int32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Int32LE (gst_byte_reader_get_int32_le): read a signed 32 bit little endian
// integer into val and update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gint32 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Int32LE() (int32, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gint32         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_int32_le(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val int32 // out
	var _ok bool   // out

	_val = int32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Int64Be (gst_byte_reader_get_int64_be): read a signed 64 bit big endian
// integer into val and update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gint64 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Int64Be() (int64, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gint64         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_int64_be(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val int64 // out
	var _ok bool   // out

	_val = int64(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Int64LE (gst_byte_reader_get_int64_le): read a signed 64 bit little endian
// integer into val and update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gint64 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Int64LE() (int64, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gint64         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_int64_le(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val int64 // out
	var _ok bool   // out

	_val = int64(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Int8 (gst_byte_reader_get_int8): read a signed 8 bit integer into val and
// update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gint8 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Int8() (int8, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gint8          // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_int8(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val int8 // out
	var _ok bool  // out

	_val = int8(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Pos (gst_byte_reader_get_pos) returns the current position of a ByteReader
// instance in bytes.
//
// The function returns the following values:
//
//   - guint: current position of reader in bytes.
func (reader *ByteReader) Pos() uint {
	var _arg0 *C.GstByteReader // out
	var _cret C.guint          // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_pos(_arg0)
	runtime.KeepAlive(reader)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// Remaining (gst_byte_reader_get_remaining) returns the remaining number of
// bytes of a ByteReader instance.
//
// The function returns the following values:
//
//   - guint: remaining number of bytes of reader instance.
func (reader *ByteReader) Remaining() uint {
	var _arg0 *C.GstByteReader // out
	var _cret C.guint          // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_remaining(_arg0)
	runtime.KeepAlive(reader)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// Size (gst_byte_reader_get_size) returns the total number of bytes of a
// ByteReader instance.
//
// The function returns the following values:
//
//   - guint: total number of bytes of reader instance.
func (reader *ByteReader) Size() uint {
	var _arg0 *C.GstByteReader // out
	var _cret C.guint          // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_size(_arg0)
	runtime.KeepAlive(reader)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// Uint16Be (gst_byte_reader_get_uint16_be): read an unsigned 16 bit big endian
// integer into val and update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #guint16 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Uint16Be() (uint16, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint16        // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_uint16_be(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val uint16 // out
	var _ok bool    // out

	_val = uint16(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Uint16LE (gst_byte_reader_get_uint16_le): read an unsigned 16 bit little
// endian integer into val and update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #guint16 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Uint16LE() (uint16, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint16        // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_uint16_le(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val uint16 // out
	var _ok bool    // out

	_val = uint16(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Uint24Be (gst_byte_reader_get_uint24_be): read an unsigned 24 bit big endian
// integer into val and update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #guint32 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Uint24Be() (uint32, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint32        // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_uint24_be(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val uint32 // out
	var _ok bool    // out

	_val = uint32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Uint24LE (gst_byte_reader_get_uint24_le): read an unsigned 24 bit little
// endian integer into val and update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #guint32 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Uint24LE() (uint32, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint32        // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_uint24_le(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val uint32 // out
	var _ok bool    // out

	_val = uint32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Uint32Be (gst_byte_reader_get_uint32_be): read an unsigned 32 bit big endian
// integer into val and update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #guint32 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Uint32Be() (uint32, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint32        // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_uint32_be(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val uint32 // out
	var _ok bool    // out

	_val = uint32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Uint32LE (gst_byte_reader_get_uint32_le): read an unsigned 32 bit little
// endian integer into val and update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #guint32 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Uint32LE() (uint32, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint32        // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_uint32_le(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val uint32 // out
	var _ok bool    // out

	_val = uint32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Uint64Be (gst_byte_reader_get_uint64_be): read an unsigned 64 bit big endian
// integer into val and update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #guint64 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Uint64Be() (uint64, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint64        // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_uint64_be(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val uint64 // out
	var _ok bool    // out

	_val = uint64(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Uint64LE (gst_byte_reader_get_uint64_le): read an unsigned 64 bit little
// endian integer into val and update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #guint64 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Uint64LE() (uint64, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint64        // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_uint64_le(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val uint64 // out
	var _ok bool    // out

	_val = uint64(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Uint8 (gst_byte_reader_get_uint8): read an unsigned 8 bit integer into val
// and update the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #guint8 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) Uint8() (byte, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint8         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_get_uint8(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val byte // out
	var _ok bool  // out

	_val = byte(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// Init (gst_byte_reader_init) initializes a ByteReader instance to read from
// data. This function can be called on already initialized instances.
//
// The function takes the following parameters:
//
//   - data from which the ByteReader should read.
func (reader *ByteReader) Init(data []byte) {
	var _arg0 *C.GstByteReader // out
	var _arg1 *C.guint8        // out
	var _arg2 C.guint

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))
	_arg2 = (C.guint)(len(data))
	if len(data) > 0 {
		_arg1 = (*C.guint8)(unsafe.Pointer(&data[0]))
	}

	C.gst_byte_reader_init(_arg0, _arg1, _arg2)
	runtime.KeepAlive(reader)
	runtime.KeepAlive(data)
}

// MaskedScanUint32 (gst_byte_reader_masked_scan_uint32): scan for pattern
// pattern with applied mask mask in the byte reader data, starting from offset
// offset relative to the current position.
//
// The bytes in pattern and mask are interpreted left-to-right, regardless of
// endianness. All four bytes of the pattern must be present in the byte reader
// data for it to match, even if the first or last bytes are masked out.
//
// It is an error to call this function without making sure that there is enough
// data (offset+size bytes) in the byte reader.
//
// The function takes the following parameters:
//
//   - mask to apply to data before matching against pattern.
//   - pattern to match (after mask is applied).
//   - offset from which to start scanning, relative to the current position.
//   - size: number of bytes to scan from offset.
//
// The function returns the following values:
//
//   - guint: offset of the first match, or -1 if no match was found.
//
//     Example:
//
//     // Assume the reader contains 0x00 0x01 0x02 ... 0xfe 0xff
//
//     gst_byte_reader_masked_scan_uint32 (reader, 0xffffffff, 0x00010203,
//     0, 256); // -> returns 0 gst_byte_reader_masked_scan_uint32
//     (reader, 0xffffffff, 0x00010203, 1, 255); // -> returns -1
//     gst_byte_reader_masked_scan_uint32 (reader, 0xffffffff, 0x01020304, 1,
//     255); // -> returns 1 gst_byte_reader_masked_scan_uint32 (reader, 0xffff,
//     0x0001, 0, 256); // -> returns -1 gst_byte_reader_masked_scan_uint32
//     (reader, 0xffff, 0x0203, 0, 256); // -> returns 0
//     gst_byte_reader_masked_scan_uint32 (reader, 0xffff0000, 0x02030000,
//     0, 256); // -> returns 2 gst_byte_reader_masked_scan_uint32 (reader,
//     0xffff0000, 0x02030000, 0, 4); // -> returns -1.
func (reader *ByteReader) MaskedScanUint32(mask uint32, pattern uint32, offset uint, size uint) uint {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint32        // out
	var _arg2 C.guint32        // out
	var _arg3 C.guint          // out
	var _arg4 C.guint          // out
	var _cret C.guint          // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))
	_arg1 = C.guint32(mask)
	_arg2 = C.guint32(pattern)
	_arg3 = C.guint(offset)
	_arg4 = C.guint(size)

	_cret = C.gst_byte_reader_masked_scan_uint32(_arg0, _arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(reader)
	runtime.KeepAlive(mask)
	runtime.KeepAlive(pattern)
	runtime.KeepAlive(offset)
	runtime.KeepAlive(size)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// MaskedScanUint32Peek (gst_byte_reader_masked_scan_uint32_peek): scan for
// pattern pattern with applied mask mask in the byte reader data, starting from
// offset offset relative to the current position.
//
// The bytes in pattern and mask are interpreted left-to-right, regardless of
// endianness. All four bytes of the pattern must be present in the byte reader
// data for it to match, even if the first or last bytes are masked out.
//
// It is an error to call this function without making sure that there is enough
// data (offset+size bytes) in the byte reader.
//
// The function takes the following parameters:
//
//   - mask to apply to data before matching against pattern.
//   - pattern to match (after mask is applied).
//   - offset from which to start scanning, relative to the current position.
//   - size: number of bytes to scan from offset.
//
// The function returns the following values:
//
//   - value: pointer to uint32 to return matching data.
//   - guint: offset of the first match, or -1 if no match was found.
func (reader *ByteReader) MaskedScanUint32Peek(mask uint32, pattern uint32, offset uint, size uint) (uint32, uint) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint32        // out
	var _arg2 C.guint32        // out
	var _arg3 C.guint          // out
	var _arg4 C.guint          // out
	var _arg5 C.guint32        // in
	var _cret C.guint          // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))
	_arg1 = C.guint32(mask)
	_arg2 = C.guint32(pattern)
	_arg3 = C.guint(offset)
	_arg4 = C.guint(size)

	_cret = C.gst_byte_reader_masked_scan_uint32_peek(_arg0, _arg1, _arg2, _arg3, _arg4, &_arg5)
	runtime.KeepAlive(reader)
	runtime.KeepAlive(mask)
	runtime.KeepAlive(pattern)
	runtime.KeepAlive(offset)
	runtime.KeepAlive(size)

	var _value uint32 // out
	var _guint uint   // out

	_value = uint32(_arg5)
	_guint = uint(_cret)

	return _value, _guint
}

// PeekFloat32Be (gst_byte_reader_peek_float32_be): read a 32 bit big endian
// floating point value into val but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gfloat to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekFloat32Be() (float32, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gfloat         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_float32_be(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val float32 // out
	var _ok bool     // out

	_val = float32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekFloat32LE (gst_byte_reader_peek_float32_le): read a 32 bit little endian
// floating point value into val but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gfloat to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekFloat32LE() (float32, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gfloat         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_float32_le(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val float32 // out
	var _ok bool     // out

	_val = float32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekFloat64Be (gst_byte_reader_peek_float64_be): read a 64 bit big endian
// floating point value into val but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gdouble to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekFloat64Be() (float64, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gdouble        // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_float64_be(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val float64 // out
	var _ok bool     // out

	_val = float64(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekFloat64LE (gst_byte_reader_peek_float64_le): read a 64 bit little endian
// floating point value into val but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gdouble to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekFloat64LE() (float64, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gdouble        // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_float64_le(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val float64 // out
	var _ok bool     // out

	_val = float64(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekInt16Be (gst_byte_reader_peek_int16_be): read a signed 16 bit big endian
// integer into val but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gint16 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekInt16Be() (int16, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gint16         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_int16_be(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val int16 // out
	var _ok bool   // out

	_val = int16(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekInt16LE (gst_byte_reader_peek_int16_le): read a signed 16 bit little
// endian integer into val but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gint16 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekInt16LE() (int16, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gint16         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_int16_le(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val int16 // out
	var _ok bool   // out

	_val = int16(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekInt24Be (gst_byte_reader_peek_int24_be): read a signed 24 bit big endian
// integer into val but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gint32 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekInt24Be() (int32, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gint32         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_int24_be(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val int32 // out
	var _ok bool   // out

	_val = int32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekInt24LE (gst_byte_reader_peek_int24_le): read a signed 24 bit little
// endian integer into val but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gint32 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekInt24LE() (int32, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gint32         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_int24_le(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val int32 // out
	var _ok bool   // out

	_val = int32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekInt32Be (gst_byte_reader_peek_int32_be): read a signed 32 bit big endian
// integer into val but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gint32 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekInt32Be() (int32, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gint32         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_int32_be(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val int32 // out
	var _ok bool   // out

	_val = int32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekInt32LE (gst_byte_reader_peek_int32_le): read a signed 32 bit little
// endian integer into val but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gint32 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekInt32LE() (int32, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gint32         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_int32_le(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val int32 // out
	var _ok bool   // out

	_val = int32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekInt64Be (gst_byte_reader_peek_int64_be): read a signed 64 bit big endian
// integer into val but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gint64 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekInt64Be() (int64, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gint64         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_int64_be(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val int64 // out
	var _ok bool   // out

	_val = int64(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekInt64LE (gst_byte_reader_peek_int64_le): read a signed 64 bit little
// endian integer into val but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gint64 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekInt64LE() (int64, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gint64         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_int64_le(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val int64 // out
	var _ok bool   // out

	_val = int64(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekInt8 (gst_byte_reader_peek_int8): read a signed 8 bit integer into val
// but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #gint8 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekInt8() (int8, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.gint8          // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_int8(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val int8 // out
	var _ok bool  // out

	_val = int8(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekUint16Be (gst_byte_reader_peek_uint16_be): read an unsigned 16 bit big
// endian integer into val but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #guint16 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekUint16Be() (uint16, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint16        // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_uint16_be(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val uint16 // out
	var _ok bool    // out

	_val = uint16(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekUint16LE (gst_byte_reader_peek_uint16_le): read an unsigned 16 bit little
// endian integer into val but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #guint16 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekUint16LE() (uint16, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint16        // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_uint16_le(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val uint16 // out
	var _ok bool    // out

	_val = uint16(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekUint24Be (gst_byte_reader_peek_uint24_be): read an unsigned 24 bit big
// endian integer into val but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #guint32 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekUint24Be() (uint32, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint32        // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_uint24_be(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val uint32 // out
	var _ok bool    // out

	_val = uint32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekUint24LE (gst_byte_reader_peek_uint24_le): read an unsigned 24 bit little
// endian integer into val but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #guint32 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekUint24LE() (uint32, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint32        // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_uint24_le(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val uint32 // out
	var _ok bool    // out

	_val = uint32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekUint32Be (gst_byte_reader_peek_uint32_be): read an unsigned 32 bit big
// endian integer into val but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #guint32 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekUint32Be() (uint32, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint32        // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_uint32_be(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val uint32 // out
	var _ok bool    // out

	_val = uint32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekUint32LE (gst_byte_reader_peek_uint32_le): read an unsigned 32 bit little
// endian integer into val but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #guint32 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekUint32LE() (uint32, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint32        // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_uint32_le(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val uint32 // out
	var _ok bool    // out

	_val = uint32(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekUint64Be (gst_byte_reader_peek_uint64_be): read an unsigned 64 bit big
// endian integer into val but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #guint64 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekUint64Be() (uint64, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint64        // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_uint64_be(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val uint64 // out
	var _ok bool    // out

	_val = uint64(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekUint64LE (gst_byte_reader_peek_uint64_le): read an unsigned 64 bit little
// endian integer into val but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #guint64 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekUint64LE() (uint64, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint64        // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_uint64_le(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val uint64 // out
	var _ok bool    // out

	_val = uint64(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// PeekUint8 (gst_byte_reader_peek_uint8): read an unsigned 8 bit integer into
// val but keep the current position.
//
// The function returns the following values:
//
//   - val: pointer to a #guint8 to store the result.
//   - ok: TRUE if successful, FALSE otherwise.
func (reader *ByteReader) PeekUint8() (byte, bool) {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint8         // in
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_peek_uint8(_arg0, &_arg1)
	runtime.KeepAlive(reader)

	var _val byte // out
	var _ok bool  // out

	_val = byte(_arg1)
	if _cret != 0 {
		_ok = true
	}

	return _val, _ok
}

// SetPos (gst_byte_reader_set_pos) sets the new position of a ByteReader
// instance to pos in bytes.
//
// The function takes the following parameters:
//
//   - pos: new position in bytes.
//
// The function returns the following values:
//
//   - ok: TRUE if the position could be set successfully, FALSE otherwise.
func (reader *ByteReader) SetPos(pos uint) bool {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint          // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))
	_arg1 = C.guint(pos)

	_cret = C.gst_byte_reader_set_pos(_arg0, _arg1)
	runtime.KeepAlive(reader)
	runtime.KeepAlive(pos)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Skip (gst_byte_reader_skip) skips nbytes bytes of the ByteReader instance.
//
// The function takes the following parameters:
//
//   - nbytes: number of bytes to skip.
//
// The function returns the following values:
//
//   - ok: TRUE if nbytes bytes could be skipped, FALSE otherwise.
func (reader *ByteReader) Skip(nbytes uint) bool {
	var _arg0 *C.GstByteReader // out
	var _arg1 C.guint          // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))
	_arg1 = C.guint(nbytes)

	_cret = C.gst_byte_reader_skip(_arg0, _arg1)
	runtime.KeepAlive(reader)
	runtime.KeepAlive(nbytes)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SkipStringUTF16 (gst_byte_reader_skip_string_utf16) skips a NUL-terminated
// UTF-16 string in the ByteReader instance, advancing the current position to
// the byte after the string.
//
// No input checking for valid UTF-16 is done.
//
// This function will fail if no NUL-terminator was found in in the data.
//
// The function returns the following values:
//
//   - ok: TRUE if a string could be skipped, FALSE otherwise.
func (reader *ByteReader) SkipStringUTF16() bool {
	var _arg0 *C.GstByteReader // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_skip_string_utf16(_arg0)
	runtime.KeepAlive(reader)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SkipStringUTF32 (gst_byte_reader_skip_string_utf32) skips a NUL-terminated
// UTF-32 string in the ByteReader instance, advancing the current position to
// the byte after the string.
//
// No input checking for valid UTF-32 is done.
//
// This function will fail if no NUL-terminator was found in in the data.
//
// The function returns the following values:
//
//   - ok: TRUE if a string could be skipped, FALSE otherwise.
func (reader *ByteReader) SkipStringUTF32() bool {
	var _arg0 *C.GstByteReader // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_skip_string_utf32(_arg0)
	runtime.KeepAlive(reader)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SkipStringUTF8 (gst_byte_reader_skip_string_utf8) skips a NUL-terminated
// string in the ByteReader instance, advancing the current position to the
// byte after the string. This will work for any NUL-terminated string with a
// character width of 8 bits, so ASCII, UTF-8, ISO-8859-N etc. No input checking
// for valid UTF-8 is done.
//
// This function will fail if no NUL-terminator was found in in the data.
//
// The function returns the following values:
//
//   - ok: TRUE if a string could be skipped, FALSE otherwise.
func (reader *ByteReader) SkipStringUTF8() bool {
	var _arg0 *C.GstByteReader // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteReader)(gextras.StructNative(unsafe.Pointer(reader)))

	_cret = C.gst_byte_reader_skip_string_utf8(_arg0)
	runtime.KeepAlive(reader)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// ByteWriter (GstByteWriter) provides a byte writer and reader that can
// write/read different integer and floating point types to/from a memory
// buffer. It provides functions for writing/reading signed/unsigned,
// little/big endian integers of 8, 16, 24, 32 and 64 bits and functions for
// reading little/big endian floating points numbers of 32 and 64 bits. It also
// provides functions to write/read NUL-terminated strings in various character
// encodings.
//
// An instance of this type is always passed by reference.
type ByteWriter struct {
	*byteWriter
}

// byteWriter is the struct that's finalized.
type byteWriter struct {
	native *C.GstByteWriter
}

// Parent: ByteReader parent.
func (b *ByteWriter) Parent() *ByteReader {
	valptr := &b.native.parent
	var _v *ByteReader // out
	_v = (*ByteReader)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// AllocSize: allocation size of the data.
func (b *ByteWriter) AllocSize() uint {
	valptr := &b.native.alloc_size
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Fixed: if TRUE no reallocations are allowed.
func (b *ByteWriter) Fixed() bool {
	valptr := &b.native.fixed
	var _v bool // out
	if *valptr != 0 {
		_v = true
	}
	return _v
}

// Owned: if FALSE no reallocations are allowed and copies of data are returned.
func (b *ByteWriter) Owned() bool {
	valptr := &b.native.owned
	var _v bool // out
	if *valptr != 0 {
		_v = true
	}
	return _v
}

// AllocSize: allocation size of the data.
func (b *ByteWriter) SetAllocSize(allocSize uint) {
	valptr := &b.native.alloc_size
	*valptr = C.guint(allocSize)
}

// Fixed: if TRUE no reallocations are allowed.
func (b *ByteWriter) SetFixed(fixed bool) {
	valptr := &b.native.fixed
	if fixed {
		*valptr = C.TRUE
	}
}

// Owned: if FALSE no reallocations are allowed and copies of data are returned.
func (b *ByteWriter) SetOwned(owned bool) {
	valptr := &b.native.owned
	if owned {
		*valptr = C.TRUE
	}
}

// EnsureFreeSpace (gst_byte_writer_ensure_free_space) checks if enough
// free space from the current write cursor is available and reallocates if
// necessary.
//
// The function takes the following parameters:
//
//   - size: number of bytes that should be available.
//
// The function returns the following values:
//
//   - ok: TRUE if at least size bytes are still available.
func (writer *ByteWriter) EnsureFreeSpace(size uint) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.guint          // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.guint(size)

	_cret = C.gst_byte_writer_ensure_free_space(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(size)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Fill (gst_byte_writer_fill) writes size bytes containing value to writer.
//
// The function takes the following parameters:
//
//   - value: value to be written.
//   - size: number of bytes to be written.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) Fill(value byte, size uint) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.guint8         // out
	var _arg2 C.guint          // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.guint8(value)
	_arg2 = C.guint(size)

	_cret = C.gst_byte_writer_fill(_arg0, _arg1, _arg2)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(value)
	runtime.KeepAlive(size)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// FreeAndGetBuffer (gst_byte_writer_free_and_get_buffer) frees writer and all
// memory allocated by it except the current data, which is returned as Buffer.
//
// Free-function: gst_buffer_unref.
//
// The function returns the following values:
//
//   - buffer: current data as buffer. gst_buffer_unref() after usage.
func (writer *ByteWriter) FreeAndGetBuffer() *gst.Buffer {
	var _arg0 *C.GstByteWriter // out
	var _cret *C.GstBuffer     // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(writer)), nil)

	_cret = C.gst_byte_writer_free_and_get_buffer(_arg0)
	runtime.KeepAlive(writer)

	var _buffer *gst.Buffer // out

	_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_buffer)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _buffer
}

// FreeAndGetData (gst_byte_writer_free_and_get_data) frees writer and all
// memory allocated by it except the current data, which is returned.
//
// Free-function: g_free.
//
// The function returns the following values:
//
//   - guint8: current data. g_free() after usage.
func (writer *ByteWriter) FreeAndGetData() *byte {
	var _arg0 *C.GstByteWriter // out
	var _cret *C.guint8        // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(writer)), nil)

	_cret = C.gst_byte_writer_free_and_get_data(_arg0)
	runtime.KeepAlive(writer)

	var _guint8 *byte // out

	_guint8 = (*byte)(unsafe.Pointer(_cret))

	return _guint8
}

// Remaining (gst_byte_writer_get_remaining) returns the remaining size of
// data that can still be written. If -1 is returned the remaining size is only
// limited by system resources.
//
// The function returns the following values:
//
//   - guint: remaining size of data that can still be written.
func (writer *ByteWriter) Remaining() uint {
	var _arg0 *C.GstByteWriter // out
	var _cret C.guint          // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))

	_cret = C.gst_byte_writer_get_remaining(_arg0)
	runtime.KeepAlive(writer)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// Init (gst_byte_writer_init) initializes writer to an empty instance.
func (writer *ByteWriter) Init() {
	var _arg0 *C.GstByteWriter // out

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))

	C.gst_byte_writer_init(_arg0)
	runtime.KeepAlive(writer)
}

// InitWithData (gst_byte_writer_init_with_data) initializes writer with the
// given memory area. If initialized is TRUE it is possible to read size bytes
// from the ByteWriter from the beginning.
//
// The function takes the following parameters:
//
//   - data: memory area for writing.
//   - initialized: if TRUE the complete data can be read from the beginning.
func (writer *ByteWriter) InitWithData(data []byte, initialized bool) {
	var _arg0 *C.GstByteWriter // out
	var _arg1 *C.guint8        // out
	var _arg2 C.guint
	var _arg3 C.gboolean // out

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg2 = (C.guint)(len(data))
	if len(data) > 0 {
		_arg1 = (*C.guint8)(unsafe.Pointer(&data[0]))
	}
	if initialized {
		_arg3 = C.TRUE
	}

	C.gst_byte_writer_init_with_data(_arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(data)
	runtime.KeepAlive(initialized)
}

// InitWithSize (gst_byte_writer_init_with_size) initializes writer with the
// given initial data size.
//
// The function takes the following parameters:
//
//   - size: initial size of data.
//   - fixed: if TRUE the data can't be reallocated.
func (writer *ByteWriter) InitWithSize(size uint, fixed bool) {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.guint          // out
	var _arg2 C.gboolean       // out

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.guint(size)
	if fixed {
		_arg2 = C.TRUE
	}

	C.gst_byte_writer_init_with_size(_arg0, _arg1, _arg2)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(size)
	runtime.KeepAlive(fixed)
}

// PutBuffer (gst_byte_writer_put_buffer) writes size bytes of data to writer.
//
// The function takes the following parameters:
//
//   - buffer: source Buffer.
//   - offset to copy from.
//   - size: total size to copy. If -1, all data is copied.
//
// The function returns the following values:
//
//   - ok: TRUE if the data could be written.
func (writer *ByteWriter) PutBuffer(buffer *gst.Buffer, offset uint, size int) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 *C.GstBuffer     // out
	var _arg2 C.gsize          // out
	var _arg3 C.gssize         // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg2 = C.gsize(offset)
	_arg3 = C.gssize(size)

	_cret = C.gst_byte_writer_put_buffer(_arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(offset)
	runtime.KeepAlive(size)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutData (gst_byte_writer_put_data) writes size bytes of data to writer.
//
// The function takes the following parameters:
//
//   - data: data to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutData(data []byte) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 *C.guint8        // out
	var _arg2 C.guint
	var _cret C.gboolean // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg2 = (C.guint)(len(data))
	if len(data) > 0 {
		_arg1 = (*C.guint8)(unsafe.Pointer(&data[0]))
	}

	_cret = C.gst_byte_writer_put_data(_arg0, _arg1, _arg2)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(data)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutFloat32Be (gst_byte_writer_put_float32_be) writes a big endian 32 bit
// float to writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutFloat32Be(val float32) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.gfloat         // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.gfloat(val)

	_cret = C.gst_byte_writer_put_float32_be(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutFloat32LE (gst_byte_writer_put_float32_le) writes a little endian 32 bit
// float to writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutFloat32LE(val float32) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.gfloat         // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.gfloat(val)

	_cret = C.gst_byte_writer_put_float32_le(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutFloat64Be (gst_byte_writer_put_float64_be) writes a big endian 64 bit
// float to writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutFloat64Be(val float64) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.gdouble        // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.gdouble(val)

	_cret = C.gst_byte_writer_put_float64_be(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutFloat64LE (gst_byte_writer_put_float64_le) writes a little endian 64 bit
// float to writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutFloat64LE(val float64) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.gdouble        // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.gdouble(val)

	_cret = C.gst_byte_writer_put_float64_le(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutInt16Be (gst_byte_writer_put_int16_be) writes a signed big endian 16 bit
// integer to writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutInt16Be(val int16) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.gint16         // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.gint16(val)

	_cret = C.gst_byte_writer_put_int16_be(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutInt16LE (gst_byte_writer_put_int16_le) writes a signed little endian 16
// bit integer to writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutInt16LE(val int16) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.gint16         // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.gint16(val)

	_cret = C.gst_byte_writer_put_int16_le(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutInt24Be (gst_byte_writer_put_int24_be) writes a signed big endian 24 bit
// integer to writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutInt24Be(val int32) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.gint32         // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.gint32(val)

	_cret = C.gst_byte_writer_put_int24_be(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutInt24LE (gst_byte_writer_put_int24_le) writes a signed little endian 24
// bit integer to writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutInt24LE(val int32) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.gint32         // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.gint32(val)

	_cret = C.gst_byte_writer_put_int24_le(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutInt32Be (gst_byte_writer_put_int32_be) writes a signed big endian 32 bit
// integer to writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutInt32Be(val int32) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.gint32         // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.gint32(val)

	_cret = C.gst_byte_writer_put_int32_be(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutInt32LE (gst_byte_writer_put_int32_le) writes a signed little endian 32
// bit integer to writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutInt32LE(val int32) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.gint32         // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.gint32(val)

	_cret = C.gst_byte_writer_put_int32_le(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutInt64Be (gst_byte_writer_put_int64_be) writes a signed big endian 64 bit
// integer to writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutInt64Be(val int64) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.gint64         // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.gint64(val)

	_cret = C.gst_byte_writer_put_int64_be(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutInt64LE (gst_byte_writer_put_int64_le) writes a signed little endian 64
// bit integer to writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutInt64LE(val int64) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.gint64         // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.gint64(val)

	_cret = C.gst_byte_writer_put_int64_le(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutInt8 (gst_byte_writer_put_int8) writes a signed 8 bit integer to writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutInt8(val int8) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.gint8          // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.gint8(val)

	_cret = C.gst_byte_writer_put_int8(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutStringUTF16 (gst_byte_writer_put_string_utf16) writes a NUL-terminated
// UTF16 string to writer (including the terminator).
//
// The function takes the following parameters:
//
//   - data: UTF16 string to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutStringUTF16(data []uint16) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 *C.guint16       // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	{
		var zero uint16
		data = append(data, zero)
		_arg1 = (*C.guint16)(unsafe.Pointer(&data[0]))
	}

	_cret = C.gst_byte_writer_put_string_utf16(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(data)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutStringUTF32 (gst_byte_writer_put_string_utf32) writes a NUL-terminated
// UTF32 string to writer (including the terminator).
//
// The function takes the following parameters:
//
//   - data: UTF32 string to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutStringUTF32(data []uint32) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 *C.guint32       // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	{
		var zero uint32
		data = append(data, zero)
		_arg1 = (*C.guint32)(unsafe.Pointer(&data[0]))
	}

	_cret = C.gst_byte_writer_put_string_utf32(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(data)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutStringUTF8 (gst_byte_writer_put_string_utf8) writes a NUL-terminated UTF8
// string to writer (including the terminator).
//
// The function takes the following parameters:
//
//   - data: UTF8 string to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutStringUTF8(data string) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 *C.gchar         // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = (*C.gchar)(unsafe.Pointer(C.CString(data)))
	defer C.free(unsafe.Pointer(_arg1))

	_cret = C.gst_byte_writer_put_string_utf8(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(data)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutUint16Be (gst_byte_writer_put_uint16_be) writes a unsigned big endian 16
// bit integer to writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutUint16Be(val uint16) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.guint16        // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.guint16(val)

	_cret = C.gst_byte_writer_put_uint16_be(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutUint16LE (gst_byte_writer_put_uint16_le) writes a unsigned little endian
// 16 bit integer to writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutUint16LE(val uint16) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.guint16        // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.guint16(val)

	_cret = C.gst_byte_writer_put_uint16_le(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutUint24Be (gst_byte_writer_put_uint24_be) writes a unsigned big endian 24
// bit integer to writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutUint24Be(val uint32) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.guint32        // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.guint32(val)

	_cret = C.gst_byte_writer_put_uint24_be(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutUint24LE (gst_byte_writer_put_uint24_le) writes a unsigned little endian
// 24 bit integer to writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutUint24LE(val uint32) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.guint32        // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.guint32(val)

	_cret = C.gst_byte_writer_put_uint24_le(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutUint32Be (gst_byte_writer_put_uint32_be) writes a unsigned big endian 32
// bit integer to writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutUint32Be(val uint32) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.guint32        // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.guint32(val)

	_cret = C.gst_byte_writer_put_uint32_be(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutUint32LE (gst_byte_writer_put_uint32_le) writes a unsigned little endian
// 32 bit integer to writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutUint32LE(val uint32) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.guint32        // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.guint32(val)

	_cret = C.gst_byte_writer_put_uint32_le(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutUint64Be (gst_byte_writer_put_uint64_be) writes a unsigned big endian 64
// bit integer to writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutUint64Be(val uint64) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.guint64        // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.guint64(val)

	_cret = C.gst_byte_writer_put_uint64_be(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutUint64LE (gst_byte_writer_put_uint64_le) writes a unsigned little endian
// 64 bit integer to writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutUint64LE(val uint64) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.guint64        // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.guint64(val)

	_cret = C.gst_byte_writer_put_uint64_le(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PutUint8 (gst_byte_writer_put_uint8) writes a unsigned 8 bit integer to
// writer.
//
// The function takes the following parameters:
//
//   - val: value to write.
//
// The function returns the following values:
//
//   - ok: TRUE if the value could be written.
func (writer *ByteWriter) PutUint8(val byte) bool {
	var _arg0 *C.GstByteWriter // out
	var _arg1 C.guint8         // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))
	_arg1 = C.guint8(val)

	_cret = C.gst_byte_writer_put_uint8(_arg0, _arg1)
	runtime.KeepAlive(writer)
	runtime.KeepAlive(val)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Reset (gst_byte_writer_reset) resets writer and frees the data if it's owned
// by writer.
func (writer *ByteWriter) Reset() {
	var _arg0 *C.GstByteWriter // out

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))

	C.gst_byte_writer_reset(_arg0)
	runtime.KeepAlive(writer)
}

// ResetAndGetBuffer (gst_byte_writer_reset_and_get_buffer) resets writer and
// returns the current data as buffer.
//
// Free-function: gst_buffer_unref.
//
// The function returns the following values:
//
//   - buffer: current data as buffer. gst_buffer_unref() after usage.
func (writer *ByteWriter) ResetAndGetBuffer() *gst.Buffer {
	var _arg0 *C.GstByteWriter // out
	var _cret *C.GstBuffer     // in

	_arg0 = (*C.GstByteWriter)(gextras.StructNative(unsafe.Pointer(writer)))

	_cret = C.gst_byte_writer_reset_and_get_buffer(_arg0)
	runtime.KeepAlive(writer)

	var _buffer *gst.Buffer // out

	_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_buffer)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _buffer
}

// CollectData (GstCollectData): structure used by the collect_pads.
//
// An instance of this type is always passed by reference.
type CollectData struct {
	*collectData
}

// collectData is the struct that's finalized.
type collectData struct {
	native *C.GstCollectData
}

// Collect: owner CollectPads.
func (c *CollectData) Collect() *CollectPads {
	valptr := &c.native.collect
	var _v *CollectPads // out
	_v = wrapCollectPads(coreglib.Take(unsafe.Pointer(*valptr)))
	return _v
}

// Pad managed by this data.
func (c *CollectData) Pad() *gst.Pad {
	valptr := &c.native.pad
	var _v *gst.Pad // out
	{
		obj := coreglib.Take(unsafe.Pointer(*valptr))
		_v = &gst.Pad{
			GstObject: gst.GstObject{
				InitiallyUnowned: coreglib.InitiallyUnowned{
					Object: obj,
				},
			},
		}
	}
	return _v
}

// Buffer: currently queued buffer.
func (c *CollectData) Buffer() *gst.Buffer {
	valptr := &c.native.buffer
	var _v *gst.Buffer // out
	_v = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_v)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})
	return _v
}

// Pos: position in the buffer.
func (c *CollectData) Pos() uint {
	valptr := &c.native.pos
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Segment: last segment received.
func (c *CollectData) Segment() *gst.Segment {
	valptr := &c.native.segment
	var _v *gst.Segment // out
	_v = (*gst.Segment)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// Pos: position in the buffer.
func (c *CollectData) SetPos(pos uint) {
	valptr := &c.native.pos
	*valptr = C.guint(pos)
}

// CollectPadsClass (GstCollectPadsClass): instance of this type is always
// passed by reference.
type CollectPadsClass struct {
	*collectPadsClass
}

// collectPadsClass is the struct that's finalized.
type collectPadsClass struct {
	native *C.GstCollectPadsClass
}

func (c *CollectPadsClass) ParentClass() *gst.ObjectClass {
	valptr := &c.native.parent_class
	var _v *gst.ObjectClass // out
	_v = (*gst.ObjectClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// DataQueueClass (GstDataQueueClass): instance of this type is always passed by
// reference.
type DataQueueClass struct {
	*dataQueueClass
}

// dataQueueClass is the struct that's finalized.
type dataQueueClass struct {
	native *C.GstDataQueueClass
}

func (d *DataQueueClass) GstReserved() [4]unsafe.Pointer {
	valptr := &d.native._gst_reserved
	var _v [4]unsafe.Pointer // out
	{
		src := &*valptr
		for i := 0; i < 4; i++ {
			_v[i] = (unsafe.Pointer)(unsafe.Pointer(src[i]))
		}
	}
	return _v
}

// FlowCombiner (GstFlowCombiner): utility struct to help handling FlowReturn
// combination. Useful for Element<!-- -->s that have multiple source pads and
// need to combine the different FlowReturn for those pads.
//
// FlowCombiner works by using the last FlowReturn for all Pad it has in its
// list and computes the combined return value and provides it to the caller.
//
// To add a new pad to the FlowCombiner use gst_flow_combiner_add_pad().
// The new Pad is stored with a default value of GST_FLOW_OK.
//
// In case you want a Pad to be removed, use gst_flow_combiner_remove_pad().
//
// Please be aware that this struct isn't thread safe as its designed to be used
// by demuxers, those usually will have a single thread operating it.
//
// These functions will take refs on the passed Pad<!-- -->s.
//
// Aside from reducing the user's code size, the main advantage of using this
// helper struct is to follow the standard rules for FlowReturn combination.
// These rules are:
//
// * GST_FLOW_EOS: only if all returns are EOS too * GST_FLOW_NOT_LINKED: only
// if all returns are NOT_LINKED too * GST_FLOW_ERROR or below: if at least one
// returns an error return * GST_FLOW_NOT_NEGOTIATED: if at least one returns a
// not-negotiated return * GST_FLOW_FLUSHING: if at least one returns flushing *
// GST_FLOW_OK: otherwise
//
// GST_FLOW_ERROR or below, GST_FLOW_NOT_NEGOTIATED and GST_FLOW_FLUSHING are
// returned immediately from the gst_flow_combiner_update_flow() function.
//
// An instance of this type is always passed by reference.
type FlowCombiner struct {
	*flowCombiner
}

// flowCombiner is the struct that's finalized.
type flowCombiner struct {
	native *C.GstFlowCombiner
}

func marshalFlowCombiner(p uintptr) (interface{}, error) {
	b := coreglib.ValueFromNative(unsafe.Pointer(p)).Boxed()
	return &FlowCombiner{&flowCombiner{(*C.GstFlowCombiner)(b)}}, nil
}

// NewFlowCombiner constructs a struct FlowCombiner.
func NewFlowCombiner() *FlowCombiner {
	var _cret *C.GstFlowCombiner // in

	_cret = C.gst_flow_combiner_new()

	var _flowCombiner *FlowCombiner // out

	_flowCombiner = (*FlowCombiner)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_flowCombiner)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_flow_combiner_unref((*C.GstFlowCombiner)(intern.C))
		},
	)

	return _flowCombiner
}

// AddPad (gst_flow_combiner_add_pad) adds a new Pad to the FlowCombiner.
//
// The function takes the following parameters:
//
//   - pad that is being added.
func (combiner *FlowCombiner) AddPad(pad *gst.Pad) {
	var _arg0 *C.GstFlowCombiner // out
	var _arg1 *C.GstPad          // out

	_arg0 = (*C.GstFlowCombiner)(gextras.StructNative(unsafe.Pointer(combiner)))
	_arg1 = (*C.GstPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))

	C.gst_flow_combiner_add_pad(_arg0, _arg1)
	runtime.KeepAlive(combiner)
	runtime.KeepAlive(pad)
}

// Clear (gst_flow_combiner_clear) removes all pads from a FlowCombiner and
// resets it to its initial state.
func (combiner *FlowCombiner) Clear() {
	var _arg0 *C.GstFlowCombiner // out

	_arg0 = (*C.GstFlowCombiner)(gextras.StructNative(unsafe.Pointer(combiner)))

	C.gst_flow_combiner_clear(_arg0)
	runtime.KeepAlive(combiner)
}

// RemovePad (gst_flow_combiner_remove_pad) removes a Pad from the FlowCombiner.
//
// The function takes the following parameters:
//
//   - pad to remove.
func (combiner *FlowCombiner) RemovePad(pad *gst.Pad) {
	var _arg0 *C.GstFlowCombiner // out
	var _arg1 *C.GstPad          // out

	_arg0 = (*C.GstFlowCombiner)(gextras.StructNative(unsafe.Pointer(combiner)))
	_arg1 = (*C.GstPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))

	C.gst_flow_combiner_remove_pad(_arg0, _arg1)
	runtime.KeepAlive(combiner)
	runtime.KeepAlive(pad)
}

// Reset (gst_flow_combiner_reset) flow combiner and all pads to their initial
// state without removing pads.
func (combiner *FlowCombiner) Reset() {
	var _arg0 *C.GstFlowCombiner // out

	_arg0 = (*C.GstFlowCombiner)(gextras.StructNative(unsafe.Pointer(combiner)))

	C.gst_flow_combiner_reset(_arg0)
	runtime.KeepAlive(combiner)
}

// UpdateFlow (gst_flow_combiner_update_flow) computes the combined flow return
// for the pads in it.
//
// The FlowReturn parameter should be the last flow return update for a pad
// in this FlowCombiner. It will use this value to be able to shortcut some
// combinations and avoid looking over all pads again. e.g. The last combined
// return is the same as the latest obtained FlowReturn.
//
// The function takes the following parameters:
//
//   - fret: latest FlowReturn received for a pad in this FlowCombiner.
//
// The function returns the following values:
//
//   - flowReturn: combined FlowReturn.
func (combiner *FlowCombiner) UpdateFlow(fret gst.FlowReturn) gst.FlowReturn {
	var _arg0 *C.GstFlowCombiner // out
	var _arg1 C.GstFlowReturn    // out
	var _cret C.GstFlowReturn    // in

	_arg0 = (*C.GstFlowCombiner)(gextras.StructNative(unsafe.Pointer(combiner)))
	_arg1 = C.GstFlowReturn(fret)

	_cret = C.gst_flow_combiner_update_flow(_arg0, _arg1)
	runtime.KeepAlive(combiner)
	runtime.KeepAlive(fret)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// UpdatePadFlow (gst_flow_combiner_update_pad_flow) sets the provided pad's
// last flow return to provided value and computes the combined flow return for
// the pads in it.
//
// The FlowReturn parameter should be the last flow return update for a pad
// in this FlowCombiner. It will use this value to be able to shortcut some
// combinations and avoid looking over all pads again. e.g. The last combined
// return is the same as the latest obtained FlowReturn.
//
// The function takes the following parameters:
//
//   - pad whose FlowReturn to update.
//   - fret: latest FlowReturn received for a pad in this FlowCombiner.
//
// The function returns the following values:
//
//   - flowReturn: combined FlowReturn.
func (combiner *FlowCombiner) UpdatePadFlow(pad *gst.Pad, fret gst.FlowReturn) gst.FlowReturn {
	var _arg0 *C.GstFlowCombiner // out
	var _arg1 *C.GstPad          // out
	var _arg2 C.GstFlowReturn    // out
	var _cret C.GstFlowReturn    // in

	_arg0 = (*C.GstFlowCombiner)(gextras.StructNative(unsafe.Pointer(combiner)))
	_arg1 = (*C.GstPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))
	_arg2 = C.GstFlowReturn(fret)

	_cret = C.gst_flow_combiner_update_pad_flow(_arg0, _arg1, _arg2)
	runtime.KeepAlive(combiner)
	runtime.KeepAlive(pad)
	runtime.KeepAlive(fret)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// PushSrcClass (GstPushSrcClass) subclasses can override any of the available
// virtual methods or not, as needed. At the minimum, the fill method should be
// overridden to produce buffers.
//
// An instance of this type is always passed by reference.
type PushSrcClass struct {
	*pushSrcClass
}

// pushSrcClass is the struct that's finalized.
type pushSrcClass struct {
	native *C.GstPushSrcClass
}

// ParentClass: element parent class.
func (p *PushSrcClass) ParentClass() *BaseSrcClass {
	valptr := &p.native.parent_class
	var _v *BaseSrcClass // out
	_v = (*BaseSrcClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}
