// Code generated by girgen. DO NOT EDIT.

package gstaudio

import (
	"fmt"
	"runtime"
	_ "runtime/cgo"
	"strings"
	"unsafe"

	"github.com/diamondburned/gotk4/pkg/core/gbox"
	"github.com/diamondburned/gotk4/pkg/core/gextras"
	coreglib "github.com/diamondburned/gotk4/pkg/core/glib"
	"github.com/go-gst/go-gst/pkg/gst"
	"github.com/go-gst/go-gst/pkg/gstbase"
)

// #cgo pkg-config: gstreamer-audio-1.0
// #cgo CFLAGS: -Wno-deprecated-declarations
// #include <stdlib.h>
// #include <glib-object.h>
// #include <gst/audio/audio.h>
// extern void callbackDelete(gpointer);
// extern void _gotk4_gstaudio1_AudioSrcClass_reset(GstAudioSrc*);
// extern void _gotk4_gstaudio1_AudioSinkClass_stop(GstAudioSink*);
// extern void _gotk4_gstaudio1_AudioSinkClass_resume(GstAudioSink*);
// extern void _gotk4_gstaudio1_AudioSinkClass_reset(GstAudioSink*);
// extern void _gotk4_gstaudio1_AudioSinkClass_pause(GstAudioSink*);
// extern void _gotk4_gstaudio1_AudioRingBufferClass_clear_all(GstAudioRingBuffer*);
// extern void _gotk4_gstaudio1_AudioRingBufferCallback(GstAudioRingBuffer*, guint8*, guint, gpointer);
// extern void _gotk4_gstaudio1_AudioEncoderClass_flush(GstAudioEncoder*);
// extern void _gotk4_gstaudio1_AudioDecoderClass_flush(GstAudioDecoder*, gboolean);
// extern void _gotk4_gstaudio1_AudioCdSrcClass_close(GstAudioCdSrc*);
// extern void _gotk4_gstaudio1_AudioBaseSinkCustomSlavingCallback(GstAudioBaseSink*, GstClockTime, GstClockTime, GstClockTimeDiff*, GstAudioBaseSinkDiscontReason, gpointer);
// extern void _gotk4_gstaudio1_AudioAggregatorPadClass_update_conversion_info(GstAudioAggregatorPad*);
// extern guint _gotk4_gstaudio1_AudioSrcClass_read(GstAudioSrc*, gpointer, guint, GstClockTime*);
// extern guint _gotk4_gstaudio1_AudioSrcClass_delay(GstAudioSrc*);
// extern guint _gotk4_gstaudio1_AudioSinkClass_delay(GstAudioSink*);
// extern guint _gotk4_gstaudio1_AudioRingBufferClass_delay(GstAudioRingBuffer*);
// extern gint _gotk4_gstaudio1_AudioSinkClass_write(GstAudioSink*, gpointer, guint);
// extern gboolean _gotk4_gstaudio1_AudioSrcClass_unprepare(GstAudioSrc*);
// extern gboolean _gotk4_gstaudio1_AudioSrcClass_prepare(GstAudioSrc*, GstAudioRingBufferSpec*);
// extern gboolean _gotk4_gstaudio1_AudioSrcClass_open(GstAudioSrc*);
// extern gboolean _gotk4_gstaudio1_AudioSrcClass_close(GstAudioSrc*);
// extern gboolean _gotk4_gstaudio1_AudioSinkClass_unprepare(GstAudioSink*);
// extern gboolean _gotk4_gstaudio1_AudioSinkClass_prepare(GstAudioSink*, GstAudioRingBufferSpec*);
// extern gboolean _gotk4_gstaudio1_AudioSinkClass_open(GstAudioSink*);
// extern gboolean _gotk4_gstaudio1_AudioSinkClass_close(GstAudioSink*);
// extern gboolean _gotk4_gstaudio1_AudioRingBufferClass_stop(GstAudioRingBuffer*);
// extern gboolean _gotk4_gstaudio1_AudioRingBufferClass_start(GstAudioRingBuffer*);
// extern gboolean _gotk4_gstaudio1_AudioRingBufferClass_resume(GstAudioRingBuffer*);
// extern gboolean _gotk4_gstaudio1_AudioRingBufferClass_release(GstAudioRingBuffer*);
// extern gboolean _gotk4_gstaudio1_AudioRingBufferClass_pause(GstAudioRingBuffer*);
// extern gboolean _gotk4_gstaudio1_AudioRingBufferClass_open_device(GstAudioRingBuffer*);
// extern gboolean _gotk4_gstaudio1_AudioRingBufferClass_close_device(GstAudioRingBuffer*);
// extern gboolean _gotk4_gstaudio1_AudioRingBufferClass_activate(GstAudioRingBuffer*, gboolean);
// extern gboolean _gotk4_gstaudio1_AudioRingBufferClass_acquire(GstAudioRingBuffer*, GstAudioRingBufferSpec*);
// extern gboolean _gotk4_gstaudio1_AudioFilterClass_setup(GstAudioFilter*, GstAudioInfo*);
// extern gboolean _gotk4_gstaudio1_AudioEncoderClass_transform_meta(GstAudioEncoder*, GstBuffer*, GstMeta*, GstBuffer*);
// extern gboolean _gotk4_gstaudio1_AudioEncoderClass_stop(GstAudioEncoder*);
// extern gboolean _gotk4_gstaudio1_AudioEncoderClass_start(GstAudioEncoder*);
// extern gboolean _gotk4_gstaudio1_AudioEncoderClass_src_query(GstAudioEncoder*, GstQuery*);
// extern gboolean _gotk4_gstaudio1_AudioEncoderClass_src_event(GstAudioEncoder*, GstEvent*);
// extern gboolean _gotk4_gstaudio1_AudioEncoderClass_sink_query(GstAudioEncoder*, GstQuery*);
// extern gboolean _gotk4_gstaudio1_AudioEncoderClass_sink_event(GstAudioEncoder*, GstEvent*);
// extern gboolean _gotk4_gstaudio1_AudioEncoderClass_set_format(GstAudioEncoder*, GstAudioInfo*);
// extern gboolean _gotk4_gstaudio1_AudioEncoderClass_propose_allocation(GstAudioEncoder*, GstQuery*);
// extern gboolean _gotk4_gstaudio1_AudioEncoderClass_open(GstAudioEncoder*);
// extern gboolean _gotk4_gstaudio1_AudioEncoderClass_negotiate(GstAudioEncoder*);
// extern gboolean _gotk4_gstaudio1_AudioEncoderClass_decide_allocation(GstAudioEncoder*, GstQuery*);
// extern gboolean _gotk4_gstaudio1_AudioEncoderClass_close(GstAudioEncoder*);
// extern gboolean _gotk4_gstaudio1_AudioDecoderClass_transform_meta(GstAudioDecoder*, GstBuffer*, GstMeta*, GstBuffer*);
// extern gboolean _gotk4_gstaudio1_AudioDecoderClass_stop(GstAudioDecoder*);
// extern gboolean _gotk4_gstaudio1_AudioDecoderClass_start(GstAudioDecoder*);
// extern gboolean _gotk4_gstaudio1_AudioDecoderClass_src_query(GstAudioDecoder*, GstQuery*);
// extern gboolean _gotk4_gstaudio1_AudioDecoderClass_src_event(GstAudioDecoder*, GstEvent*);
// extern gboolean _gotk4_gstaudio1_AudioDecoderClass_sink_query(GstAudioDecoder*, GstQuery*);
// extern gboolean _gotk4_gstaudio1_AudioDecoderClass_sink_event(GstAudioDecoder*, GstEvent*);
// extern gboolean _gotk4_gstaudio1_AudioDecoderClass_set_format(GstAudioDecoder*, GstCaps*);
// extern gboolean _gotk4_gstaudio1_AudioDecoderClass_propose_allocation(GstAudioDecoder*, GstQuery*);
// extern gboolean _gotk4_gstaudio1_AudioDecoderClass_open(GstAudioDecoder*);
// extern gboolean _gotk4_gstaudio1_AudioDecoderClass_negotiate(GstAudioDecoder*);
// extern gboolean _gotk4_gstaudio1_AudioDecoderClass_decide_allocation(GstAudioDecoder*, GstQuery*);
// extern gboolean _gotk4_gstaudio1_AudioDecoderClass_close(GstAudioDecoder*);
// extern gboolean _gotk4_gstaudio1_AudioCdSrcClass_open(GstAudioCdSrc*, gchar*);
// extern gboolean _gotk4_gstaudio1_AudioAggregatorClass_aggregate_one_buffer(GstAudioAggregator*, GstAudioAggregatorPad*, GstBuffer*, guint, GstBuffer*, guint, guint);
// extern GstFlowReturn _gotk4_gstaudio1_AudioEncoderClass_handle_frame(GstAudioEncoder*, GstBuffer*);
// extern GstFlowReturn _gotk4_gstaudio1_AudioDecoderClass_parse(GstAudioDecoder*, GstAdapter*, gint*, gint*);
// extern GstFlowReturn _gotk4_gstaudio1_AudioDecoderClass_handle_frame(GstAudioDecoder*, GstBuffer*);
// extern GstClockTime _gotk4_gstaudio1_AudioClockGetTimeFunc(GstClock*, gpointer);
// extern GstCaps* _gotk4_gstaudio1_AudioEncoderClass_getcaps(GstAudioEncoder*, GstCaps*);
// extern GstCaps* _gotk4_gstaudio1_AudioDecoderClass_getcaps(GstAudioDecoder*, GstCaps*);
// extern GstBuffer* _gotk4_gstaudio1_AudioCdSrcClass_read_sector(GstAudioCdSrc*, gint);
// extern GstBuffer* _gotk4_gstaudio1_AudioBaseSinkClass_payload(GstAudioBaseSink*, GstBuffer*);
// extern GstBuffer* _gotk4_gstaudio1_AudioAggregatorPadClass_convert_buffer(GstAudioAggregatorPad*, GstAudioInfo*, GstAudioInfo*, GstBuffer*);
// extern GstBuffer* _gotk4_gstaudio1_AudioAggregatorClass_create_output_buffer(GstAudioAggregator*, guint);
// extern GstAudioRingBuffer* _gotk4_gstaudio1_AudioBaseSrcClass_create_ringbuffer(GstAudioBaseSrc*);
// extern GstAudioRingBuffer* _gotk4_gstaudio1_AudioBaseSinkClass_create_ringbuffer(GstAudioBaseSink*);
// GstAudioRingBuffer* _gotk4_gstaudio1_AudioBaseSink_virtual_create_ringbuffer(void* fnptr, GstAudioBaseSink* arg0) {
//   return ((GstAudioRingBuffer* (*)(GstAudioBaseSink*))(fnptr))(arg0);
// };
// GstAudioRingBuffer* _gotk4_gstaudio1_AudioBaseSrc_virtual_create_ringbuffer(void* fnptr, GstAudioBaseSrc* arg0) {
//   return ((GstAudioRingBuffer* (*)(GstAudioBaseSrc*))(fnptr))(arg0);
// };
// GstBuffer* _gotk4_gstaudio1_AudioAggregatorPad_virtual_convert_buffer(void* fnptr, GstAudioAggregatorPad* arg0, GstAudioInfo* arg1, GstAudioInfo* arg2, GstBuffer* arg3) {
//   return ((GstBuffer* (*)(GstAudioAggregatorPad*, GstAudioInfo*, GstAudioInfo*, GstBuffer*))(fnptr))(arg0, arg1, arg2, arg3);
// };
// GstBuffer* _gotk4_gstaudio1_AudioAggregator_virtual_create_output_buffer(void* fnptr, GstAudioAggregator* arg0, guint arg1) {
//   return ((GstBuffer* (*)(GstAudioAggregator*, guint))(fnptr))(arg0, arg1);
// };
// GstBuffer* _gotk4_gstaudio1_AudioBaseSink_virtual_payload(void* fnptr, GstAudioBaseSink* arg0, GstBuffer* arg1) {
//   return ((GstBuffer* (*)(GstAudioBaseSink*, GstBuffer*))(fnptr))(arg0, arg1);
// };
// GstBuffer* _gotk4_gstaudio1_AudioCdSrc_virtual_read_sector(void* fnptr, GstAudioCdSrc* arg0, gint arg1) {
//   return ((GstBuffer* (*)(GstAudioCdSrc*, gint))(fnptr))(arg0, arg1);
// };
// GstCaps* _gotk4_gstaudio1_AudioDecoder_virtual_getcaps(void* fnptr, GstAudioDecoder* arg0, GstCaps* arg1) {
//   return ((GstCaps* (*)(GstAudioDecoder*, GstCaps*))(fnptr))(arg0, arg1);
// };
// GstCaps* _gotk4_gstaudio1_AudioEncoder_virtual_getcaps(void* fnptr, GstAudioEncoder* arg0, GstCaps* arg1) {
//   return ((GstCaps* (*)(GstAudioEncoder*, GstCaps*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstaudio1_AudioDecoder_virtual_handle_frame(void* fnptr, GstAudioDecoder* arg0, GstBuffer* arg1) {
//   return ((GstFlowReturn (*)(GstAudioDecoder*, GstBuffer*))(fnptr))(arg0, arg1);
// };
// GstFlowReturn _gotk4_gstaudio1_AudioDecoder_virtual_parse(void* fnptr, GstAudioDecoder* arg0, GstAdapter* arg1, gint* arg2, gint* arg3) {
//   return ((GstFlowReturn (*)(GstAudioDecoder*, GstAdapter*, gint*, gint*))(fnptr))(arg0, arg1, arg2, arg3);
// };
// GstFlowReturn _gotk4_gstaudio1_AudioEncoder_virtual_handle_frame(void* fnptr, GstAudioEncoder* arg0, GstBuffer* arg1) {
//   return ((GstFlowReturn (*)(GstAudioEncoder*, GstBuffer*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstaudio1_AudioAggregator_virtual_aggregate_one_buffer(void* fnptr, GstAudioAggregator* arg0, GstAudioAggregatorPad* arg1, GstBuffer* arg2, guint arg3, GstBuffer* arg4, guint arg5, guint arg6) {
//   return ((gboolean (*)(GstAudioAggregator*, GstAudioAggregatorPad*, GstBuffer*, guint, GstBuffer*, guint, guint))(fnptr))(arg0, arg1, arg2, arg3, arg4, arg5, arg6);
// };
// gboolean _gotk4_gstaudio1_AudioCdSrc_virtual_open(void* fnptr, GstAudioCdSrc* arg0, gchar* arg1) {
//   return ((gboolean (*)(GstAudioCdSrc*, gchar*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstaudio1_AudioDecoder_virtual_close(void* fnptr, GstAudioDecoder* arg0) {
//   return ((gboolean (*)(GstAudioDecoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioDecoder_virtual_decide_allocation(void* fnptr, GstAudioDecoder* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstAudioDecoder*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstaudio1_AudioDecoder_virtual_negotiate(void* fnptr, GstAudioDecoder* arg0) {
//   return ((gboolean (*)(GstAudioDecoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioDecoder_virtual_open(void* fnptr, GstAudioDecoder* arg0) {
//   return ((gboolean (*)(GstAudioDecoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioDecoder_virtual_propose_allocation(void* fnptr, GstAudioDecoder* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstAudioDecoder*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstaudio1_AudioDecoder_virtual_set_format(void* fnptr, GstAudioDecoder* arg0, GstCaps* arg1) {
//   return ((gboolean (*)(GstAudioDecoder*, GstCaps*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstaudio1_AudioDecoder_virtual_sink_event(void* fnptr, GstAudioDecoder* arg0, GstEvent* arg1) {
//   return ((gboolean (*)(GstAudioDecoder*, GstEvent*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstaudio1_AudioDecoder_virtual_sink_query(void* fnptr, GstAudioDecoder* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstAudioDecoder*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstaudio1_AudioDecoder_virtual_src_event(void* fnptr, GstAudioDecoder* arg0, GstEvent* arg1) {
//   return ((gboolean (*)(GstAudioDecoder*, GstEvent*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstaudio1_AudioDecoder_virtual_src_query(void* fnptr, GstAudioDecoder* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstAudioDecoder*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstaudio1_AudioDecoder_virtual_start(void* fnptr, GstAudioDecoder* arg0) {
//   return ((gboolean (*)(GstAudioDecoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioDecoder_virtual_stop(void* fnptr, GstAudioDecoder* arg0) {
//   return ((gboolean (*)(GstAudioDecoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioDecoder_virtual_transform_meta(void* fnptr, GstAudioDecoder* arg0, GstBuffer* arg1, GstMeta* arg2, GstBuffer* arg3) {
//   return ((gboolean (*)(GstAudioDecoder*, GstBuffer*, GstMeta*, GstBuffer*))(fnptr))(arg0, arg1, arg2, arg3);
// };
// gboolean _gotk4_gstaudio1_AudioEncoder_virtual_close(void* fnptr, GstAudioEncoder* arg0) {
//   return ((gboolean (*)(GstAudioEncoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioEncoder_virtual_decide_allocation(void* fnptr, GstAudioEncoder* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstAudioEncoder*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstaudio1_AudioEncoder_virtual_negotiate(void* fnptr, GstAudioEncoder* arg0) {
//   return ((gboolean (*)(GstAudioEncoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioEncoder_virtual_open(void* fnptr, GstAudioEncoder* arg0) {
//   return ((gboolean (*)(GstAudioEncoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioEncoder_virtual_propose_allocation(void* fnptr, GstAudioEncoder* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstAudioEncoder*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstaudio1_AudioEncoder_virtual_set_format(void* fnptr, GstAudioEncoder* arg0, GstAudioInfo* arg1) {
//   return ((gboolean (*)(GstAudioEncoder*, GstAudioInfo*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstaudio1_AudioEncoder_virtual_sink_event(void* fnptr, GstAudioEncoder* arg0, GstEvent* arg1) {
//   return ((gboolean (*)(GstAudioEncoder*, GstEvent*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstaudio1_AudioEncoder_virtual_sink_query(void* fnptr, GstAudioEncoder* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstAudioEncoder*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstaudio1_AudioEncoder_virtual_src_event(void* fnptr, GstAudioEncoder* arg0, GstEvent* arg1) {
//   return ((gboolean (*)(GstAudioEncoder*, GstEvent*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstaudio1_AudioEncoder_virtual_src_query(void* fnptr, GstAudioEncoder* arg0, GstQuery* arg1) {
//   return ((gboolean (*)(GstAudioEncoder*, GstQuery*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstaudio1_AudioEncoder_virtual_start(void* fnptr, GstAudioEncoder* arg0) {
//   return ((gboolean (*)(GstAudioEncoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioEncoder_virtual_stop(void* fnptr, GstAudioEncoder* arg0) {
//   return ((gboolean (*)(GstAudioEncoder*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioEncoder_virtual_transform_meta(void* fnptr, GstAudioEncoder* arg0, GstBuffer* arg1, GstMeta* arg2, GstBuffer* arg3) {
//   return ((gboolean (*)(GstAudioEncoder*, GstBuffer*, GstMeta*, GstBuffer*))(fnptr))(arg0, arg1, arg2, arg3);
// };
// gboolean _gotk4_gstaudio1_AudioFilter_virtual_setup(void* fnptr, GstAudioFilter* arg0, GstAudioInfo* arg1) {
//   return ((gboolean (*)(GstAudioFilter*, GstAudioInfo*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstaudio1_AudioRingBuffer_virtual_acquire(void* fnptr, GstAudioRingBuffer* arg0, GstAudioRingBufferSpec* arg1) {
//   return ((gboolean (*)(GstAudioRingBuffer*, GstAudioRingBufferSpec*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstaudio1_AudioRingBuffer_virtual_activate(void* fnptr, GstAudioRingBuffer* arg0, gboolean arg1) {
//   return ((gboolean (*)(GstAudioRingBuffer*, gboolean))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstaudio1_AudioRingBuffer_virtual_close_device(void* fnptr, GstAudioRingBuffer* arg0) {
//   return ((gboolean (*)(GstAudioRingBuffer*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioRingBuffer_virtual_open_device(void* fnptr, GstAudioRingBuffer* arg0) {
//   return ((gboolean (*)(GstAudioRingBuffer*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioRingBuffer_virtual_pause(void* fnptr, GstAudioRingBuffer* arg0) {
//   return ((gboolean (*)(GstAudioRingBuffer*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioRingBuffer_virtual_release(void* fnptr, GstAudioRingBuffer* arg0) {
//   return ((gboolean (*)(GstAudioRingBuffer*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioRingBuffer_virtual_resume(void* fnptr, GstAudioRingBuffer* arg0) {
//   return ((gboolean (*)(GstAudioRingBuffer*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioRingBuffer_virtual_start(void* fnptr, GstAudioRingBuffer* arg0) {
//   return ((gboolean (*)(GstAudioRingBuffer*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioRingBuffer_virtual_stop(void* fnptr, GstAudioRingBuffer* arg0) {
//   return ((gboolean (*)(GstAudioRingBuffer*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioSink_virtual_close(void* fnptr, GstAudioSink* arg0) {
//   return ((gboolean (*)(GstAudioSink*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioSink_virtual_open(void* fnptr, GstAudioSink* arg0) {
//   return ((gboolean (*)(GstAudioSink*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioSink_virtual_prepare(void* fnptr, GstAudioSink* arg0, GstAudioRingBufferSpec* arg1) {
//   return ((gboolean (*)(GstAudioSink*, GstAudioRingBufferSpec*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstaudio1_AudioSink_virtual_unprepare(void* fnptr, GstAudioSink* arg0) {
//   return ((gboolean (*)(GstAudioSink*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioSrc_virtual_close(void* fnptr, GstAudioSrc* arg0) {
//   return ((gboolean (*)(GstAudioSrc*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioSrc_virtual_open(void* fnptr, GstAudioSrc* arg0) {
//   return ((gboolean (*)(GstAudioSrc*))(fnptr))(arg0);
// };
// gboolean _gotk4_gstaudio1_AudioSrc_virtual_prepare(void* fnptr, GstAudioSrc* arg0, GstAudioRingBufferSpec* arg1) {
//   return ((gboolean (*)(GstAudioSrc*, GstAudioRingBufferSpec*))(fnptr))(arg0, arg1);
// };
// gboolean _gotk4_gstaudio1_AudioSrc_virtual_unprepare(void* fnptr, GstAudioSrc* arg0) {
//   return ((gboolean (*)(GstAudioSrc*))(fnptr))(arg0);
// };
// gint _gotk4_gstaudio1_AudioSink_virtual_write(void* fnptr, GstAudioSink* arg0, gpointer arg1, guint arg2) {
//   return ((gint (*)(GstAudioSink*, gpointer, guint))(fnptr))(arg0, arg1, arg2);
// };
// guint _gotk4_gstaudio1_AudioRingBuffer_virtual_delay(void* fnptr, GstAudioRingBuffer* arg0) {
//   return ((guint (*)(GstAudioRingBuffer*))(fnptr))(arg0);
// };
// guint _gotk4_gstaudio1_AudioSink_virtual_delay(void* fnptr, GstAudioSink* arg0) {
//   return ((guint (*)(GstAudioSink*))(fnptr))(arg0);
// };
// guint _gotk4_gstaudio1_AudioSrc_virtual_delay(void* fnptr, GstAudioSrc* arg0) {
//   return ((guint (*)(GstAudioSrc*))(fnptr))(arg0);
// };
// guint _gotk4_gstaudio1_AudioSrc_virtual_read(void* fnptr, GstAudioSrc* arg0, gpointer arg1, guint arg2, GstClockTime* arg3) {
//   return ((guint (*)(GstAudioSrc*, gpointer, guint, GstClockTime*))(fnptr))(arg0, arg1, arg2, arg3);
// };
// void _gotk4_gstaudio1_AudioAggregatorPad_virtual_update_conversion_info(void* fnptr, GstAudioAggregatorPad* arg0) {
//   ((void (*)(GstAudioAggregatorPad*))(fnptr))(arg0);
// };
// void _gotk4_gstaudio1_AudioCdSrc_virtual_close(void* fnptr, GstAudioCdSrc* arg0) {
//   ((void (*)(GstAudioCdSrc*))(fnptr))(arg0);
// };
// void _gotk4_gstaudio1_AudioDecoder_virtual_flush(void* fnptr, GstAudioDecoder* arg0, gboolean arg1) {
//   ((void (*)(GstAudioDecoder*, gboolean))(fnptr))(arg0, arg1);
// };
// void _gotk4_gstaudio1_AudioEncoder_virtual_flush(void* fnptr, GstAudioEncoder* arg0) {
//   ((void (*)(GstAudioEncoder*))(fnptr))(arg0);
// };
// void _gotk4_gstaudio1_AudioRingBuffer_virtual_clear_all(void* fnptr, GstAudioRingBuffer* arg0) {
//   ((void (*)(GstAudioRingBuffer*))(fnptr))(arg0);
// };
// void _gotk4_gstaudio1_AudioSink_virtual_pause(void* fnptr, GstAudioSink* arg0) {
//   ((void (*)(GstAudioSink*))(fnptr))(arg0);
// };
// void _gotk4_gstaudio1_AudioSink_virtual_reset(void* fnptr, GstAudioSink* arg0) {
//   ((void (*)(GstAudioSink*))(fnptr))(arg0);
// };
// void _gotk4_gstaudio1_AudioSink_virtual_resume(void* fnptr, GstAudioSink* arg0) {
//   ((void (*)(GstAudioSink*))(fnptr))(arg0);
// };
// void _gotk4_gstaudio1_AudioSink_virtual_stop(void* fnptr, GstAudioSink* arg0) {
//   ((void (*)(GstAudioSink*))(fnptr))(arg0);
// };
// void _gotk4_gstaudio1_AudioSrc_virtual_reset(void* fnptr, GstAudioSrc* arg0) {
//   ((void (*)(GstAudioSrc*))(fnptr))(arg0);
// };
import "C"

// GType values.
var (
	GTypeAudioBaseSinkDiscontReason        = coreglib.Type(C.gst_audio_base_sink_discont_reason_get_type())
	GTypeAudioBaseSinkSlaveMethod          = coreglib.Type(C.gst_audio_base_sink_slave_method_get_type())
	GTypeAudioBaseSrcSlaveMethod           = coreglib.Type(C.gst_audio_base_src_slave_method_get_type())
	GTypeAudioCdSrcMode                    = coreglib.Type(C.gst_audio_cd_src_mode_get_type())
	GTypeAudioChannelPosition              = coreglib.Type(C.gst_audio_channel_position_get_type())
	GTypeAudioDitherMethod                 = coreglib.Type(C.gst_audio_dither_method_get_type())
	GTypeAudioFormat                       = coreglib.Type(C.gst_audio_format_get_type())
	GTypeAudioLayout                       = coreglib.Type(C.gst_audio_layout_get_type())
	GTypeAudioNoiseShapingMethod           = coreglib.Type(C.gst_audio_noise_shaping_method_get_type())
	GTypeAudioResamplerFilterInterpolation = coreglib.Type(C.gst_audio_resampler_filter_interpolation_get_type())
	GTypeAudioResamplerFilterMode          = coreglib.Type(C.gst_audio_resampler_filter_mode_get_type())
	GTypeAudioResamplerMethod              = coreglib.Type(C.gst_audio_resampler_method_get_type())
	GTypeAudioRingBufferFormatType         = coreglib.Type(C.gst_audio_ring_buffer_format_type_get_type())
	GTypeAudioRingBufferState              = coreglib.Type(C.gst_audio_ring_buffer_state_get_type())
	GTypeDsdFormat                         = coreglib.Type(C.gst_dsd_format_get_type())
	GTypeAudioChannelMixerFlags            = coreglib.Type(C.gst_audio_channel_mixer_flags_get_type())
	GTypeAudioConverterFlags               = coreglib.Type(C.gst_audio_converter_flags_get_type())
	GTypeAudioFlags                        = coreglib.Type(C.gst_audio_flags_get_type())
	GTypeAudioFormatFlags                  = coreglib.Type(C.gst_audio_format_flags_get_type())
	GTypeAudioPackFlags                    = coreglib.Type(C.gst_audio_pack_flags_get_type())
	GTypeAudioQuantizeFlags                = coreglib.Type(C.gst_audio_quantize_flags_get_type())
	GTypeAudioResamplerFlags               = coreglib.Type(C.gst_audio_resampler_flags_get_type())
	GTypeStreamVolume                      = coreglib.Type(C.gst_stream_volume_get_type())
	GTypeAudioAggregator                   = coreglib.Type(C.gst_audio_aggregator_get_type())
	GTypeAudioAggregatorConvertPad         = coreglib.Type(C.gst_audio_aggregator_convert_pad_get_type())
	GTypeAudioAggregatorPad                = coreglib.Type(C.gst_audio_aggregator_pad_get_type())
	GTypeAudioBaseSink                     = coreglib.Type(C.gst_audio_base_sink_get_type())
	GTypeAudioBaseSrc                      = coreglib.Type(C.gst_audio_base_src_get_type())
	GTypeAudioCdSrc                        = coreglib.Type(C.gst_audio_cd_src_get_type())
	GTypeAudioClock                        = coreglib.Type(C.gst_audio_clock_get_type())
	GTypeAudioDecoder                      = coreglib.Type(C.gst_audio_decoder_get_type())
	GTypeAudioEncoder                      = coreglib.Type(C.gst_audio_encoder_get_type())
	GTypeAudioFilter                       = coreglib.Type(C.gst_audio_filter_get_type())
	GTypeAudioRingBuffer                   = coreglib.Type(C.gst_audio_ring_buffer_get_type())
	GTypeAudioSink                         = coreglib.Type(C.gst_audio_sink_get_type())
	GTypeAudioSrc                          = coreglib.Type(C.gst_audio_src_get_type())
	GTypeAudioConverter                    = coreglib.Type(C.gst_audio_converter_get_type())
	GTypeAudioFormatInfo                   = coreglib.Type(C.gst_audio_format_info_get_type())
	GTypeAudioInfo                         = coreglib.Type(C.gst_audio_info_get_type())
	GTypeAudioStreamAlign                  = coreglib.Type(C.gst_audio_stream_align_get_type())
	GTypeDsdInfo                           = coreglib.Type(C.gst_dsd_info_get_type())
)

func init() {
	coreglib.RegisterGValueMarshalers([]coreglib.TypeMarshaler{
		coreglib.TypeMarshaler{T: GTypeAudioBaseSinkDiscontReason, F: marshalAudioBaseSinkDiscontReason},
		coreglib.TypeMarshaler{T: GTypeAudioBaseSinkSlaveMethod, F: marshalAudioBaseSinkSlaveMethod},
		coreglib.TypeMarshaler{T: GTypeAudioBaseSrcSlaveMethod, F: marshalAudioBaseSrcSlaveMethod},
		coreglib.TypeMarshaler{T: GTypeAudioCdSrcMode, F: marshalAudioCdSrcMode},
		coreglib.TypeMarshaler{T: GTypeAudioChannelPosition, F: marshalAudioChannelPosition},
		coreglib.TypeMarshaler{T: GTypeAudioDitherMethod, F: marshalAudioDitherMethod},
		coreglib.TypeMarshaler{T: GTypeAudioFormat, F: marshalAudioFormat},
		coreglib.TypeMarshaler{T: GTypeAudioLayout, F: marshalAudioLayout},
		coreglib.TypeMarshaler{T: GTypeAudioNoiseShapingMethod, F: marshalAudioNoiseShapingMethod},
		coreglib.TypeMarshaler{T: GTypeAudioResamplerFilterInterpolation, F: marshalAudioResamplerFilterInterpolation},
		coreglib.TypeMarshaler{T: GTypeAudioResamplerFilterMode, F: marshalAudioResamplerFilterMode},
		coreglib.TypeMarshaler{T: GTypeAudioResamplerMethod, F: marshalAudioResamplerMethod},
		coreglib.TypeMarshaler{T: GTypeAudioRingBufferFormatType, F: marshalAudioRingBufferFormatType},
		coreglib.TypeMarshaler{T: GTypeAudioRingBufferState, F: marshalAudioRingBufferState},
		coreglib.TypeMarshaler{T: GTypeDsdFormat, F: marshalDsdFormat},
		coreglib.TypeMarshaler{T: GTypeAudioChannelMixerFlags, F: marshalAudioChannelMixerFlags},
		coreglib.TypeMarshaler{T: GTypeAudioConverterFlags, F: marshalAudioConverterFlags},
		coreglib.TypeMarshaler{T: GTypeAudioFlags, F: marshalAudioFlags},
		coreglib.TypeMarshaler{T: GTypeAudioFormatFlags, F: marshalAudioFormatFlags},
		coreglib.TypeMarshaler{T: GTypeAudioPackFlags, F: marshalAudioPackFlags},
		coreglib.TypeMarshaler{T: GTypeAudioQuantizeFlags, F: marshalAudioQuantizeFlags},
		coreglib.TypeMarshaler{T: GTypeAudioResamplerFlags, F: marshalAudioResamplerFlags},
		coreglib.TypeMarshaler{T: GTypeStreamVolume, F: marshalStreamVolume},
		coreglib.TypeMarshaler{T: GTypeAudioAggregator, F: marshalAudioAggregator},
		coreglib.TypeMarshaler{T: GTypeAudioAggregatorConvertPad, F: marshalAudioAggregatorConvertPad},
		coreglib.TypeMarshaler{T: GTypeAudioAggregatorPad, F: marshalAudioAggregatorPad},
		coreglib.TypeMarshaler{T: GTypeAudioBaseSink, F: marshalAudioBaseSink},
		coreglib.TypeMarshaler{T: GTypeAudioBaseSrc, F: marshalAudioBaseSrc},
		coreglib.TypeMarshaler{T: GTypeAudioCdSrc, F: marshalAudioCdSrc},
		coreglib.TypeMarshaler{T: GTypeAudioClock, F: marshalAudioClock},
		coreglib.TypeMarshaler{T: GTypeAudioDecoder, F: marshalAudioDecoder},
		coreglib.TypeMarshaler{T: GTypeAudioEncoder, F: marshalAudioEncoder},
		coreglib.TypeMarshaler{T: GTypeAudioFilter, F: marshalAudioFilter},
		coreglib.TypeMarshaler{T: GTypeAudioRingBuffer, F: marshalAudioRingBuffer},
		coreglib.TypeMarshaler{T: GTypeAudioSink, F: marshalAudioSink},
		coreglib.TypeMarshaler{T: GTypeAudioSrc, F: marshalAudioSrc},
		coreglib.TypeMarshaler{T: GTypeAudioConverter, F: marshalAudioConverter},
		coreglib.TypeMarshaler{T: GTypeAudioFormatInfo, F: marshalAudioFormatInfo},
		coreglib.TypeMarshaler{T: GTypeAudioInfo, F: marshalAudioInfo},
		coreglib.TypeMarshaler{T: GTypeAudioStreamAlign, F: marshalAudioStreamAlign},
		coreglib.TypeMarshaler{T: GTypeDsdInfo, F: marshalDsdInfo},
	})
}

// AUDIO_CHANNELS_RANGE (GST_AUDIO_CHANNELS_RANGE): maximum range of allowed
// channels, for use in template caps strings.
const AUDIO_CHANNELS_RANGE = "(int) [ 1, max ]"

// AUDIO_CONVERTER_OPT_DITHER_METHOD (GST_AUDIO_CONVERTER_OPT_DITHER_METHOD) The
// dither method to use when changing bit depth. Default is T_AUDIO_DITHER_NONE.
const AUDIO_CONVERTER_OPT_DITHER_METHOD = "GstAudioConverter.dither-method"

// AUDIO_CONVERTER_OPT_DITHER_THRESHOLD
// (GST_AUDIO_CONVERTER_OPT_DITHER_THRESHOLD): threshold for the output bit
// depth at/below which to apply dithering.
//
// Default is 20 bit.
const AUDIO_CONVERTER_OPT_DITHER_THRESHOLD = "GstAudioConverter.dither-threshold"

// AUDIO_CONVERTER_OPT_MIX_MATRIX (GST_AUDIO_CONVERTER_OPT_MIX_MATRIX) The
// channel mapping matrix.
//
// The matrix coefficients must be between -1 and 1: the number of rows is equal
// to the number of output channels and the number of columns is equal to the
// number of input channels.
//
// # Example matrix generation code
//
// To generate the matrix using code:
//
//	GValue v = G_VALUE_INIT;
//	GValue v2 = G_VALUE_INIT;
//	GValue v3 = G_VALUE_INIT;
//
//	g_value_init (&v2, GST_TYPE_ARRAY);
//	g_value_init (&v3, G_TYPE_DOUBLE);
//	g_value_set_double (&v3, 1);
//	gst_value_array_append_value (&v2, &v3);
//	g_value_unset (&v3);
//	[ Repeat for as many double as your input channels - unset and reinit v3 ]
//	g_value_init (&v, GST_TYPE_ARRAY);
//	gst_value_array_append_value (&v, &v2);
//	g_value_unset (&v2);
//	[ Repeat for as many v2's as your output channels - unset and reinit v2]
//	g_object_set_property (G_OBJECT (audiomixmatrix), "matrix", &v);
//	g_value_unset (&v);.
const AUDIO_CONVERTER_OPT_MIX_MATRIX = "GstAudioConverter.mix-matrix"

// AUDIO_CONVERTER_OPT_NOISE_SHAPING_METHOD
// (GST_AUDIO_CONVERTER_OPT_NOISE_SHAPING_METHOD) The noise shaping
// method to use to mask noise from quantization errors. Default is
// T_AUDIO_NOISE_SHAPING_NONE.
const AUDIO_CONVERTER_OPT_NOISE_SHAPING_METHOD = "GstAudioConverter.noise-shaping-method"

// AUDIO_CONVERTER_OPT_QUANTIZATION (GST_AUDIO_CONVERTER_OPT_QUANTIZATION) The
// quantization amount. Components will be quantized to multiples of this value.
// Default is 1.
const AUDIO_CONVERTER_OPT_QUANTIZATION = "GstAudioConverter.quantization"

// AUDIO_CONVERTER_OPT_RESAMPLER_METHOD
// (GST_AUDIO_CONVERTER_OPT_RESAMPLER_METHOD) The resampler method to use when
// changing sample rates. Default is T_AUDIO_RESAMPLER_METHOD_BLACKMAN_NUTTALL.
const AUDIO_CONVERTER_OPT_RESAMPLER_METHOD = "GstAudioConverter.resampler-method"

// AUDIO_DECODER_MAX_ERRORS (GST_AUDIO_DECODER_MAX_ERRORS): default maximum
// number of errors tolerated before signaling error.
const AUDIO_DECODER_MAX_ERRORS = -1

// AUDIO_DECODER_SINK_NAME (GST_AUDIO_DECODER_SINK_NAME): name of the templates
// for the sink pad.
const AUDIO_DECODER_SINK_NAME = "sink"

// AUDIO_DECODER_SRC_NAME (GST_AUDIO_DECODER_SRC_NAME): name of the templates
// for the source pad.
const AUDIO_DECODER_SRC_NAME = "src"

// AUDIO_DEF_CHANNELS (GST_AUDIO_DEF_CHANNELS): standard number of channels used
// in consumer audio.
const AUDIO_DEF_CHANNELS = 2

// AUDIO_DEF_FORMAT (GST_AUDIO_DEF_FORMAT): standard format used in consumer
// audio.
const AUDIO_DEF_FORMAT = "S16LE"

// AUDIO_DEF_RATE (GST_AUDIO_DEF_RATE): standard sampling rate used in consumer
// audio.
const AUDIO_DEF_RATE = 44100

// AUDIO_ENCODER_SINK_NAME (GST_AUDIO_ENCODER_SINK_NAME): name of the templates
// for the sink pad.
const AUDIO_ENCODER_SINK_NAME = "sink"

// AUDIO_ENCODER_SRC_NAME (GST_AUDIO_ENCODER_SRC_NAME): name of the templates
// for the source pad.
const AUDIO_ENCODER_SRC_NAME = "src"

// AUDIO_FORMATS_ALL (GST_AUDIO_FORMATS_ALL): list of all audio formats, for use
// in template caps strings.
//
// Formats are sorted by decreasing "quality", using these criteria by priority:
// - depth - width - Float > Signed > Unsigned - native endianness preferred.
const AUDIO_FORMATS_ALL = "{ F64BE, F64LE, F32BE, F32LE, S32BE, S32LE, U32BE, U32LE, S24_32BE, S24_32LE, U24_32BE, U24_32LE, S24BE, S24LE, U24BE, U24LE, S20BE, S20LE, U20BE, U20LE, S18BE, S18LE, U18BE, U18LE, S16BE, S16LE, U16BE, U16LE, S8, U8 }"

// AUDIO_RATE_RANGE (GST_AUDIO_RATE_RANGE): maximum range of allowed sample
// rates, for use in template caps strings.
const AUDIO_RATE_RANGE = "(int) [ 1, max ]"

// AUDIO_RESAMPLER_OPT_CUBIC_B (GST_AUDIO_RESAMPLER_OPT_CUBIC_B): g_TYPE_DOUBLE,
// B parameter of the cubic filter. Values between 0.0 and 2.0 are accepted.
// 1.0 is the default.
//
// Below are some values of popular filters: B C Hermite 0.0 0.0 Spline 1.0 0.0
// Catmull-Rom 0.0 1/2.
const AUDIO_RESAMPLER_OPT_CUBIC_B = "GstAudioResampler.cubic-b"

// AUDIO_RESAMPLER_OPT_CUBIC_C (GST_AUDIO_RESAMPLER_OPT_CUBIC_C): g_TYPE_DOUBLE,
// C parameter of the cubic filter. Values between 0.0 and 2.0 are accepted.
// 0.0 is the default.
//
// See T_AUDIO_RESAMPLER_OPT_CUBIC_B for some more common values.
const AUDIO_RESAMPLER_OPT_CUBIC_C = "GstAudioResampler.cubic-c"

// AUDIO_RESAMPLER_OPT_CUTOFF (GST_AUDIO_RESAMPLER_OPT_CUTOFF): g_TYPE_DOUBLE,
// Cutoff parameter for the filter. 0.940 is the default.
const AUDIO_RESAMPLER_OPT_CUTOFF = "GstAudioResampler.cutoff"

// AUDIO_RESAMPLER_OPT_FILTER_INTERPOLATION
// (GST_AUDIO_RESAMPLER_OPT_FILTER_INTERPOLATION):
// GST_TYPE_AUDIO_RESAMPLER_INTERPOLATION: how the filter coefficients should be
// interpolated. GST_AUDIO_RESAMPLER_FILTER_INTERPOLATION_CUBIC is default.
const AUDIO_RESAMPLER_OPT_FILTER_INTERPOLATION = "GstAudioResampler.filter-interpolation"

// AUDIO_RESAMPLER_OPT_FILTER_MODE (GST_AUDIO_RESAMPLER_OPT_FILTER_MODE):
// GST_TYPE_AUDIO_RESAMPLER_FILTER_MODE: how the filter tables should be
// constructed. GST_AUDIO_RESAMPLER_FILTER_MODE_AUTO is the default.
const AUDIO_RESAMPLER_OPT_FILTER_MODE = "GstAudioResampler.filter-mode"

// AUDIO_RESAMPLER_OPT_FILTER_MODE_THRESHOLD
// (GST_AUDIO_RESAMPLER_OPT_FILTER_MODE_THRESHOLD): g_TYPE_UINT: the amount of
// memory to use for full filter tables before switching to interpolated filter
// tables. 1048576 is the default.
const AUDIO_RESAMPLER_OPT_FILTER_MODE_THRESHOLD = "GstAudioResampler.filter-mode-threshold"

// AUDIO_RESAMPLER_OPT_FILTER_OVERSAMPLE
// (GST_AUDIO_RESAMPLER_OPT_FILTER_OVERSAMPLE): g_TYPE_UINT, oversampling to use
// when interpolating filters 8 is the default.
const AUDIO_RESAMPLER_OPT_FILTER_OVERSAMPLE = "GstAudioResampler.filter-oversample"

// AUDIO_RESAMPLER_OPT_MAX_PHASE_ERROR
// (GST_AUDIO_RESAMPLER_OPT_MAX_PHASE_ERROR): g_TYPE_DOUBLE: The maximum allowed
// phase error when switching sample rates. 0.1 is the default.
const AUDIO_RESAMPLER_OPT_MAX_PHASE_ERROR = "GstAudioResampler.max-phase-error"

// AUDIO_RESAMPLER_OPT_N_TAPS (GST_AUDIO_RESAMPLER_OPT_N_TAPS): g_TYPE_INT:
// the number of taps to use for the filter. 0 is the default and selects the
// taps automatically.
const AUDIO_RESAMPLER_OPT_N_TAPS = "GstAudioResampler.n-taps"

// AUDIO_RESAMPLER_OPT_STOP_ATTENUATION
// (GST_AUDIO_RESAMPLER_OPT_STOP_ATTENUATION): g_TYPE_DOUBLE, stopband
// attenuation in decibels. The attenuation after the stopband for the kaiser
// window. 85 dB is the default.
const AUDIO_RESAMPLER_OPT_STOP_ATTENUATION = "GstAudioResampler.stop-attenutation"

// AUDIO_RESAMPLER_OPT_TRANSITION_BANDWIDTH
// (GST_AUDIO_RESAMPLER_OPT_TRANSITION_BANDWIDTH): g_TYPE_DOUBLE, transition
// bandwidth. The width of the transition band for the kaiser window. 0.087 is
// the default.
const AUDIO_RESAMPLER_OPT_TRANSITION_BANDWIDTH = "GstAudioResampler.transition-bandwidth"
const AUDIO_RESAMPLER_QUALITY_DEFAULT = 4
const AUDIO_RESAMPLER_QUALITY_MAX = 10
const AUDIO_RESAMPLER_QUALITY_MIN = 0

// DSD_FORMATS_ALL (GST_DSD_FORMATS_ALL): list of all DSD formats, for use in
// template caps strings.
//
// Big endian formats are preferred, since little-endian ones flip around the
// DSD bytes, and most DSD hardware uses big endian formats.
const DSD_FORMATS_ALL = "{ DSDU32BE, DSDU16BE, DSDU8, DSDU32LE, DSDU16LE }"

// DSD_MEDIA_TYPE (GST_DSD_MEDIA_TYPE): GStreamer media type for DSD.
const DSD_MEDIA_TYPE = "audio/x-dsd"

// DSD_SILENCE_PATTERN_BYTE (GST_DSD_SILENCE_PATTERN_BYTE): silence pattern for
// DSD data.
//
// In DSD, a nullbyte does not correspond to silence. To fill memory regions
// with "DSD silence", these regions must be filled with byte 0x69 instead (this
// is the DSD silence pattern). This constant provides that pattern in a more
// readable fashion.
const DSD_SILENCE_PATTERN_BYTE = 105

// META_TAG_AUDIO_CHANNELS_STR (GST_META_TAG_AUDIO_CHANNELS_STR): this metadata
// stays relevant as long as channels are unchanged.
const META_TAG_AUDIO_CHANNELS_STR = "channels"

// META_TAG_AUDIO_RATE_STR (GST_META_TAG_AUDIO_RATE_STR): this metadata stays
// relevant as long as sample rate is unchanged.
const META_TAG_AUDIO_RATE_STR = "rate"

// META_TAG_AUDIO_STR (GST_META_TAG_AUDIO_STR): this metadata is relevant for
// audio streams.
const META_TAG_AUDIO_STR = "audio"

// META_TAG_DSD_PLANE_OFFSETS_STR (GST_META_TAG_DSD_PLANE_OFFSETS_STR): this
// metadata stays relevant as long as the DSD plane offsets are unchanged.
const META_TAG_DSD_PLANE_OFFSETS_STR = "dsdplaneoffsets"

// AudioBaseSinkDiscontReason (GstAudioBaseSinkDiscontReason): different
// possible reasons for discontinuities. This enum is useful for the custom
// slave method.
type AudioBaseSinkDiscontReason C.gint

const (
	// AudioBaseSinkDiscontReasonNoDiscont
	// (GST_AUDIO_BASE_SINK_DISCONT_REASON_NO_DISCONT): no discontinuity
	// occurred.
	AudioBaseSinkDiscontReasonNoDiscont AudioBaseSinkDiscontReason = iota
	// AudioBaseSinkDiscontReasonNewCaps
	// (GST_AUDIO_BASE_SINK_DISCONT_REASON_NEW_CAPS): new caps are set, causing
	// renegotiotion.
	AudioBaseSinkDiscontReasonNewCaps
	// AudioBaseSinkDiscontReasonFlush
	// (GST_AUDIO_BASE_SINK_DISCONT_REASON_FLUSH) samples have been flushed.
	AudioBaseSinkDiscontReasonFlush
	// AudioBaseSinkDiscontReasonSyncLatency
	// (GST_AUDIO_BASE_SINK_DISCONT_REASON_SYNC_LATENCY): sink was synchronized
	// to the estimated latency (occurs during initialization).
	AudioBaseSinkDiscontReasonSyncLatency
	// AudioBaseSinkDiscontReasonAlignment
	// (GST_AUDIO_BASE_SINK_DISCONT_REASON_ALIGNMENT): aligning buffers failed
	// because the timestamps are too discontinuous.
	AudioBaseSinkDiscontReasonAlignment
	// AudioBaseSinkDiscontReasonDeviceFailure
	// (GST_AUDIO_BASE_SINK_DISCONT_REASON_DEVICE_FAILURE): audio output device
	// experienced and recovered from an error but introduced latency in the
	// process (see also gst_audio_base_sink_report_device_failure()).
	AudioBaseSinkDiscontReasonDeviceFailure
)

func marshalAudioBaseSinkDiscontReason(p uintptr) (interface{}, error) {
	return AudioBaseSinkDiscontReason(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for AudioBaseSinkDiscontReason.
func (a AudioBaseSinkDiscontReason) String() string {
	switch a {
	case AudioBaseSinkDiscontReasonNoDiscont:
		return "NoDiscont"
	case AudioBaseSinkDiscontReasonNewCaps:
		return "NewCaps"
	case AudioBaseSinkDiscontReasonFlush:
		return "Flush"
	case AudioBaseSinkDiscontReasonSyncLatency:
		return "SyncLatency"
	case AudioBaseSinkDiscontReasonAlignment:
		return "Alignment"
	case AudioBaseSinkDiscontReasonDeviceFailure:
		return "DeviceFailure"
	default:
		return fmt.Sprintf("AudioBaseSinkDiscontReason(%d)", a)
	}
}

// AudioBaseSinkSlaveMethod (GstAudioBaseSinkSlaveMethod): different possible
// clock slaving algorithms used when the internal audio clock is not selected
// as the pipeline master clock.
type AudioBaseSinkSlaveMethod C.gint

const (
	// AudioBaseSinkSlaveResample (GST_AUDIO_BASE_SINK_SLAVE_RESAMPLE): resample
	// to match the master clock.
	AudioBaseSinkSlaveResample AudioBaseSinkSlaveMethod = iota
	// AudioBaseSinkSlaveSkew (GST_AUDIO_BASE_SINK_SLAVE_SKEW): adjust playout
	// pointer when master clock drifts too much.
	AudioBaseSinkSlaveSkew
	// AudioBaseSinkSlaveNone (GST_AUDIO_BASE_SINK_SLAVE_NONE): no adjustment is
	// done.
	AudioBaseSinkSlaveNone
	// AudioBaseSinkSlaveCustom (GST_AUDIO_BASE_SINK_SLAVE_CUSTOM): use custom
	// clock slaving algorithm (Since: 1.6).
	AudioBaseSinkSlaveCustom
)

func marshalAudioBaseSinkSlaveMethod(p uintptr) (interface{}, error) {
	return AudioBaseSinkSlaveMethod(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for AudioBaseSinkSlaveMethod.
func (a AudioBaseSinkSlaveMethod) String() string {
	switch a {
	case AudioBaseSinkSlaveResample:
		return "Resample"
	case AudioBaseSinkSlaveSkew:
		return "Skew"
	case AudioBaseSinkSlaveNone:
		return "None"
	case AudioBaseSinkSlaveCustom:
		return "Custom"
	default:
		return fmt.Sprintf("AudioBaseSinkSlaveMethod(%d)", a)
	}
}

// AudioBaseSrcSlaveMethod (GstAudioBaseSrcSlaveMethod): different possible
// clock slaving algorithms when the internal audio clock was not selected as
// the pipeline clock.
type AudioBaseSrcSlaveMethod C.gint

const (
	// AudioBaseSrcSlaveResample (GST_AUDIO_BASE_SRC_SLAVE_RESAMPLE): resample
	// to match the master clock.
	AudioBaseSrcSlaveResample AudioBaseSrcSlaveMethod = iota
	// AudioBaseSrcSlaveReTimestamp (GST_AUDIO_BASE_SRC_SLAVE_RE_TIMESTAMP):
	// retimestamp output buffers with master clock time.
	AudioBaseSrcSlaveReTimestamp
	// AudioBaseSrcSlaveSkew (GST_AUDIO_BASE_SRC_SLAVE_SKEW): adjust capture
	// pointer when master clock drifts too much.
	AudioBaseSrcSlaveSkew
	// AudioBaseSrcSlaveNone (GST_AUDIO_BASE_SRC_SLAVE_NONE): no adjustment is
	// done.
	AudioBaseSrcSlaveNone
)

func marshalAudioBaseSrcSlaveMethod(p uintptr) (interface{}, error) {
	return AudioBaseSrcSlaveMethod(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for AudioBaseSrcSlaveMethod.
func (a AudioBaseSrcSlaveMethod) String() string {
	switch a {
	case AudioBaseSrcSlaveResample:
		return "Resample"
	case AudioBaseSrcSlaveReTimestamp:
		return "ReTimestamp"
	case AudioBaseSrcSlaveSkew:
		return "Skew"
	case AudioBaseSrcSlaveNone:
		return "None"
	default:
		return fmt.Sprintf("AudioBaseSrcSlaveMethod(%d)", a)
	}
}

// AudioCdSrcMode (GstAudioCdSrcMode): mode in which the CD audio source
// operates. Influences timestamping, EOS handling and seeking.
type AudioCdSrcMode C.gint

const (
	// AudioCdSrcModeNormal (GST_AUDIO_CD_SRC_MODE_NORMAL): each single track is
	// a stream.
	AudioCdSrcModeNormal AudioCdSrcMode = iota
	// AudioCdSrcModeContinuous (GST_AUDIO_CD_SRC_MODE_CONTINUOUS): entire disc
	// is a single stream.
	AudioCdSrcModeContinuous
)

func marshalAudioCdSrcMode(p uintptr) (interface{}, error) {
	return AudioCdSrcMode(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for AudioCdSrcMode.
func (a AudioCdSrcMode) String() string {
	switch a {
	case AudioCdSrcModeNormal:
		return "Normal"
	case AudioCdSrcModeContinuous:
		return "Continuous"
	default:
		return fmt.Sprintf("AudioCdSrcMode(%d)", a)
	}
}

// AudioChannelPosition (GstAudioChannelPosition): audio channel positions.
//
// These are the channels defined in SMPTE 2036-2-2008 Table 1 for 22.2 audio
// systems with the Surround and Wide channels from DTS Coherent Acoustics
// (v.1.3.1) and 10.2 and 7.1 layouts. In the caps the actual channel layout
// is expressed with a channel count and a channel mask, which describes the
// existing channels. The positions in the bit mask correspond to the enum
// values. For negotiation it is allowed to have more bits set in the channel
// mask than the number of channels to specify the allowed channel positions but
// this is not allowed in negotiated caps. It is not allowed in any situation
// other than the one mentioned below to have less bits set in the channel mask
// than the number of channels.
//
// GST_AUDIO_CHANNEL_POSITION_MONO can only be used with a single mono channel
// that has no direction information and would be mixed into all directional
// channels. This is expressed in caps by having a single channel and no channel
// mask.
//
// GST_AUDIO_CHANNEL_POSITION_NONE can only be used if all channels have this
// position. This is expressed in caps by having a channel mask with no bits
// set.
//
// As another special case it is allowed to have two channels without a channel
// mask. This implicitly means that this is a stereo stream with a front left
// and front right channel.
type AudioChannelPosition C.gint

const (
	// AudioChannelPositionNone (GST_AUDIO_CHANNEL_POSITION_NONE): used for
	// position-less channels, e.g. from a sound card that records 1024
	// channels; mutually exclusive with any other channel position.
	AudioChannelPositionNone AudioChannelPosition = -3
	// AudioChannelPositionMono (GST_AUDIO_CHANNEL_POSITION_MONO): mono without
	// direction; can only be used with 1 channel.
	AudioChannelPositionMono AudioChannelPosition = -2
	// AudioChannelPositionInvalid (GST_AUDIO_CHANNEL_POSITION_INVALID):
	// invalid position.
	AudioChannelPositionInvalid AudioChannelPosition = -1
	// AudioChannelPositionFrontLeft (GST_AUDIO_CHANNEL_POSITION_FRONT_LEFT):
	// front left.
	AudioChannelPositionFrontLeft AudioChannelPosition = 0
	// AudioChannelPositionFrontRight (GST_AUDIO_CHANNEL_POSITION_FRONT_RIGHT):
	// front right.
	AudioChannelPositionFrontRight AudioChannelPosition = 1
	// AudioChannelPositionFrontCenter
	// (GST_AUDIO_CHANNEL_POSITION_FRONT_CENTER): front center.
	AudioChannelPositionFrontCenter AudioChannelPosition = 2
	// AudioChannelPositionLfe1 (GST_AUDIO_CHANNEL_POSITION_LFE1): low-frequency
	// effects 1 (subwoofer).
	AudioChannelPositionLfe1 AudioChannelPosition = 3
	// AudioChannelPositionRearLeft (GST_AUDIO_CHANNEL_POSITION_REAR_LEFT):
	// rear left.
	AudioChannelPositionRearLeft AudioChannelPosition = 4
	// AudioChannelPositionRearRight (GST_AUDIO_CHANNEL_POSITION_REAR_RIGHT):
	// rear right.
	AudioChannelPositionRearRight AudioChannelPosition = 5
	// AudioChannelPositionFrontLeftOfCenter
	// (GST_AUDIO_CHANNEL_POSITION_FRONT_LEFT_OF_CENTER): front left of center.
	AudioChannelPositionFrontLeftOfCenter AudioChannelPosition = 6
	// AudioChannelPositionFrontRightOfCenter
	// (GST_AUDIO_CHANNEL_POSITION_FRONT_RIGHT_OF_CENTER): front right of
	// center.
	AudioChannelPositionFrontRightOfCenter AudioChannelPosition = 7
	// AudioChannelPositionRearCenter (GST_AUDIO_CHANNEL_POSITION_REAR_CENTER):
	// rear center.
	AudioChannelPositionRearCenter AudioChannelPosition = 8
	// AudioChannelPositionLfe2 (GST_AUDIO_CHANNEL_POSITION_LFE2): low-frequency
	// effects 2 (subwoofer).
	AudioChannelPositionLfe2 AudioChannelPosition = 9
	// AudioChannelPositionSideLeft (GST_AUDIO_CHANNEL_POSITION_SIDE_LEFT):
	// side left.
	AudioChannelPositionSideLeft AudioChannelPosition = 10
	// AudioChannelPositionSideRight (GST_AUDIO_CHANNEL_POSITION_SIDE_RIGHT):
	// side right.
	AudioChannelPositionSideRight AudioChannelPosition = 11
	// AudioChannelPositionTopFrontLeft
	// (GST_AUDIO_CHANNEL_POSITION_TOP_FRONT_LEFT): top front left.
	AudioChannelPositionTopFrontLeft AudioChannelPosition = 12
	// AudioChannelPositionTopFrontRight
	// (GST_AUDIO_CHANNEL_POSITION_TOP_FRONT_RIGHT): top front right.
	AudioChannelPositionTopFrontRight AudioChannelPosition = 13
	// AudioChannelPositionTopFrontCenter
	// (GST_AUDIO_CHANNEL_POSITION_TOP_FRONT_CENTER): top front center.
	AudioChannelPositionTopFrontCenter AudioChannelPosition = 14
	// AudioChannelPositionTopCenter (GST_AUDIO_CHANNEL_POSITION_TOP_CENTER):
	// top center.
	AudioChannelPositionTopCenter AudioChannelPosition = 15
	// AudioChannelPositionTopRearLeft
	// (GST_AUDIO_CHANNEL_POSITION_TOP_REAR_LEFT): top rear left.
	AudioChannelPositionTopRearLeft AudioChannelPosition = 16
	// AudioChannelPositionTopRearRight
	// (GST_AUDIO_CHANNEL_POSITION_TOP_REAR_RIGHT): top rear right.
	AudioChannelPositionTopRearRight AudioChannelPosition = 17
	// AudioChannelPositionTopSideLeft
	// (GST_AUDIO_CHANNEL_POSITION_TOP_SIDE_LEFT): top side right.
	AudioChannelPositionTopSideLeft AudioChannelPosition = 18
	// AudioChannelPositionTopSideRight
	// (GST_AUDIO_CHANNEL_POSITION_TOP_SIDE_RIGHT): top rear right.
	AudioChannelPositionTopSideRight AudioChannelPosition = 19
	// AudioChannelPositionTopRearCenter
	// (GST_AUDIO_CHANNEL_POSITION_TOP_REAR_CENTER): top rear center.
	AudioChannelPositionTopRearCenter AudioChannelPosition = 20
	// AudioChannelPositionBottomFrontCenter
	// (GST_AUDIO_CHANNEL_POSITION_BOTTOM_FRONT_CENTER): bottom front center.
	AudioChannelPositionBottomFrontCenter AudioChannelPosition = 21
	// AudioChannelPositionBottomFrontLeft
	// (GST_AUDIO_CHANNEL_POSITION_BOTTOM_FRONT_LEFT): bottom front left.
	AudioChannelPositionBottomFrontLeft AudioChannelPosition = 22
	// AudioChannelPositionBottomFrontRight
	// (GST_AUDIO_CHANNEL_POSITION_BOTTOM_FRONT_RIGHT): bottom front right.
	AudioChannelPositionBottomFrontRight AudioChannelPosition = 23
	// AudioChannelPositionWideLeft (GST_AUDIO_CHANNEL_POSITION_WIDE_LEFT):
	// wide left (between front left and side left).
	AudioChannelPositionWideLeft AudioChannelPosition = 24
	// AudioChannelPositionWideRight (GST_AUDIO_CHANNEL_POSITION_WIDE_RIGHT):
	// wide right (between front right and side right).
	AudioChannelPositionWideRight AudioChannelPosition = 25
	// AudioChannelPositionSurroundLeft
	// (GST_AUDIO_CHANNEL_POSITION_SURROUND_LEFT): surround left (between rear
	// left and side left).
	AudioChannelPositionSurroundLeft AudioChannelPosition = 26
	// AudioChannelPositionSurroundRight
	// (GST_AUDIO_CHANNEL_POSITION_SURROUND_RIGHT): surround right (between rear
	// right and side right).
	AudioChannelPositionSurroundRight AudioChannelPosition = 27
)

func marshalAudioChannelPosition(p uintptr) (interface{}, error) {
	return AudioChannelPosition(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for AudioChannelPosition.
func (a AudioChannelPosition) String() string {
	switch a {
	case AudioChannelPositionNone:
		return "None"
	case AudioChannelPositionMono:
		return "Mono"
	case AudioChannelPositionInvalid:
		return "Invalid"
	case AudioChannelPositionFrontLeft:
		return "FrontLeft"
	case AudioChannelPositionFrontRight:
		return "FrontRight"
	case AudioChannelPositionFrontCenter:
		return "FrontCenter"
	case AudioChannelPositionLfe1:
		return "Lfe1"
	case AudioChannelPositionRearLeft:
		return "RearLeft"
	case AudioChannelPositionRearRight:
		return "RearRight"
	case AudioChannelPositionFrontLeftOfCenter:
		return "FrontLeftOfCenter"
	case AudioChannelPositionFrontRightOfCenter:
		return "FrontRightOfCenter"
	case AudioChannelPositionRearCenter:
		return "RearCenter"
	case AudioChannelPositionLfe2:
		return "Lfe2"
	case AudioChannelPositionSideLeft:
		return "SideLeft"
	case AudioChannelPositionSideRight:
		return "SideRight"
	case AudioChannelPositionTopFrontLeft:
		return "TopFrontLeft"
	case AudioChannelPositionTopFrontRight:
		return "TopFrontRight"
	case AudioChannelPositionTopFrontCenter:
		return "TopFrontCenter"
	case AudioChannelPositionTopCenter:
		return "TopCenter"
	case AudioChannelPositionTopRearLeft:
		return "TopRearLeft"
	case AudioChannelPositionTopRearRight:
		return "TopRearRight"
	case AudioChannelPositionTopSideLeft:
		return "TopSideLeft"
	case AudioChannelPositionTopSideRight:
		return "TopSideRight"
	case AudioChannelPositionTopRearCenter:
		return "TopRearCenter"
	case AudioChannelPositionBottomFrontCenter:
		return "BottomFrontCenter"
	case AudioChannelPositionBottomFrontLeft:
		return "BottomFrontLeft"
	case AudioChannelPositionBottomFrontRight:
		return "BottomFrontRight"
	case AudioChannelPositionWideLeft:
		return "WideLeft"
	case AudioChannelPositionWideRight:
		return "WideRight"
	case AudioChannelPositionSurroundLeft:
		return "SurroundLeft"
	case AudioChannelPositionSurroundRight:
		return "SurroundRight"
	default:
		return fmt.Sprintf("AudioChannelPosition(%d)", a)
	}
}

// AudioDitherMethod (GstAudioDitherMethod): set of available dithering methods.
type AudioDitherMethod C.gint

const (
	// AudioDitherNone (GST_AUDIO_DITHER_NONE): no dithering.
	AudioDitherNone AudioDitherMethod = iota
	// AudioDitherRpdf (GST_AUDIO_DITHER_RPDF): rectangular dithering.
	AudioDitherRpdf
	// AudioDitherTpdf (GST_AUDIO_DITHER_TPDF): triangular dithering (default).
	AudioDitherTpdf
	// AudioDitherTpdfHf (GST_AUDIO_DITHER_TPDF_HF): high frequency triangular
	// dithering.
	AudioDitherTpdfHf
)

func marshalAudioDitherMethod(p uintptr) (interface{}, error) {
	return AudioDitherMethod(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for AudioDitherMethod.
func (a AudioDitherMethod) String() string {
	switch a {
	case AudioDitherNone:
		return "None"
	case AudioDitherRpdf:
		return "Rpdf"
	case AudioDitherTpdf:
		return "Tpdf"
	case AudioDitherTpdfHf:
		return "TpdfHf"
	default:
		return fmt.Sprintf("AudioDitherMethod(%d)", a)
	}
}

// AudioFormat (GstAudioFormat): enum value describing the most common audio
// formats.
type AudioFormat C.gint

const (
	// AudioFormatUnknown (GST_AUDIO_FORMAT_UNKNOWN): unknown or unset audio
	// format.
	AudioFormatUnknown AudioFormat = 0
	// AudioFormatEncoded (GST_AUDIO_FORMAT_ENCODED): encoded audio format.
	AudioFormatEncoded AudioFormat = 1
	// AudioFormatS8 (GST_AUDIO_FORMAT_S8): 8 bits in 8 bits, signed.
	AudioFormatS8 AudioFormat = 2
	// AudioFormatU8 (GST_AUDIO_FORMAT_U8): 8 bits in 8 bits, unsigned.
	AudioFormatU8 AudioFormat = 3
	// AudioFormatS16LE (GST_AUDIO_FORMAT_S16LE): 16 bits in 16 bits, signed,
	// little endian.
	AudioFormatS16LE AudioFormat = 4
	// AudioFormatS16Be (GST_AUDIO_FORMAT_S16BE): 16 bits in 16 bits, signed,
	// big endian.
	AudioFormatS16Be AudioFormat = 5
	// AudioFormatU16LE (GST_AUDIO_FORMAT_U16LE): 16 bits in 16 bits, unsigned,
	// little endian.
	AudioFormatU16LE AudioFormat = 6
	// AudioFormatU16Be (GST_AUDIO_FORMAT_U16BE): 16 bits in 16 bits, unsigned,
	// big endian.
	AudioFormatU16Be AudioFormat = 7
	// AudioFormatS2432LE (GST_AUDIO_FORMAT_S24_32LE): 24 bits in 32 bits,
	// signed, little endian.
	AudioFormatS2432LE AudioFormat = 8
	// AudioFormatS2432Be (GST_AUDIO_FORMAT_S24_32BE): 24 bits in 32 bits,
	// signed, big endian.
	AudioFormatS2432Be AudioFormat = 9
	// AudioFormatU2432LE (GST_AUDIO_FORMAT_U24_32LE): 24 bits in 32 bits,
	// unsigned, little endian.
	AudioFormatU2432LE AudioFormat = 10
	// AudioFormatU2432Be (GST_AUDIO_FORMAT_U24_32BE): 24 bits in 32 bits,
	// unsigned, big endian.
	AudioFormatU2432Be AudioFormat = 11
	// AudioFormatS32LE (GST_AUDIO_FORMAT_S32LE): 32 bits in 32 bits, signed,
	// little endian.
	AudioFormatS32LE AudioFormat = 12
	// AudioFormatS32Be (GST_AUDIO_FORMAT_S32BE): 32 bits in 32 bits, signed,
	// big endian.
	AudioFormatS32Be AudioFormat = 13
	// AudioFormatU32LE (GST_AUDIO_FORMAT_U32LE): 32 bits in 32 bits, unsigned,
	// little endian.
	AudioFormatU32LE AudioFormat = 14
	// AudioFormatU32Be (GST_AUDIO_FORMAT_U32BE): 32 bits in 32 bits, unsigned,
	// big endian.
	AudioFormatU32Be AudioFormat = 15
	// AudioFormatS24LE (GST_AUDIO_FORMAT_S24LE): 24 bits in 24 bits, signed,
	// little endian.
	AudioFormatS24LE AudioFormat = 16
	// AudioFormatS24Be (GST_AUDIO_FORMAT_S24BE): 24 bits in 24 bits, signed,
	// big endian.
	AudioFormatS24Be AudioFormat = 17
	// AudioFormatU24LE (GST_AUDIO_FORMAT_U24LE): 24 bits in 24 bits, unsigned,
	// little endian.
	AudioFormatU24LE AudioFormat = 18
	// AudioFormatU24Be (GST_AUDIO_FORMAT_U24BE): 24 bits in 24 bits, unsigned,
	// big endian.
	AudioFormatU24Be AudioFormat = 19
	// AudioFormatS20LE (GST_AUDIO_FORMAT_S20LE): 20 bits in 24 bits, signed,
	// little endian.
	AudioFormatS20LE AudioFormat = 20
	// AudioFormatS20Be (GST_AUDIO_FORMAT_S20BE): 20 bits in 24 bits, signed,
	// big endian.
	AudioFormatS20Be AudioFormat = 21
	// AudioFormatU20LE (GST_AUDIO_FORMAT_U20LE): 20 bits in 24 bits, unsigned,
	// little endian.
	AudioFormatU20LE AudioFormat = 22
	// AudioFormatU20Be (GST_AUDIO_FORMAT_U20BE): 20 bits in 24 bits, unsigned,
	// big endian.
	AudioFormatU20Be AudioFormat = 23
	// AudioFormatS18LE (GST_AUDIO_FORMAT_S18LE): 18 bits in 24 bits, signed,
	// little endian.
	AudioFormatS18LE AudioFormat = 24
	// AudioFormatS18Be (GST_AUDIO_FORMAT_S18BE): 18 bits in 24 bits, signed,
	// big endian.
	AudioFormatS18Be AudioFormat = 25
	// AudioFormatU18LE (GST_AUDIO_FORMAT_U18LE): 18 bits in 24 bits, unsigned,
	// little endian.
	AudioFormatU18LE AudioFormat = 26
	// AudioFormatU18Be (GST_AUDIO_FORMAT_U18BE): 18 bits in 24 bits, unsigned,
	// big endian.
	AudioFormatU18Be AudioFormat = 27
	// AudioFormatF32LE (GST_AUDIO_FORMAT_F32LE): 32-bit floating point samples,
	// little endian.
	AudioFormatF32LE AudioFormat = 28
	// AudioFormatF32Be (GST_AUDIO_FORMAT_F32BE): 32-bit floating point samples,
	// big endian.
	AudioFormatF32Be AudioFormat = 29
	// AudioFormatF64LE (GST_AUDIO_FORMAT_F64LE): 64-bit floating point samples,
	// little endian.
	AudioFormatF64LE AudioFormat = 30
	// AudioFormatF64Be (GST_AUDIO_FORMAT_F64BE): 64-bit floating point samples,
	// big endian.
	AudioFormatF64Be AudioFormat = 31
	// AudioFormatS16 (GST_AUDIO_FORMAT_S16): 16 bits in 16 bits, signed,
	// native endianness.
	AudioFormatS16 AudioFormat = 4
	// AudioFormatU16 (GST_AUDIO_FORMAT_U16): 16 bits in 16 bits, unsigned,
	// native endianness.
	AudioFormatU16 AudioFormat = 6
	// AudioFormatS2432 (GST_AUDIO_FORMAT_S24_32): 24 bits in 32 bits, signed,
	// native endianness.
	AudioFormatS2432 AudioFormat = 8
	// AudioFormatU2432 (GST_AUDIO_FORMAT_U24_32): 24 bits in 32 bits, unsigned,
	// native endianness.
	AudioFormatU2432 AudioFormat = 10
	// AudioFormatS32 (GST_AUDIO_FORMAT_S32): 32 bits in 32 bits, signed,
	// native endianness.
	AudioFormatS32 AudioFormat = 12
	// AudioFormatU32 (GST_AUDIO_FORMAT_U32): 32 bits in 32 bits, unsigned,
	// native endianness.
	AudioFormatU32 AudioFormat = 14
	// AudioFormatS24 (GST_AUDIO_FORMAT_S24): 24 bits in 24 bits, signed,
	// native endianness.
	AudioFormatS24 AudioFormat = 16
	// AudioFormatU24 (GST_AUDIO_FORMAT_U24): 24 bits in 24 bits, unsigned,
	// native endianness.
	AudioFormatU24 AudioFormat = 18
	// AudioFormatS20 (GST_AUDIO_FORMAT_S20): 20 bits in 24 bits, signed,
	// native endianness.
	AudioFormatS20 AudioFormat = 20
	// AudioFormatU20 (GST_AUDIO_FORMAT_U20): 20 bits in 24 bits, unsigned,
	// native endianness.
	AudioFormatU20 AudioFormat = 22
	// AudioFormatS18 (GST_AUDIO_FORMAT_S18): 18 bits in 24 bits, signed,
	// native endianness.
	AudioFormatS18 AudioFormat = 24
	// AudioFormatU18 (GST_AUDIO_FORMAT_U18): 18 bits in 24 bits, unsigned,
	// native endianness.
	AudioFormatU18 AudioFormat = 26
	// AudioFormatF32 (GST_AUDIO_FORMAT_F32): 32-bit floating point samples,
	// native endianness.
	AudioFormatF32 AudioFormat = 28
	// AudioFormatF64 (GST_AUDIO_FORMAT_F64): 64-bit floating point samples,
	// native endianness.
	AudioFormatF64 AudioFormat = 30
)

func marshalAudioFormat(p uintptr) (interface{}, error) {
	return AudioFormat(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for AudioFormat.
func (a AudioFormat) String() string {
	switch a {
	case AudioFormatUnknown:
		return "Unknown"
	case AudioFormatEncoded:
		return "Encoded"
	case AudioFormatS8:
		return "S8"
	case AudioFormatU8:
		return "U8"
	case AudioFormatS16LE:
		return "S16LE"
	case AudioFormatS16Be:
		return "S16Be"
	case AudioFormatU16LE:
		return "U16LE"
	case AudioFormatU16Be:
		return "U16Be"
	case AudioFormatS2432LE:
		return "S2432LE"
	case AudioFormatS2432Be:
		return "S2432Be"
	case AudioFormatU2432LE:
		return "U2432LE"
	case AudioFormatU2432Be:
		return "U2432Be"
	case AudioFormatS32LE:
		return "S32LE"
	case AudioFormatS32Be:
		return "S32Be"
	case AudioFormatU32LE:
		return "U32LE"
	case AudioFormatU32Be:
		return "U32Be"
	case AudioFormatS24LE:
		return "S24LE"
	case AudioFormatS24Be:
		return "S24Be"
	case AudioFormatU24LE:
		return "U24LE"
	case AudioFormatU24Be:
		return "U24Be"
	case AudioFormatS20LE:
		return "S20LE"
	case AudioFormatS20Be:
		return "S20Be"
	case AudioFormatU20LE:
		return "U20LE"
	case AudioFormatU20Be:
		return "U20Be"
	case AudioFormatS18LE:
		return "S18LE"
	case AudioFormatS18Be:
		return "S18Be"
	case AudioFormatU18LE:
		return "U18LE"
	case AudioFormatU18Be:
		return "U18Be"
	case AudioFormatF32LE:
		return "F32LE"
	case AudioFormatF32Be:
		return "F32Be"
	case AudioFormatF64LE:
		return "F64LE"
	case AudioFormatF64Be:
		return "F64Be"
	default:
		return fmt.Sprintf("AudioFormat(%d)", a)
	}
}

// AudioFormatBuildInteger (gst_audio_format_build_integer): construct a
// AudioFormat with given parameters.
//
// The function takes the following parameters:
//
//   - sign: signed or unsigned format.
//   - endianness: g_LITTLE_ENDIAN or G_BIG_ENDIAN.
//   - width: amount of bits used per sample.
//   - depth: amount of used bits in width.
//
// The function returns the following values:
//
//   - audioFormat or GST_AUDIO_FORMAT_UNKNOWN when no audio format exists with
//     the given parameters.
func AudioFormatBuildInteger(sign bool, endianness, width, depth int) AudioFormat {
	var _arg1 C.gboolean       // out
	var _arg2 C.gint           // out
	var _arg3 C.gint           // out
	var _arg4 C.gint           // out
	var _cret C.GstAudioFormat // in

	if sign {
		_arg1 = C.TRUE
	}
	_arg2 = C.gint(endianness)
	_arg3 = C.gint(width)
	_arg4 = C.gint(depth)

	_cret = C.gst_audio_format_build_integer(_arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(sign)
	runtime.KeepAlive(endianness)
	runtime.KeepAlive(width)
	runtime.KeepAlive(depth)

	var _audioFormat AudioFormat // out

	_audioFormat = AudioFormat(_cret)

	return _audioFormat
}

// AudioFormatFillSilence (gst_audio_format_fill_silence): fill length bytes in
// dest with silence samples for info.
//
// Deprecated: Use gst_audio_format_info_fill_silence() instead.
//
// The function takes the following parameters:
//
//   - info: AudioFormatInfo.
//   - dest: destination to fill.
func AudioFormatFillSilence(info *AudioFormatInfo, dest []byte) {
	var _arg1 *C.GstAudioFormatInfo // out
	var _arg2 C.gpointer            // out
	var _arg3 C.gsize

	_arg1 = (*C.GstAudioFormatInfo)(gextras.StructNative(unsafe.Pointer(info)))
	_arg3 = (C.gsize)(len(dest))
	if len(dest) > 0 {
		_arg2 = (C.gpointer)(unsafe.Pointer(&dest[0]))
	}

	C.gst_audio_format_fill_silence(_arg1, _arg2, _arg3)
	runtime.KeepAlive(info)
	runtime.KeepAlive(dest)
}

// AudioFormatFromString (gst_audio_format_from_string): convert the format
// string to its AudioFormat.
//
// The function takes the following parameters:
//
//   - format string.
//
// The function returns the following values:
//
//   - audioFormat for format or GST_AUDIO_FORMAT_UNKNOWN when the string is not
//     a known format.
func AudioFormatFromString(format string) AudioFormat {
	var _arg1 *C.gchar         // out
	var _cret C.GstAudioFormat // in

	_arg1 = (*C.gchar)(unsafe.Pointer(C.CString(format)))
	defer C.free(unsafe.Pointer(_arg1))

	_cret = C.gst_audio_format_from_string(_arg1)
	runtime.KeepAlive(format)

	var _audioFormat AudioFormat // out

	_audioFormat = AudioFormat(_cret)

	return _audioFormat
}

// AudioFormatGetInfo (gst_audio_format_get_info): get the AudioFormatInfo for
// format.
//
// The function takes the following parameters:
//
//   - format: AudioFormat.
//
// The function returns the following values:
//
//   - audioFormatInfo for format.
func AudioFormatGetInfo(format AudioFormat) *AudioFormatInfo {
	var _arg1 C.GstAudioFormat      // out
	var _cret *C.GstAudioFormatInfo // in

	_arg1 = C.GstAudioFormat(format)

	_cret = C.gst_audio_format_get_info(_arg1)
	runtime.KeepAlive(format)

	var _audioFormatInfo *AudioFormatInfo // out

	_audioFormatInfo = (*AudioFormatInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _audioFormatInfo
}

func AudioFormatToString(format AudioFormat) string {
	var _arg1 C.GstAudioFormat // out
	var _cret *C.gchar         // in

	_arg1 = C.GstAudioFormat(format)

	_cret = C.gst_audio_format_to_string(_arg1)
	runtime.KeepAlive(format)

	var _utf8 string // out

	_utf8 = C.GoString((*C.gchar)(unsafe.Pointer(_cret)))

	return _utf8
}

// AudioLayout (GstAudioLayout): layout of the audio samples for the different
// channels.
type AudioLayout C.gint

const (
	// AudioLayoutInterleaved (GST_AUDIO_LAYOUT_INTERLEAVED): interleaved audio.
	AudioLayoutInterleaved AudioLayout = iota
	// AudioLayoutNonInterleaved (GST_AUDIO_LAYOUT_NON_INTERLEAVED):
	// non-interleaved audio.
	AudioLayoutNonInterleaved
)

func marshalAudioLayout(p uintptr) (interface{}, error) {
	return AudioLayout(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for AudioLayout.
func (a AudioLayout) String() string {
	switch a {
	case AudioLayoutInterleaved:
		return "Interleaved"
	case AudioLayoutNonInterleaved:
		return "NonInterleaved"
	default:
		return fmt.Sprintf("AudioLayout(%d)", a)
	}
}

// AudioNoiseShapingMethod (GstAudioNoiseShapingMethod): set of available noise
// shaping methods.
type AudioNoiseShapingMethod C.gint

const (
	// AudioNoiseShapingNone (GST_AUDIO_NOISE_SHAPING_NONE): no noise shaping
	// (default).
	AudioNoiseShapingNone AudioNoiseShapingMethod = iota
	// AudioNoiseShapingErrorFeedback (GST_AUDIO_NOISE_SHAPING_ERROR_FEEDBACK):
	// error feedback.
	AudioNoiseShapingErrorFeedback
	// AudioNoiseShapingSimple (GST_AUDIO_NOISE_SHAPING_SIMPLE): simple 2-pole
	// noise shaping.
	AudioNoiseShapingSimple
	// AudioNoiseShapingMedium (GST_AUDIO_NOISE_SHAPING_MEDIUM): medium 5-pole
	// noise shaping.
	AudioNoiseShapingMedium
	// AudioNoiseShapingHigh (GST_AUDIO_NOISE_SHAPING_HIGH): high 8-pole noise
	// shaping.
	AudioNoiseShapingHigh
)

func marshalAudioNoiseShapingMethod(p uintptr) (interface{}, error) {
	return AudioNoiseShapingMethod(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for AudioNoiseShapingMethod.
func (a AudioNoiseShapingMethod) String() string {
	switch a {
	case AudioNoiseShapingNone:
		return "None"
	case AudioNoiseShapingErrorFeedback:
		return "ErrorFeedback"
	case AudioNoiseShapingSimple:
		return "Simple"
	case AudioNoiseShapingMedium:
		return "Medium"
	case AudioNoiseShapingHigh:
		return "High"
	default:
		return fmt.Sprintf("AudioNoiseShapingMethod(%d)", a)
	}
}

// AudioResamplerFilterInterpolation (GstAudioResamplerFilterInterpolation):
// different filter interpolation methods.
type AudioResamplerFilterInterpolation C.gint

const (
	// AudioResamplerFilterInterpolationNone
	// (GST_AUDIO_RESAMPLER_FILTER_INTERPOLATION_NONE): no interpolation.
	AudioResamplerFilterInterpolationNone AudioResamplerFilterInterpolation = iota
	// AudioResamplerFilterInterpolationLinear
	// (GST_AUDIO_RESAMPLER_FILTER_INTERPOLATION_LINEAR): linear interpolation
	// of the filter coefficients.
	AudioResamplerFilterInterpolationLinear
	// AudioResamplerFilterInterpolationCubic
	// (GST_AUDIO_RESAMPLER_FILTER_INTERPOLATION_CUBIC): cubic interpolation of
	// the filter coefficients.
	AudioResamplerFilterInterpolationCubic
)

func marshalAudioResamplerFilterInterpolation(p uintptr) (interface{}, error) {
	return AudioResamplerFilterInterpolation(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for AudioResamplerFilterInterpolation.
func (a AudioResamplerFilterInterpolation) String() string {
	switch a {
	case AudioResamplerFilterInterpolationNone:
		return "None"
	case AudioResamplerFilterInterpolationLinear:
		return "Linear"
	case AudioResamplerFilterInterpolationCubic:
		return "Cubic"
	default:
		return fmt.Sprintf("AudioResamplerFilterInterpolation(%d)", a)
	}
}

// AudioResamplerFilterMode (GstAudioResamplerFilterMode): select for the filter
// tables should be set up.
type AudioResamplerFilterMode C.gint

const (
	// AudioResamplerFilterModeInterpolated
	// (GST_AUDIO_RESAMPLER_FILTER_MODE_INTERPOLATED): use interpolated
	// filter tables. This uses less memory but more CPU and is slightly less
	// accurate but it allows for more efficient variable rate resampling with
	// gst_audio_resampler_update().
	AudioResamplerFilterModeInterpolated AudioResamplerFilterMode = iota
	// AudioResamplerFilterModeFull (GST_AUDIO_RESAMPLER_FILTER_MODE_FULL):
	// use full filter table. This uses more memory but less CPU.
	AudioResamplerFilterModeFull
	// AudioResamplerFilterModeAuto (GST_AUDIO_RESAMPLER_FILTER_MODE_AUTO):
	// automatically choose between interpolated and full filter tables.
	AudioResamplerFilterModeAuto
)

func marshalAudioResamplerFilterMode(p uintptr) (interface{}, error) {
	return AudioResamplerFilterMode(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for AudioResamplerFilterMode.
func (a AudioResamplerFilterMode) String() string {
	switch a {
	case AudioResamplerFilterModeInterpolated:
		return "Interpolated"
	case AudioResamplerFilterModeFull:
		return "Full"
	case AudioResamplerFilterModeAuto:
		return "Auto"
	default:
		return fmt.Sprintf("AudioResamplerFilterMode(%d)", a)
	}
}

// AudioResamplerMethod (GstAudioResamplerMethod): different subsampling and
// upsampling methods.
type AudioResamplerMethod C.gint

const (
	// AudioResamplerMethodNearest (GST_AUDIO_RESAMPLER_METHOD_NEAREST)
	// duplicates the samples when upsampling and drops when downsampling.
	AudioResamplerMethodNearest AudioResamplerMethod = iota
	// AudioResamplerMethodLinear (GST_AUDIO_RESAMPLER_METHOD_LINEAR) uses
	// linear interpolation to reconstruct missing samples and averaging to
	// downsample.
	AudioResamplerMethodLinear
	// AudioResamplerMethodCubic (GST_AUDIO_RESAMPLER_METHOD_CUBIC) uses cubic
	// interpolation.
	AudioResamplerMethodCubic
	// AudioResamplerMethodBlackmanNuttall
	// (GST_AUDIO_RESAMPLER_METHOD_BLACKMAN_NUTTALL) uses Blackman-Nuttall
	// windowed sinc interpolation.
	AudioResamplerMethodBlackmanNuttall
	// AudioResamplerMethodKaiser (GST_AUDIO_RESAMPLER_METHOD_KAISER) uses
	// Kaiser windowed sinc interpolation.
	AudioResamplerMethodKaiser
)

func marshalAudioResamplerMethod(p uintptr) (interface{}, error) {
	return AudioResamplerMethod(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for AudioResamplerMethod.
func (a AudioResamplerMethod) String() string {
	switch a {
	case AudioResamplerMethodNearest:
		return "Nearest"
	case AudioResamplerMethodLinear:
		return "Linear"
	case AudioResamplerMethodCubic:
		return "Cubic"
	case AudioResamplerMethodBlackmanNuttall:
		return "BlackmanNuttall"
	case AudioResamplerMethodKaiser:
		return "Kaiser"
	default:
		return fmt.Sprintf("AudioResamplerMethod(%d)", a)
	}
}

// AudioRingBufferFormatType (GstAudioRingBufferFormatType): format of the
// samples in the ringbuffer.
type AudioRingBufferFormatType C.gint

const (
	// AudioRingBufferFormatTypeRaw (GST_AUDIO_RING_BUFFER_FORMAT_TYPE_RAW)
	// samples in linear or float.
	AudioRingBufferFormatTypeRaw AudioRingBufferFormatType = iota
	// AudioRingBufferFormatTypeMuLaw (GST_AUDIO_RING_BUFFER_FORMAT_TYPE_MU_LAW)
	// samples in mulaw.
	AudioRingBufferFormatTypeMuLaw
	// AudioRingBufferFormatTypeALaw (GST_AUDIO_RING_BUFFER_FORMAT_TYPE_A_LAW)
	// samples in alaw.
	AudioRingBufferFormatTypeALaw
	// AudioRingBufferFormatTypeImaAdpcm
	// (GST_AUDIO_RING_BUFFER_FORMAT_TYPE_IMA_ADPCM) samples in ima adpcm.
	AudioRingBufferFormatTypeImaAdpcm
	// AudioRingBufferFormatTypeMpeg (GST_AUDIO_RING_BUFFER_FORMAT_TYPE_MPEG)
	// samples in mpeg audio (but not AAC) format.
	AudioRingBufferFormatTypeMpeg
	// AudioRingBufferFormatTypeGsm (GST_AUDIO_RING_BUFFER_FORMAT_TYPE_GSM)
	// samples in gsm format.
	AudioRingBufferFormatTypeGsm
	// AudioRingBufferFormatTypeIec958
	// (GST_AUDIO_RING_BUFFER_FORMAT_TYPE_IEC958) samples in IEC958 frames (e.g.
	// AC3).
	AudioRingBufferFormatTypeIec958
	// AudioRingBufferFormatTypeAc3 (GST_AUDIO_RING_BUFFER_FORMAT_TYPE_AC3)
	// samples in AC3 format.
	AudioRingBufferFormatTypeAc3
	// AudioRingBufferFormatTypeEac3 (GST_AUDIO_RING_BUFFER_FORMAT_TYPE_EAC3)
	// samples in EAC3 format.
	AudioRingBufferFormatTypeEac3
	// AudioRingBufferFormatTypeDts (GST_AUDIO_RING_BUFFER_FORMAT_TYPE_DTS)
	// samples in DTS format.
	AudioRingBufferFormatTypeDts
	// AudioRingBufferFormatTypeMpeg2Aac
	// (GST_AUDIO_RING_BUFFER_FORMAT_TYPE_MPEG2_AAC) samples in MPEG-2 AAC ADTS
	// format.
	AudioRingBufferFormatTypeMpeg2Aac
	// AudioRingBufferFormatTypeMpeg4Aac
	// (GST_AUDIO_RING_BUFFER_FORMAT_TYPE_MPEG4_AAC) samples in MPEG-4 AAC ADTS
	// format.
	AudioRingBufferFormatTypeMpeg4Aac
	// AudioRingBufferFormatTypeMpeg2AacRaw
	// (GST_AUDIO_RING_BUFFER_FORMAT_TYPE_MPEG2_AAC_RAW) samples in MPEG-2 AAC
	// raw format (Since: 1.12).
	AudioRingBufferFormatTypeMpeg2AacRaw
	// AudioRingBufferFormatTypeMpeg4AacRaw
	// (GST_AUDIO_RING_BUFFER_FORMAT_TYPE_MPEG4_AAC_RAW) samples in MPEG-4 AAC
	// raw format (Since: 1.12).
	AudioRingBufferFormatTypeMpeg4AacRaw
	// AudioRingBufferFormatTypeFlac (GST_AUDIO_RING_BUFFER_FORMAT_TYPE_FLAC)
	// samples in FLAC format (Since: 1.12).
	AudioRingBufferFormatTypeFlac
	// AudioRingBufferFormatTypeDsd (GST_AUDIO_RING_BUFFER_FORMAT_TYPE_DSD)
	// samples in DSD format (Since: 1.24).
	AudioRingBufferFormatTypeDsd
)

func marshalAudioRingBufferFormatType(p uintptr) (interface{}, error) {
	return AudioRingBufferFormatType(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for AudioRingBufferFormatType.
func (a AudioRingBufferFormatType) String() string {
	switch a {
	case AudioRingBufferFormatTypeRaw:
		return "Raw"
	case AudioRingBufferFormatTypeMuLaw:
		return "MuLaw"
	case AudioRingBufferFormatTypeALaw:
		return "ALaw"
	case AudioRingBufferFormatTypeImaAdpcm:
		return "ImaAdpcm"
	case AudioRingBufferFormatTypeMpeg:
		return "Mpeg"
	case AudioRingBufferFormatTypeGsm:
		return "Gsm"
	case AudioRingBufferFormatTypeIec958:
		return "Iec958"
	case AudioRingBufferFormatTypeAc3:
		return "Ac3"
	case AudioRingBufferFormatTypeEac3:
		return "Eac3"
	case AudioRingBufferFormatTypeDts:
		return "Dts"
	case AudioRingBufferFormatTypeMpeg2Aac:
		return "Mpeg2Aac"
	case AudioRingBufferFormatTypeMpeg4Aac:
		return "Mpeg4Aac"
	case AudioRingBufferFormatTypeMpeg2AacRaw:
		return "Mpeg2AacRaw"
	case AudioRingBufferFormatTypeMpeg4AacRaw:
		return "Mpeg4AacRaw"
	case AudioRingBufferFormatTypeFlac:
		return "Flac"
	case AudioRingBufferFormatTypeDsd:
		return "Dsd"
	default:
		return fmt.Sprintf("AudioRingBufferFormatType(%d)", a)
	}
}

// AudioRingBufferState (GstAudioRingBufferState): state of the ringbuffer.
type AudioRingBufferState C.gint

const (
	// AudioRingBufferStateStopped (GST_AUDIO_RING_BUFFER_STATE_STOPPED):
	// ringbuffer is stopped.
	AudioRingBufferStateStopped AudioRingBufferState = iota
	// AudioRingBufferStatePaused (GST_AUDIO_RING_BUFFER_STATE_PAUSED):
	// ringbuffer is paused.
	AudioRingBufferStatePaused
	// AudioRingBufferStateStarted (GST_AUDIO_RING_BUFFER_STATE_STARTED):
	// ringbuffer is started.
	AudioRingBufferStateStarted
	// AudioRingBufferStateError (GST_AUDIO_RING_BUFFER_STATE_ERROR): ringbuffer
	// has encountered an error after it has been started, e.g. because the
	// device was disconnected (Since: 1.2).
	AudioRingBufferStateError
)

func marshalAudioRingBufferState(p uintptr) (interface{}, error) {
	return AudioRingBufferState(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for AudioRingBufferState.
func (a AudioRingBufferState) String() string {
	switch a {
	case AudioRingBufferStateStopped:
		return "Stopped"
	case AudioRingBufferStatePaused:
		return "Paused"
	case AudioRingBufferStateStarted:
		return "Started"
	case AudioRingBufferStateError:
		return "Error"
	default:
		return fmt.Sprintf("AudioRingBufferState(%d)", a)
	}
}

// DsdFormat (GstDsdFormat): enum value describing how DSD bits are grouped.
type DsdFormat C.gint

const (
	// DsdFormatUnknown (GST_DSD_FORMAT_UNKNOWN): unknown / invalid DSD format.
	DsdFormatUnknown DsdFormat = 0
	// DsdFormatU8 (GST_DSD_FORMAT_U8): 8 DSD bits in 1 byte.
	DsdFormatU8 DsdFormat = 1
	// DsdFormatU16LE (GST_DSD_FORMAT_U16LE): 16 DSD bits in 2 bytes, little
	// endian order.
	DsdFormatU16LE DsdFormat = 2
	// DsdFormatU16Be (GST_DSD_FORMAT_U16BE): 16 DSD bits in 2 bytes, big endian
	// order.
	DsdFormatU16Be DsdFormat = 3
	// DsdFormatU32LE (GST_DSD_FORMAT_U32LE): 32 DSD bits in 4 bytes, little
	// endian order.
	DsdFormatU32LE DsdFormat = 4
	// DsdFormatU32Be (GST_DSD_FORMAT_U32BE): 32 DSD bits in 4 bytes, big endian
	// order.
	DsdFormatU32Be DsdFormat = 5
	// NumDsdFormats (GST_NUM_DSD_FORMATS): number of valid DSD formats.
	NumDsdFormats DsdFormat = 6
	// DsdFormatU16 (GST_DSD_FORMAT_U16): 16 DSD bits in 2 bytes, native
	// endianness.
	DsdFormatU16 DsdFormat = 2
	// DsdFormatU32 (GST_DSD_FORMAT_U32): 32 DSD bits in 4 bytes, native
	// endianness.
	DsdFormatU32 DsdFormat = 4
)

func marshalDsdFormat(p uintptr) (interface{}, error) {
	return DsdFormat(coreglib.ValueFromNative(unsafe.Pointer(p)).Enum()), nil
}

// String returns the name in string for DsdFormat.
func (d DsdFormat) String() string {
	switch d {
	case DsdFormatUnknown:
		return "DsdFormatUnknown"
	case DsdFormatU8:
		return "DsdFormatU8"
	case DsdFormatU16LE:
		return "DsdFormatU16LE"
	case DsdFormatU16Be:
		return "DsdFormatU16Be"
	case DsdFormatU32LE:
		return "DsdFormatU32LE"
	case DsdFormatU32Be:
		return "DsdFormatU32Be"
	case NumDsdFormats:
		return "NumDsdFormats"
	default:
		return fmt.Sprintf("DsdFormat(%d)", d)
	}
}

// DsdFormatFromString (gst_dsd_format_from_string): convert the DSD format
// string str to its DsdFormat.
//
// The function takes the following parameters:
//
//   - str: DSD format string.
//
// The function returns the following values:
//
//   - dsdFormat for format or GST_DSD_FORMAT_UNKNOWN when the string is not a
//     known format.
func DsdFormatFromString(str string) DsdFormat {
	var _arg1 *C.gchar       // out
	var _cret C.GstDsdFormat // in

	_arg1 = (*C.gchar)(unsafe.Pointer(C.CString(str)))
	defer C.free(unsafe.Pointer(_arg1))

	_cret = C.gst_dsd_format_from_string(_arg1)
	runtime.KeepAlive(str)

	var _dsdFormat DsdFormat // out

	_dsdFormat = DsdFormat(_cret)

	return _dsdFormat
}

// The function takes the following parameters:
//
//   - format: DsdFormat.
//
// The function returns the following values:
//
//   - guint: number of bytes in this DSD grouping format.
func DsdFormatGetWidth(format DsdFormat) uint {
	var _arg1 C.GstDsdFormat // out
	var _cret C.guint        // in

	_arg1 = C.GstDsdFormat(format)

	_cret = C.gst_dsd_format_get_width(_arg1)
	runtime.KeepAlive(format)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// DsdFormatToString (gst_dsd_format_to_string) returns a string containing a
// descriptive name for the DsdFormat if there is one, or NULL otherwise.
//
// The function takes the following parameters:
//
//   - format: DsdFormat.
//
// The function returns the following values:
//
//   - utf8: name corresponding to format.
func DsdFormatToString(format DsdFormat) string {
	var _arg1 C.GstDsdFormat // out
	var _cret *C.gchar       // in

	_arg1 = C.GstDsdFormat(format)

	_cret = C.gst_dsd_format_to_string(_arg1)
	runtime.KeepAlive(format)

	var _utf8 string // out

	_utf8 = C.GoString((*C.gchar)(unsafe.Pointer(_cret)))

	return _utf8
}

// StreamVolumeFormat (GstStreamVolumeFormat): different representations of a
// stream volume. gst_stream_volume_convert_volume() allows to convert between
// the different representations.
//
// Formulas to convert from a linear to a cubic or dB volume are cbrt(val) and
// 20 * log10 (val).
type StreamVolumeFormat C.gint

const (
	// StreamVolumeFormatLinear (GST_STREAM_VOLUME_FORMAT_LINEAR): linear scale
	// factor, 1.0 = 100%.
	StreamVolumeFormatLinear StreamVolumeFormat = iota
	// StreamVolumeFormatCubic (GST_STREAM_VOLUME_FORMAT_CUBIC): cubic volume
	// scale.
	StreamVolumeFormatCubic
	// StreamVolumeFormatDb (GST_STREAM_VOLUME_FORMAT_DB): logarithmic volume
	// scale (dB, amplitude not power).
	StreamVolumeFormatDb
)

// String returns the name in string for StreamVolumeFormat.
func (s StreamVolumeFormat) String() string {
	switch s {
	case StreamVolumeFormatLinear:
		return "Linear"
	case StreamVolumeFormatCubic:
		return "Cubic"
	case StreamVolumeFormatDb:
		return "Db"
	default:
		return fmt.Sprintf("StreamVolumeFormat(%d)", s)
	}
}

// AudioChannelMixerFlags (GstAudioChannelMixerFlags) flags passed to
// gst_audio_channel_mixer_new().
type AudioChannelMixerFlags C.guint

const (
	// AudioChannelMixerFlagsNone (GST_AUDIO_CHANNEL_MIXER_FLAGS_NONE): no flag.
	AudioChannelMixerFlagsNone AudioChannelMixerFlags = 0b0
	// AudioChannelMixerFlagsNonInterleavedIn
	// (GST_AUDIO_CHANNEL_MIXER_FLAGS_NON_INTERLEAVED_IN): input channels are
	// not interleaved.
	AudioChannelMixerFlagsNonInterleavedIn AudioChannelMixerFlags = 0b1
	// AudioChannelMixerFlagsNonInterleavedOut
	// (GST_AUDIO_CHANNEL_MIXER_FLAGS_NON_INTERLEAVED_OUT): output channels are
	// not interleaved.
	AudioChannelMixerFlagsNonInterleavedOut AudioChannelMixerFlags = 0b10
	// AudioChannelMixerFlagsUnpositionedIn
	// (GST_AUDIO_CHANNEL_MIXER_FLAGS_UNPOSITIONED_IN): input channels are
	// explicitly unpositioned.
	AudioChannelMixerFlagsUnpositionedIn AudioChannelMixerFlags = 0b100
	// AudioChannelMixerFlagsUnpositionedOut
	// (GST_AUDIO_CHANNEL_MIXER_FLAGS_UNPOSITIONED_OUT): output channels are
	// explicitly unpositioned.
	AudioChannelMixerFlagsUnpositionedOut AudioChannelMixerFlags = 0b1000
)

func marshalAudioChannelMixerFlags(p uintptr) (interface{}, error) {
	return AudioChannelMixerFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for AudioChannelMixerFlags.
func (a AudioChannelMixerFlags) String() string {
	if a == 0 {
		return "AudioChannelMixerFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(180)

	for a != 0 {
		next := a & (a - 1)
		bit := a - next

		switch bit {
		case AudioChannelMixerFlagsNone:
			builder.WriteString("None|")
		case AudioChannelMixerFlagsNonInterleavedIn:
			builder.WriteString("NonInterleavedIn|")
		case AudioChannelMixerFlagsNonInterleavedOut:
			builder.WriteString("NonInterleavedOut|")
		case AudioChannelMixerFlagsUnpositionedIn:
			builder.WriteString("UnpositionedIn|")
		case AudioChannelMixerFlagsUnpositionedOut:
			builder.WriteString("UnpositionedOut|")
		default:
			builder.WriteString(fmt.Sprintf("AudioChannelMixerFlags(0b%b)|", bit))
		}

		a = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if a contains other.
func (a AudioChannelMixerFlags) Has(other AudioChannelMixerFlags) bool {
	return (a & other) == other
}

// AudioConverterFlags (GstAudioConverterFlags): extra flags passed to
// gst_audio_converter_new() and gst_audio_converter_samples().
type AudioConverterFlags C.guint

const (
	// AudioConverterFlagNone (GST_AUDIO_CONVERTER_FLAG_NONE): no flag.
	AudioConverterFlagNone AudioConverterFlags = 0b0
	// AudioConverterFlagInWritable (GST_AUDIO_CONVERTER_FLAG_IN_WRITABLE):
	// input sample arrays are writable and can be used as temporary storage
	// during conversion.
	AudioConverterFlagInWritable AudioConverterFlags = 0b1
	// AudioConverterFlagVariableRate (GST_AUDIO_CONVERTER_FLAG_VARIABLE_RATE):
	// allow arbitrary rate updates with gst_audio_converter_update_config().
	AudioConverterFlagVariableRate AudioConverterFlags = 0b10
)

func marshalAudioConverterFlags(p uintptr) (interface{}, error) {
	return AudioConverterFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for AudioConverterFlags.
func (a AudioConverterFlags) String() string {
	if a == 0 {
		return "AudioConverterFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(82)

	for a != 0 {
		next := a & (a - 1)
		bit := a - next

		switch bit {
		case AudioConverterFlagNone:
			builder.WriteString("None|")
		case AudioConverterFlagInWritable:
			builder.WriteString("InWritable|")
		case AudioConverterFlagVariableRate:
			builder.WriteString("VariableRate|")
		default:
			builder.WriteString(fmt.Sprintf("AudioConverterFlags(0b%b)|", bit))
		}

		a = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if a contains other.
func (a AudioConverterFlags) Has(other AudioConverterFlags) bool {
	return (a & other) == other
}

// AudioFlags (GstAudioFlags): extra audio flags.
type AudioFlags C.guint

const (
	// AudioFlagNone (GST_AUDIO_FLAG_NONE): no valid flag.
	AudioFlagNone AudioFlags = 0b0
	// AudioFlagUnpositioned (GST_AUDIO_FLAG_UNPOSITIONED): position array
	// explicitly contains unpositioned channels.
	AudioFlagUnpositioned AudioFlags = 0b1
)

func marshalAudioFlags(p uintptr) (interface{}, error) {
	return AudioFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for AudioFlags.
func (a AudioFlags) String() string {
	if a == 0 {
		return "AudioFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(35)

	for a != 0 {
		next := a & (a - 1)
		bit := a - next

		switch bit {
		case AudioFlagNone:
			builder.WriteString("None|")
		case AudioFlagUnpositioned:
			builder.WriteString("Unpositioned|")
		default:
			builder.WriteString(fmt.Sprintf("AudioFlags(0b%b)|", bit))
		}

		a = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if a contains other.
func (a AudioFlags) Has(other AudioFlags) bool {
	return (a & other) == other
}

// AudioFormatFlags (GstAudioFormatFlags): different audio flags that a format
// info can have.
type AudioFormatFlags C.guint

const (
	// AudioFormatFlagInteger (GST_AUDIO_FORMAT_FLAG_INTEGER): integer samples.
	AudioFormatFlagInteger AudioFormatFlags = 0b1
	// AudioFormatFlagFloat (GST_AUDIO_FORMAT_FLAG_FLOAT): float samples.
	AudioFormatFlagFloat AudioFormatFlags = 0b10
	// AudioFormatFlagSigned (GST_AUDIO_FORMAT_FLAG_SIGNED): signed samples.
	AudioFormatFlagSigned AudioFormatFlags = 0b100
	// AudioFormatFlagComplex (GST_AUDIO_FORMAT_FLAG_COMPLEX): complex layout.
	AudioFormatFlagComplex AudioFormatFlags = 0b10000
	// AudioFormatFlagUnpack (GST_AUDIO_FORMAT_FLAG_UNPACK): format can be used
	// in AudioFormatUnpack and AudioFormatPack functions.
	AudioFormatFlagUnpack AudioFormatFlags = 0b100000
)

func marshalAudioFormatFlags(p uintptr) (interface{}, error) {
	return AudioFormatFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for AudioFormatFlags.
func (a AudioFormatFlags) String() string {
	if a == 0 {
		return "AudioFormatFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(110)

	for a != 0 {
		next := a & (a - 1)
		bit := a - next

		switch bit {
		case AudioFormatFlagInteger:
			builder.WriteString("Integer|")
		case AudioFormatFlagFloat:
			builder.WriteString("Float|")
		case AudioFormatFlagSigned:
			builder.WriteString("Signed|")
		case AudioFormatFlagComplex:
			builder.WriteString("Complex|")
		case AudioFormatFlagUnpack:
			builder.WriteString("Unpack|")
		default:
			builder.WriteString(fmt.Sprintf("AudioFormatFlags(0b%b)|", bit))
		}

		a = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if a contains other.
func (a AudioFormatFlags) Has(other AudioFormatFlags) bool {
	return (a & other) == other
}

// AudioPackFlags (GstAudioPackFlags): different flags that can be used when
// packing and unpacking.
type AudioPackFlags C.guint

const (
	// AudioPackFlagNone (GST_AUDIO_PACK_FLAG_NONE): no flag.
	AudioPackFlagNone AudioPackFlags = 0b0
	// AudioPackFlagTruncateRange (GST_AUDIO_PACK_FLAG_TRUNCATE_RANGE):
	// when the source has a smaller depth than the target format, set the least
	// significant bits of the target to 0. This is likely slightly faster but
	// less accurate. When this flag is not specified, the most significant
	// bits of the source are duplicated in the least significant bits of the
	// destination.
	AudioPackFlagTruncateRange AudioPackFlags = 0b1
)

func marshalAudioPackFlags(p uintptr) (interface{}, error) {
	return AudioPackFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for AudioPackFlags.
func (a AudioPackFlags) String() string {
	if a == 0 {
		return "AudioPackFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(44)

	for a != 0 {
		next := a & (a - 1)
		bit := a - next

		switch bit {
		case AudioPackFlagNone:
			builder.WriteString("None|")
		case AudioPackFlagTruncateRange:
			builder.WriteString("TruncateRange|")
		default:
			builder.WriteString(fmt.Sprintf("AudioPackFlags(0b%b)|", bit))
		}

		a = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if a contains other.
func (a AudioPackFlags) Has(other AudioPackFlags) bool {
	return (a & other) == other
}

// AudioQuantizeFlags (GstAudioQuantizeFlags): extra flags that can be passed to
// gst_audio_quantize_new().
type AudioQuantizeFlags C.guint

const (
	// AudioQuantizeFlagNone (GST_AUDIO_QUANTIZE_FLAG_NONE): no flags.
	AudioQuantizeFlagNone AudioQuantizeFlags = 0b0
	// AudioQuantizeFlagNonInterleaved (GST_AUDIO_QUANTIZE_FLAG_NON_INTERLEAVED)
	// samples are non-interleaved.
	AudioQuantizeFlagNonInterleaved AudioQuantizeFlags = 0b1
)

func marshalAudioQuantizeFlags(p uintptr) (interface{}, error) {
	return AudioQuantizeFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for AudioQuantizeFlags.
func (a AudioQuantizeFlags) String() string {
	if a == 0 {
		return "AudioQuantizeFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(53)

	for a != 0 {
		next := a & (a - 1)
		bit := a - next

		switch bit {
		case AudioQuantizeFlagNone:
			builder.WriteString("None|")
		case AudioQuantizeFlagNonInterleaved:
			builder.WriteString("NonInterleaved|")
		default:
			builder.WriteString(fmt.Sprintf("AudioQuantizeFlags(0b%b)|", bit))
		}

		a = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if a contains other.
func (a AudioQuantizeFlags) Has(other AudioQuantizeFlags) bool {
	return (a & other) == other
}

// AudioResamplerFlags (GstAudioResamplerFlags): different resampler flags.
type AudioResamplerFlags C.guint

const (
	// AudioResamplerFlagNone (GST_AUDIO_RESAMPLER_FLAG_NONE): no flags.
	AudioResamplerFlagNone AudioResamplerFlags = 0b0
	// AudioResamplerFlagNonInterleavedIn
	// (GST_AUDIO_RESAMPLER_FLAG_NON_INTERLEAVED_IN): input samples are
	// non-interleaved. an array of blocks of samples, one for each channel,
	// should be passed to the resample function.
	AudioResamplerFlagNonInterleavedIn AudioResamplerFlags = 0b1
	// AudioResamplerFlagNonInterleavedOut
	// (GST_AUDIO_RESAMPLER_FLAG_NON_INTERLEAVED_OUT): output samples are
	// non-interleaved. an array of blocks of samples, one for each channel,
	// should be passed to the resample function.
	AudioResamplerFlagNonInterleavedOut AudioResamplerFlags = 0b10
	// AudioResamplerFlagVariableRate (GST_AUDIO_RESAMPLER_FLAG_VARIABLE_RATE):
	// optimize for dynamic updates of the sample rates with
	// gst_audio_resampler_update(). This will select an interpolating filter
	// when T_AUDIO_RESAMPLER_FILTER_MODE_AUTO is configured.
	AudioResamplerFlagVariableRate AudioResamplerFlags = 0b100
)

func marshalAudioResamplerFlags(p uintptr) (interface{}, error) {
	return AudioResamplerFlags(coreglib.ValueFromNative(unsafe.Pointer(p)).Flags()), nil
}

// String returns the names in string for AudioResamplerFlags.
func (a AudioResamplerFlags) String() string {
	if a == 0 {
		return "AudioResamplerFlags(0)"
	}

	var builder strings.Builder
	builder.Grow(124)

	for a != 0 {
		next := a & (a - 1)
		bit := a - next

		switch bit {
		case AudioResamplerFlagNone:
			builder.WriteString("None|")
		case AudioResamplerFlagNonInterleavedIn:
			builder.WriteString("NonInterleavedIn|")
		case AudioResamplerFlagNonInterleavedOut:
			builder.WriteString("NonInterleavedOut|")
		case AudioResamplerFlagVariableRate:
			builder.WriteString("VariableRate|")
		default:
			builder.WriteString(fmt.Sprintf("AudioResamplerFlags(0b%b)|", bit))
		}

		a = next
	}

	return strings.TrimSuffix(builder.String(), "|")
}

// Has returns true if a contains other.
func (a AudioResamplerFlags) Has(other AudioResamplerFlags) bool {
	return (a & other) == other
}

// AudioBaseSinkCustomSlavingCallback: this function is set with
// gst_audio_base_sink_set_custom_slaving_callback() and is called during
// playback. It receives the current time of external and internal clocks,
// which the callback can then use to apply any custom slaving/synchronization
// schemes.
//
// The external clock is the sink's element clock, the internal one is the
// internal audio clock. The internal audio clock's calibration is applied
// to the timestamps before they are passed to the callback. The difference
// between etime and itime is the skew; how much internal and external clock lie
// apart from each other. A skew of 0 means both clocks are perfectly in sync.
// itime > etime means the external clock is going slower, while itime < etime
// means it is going faster than the internal clock. etime and itime are always
// valid timestamps, except for when a discontinuity happens.
//
// requested_skew is an output value the callback can write to. It informs
// the sink of whether or not it should move the playout pointer, and if so,
// by how much. This pointer is only NULL if a discontinuity occurs; otherwise,
// it is safe to write to *requested_skew. The default skew is 0.
//
// The sink may experience discontinuities. If one happens, discont is TRUE,
// itime, etime are set to GST_CLOCK_TIME_NONE, and requested_skew is NULL.
// This makes it possible to reset custom clock slaving algorithms when a
// discontinuity happens.
type AudioBaseSinkCustomSlavingCallback func(sink *AudioBaseSink, etime, itime gst.ClockTime, requestedSkew *gst.ClockTimeDiff, discontReason AudioBaseSinkDiscontReason)

// AudioClockGetTimeFunc: this function will be called whenever the
// current clock time needs to be calculated. If this function returns
// T_CLOCK_TIME_NONE, the last reported time will be returned by the clock.
type AudioClockGetTimeFunc func(clock gst.Clocker) (clockTime gst.ClockTime)

// AudioRingBufferCallback: this function is set with
// gst_audio_ring_buffer_set_callback() and is called to fill the memory at data
// with len bytes of samples.
type AudioRingBufferCallback func(rbuf AudioRingBufferer, data []byte)

// AudioChannelGetFallbackMask (gst_audio_channel_get_fallback_mask): get the
// fallback channel-mask for the given number of channels.
//
// This function returns a reasonable fallback channel-mask and should be called
// as a last resort when the specific channel map is unknown.
//
// The function takes the following parameters:
//
//   - channels: number of channels.
//
// The function returns the following values:
//
//   - guint64: fallback channel-mask for channels or 0 when there is no mask
//     and mono.
func AudioChannelGetFallbackMask(channels int) uint64 {
	var _arg1 C.gint    // out
	var _cret C.guint64 // in

	_arg1 = C.gint(channels)

	_cret = C.gst_audio_channel_get_fallback_mask(_arg1)
	runtime.KeepAlive(channels)

	var _guint64 uint64 // out

	_guint64 = uint64(_cret)

	return _guint64
}

// AudioChannelPositionsFromMask (gst_audio_channel_positions_from_mask):
// convert the channels present in channel_mask to a position array (which
// should have at least channels entries ensured by caller). If channel_mask
// is set to 0, it is considered as 'not present' for purpose of conversion.
// A partially valid channel_mask with less bits set than the number of channels
// is considered valid.
//
// The function takes the following parameters:
//
//   - channelMask: input channel_mask.
//   - position: the GstAudioChannelPosition<!-- -->s.
//
// The function returns the following values:
//
//   - ok: TRUE if channel and channel mask are valid and could be converted.
func AudioChannelPositionsFromMask(channelMask uint64, position []AudioChannelPosition) bool {
	var _arg2 C.guint64                  // out
	var _arg3 *C.GstAudioChannelPosition // out
	var _arg1 C.gint
	var _cret C.gboolean // in

	_arg2 = C.guint64(channelMask)
	_arg1 = (C.gint)(len(position))
	if len(position) > 0 {
		_arg3 = (*C.GstAudioChannelPosition)(unsafe.Pointer(&position[0]))
	}

	_cret = C.gst_audio_channel_positions_from_mask(_arg1, _arg2, _arg3)
	runtime.KeepAlive(channelMask)
	runtime.KeepAlive(position)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// AudioChannelPositionsToMask (gst_audio_channel_positions_to_mask): convert
// the position array of channels channels to a bitmask.
//
// If force_order is TRUE it additionally checks if the channels are in the
// order required by GStreamer.
//
// The function takes the following parameters:
//
//   - position: GstAudioChannelPositions.
//   - forceOrder: only consider the GStreamer channel order.
//
// The function returns the following values:
//
//   - channelMask: output channel mask.
//   - ok: TRUE if the channel positions are valid and could be converted.
func AudioChannelPositionsToMask(position []AudioChannelPosition, forceOrder bool) (uint64, bool) {
	var _arg1 *C.GstAudioChannelPosition // out
	var _arg2 C.gint
	var _arg3 C.gboolean // out
	var _arg4 C.guint64  // in
	var _cret C.gboolean // in

	_arg2 = (C.gint)(len(position))
	if len(position) > 0 {
		_arg1 = (*C.GstAudioChannelPosition)(unsafe.Pointer(&position[0]))
	}
	if forceOrder {
		_arg3 = C.TRUE
	}

	_cret = C.gst_audio_channel_positions_to_mask(_arg1, _arg2, _arg3, &_arg4)
	runtime.KeepAlive(position)
	runtime.KeepAlive(forceOrder)

	var _channelMask uint64 // out
	var _ok bool            // out

	_channelMask = uint64(_arg4)
	if _cret != 0 {
		_ok = true
	}

	return _channelMask, _ok
}

// AudioChannelPositionsToString (gst_audio_channel_positions_to_string)
// converts position to a human-readable string representation for debugging
// purposes.
//
// The function takes the following parameters:
//
//   - position: GstAudioChannelPositions to convert.
//
// The function returns the following values:
//
//   - utf8: newly allocated string representing position.
func AudioChannelPositionsToString(position []AudioChannelPosition) string {
	var _arg1 *C.GstAudioChannelPosition // out
	var _arg2 C.gint
	var _cret *C.gchar // in

	_arg2 = (C.gint)(len(position))
	if len(position) > 0 {
		_arg1 = (*C.GstAudioChannelPosition)(unsafe.Pointer(&position[0]))
	}

	_cret = C.gst_audio_channel_positions_to_string(_arg1, _arg2)
	runtime.KeepAlive(position)

	var _utf8 string // out

	_utf8 = C.GoString((*C.gchar)(unsafe.Pointer(_cret)))
	defer C.free(unsafe.Pointer(_cret))

	return _utf8
}

// AudioChannelPositionsToValidOrder
// (gst_audio_channel_positions_to_valid_order) reorders the channel positions
// in position from any order to the GStreamer channel order.
//
// The function takes the following parameters:
//
//   - position: channel positions to reorder to.
//
// The function returns the following values:
//
//   - ok: TRUE if the channel positions are valid and reordering was
//     successful.
func AudioChannelPositionsToValidOrder(position []AudioChannelPosition) bool {
	var _arg1 *C.GstAudioChannelPosition // out
	var _arg2 C.gint
	var _cret C.gboolean // in

	_arg2 = (C.gint)(len(position))
	if len(position) > 0 {
		_arg1 = (*C.GstAudioChannelPosition)(unsafe.Pointer(&position[0]))
	}

	_cret = C.gst_audio_channel_positions_to_valid_order(_arg1, _arg2)
	runtime.KeepAlive(position)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// AudioCheckValidChannelPositions (gst_audio_check_valid_channel_positions)
// checks if position contains valid channel positions for channels channels.
// If force_order is TRUE it additionally checks if the channels are in the
// order required by GStreamer.
//
// The function takes the following parameters:
//
//   - position: GstAudioChannelPositions to check.
//   - forceOrder: only consider the GStreamer channel order.
//
// The function returns the following values:
//
//   - ok: TRUE if the channel positions are valid.
func AudioCheckValidChannelPositions(position []AudioChannelPosition, forceOrder bool) bool {
	var _arg1 *C.GstAudioChannelPosition // out
	var _arg2 C.gint
	var _arg3 C.gboolean // out
	var _cret C.gboolean // in

	_arg2 = (C.gint)(len(position))
	if len(position) > 0 {
		_arg1 = (*C.GstAudioChannelPosition)(unsafe.Pointer(&position[0]))
	}
	if forceOrder {
		_arg3 = C.TRUE
	}

	_cret = C.gst_audio_check_valid_channel_positions(_arg1, _arg2, _arg3)
	runtime.KeepAlive(position)
	runtime.KeepAlive(forceOrder)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

func AudioClippingMetaApiGetType() coreglib.Type {
	var _cret C.GType // in

	_cret = C.gst_audio_clipping_meta_api_get_type()

	var _gType coreglib.Type // out

	_gType = coreglib.Type(_cret)

	return _gType
}

func AudioDownmixMetaApiGetType() coreglib.Type {
	var _cret C.GType // in

	_cret = C.gst_audio_downmix_meta_api_get_type()

	var _gType coreglib.Type // out

	_gType = coreglib.Type(_cret)

	return _gType
}

// AudioFormatsRaw (gst_audio_formats_raw): return all the raw audio formats
// supported by GStreamer.
//
// The function returns the following values:
//
//   - audioFormats: array of AudioFormat.
func AudioFormatsRaw() []AudioFormat {
	var _cret *C.GstAudioFormat // in
	var _arg1 C.guint           // in

	_cret = C.gst_audio_formats_raw(&_arg1)

	var _audioFormats []AudioFormat // out

	_audioFormats = make([]AudioFormat, _arg1)
	copy(_audioFormats, unsafe.Slice((*AudioFormat)(unsafe.Pointer(_cret)), _arg1))

	return _audioFormats
}

// AudioIec61937FrameSize (gst_audio_iec61937_frame_size): calculated the size
// of the buffer expected by gst_audio_iec61937_payload() for payloading type
// from spec.
//
// The function takes the following parameters:
//
//   - spec: ringbufer spec.
//
// The function returns the following values:
//
//   - guint: size or 0 if the given type is not supported or cannot be
//     payloaded.
func AudioIec61937FrameSize(spec *AudioRingBufferSpec) uint {
	var _arg1 *C.GstAudioRingBufferSpec // out
	var _cret C.guint                   // in

	_arg1 = (*C.GstAudioRingBufferSpec)(gextras.StructNative(unsafe.Pointer(spec)))

	_cret = C.gst_audio_iec61937_frame_size(_arg1)
	runtime.KeepAlive(spec)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// AudioIec61937Payload (gst_audio_iec61937_payload) payloads src in the form
// specified by IEC 61937 for the type from spec and stores the result in dst.
// src must contain exactly one frame of data and the frame is not checked for
// errors.
//
// The function takes the following parameters:
//
//   - src: buffer containing the data to payload.
//   - dst: destination buffer to store the payloaded contents in. Should not
//     overlap with src.
//   - spec: ringbufer spec for src.
//   - endianness: expected byte order of the payloaded data.
//
// The function returns the following values:
//
//   - ok: transfer-full: TRUE if the payloading was successful, FALSE
//     otherwise.
func AudioIec61937Payload(src, dst []byte, spec *AudioRingBufferSpec, endianness int) bool {
	var _arg1 *C.guint8 // out
	var _arg2 C.guint
	var _arg3 *C.guint8 // out
	var _arg4 C.guint
	var _arg5 *C.GstAudioRingBufferSpec // out
	var _arg6 C.gint                    // out
	var _cret C.gboolean                // in

	_arg2 = (C.guint)(len(src))
	if len(src) > 0 {
		_arg1 = (*C.guint8)(unsafe.Pointer(&src[0]))
	}
	_arg4 = (C.guint)(len(dst))
	if len(dst) > 0 {
		_arg3 = (*C.guint8)(unsafe.Pointer(&dst[0]))
	}
	_arg5 = (*C.GstAudioRingBufferSpec)(gextras.StructNative(unsafe.Pointer(spec)))
	_arg6 = C.gint(endianness)

	_cret = C.gst_audio_iec61937_payload(_arg1, _arg2, _arg3, _arg4, _arg5, _arg6)
	runtime.KeepAlive(src)
	runtime.KeepAlive(dst)
	runtime.KeepAlive(spec)
	runtime.KeepAlive(endianness)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// AudioLevelMetaApiGetType (gst_audio_level_meta_api_get_type): return the
// #GType associated with AudioLevelMeta.
//
// The function returns the following values:
//
//   - gType: #GType.
func AudioLevelMetaApiGetType() coreglib.Type {
	var _cret C.GType // in

	_cret = C.gst_audio_level_meta_api_get_type()

	var _gType coreglib.Type // out

	_gType = coreglib.Type(_cret)

	return _gType
}

// AudioMakeRawCaps (gst_audio_make_raw_caps): return a generic raw audio caps
// for formats defined in formats. If formats is NULL returns a caps for all the
// supported raw audio formats, see gst_audio_formats_raw().
//
// The function takes the following parameters:
//
//   - formats (optional): array of raw AudioFormat, or NULL.
//   - layout of audio samples.
//
// The function returns the following values:
//
//   - caps: audio GstCaps.
func AudioMakeRawCaps(formats []AudioFormat, layout AudioLayout) *gst.Caps {
	var _arg1 *C.GstAudioFormat // out
	var _arg2 C.guint
	var _arg3 C.GstAudioLayout // out
	var _cret *C.GstCaps       // in

	_arg2 = (C.guint)(len(formats))
	if len(formats) > 0 {
		_arg1 = (*C.GstAudioFormat)(unsafe.Pointer(&formats[0]))
	}
	_arg3 = C.GstAudioLayout(layout)

	_cret = C.gst_audio_make_raw_caps(_arg1, _arg2, _arg3)
	runtime.KeepAlive(formats)
	runtime.KeepAlive(layout)

	var _caps *gst.Caps // out

	_caps = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_caps)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _caps
}

func AudioMetaApiGetType() coreglib.Type {
	var _cret C.GType // in

	_cret = C.gst_audio_meta_api_get_type()

	var _gType coreglib.Type // out

	_gType = coreglib.Type(_cret)

	return _gType
}

// AudioReorderChannels (gst_audio_reorder_channels) reorders data from the
// channel positions from to the channel positions to. from and to must contain
// the same number of positions and the same positions, only in a different
// order.
//
// Note: this function assumes the audio data is in interleaved layout.
//
// The function takes the following parameters:
//
//   - data: pointer to the memory.
//   - format: GstAudioFormat of the buffer.
//   - from: channel positions in the buffer.
//   - to: channel positions to convert to.
//
// The function returns the following values:
//
//   - ok: TRUE if the reordering was possible.
func AudioReorderChannels(data []byte, format AudioFormat, from, to []AudioChannelPosition) bool {
	var _arg1 C.gpointer // out
	var _arg2 C.gsize
	var _arg3 C.GstAudioFormat           // out
	var _arg5 *C.GstAudioChannelPosition // out
	var _arg4 C.gint
	var _arg6 *C.GstAudioChannelPosition // out
	var _cret C.gboolean                 // in

	_arg2 = (C.gsize)(len(data))
	if len(data) > 0 {
		_arg1 = (C.gpointer)(unsafe.Pointer(&data[0]))
	}
	_arg3 = C.GstAudioFormat(format)
	_arg4 = (C.gint)(len(from))
	if len(from) > 0 {
		_arg5 = (*C.GstAudioChannelPosition)(unsafe.Pointer(&from[0]))
	}
	_arg4 = (C.gint)(len(to))
	if len(to) > 0 {
		_arg6 = (*C.GstAudioChannelPosition)(unsafe.Pointer(&to[0]))
	}

	_cret = C.gst_audio_reorder_channels(_arg1, _arg2, _arg3, _arg4, _arg5, _arg6)
	runtime.KeepAlive(data)
	runtime.KeepAlive(format)
	runtime.KeepAlive(from)
	runtime.KeepAlive(to)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// BufferAddAudioClippingMeta (gst_buffer_add_audio_clipping_meta) attaches
// AudioClippingMeta metadata to buffer with the given parameters.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//   - format: gstFormat of start and stop, GST_FORMAT_DEFAULT is samples.
//   - start: amount of audio to clip from start of buffer.
//   - end: amount of to clip from end of buffer.
//
// The function returns the following values:
//
//   - audioClippingMeta on buffer.
func BufferAddAudioClippingMeta(buffer *gst.Buffer, format gst.Format, start, end uint64) *AudioClippingMeta {
	var _arg1 *C.GstBuffer            // out
	var _arg2 C.GstFormat             // out
	var _arg3 C.guint64               // out
	var _arg4 C.guint64               // out
	var _cret *C.GstAudioClippingMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg2 = C.GstFormat(format)
	_arg3 = C.guint64(start)
	_arg4 = C.guint64(end)

	_cret = C.gst_buffer_add_audio_clipping_meta(_arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(format)
	runtime.KeepAlive(start)
	runtime.KeepAlive(end)

	var _audioClippingMeta *AudioClippingMeta // out

	_audioClippingMeta = (*AudioClippingMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _audioClippingMeta
}

// BufferAddAudioDownmixMeta (gst_buffer_add_audio_downmix_meta) attaches
// AudioDownmixMeta metadata to buffer with the given parameters.
//
// matrix is an two-dimensional array of to_channels times from_channels
// coefficients, i.e. the i-th output channels is constructed by multiplicating
// the input channels with the coefficients in matrix[i] and taking the sum of
// the results.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//   - fromPosition: channel positions of the source.
//   - toPosition: channel positions of the destination.
//   - matrix coefficients.
//
// The function returns the following values:
//
//   - audioDownmixMeta on buffer.
func BufferAddAudioDownmixMeta(buffer *gst.Buffer, fromPosition, toPosition []AudioChannelPosition, matrix **float32) *AudioDownmixMeta {
	var _arg1 *C.GstBuffer               // out
	var _arg2 *C.GstAudioChannelPosition // out
	var _arg3 C.gint
	var _arg4 *C.GstAudioChannelPosition // out
	var _arg5 C.gint
	var _arg6 **C.gfloat             // out
	var _cret *C.GstAudioDownmixMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg3 = (C.gint)(len(fromPosition))
	if len(fromPosition) > 0 {
		_arg2 = (*C.GstAudioChannelPosition)(unsafe.Pointer(&fromPosition[0]))
	}
	_arg5 = (C.gint)(len(toPosition))
	if len(toPosition) > 0 {
		_arg4 = (*C.GstAudioChannelPosition)(unsafe.Pointer(&toPosition[0]))
	}
	_arg6 = (**C.gfloat)(unsafe.Pointer(matrix))

	_cret = C.gst_buffer_add_audio_downmix_meta(_arg1, _arg2, _arg3, _arg4, _arg5, _arg6)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(fromPosition)
	runtime.KeepAlive(toPosition)
	runtime.KeepAlive(matrix)

	var _audioDownmixMeta *AudioDownmixMeta // out

	_audioDownmixMeta = (*AudioDownmixMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _audioDownmixMeta
}

// BufferAddAudioLevelMeta (gst_buffer_add_audio_level_meta) attaches audio
// level information to buffer. (RFC 6464).
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//   - level: -dBov from 0-127 (127 is silence).
//   - voiceActivity: whether the buffer contains voice activity.
//
// The function returns the following values:
//
//   - audioLevelMeta (optional) on buffer.
func BufferAddAudioLevelMeta(buffer *gst.Buffer, level byte, voiceActivity bool) *AudioLevelMeta {
	var _arg1 *C.GstBuffer         // out
	var _arg2 C.guint8             // out
	var _arg3 C.gboolean           // out
	var _cret *C.GstAudioLevelMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg2 = C.guint8(level)
	if voiceActivity {
		_arg3 = C.TRUE
	}

	_cret = C.gst_buffer_add_audio_level_meta(_arg1, _arg2, _arg3)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(level)
	runtime.KeepAlive(voiceActivity)

	var _audioLevelMeta *AudioLevelMeta // out

	if _cret != nil {
		_audioLevelMeta = (*AudioLevelMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	}

	return _audioLevelMeta
}

// BufferAddAudioMeta (gst_buffer_add_audio_meta) allocates and attaches a
// AudioMeta on buffer, which must be writable for that purpose. The fields of
// the AudioMeta are directly populated from the arguments of this function.
//
// When info->layout is GST_AUDIO_LAYOUT_NON_INTERLEAVED and offsets is NULL,
// the offsets are calculated with a formula that assumes the planes are tightly
// packed and in sequence: offsets[channel] = channel * samples * sample_stride
//
// It is not allowed for channels to overlap in memory, i.e. for each i in [0,
// channels), the range [offsets[i], offsets[i] + samples * sample_stride)
// must not overlap with any other such range. This function will assert if the
// parameters specified cause this restriction to be violated.
//
// It is, obviously, also not allowed to specify parameters that would cause
// out-of-bounds memory access on buffer. This is also checked, which means that
// you must add enough memory on the buffer before adding this meta.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//   - info: audio properties of the buffer.
//   - samples: number of valid samples in the buffer.
//   - offsets (optional) (in bytes) where each channel plane starts in the
//     buffer or NULL to calculate it (see below); must be NULL also when
//     info->layout is GST_AUDIO_LAYOUT_INTERLEAVED.
//
// The function returns the following values:
//
//   - audioMeta that was attached on the buffer.
func BufferAddAudioMeta(buffer *gst.Buffer, info *AudioInfo, samples uint, offsets *uint) *AudioMeta {
	var _arg1 *C.GstBuffer    // out
	var _arg2 *C.GstAudioInfo // out
	var _arg3 C.gsize         // out
	var _arg4 *C.gsize        // out
	var _cret *C.GstAudioMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg2 = (*C.GstAudioInfo)(gextras.StructNative(unsafe.Pointer(info)))
	_arg3 = C.gsize(samples)
	if offsets != nil {
		_arg4 = (*C.gsize)(unsafe.Pointer(offsets))
	}

	_cret = C.gst_buffer_add_audio_meta(_arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(info)
	runtime.KeepAlive(samples)
	runtime.KeepAlive(offsets)

	var _audioMeta *AudioMeta // out

	_audioMeta = (*AudioMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _audioMeta
}

// BufferAddDsdPlaneOffsetMeta (gst_buffer_add_dsd_plane_offset_meta) allocates
// and attaches a DsdPlaneOffsetMeta on buffer, which must be writable for that
// purpose. The fields of the DsdPlaneOffsetMeta are directly populated from the
// arguments of this function.
//
// If offsets is NULL, then the meta's offsets field is left uninitialized.
// This is useful if for example offset values are to be calculated in the
// meta's offsets field in-place. Similarly, num_bytes_per_channel can be set
// to 0, but only if offsets is NULL. This is useful if the number of bytes per
// channel is known only later.
//
// It is not allowed for channels to overlap in memory, i.e. for each i in [0,
// channels), the range [offsets[i], offsets[i] + num_bytes_per_channel) must
// not overlap with any other such range. This function will assert if the
// parameters specified cause this restriction to be violated.
//
// It is, obviously, also not allowed to specify parameters that would cause
// out-of-bounds memory access on buffer. This is also checked, which means that
// you must add enough memory on the buffer before adding this meta.
//
// This meta is only needed for non-interleaved (= planar) DSD data.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//   - numChannels: number of channels in the DSD data.
//   - numBytesPerChannel: number of bytes per channel.
//   - offsets (optional) (in bytes) where each channel plane starts in the
//     buffer.
//
// The function returns the following values:
//
//   - dsdPlaneOffsetMeta that was attached on the buffer.
func BufferAddDsdPlaneOffsetMeta(buffer *gst.Buffer, numChannels int, numBytesPerChannel uint, offsets *uint) *DsdPlaneOffsetMeta {
	var _arg1 *C.GstBuffer             // out
	var _arg2 C.gint                   // out
	var _arg3 C.gsize                  // out
	var _arg4 *C.gsize                 // out
	var _cret *C.GstDsdPlaneOffsetMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg2 = C.gint(numChannels)
	_arg3 = C.gsize(numBytesPerChannel)
	if offsets != nil {
		_arg4 = (*C.gsize)(unsafe.Pointer(offsets))
	}

	_cret = C.gst_buffer_add_dsd_plane_offset_meta(_arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(numChannels)
	runtime.KeepAlive(numBytesPerChannel)
	runtime.KeepAlive(offsets)

	var _dsdPlaneOffsetMeta *DsdPlaneOffsetMeta // out

	_dsdPlaneOffsetMeta = (*DsdPlaneOffsetMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _dsdPlaneOffsetMeta
}

// BufferGetAudioDownmixMetaForChannels
// (gst_buffer_get_audio_downmix_meta_for_channels): find the AudioDownmixMeta
// on buffer for the given destination channel positions.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//   - toPosition: channel positions of the destination.
//
// The function returns the following values:
//
//   - audioDownmixMeta on buffer.
func BufferGetAudioDownmixMetaForChannels(buffer *gst.Buffer, toPosition []AudioChannelPosition) *AudioDownmixMeta {
	var _arg1 *C.GstBuffer               // out
	var _arg2 *C.GstAudioChannelPosition // out
	var _arg3 C.gint
	var _cret *C.GstAudioDownmixMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg3 = (C.gint)(len(toPosition))
	if len(toPosition) > 0 {
		_arg2 = (*C.GstAudioChannelPosition)(unsafe.Pointer(&toPosition[0]))
	}

	_cret = C.gst_buffer_get_audio_downmix_meta_for_channels(_arg1, _arg2, _arg3)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(toPosition)

	var _audioDownmixMeta *AudioDownmixMeta // out

	_audioDownmixMeta = (*AudioDownmixMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _audioDownmixMeta
}

// BufferGetAudioLevelMeta (gst_buffer_get_audio_level_meta): find the
// AudioLevelMeta on buffer.
//
// The function takes the following parameters:
//
//   - buffer: Buffer.
//
// The function returns the following values:
//
//   - audioLevelMeta (optional) or NULL when there is no such metadata on
//     buffer.
func BufferGetAudioLevelMeta(buffer *gst.Buffer) *AudioLevelMeta {
	var _arg1 *C.GstBuffer         // out
	var _cret *C.GstAudioLevelMeta // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))

	_cret = C.gst_buffer_get_audio_level_meta(_arg1)
	runtime.KeepAlive(buffer)

	var _audioLevelMeta *AudioLevelMeta // out

	if _cret != nil {
		_audioLevelMeta = (*AudioLevelMeta)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	}

	return _audioLevelMeta
}

// DsdConvert (gst_dsd_convert) converts DSD data from one layout and grouping
// format to another. num_bytes must be an integer multiple of the width
// of both input and output format. For example, if the input format is
// GST_DSD_FORMAT_U32LE, and the output format is GST_DSD_FORMAT_U16BE, then
// num_bytes must be an integer multiple of both 4 (U32LE width) and 2 (U16BE
// width).
//
// reverse_byte_bits is necessary if the bit order within the DSD bytes needs
// to be reversed. This is rarely necessary, and is not to be confused with the
// endianness of formats (which determines the ordering of *bytes*).
//
// input_plane_offsets must not be NULL if input_layout is set to
// T_AUDIO_LAYOUT_NON_INTERLEAVED. The same applies to output_plane_offsets.
// These plane offsets define the starting offset of the planes (there
// is exactly one plane per channel) within input_data and output_data
// respectively. If GST_AUDIO_LAYOUT_INTERLEAVED is used, the plane offsets are
// ignored.
//
// The function takes the following parameters:
//
//   - inputData: DSD format conversion's input source.
//   - outputData: DSD format conversion's output destination.
//   - inputFormat: DSD format of the input data to convert from.
//   - outputFormat: DSD format of the output data to convert to.
//   - inputLayout: input data layout.
//   - outputLayout: output data layout.
//   - inputPlaneOffsets: plane offsets for non-interleaved input data.
//   - outputPlaneOffsets: plane offsets for non-interleaved output data.
//   - numDsdBytes: how many bytes with DSD data to convert.
//   - numChannels: number of channels (must be at least 1).
//   - reverseByteBits: if TRUE, reverse the bits in each DSD byte.
func DsdConvert(inputData, outputData *byte, inputFormat, outputFormat DsdFormat, inputLayout, outputLayout AudioLayout, inputPlaneOffsets, outputPlaneOffsets *uint, numDsdBytes uint, numChannels int, reverseByteBits bool) {
	var _arg1 *C.guint8        // out
	var _arg2 *C.guint8        // out
	var _arg3 C.GstDsdFormat   // out
	var _arg4 C.GstDsdFormat   // out
	var _arg5 C.GstAudioLayout // out
	var _arg6 C.GstAudioLayout // out
	var _arg7 *C.gsize         // out
	var _arg8 *C.gsize         // out
	var _arg9 C.gsize          // out
	var _arg10 C.gint          // out
	var _arg11 C.gboolean      // out

	_arg1 = (*C.guint8)(unsafe.Pointer(inputData))
	_arg2 = (*C.guint8)(unsafe.Pointer(outputData))
	_arg3 = C.GstDsdFormat(inputFormat)
	_arg4 = C.GstDsdFormat(outputFormat)
	_arg5 = C.GstAudioLayout(inputLayout)
	_arg6 = C.GstAudioLayout(outputLayout)
	_arg7 = (*C.gsize)(unsafe.Pointer(inputPlaneOffsets))
	_arg8 = (*C.gsize)(unsafe.Pointer(outputPlaneOffsets))
	_arg9 = C.gsize(numDsdBytes)
	_arg10 = C.gint(numChannels)
	if reverseByteBits {
		_arg11 = C.TRUE
	}

	C.gst_dsd_convert(_arg1, _arg2, _arg3, _arg4, _arg5, _arg6, _arg7, _arg8, _arg9, _arg10, _arg11)
	runtime.KeepAlive(inputData)
	runtime.KeepAlive(outputData)
	runtime.KeepAlive(inputFormat)
	runtime.KeepAlive(outputFormat)
	runtime.KeepAlive(inputLayout)
	runtime.KeepAlive(outputLayout)
	runtime.KeepAlive(inputPlaneOffsets)
	runtime.KeepAlive(outputPlaneOffsets)
	runtime.KeepAlive(numDsdBytes)
	runtime.KeepAlive(numChannels)
	runtime.KeepAlive(reverseByteBits)
}

func DsdPlaneOffsetMetaApiGetType() coreglib.Type {
	var _cret C.GType // in

	_cret = C.gst_dsd_plane_offset_meta_api_get_type()

	var _gType coreglib.Type // out

	_gType = coreglib.Type(_cret)

	return _gType
}

// StreamVolumeOverrider contains methods that are overridable.
type StreamVolumeOverrider interface {
}

// StreamVolume (GstStreamVolume): this interface is implemented by elements
// that provide a stream volume. Examples for such elements are #volume and
// #playbin.
//
// Applications can use this interface to get or set the current stream volume.
// For this the "volume" #GObject property can be used or the helper functions
// gst_stream_volume_set_volume() and gst_stream_volume_get_volume(). This
// volume is always a linear factor, i.e. 0.0 is muted 1.0 is 100%. For showing
// the volume in a GUI it might make sense to convert it to a different format
// by using gst_stream_volume_convert_volume(). Volume sliders should usually
// use a cubic volume.
//
// Separate from the volume the stream can also be muted by the "mute" #GObject
// property or gst_stream_volume_set_mute() and gst_stream_volume_get_mute().
//
// Elements that provide some kind of stream volume should implement the
// "volume" and "mute" #GObject properties and handle setting and getting of
// them properly. The volume property is defined to be a linear volume factor.
//
// StreamVolume wraps an interface. This means the user can get the
// underlying type by calling Cast().
type StreamVolume struct {
	_ [0]func() // equal guard
	*coreglib.Object
}

var (
	_ coreglib.Objector = (*StreamVolume)(nil)
)

// StreamVolumer describes types inherited from StreamVolume.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type StreamVolumer interface {
	coreglib.Objector

	Mute() bool
	Volume(format StreamVolumeFormat) float64
	SetMute(mute bool)
	SetVolume(format StreamVolumeFormat, val float64)
}

var _ StreamVolumer = (*StreamVolume)(nil)

func ifaceInitStreamVolumer(gifacePtr, data C.gpointer) {
}

func wrapStreamVolume(obj *coreglib.Object) *StreamVolume {
	return &StreamVolume{
		Object: obj,
	}
}

func marshalStreamVolume(p uintptr) (interface{}, error) {
	return wrapStreamVolume(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

// The function returns the following values:
//
//   - ok returns TRUE if the stream is muted.
func (volume *StreamVolume) Mute() bool {
	var _arg0 *C.GstStreamVolume // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstStreamVolume)(unsafe.Pointer(coreglib.BaseObject(volume).Native()))

	_cret = C.gst_stream_volume_get_mute(_arg0)
	runtime.KeepAlive(volume)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function takes the following parameters:
//
//   - format which should be returned.
//
// The function returns the following values:
//
//   - gdouble: current stream volume as linear factor.
func (volume *StreamVolume) Volume(format StreamVolumeFormat) float64 {
	var _arg0 *C.GstStreamVolume      // out
	var _arg1 C.GstStreamVolumeFormat // out
	var _cret C.gdouble               // in

	_arg0 = (*C.GstStreamVolume)(unsafe.Pointer(coreglib.BaseObject(volume).Native()))
	_arg1 = C.GstStreamVolumeFormat(format)

	_cret = C.gst_stream_volume_get_volume(_arg0, _arg1)
	runtime.KeepAlive(volume)
	runtime.KeepAlive(format)

	var _gdouble float64 // out

	_gdouble = float64(_cret)

	return _gdouble
}

// The function takes the following parameters:
//
//   - mute: mute state that should be set.
func (volume *StreamVolume) SetMute(mute bool) {
	var _arg0 *C.GstStreamVolume // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstStreamVolume)(unsafe.Pointer(coreglib.BaseObject(volume).Native()))
	if mute {
		_arg1 = C.TRUE
	}

	C.gst_stream_volume_set_mute(_arg0, _arg1)
	runtime.KeepAlive(volume)
	runtime.KeepAlive(mute)
}

// The function takes the following parameters:
//
//   - format of val.
//   - val: linear volume factor that should be set.
func (volume *StreamVolume) SetVolume(format StreamVolumeFormat, val float64) {
	var _arg0 *C.GstStreamVolume      // out
	var _arg1 C.GstStreamVolumeFormat // out
	var _arg2 C.gdouble               // out

	_arg0 = (*C.GstStreamVolume)(unsafe.Pointer(coreglib.BaseObject(volume).Native()))
	_arg1 = C.GstStreamVolumeFormat(format)
	_arg2 = C.gdouble(val)

	C.gst_stream_volume_set_volume(_arg0, _arg1, _arg2)
	runtime.KeepAlive(volume)
	runtime.KeepAlive(format)
	runtime.KeepAlive(val)
}

// The function takes the following parameters:
//
//   - from to convert from.
//   - to to convert to.
//   - val: volume in from format that should be converted.
//
// The function returns the following values:
//
//   - gdouble: converted volume.
func StreamVolumeConvertVolume(from, to StreamVolumeFormat, val float64) float64 {
	var _arg1 C.GstStreamVolumeFormat // out
	var _arg2 C.GstStreamVolumeFormat // out
	var _arg3 C.gdouble               // out
	var _cret C.gdouble               // in

	_arg1 = C.GstStreamVolumeFormat(from)
	_arg2 = C.GstStreamVolumeFormat(to)
	_arg3 = C.gdouble(val)

	_cret = C.gst_stream_volume_convert_volume(_arg1, _arg2, _arg3)
	runtime.KeepAlive(from)
	runtime.KeepAlive(to)
	runtime.KeepAlive(val)

	var _gdouble float64 // out

	_gdouble = float64(_cret)

	return _gdouble
}

// AudioAggregatorOverrides contains methods that are overridable.
type AudioAggregatorOverrides struct {
	// AggregateOneBuffer aggregates one input buffer to the output buffer.
	// The in_offset and out_offset are in "frames", which is the size of a
	// sample times the number of channels. Returns TRUE if any non-silence was
	// added to the buffer.
	//
	// The function takes the following parameters:
	//
	//   - pad
	//   - inbuf
	//   - inOffset
	//   - outbuf
	//   - outOffset
	//   - numFrames
	AggregateOneBuffer func(pad *AudioAggregatorPad, inbuf *gst.Buffer, inOffset uint, outbuf *gst.Buffer, outOffset, numFrames uint) bool
	// CreateOutputBuffer: create a new output buffer contains num_frames
	// frames.
	CreateOutputBuffer func(numFrames uint) *gst.Buffer
}

func defaultAudioAggregatorOverrides(v *AudioAggregator) AudioAggregatorOverrides {
	return AudioAggregatorOverrides{
		AggregateOneBuffer: v.aggregateOneBuffer,
		CreateOutputBuffer: v.createOutputBuffer,
	}
}

// AudioAggregator (GstAudioAggregator) subclasses must use (a
// subclass of) AudioAggregatorPad for both their source and sink pads,
// gst_element_class_add_static_pad_template_with_gtype() is a convenient
// helper.
//
// AudioAggregator can perform conversion on the data arriving on its
// sink pads, based on the format expected downstream: in order to enable
// that behaviour, the GType of the sink pads must either be a (subclass
// of) AudioAggregatorConvertPad to use the default AudioConverter
// implementation, or a subclass of AudioAggregatorPad implementing
// AudioAggregatorPadClass.convert_buffer.
//
// To allow for the output caps to change, the mechanism is the same as above,
// with the GType of the source pad.
//
// See AudioMixer for an example.
//
// When conversion is enabled, AudioAggregator will accept any type of raw
// audio caps and perform conversion on the data arriving on its sink pads,
// with whatever downstream expects as the target format.
//
// In case downstream caps are not fully fixated, it will use the first
// configured sink pad to finish fixating its source pad caps.
//
// A notable exception for now is the sample rate, sink pads must have the same
// sample rate as either the downstream requirement, or the first configured
// pad, or a combination of both (when downstream specifies a range or a set of
// acceptable rates).
//
// The Aggregator::samples-selected signal is provided with some additional
// information about the output buffer:
//
// - "offset" G_TYPE_UINT64 Offset in samples since segment start for the
// position that is next to be filled in the output buffer.
//
// - "frames" G_TYPE_UINT Number of frames per output buffer.
//
// In addition the gst_aggregator_peek_next_sample() function returns additional
// information in the info Structure of the returned sample:
//
// - "output-offset" G_TYPE_UINT64 Sample offset in output segment relative to
// the output segment's start where the current position of this input buffer
// would be placed
//
// - "position" G_TYPE_UINT current position in the input buffer in samples
//
// - "size" G_TYPE_UINT size of the input buffer in samples.
type AudioAggregator struct {
	_ [0]func() // equal guard
	gstbase.Aggregator
}

var (
	_ gstbase.Aggregatorrer = (*AudioAggregator)(nil)
)

// AudioAggregatorrer describes types inherited from AudioAggregator.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type AudioAggregatorrer interface {
	gstbase.Aggregatorrer

	SetSinkCaps(pad *AudioAggregatorPad, caps *gst.Caps)

	baseAudioAggregator() *AudioAggregator
}

var _ AudioAggregatorrer = (*AudioAggregator)(nil)

func init() {
	coreglib.RegisterClassInfo[*AudioAggregator, *AudioAggregatorClass, AudioAggregatorOverrides](
		GTypeAudioAggregator,
		initAudioAggregatorClass,
		wrapAudioAggregator,
		defaultAudioAggregatorOverrides,
	)
}

func initAudioAggregatorClass(gclass unsafe.Pointer, overrides AudioAggregatorOverrides, classInitFunc func(*AudioAggregatorClass)) {
	pclass := (*C.GstAudioAggregatorClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeAudioAggregator))))

	if overrides.AggregateOneBuffer != nil {
		pclass.aggregate_one_buffer = (*[0]byte)(C._gotk4_gstaudio1_AudioAggregatorClass_aggregate_one_buffer)
	}

	if overrides.CreateOutputBuffer != nil {
		pclass.create_output_buffer = (*[0]byte)(C._gotk4_gstaudio1_AudioAggregatorClass_create_output_buffer)
	}

	if classInitFunc != nil {
		class := (*AudioAggregatorClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapAudioAggregator(obj *coreglib.Object) *AudioAggregator {
	return &AudioAggregator{
		Aggregator: gstbase.Aggregator{
			Element: gst.Element{
				GstObject: gst.GstObject{
					InitiallyUnowned: coreglib.InitiallyUnowned{
						Object: obj,
					},
				},
			},
		},
	}
}

func marshalAudioAggregator(p uintptr) (interface{}, error) {
	return wrapAudioAggregator(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (aagg *AudioAggregator) baseAudioAggregator() *AudioAggregator {
	return aagg
}

// BaseAudioAggregator returns the underlying base object.
func BaseAudioAggregator(obj AudioAggregatorrer) *AudioAggregator {
	return obj.baseAudioAggregator()
}

// The function takes the following parameters:
//
//   - pad
//   - caps
func (aagg *AudioAggregator) SetSinkCaps(pad *AudioAggregatorPad, caps *gst.Caps) {
	var _arg0 *C.GstAudioAggregator    // out
	var _arg1 *C.GstAudioAggregatorPad // out
	var _arg2 *C.GstCaps               // out

	_arg0 = (*C.GstAudioAggregator)(unsafe.Pointer(coreglib.BaseObject(aagg).Native()))
	_arg1 = (*C.GstAudioAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))
	_arg2 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	C.gst_audio_aggregator_set_sink_caps(_arg0, _arg1, _arg2)
	runtime.KeepAlive(aagg)
	runtime.KeepAlive(pad)
	runtime.KeepAlive(caps)
}

// aggregateOneBuffer aggregates one input buffer to the output buffer.
// The in_offset and out_offset are in "frames", which is the size of a sample
// times the number of channels. Returns TRUE if any non-silence was added to
// the buffer.
//
// The function takes the following parameters:
//
//   - pad
//   - inbuf
//   - inOffset
//   - outbuf
//   - outOffset
//   - numFrames
func (aagg *AudioAggregator) aggregateOneBuffer(pad *AudioAggregatorPad, inbuf *gst.Buffer, inOffset uint, outbuf *gst.Buffer, outOffset, numFrames uint) bool {
	gclass := (*C.GstAudioAggregatorClass)(coreglib.PeekParentClass(aagg))
	fnarg := gclass.aggregate_one_buffer

	var _arg0 *C.GstAudioAggregator    // out
	var _arg1 *C.GstAudioAggregatorPad // out
	var _arg2 *C.GstBuffer             // out
	var _arg3 C.guint                  // out
	var _arg4 *C.GstBuffer             // out
	var _arg5 C.guint                  // out
	var _arg6 C.guint                  // out
	var _cret C.gboolean               // in

	_arg0 = (*C.GstAudioAggregator)(unsafe.Pointer(coreglib.BaseObject(aagg).Native()))
	_arg1 = (*C.GstAudioAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))
	_arg2 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(inbuf)))
	_arg3 = C.guint(inOffset)
	_arg4 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(outbuf)))
	_arg5 = C.guint(outOffset)
	_arg6 = C.guint(numFrames)

	_cret = C._gotk4_gstaudio1_AudioAggregator_virtual_aggregate_one_buffer(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2, _arg3, _arg4, _arg5, _arg6)
	runtime.KeepAlive(aagg)
	runtime.KeepAlive(pad)
	runtime.KeepAlive(inbuf)
	runtime.KeepAlive(inOffset)
	runtime.KeepAlive(outbuf)
	runtime.KeepAlive(outOffset)
	runtime.KeepAlive(numFrames)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// createOutputBuffer: create a new output buffer contains num_frames frames.
func (aagg *AudioAggregator) createOutputBuffer(numFrames uint) *gst.Buffer {
	gclass := (*C.GstAudioAggregatorClass)(coreglib.PeekParentClass(aagg))
	fnarg := gclass.create_output_buffer

	var _arg0 *C.GstAudioAggregator // out
	var _arg1 C.guint               // out
	var _cret *C.GstBuffer          // in

	_arg0 = (*C.GstAudioAggregator)(unsafe.Pointer(coreglib.BaseObject(aagg).Native()))
	_arg1 = C.guint(numFrames)

	_cret = C._gotk4_gstaudio1_AudioAggregator_virtual_create_output_buffer(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(aagg)
	runtime.KeepAlive(numFrames)

	var _buffer *gst.Buffer // out

	_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_buffer)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _buffer
}

// AudioAggregatorConvertPadOverrides contains methods that are overridable.
type AudioAggregatorConvertPadOverrides struct {
}

func defaultAudioAggregatorConvertPadOverrides(v *AudioAggregatorConvertPad) AudioAggregatorConvertPadOverrides {
	return AudioAggregatorConvertPadOverrides{}
}

// AudioAggregatorConvertPad (GstAudioAggregatorConvertPad): implementation of
// GstPad that can be used with AudioAggregator.
//
// See AudioAggregator for more details.
type AudioAggregatorConvertPad struct {
	_ [0]func() // equal guard
	AudioAggregatorPad
}

var (
	_ gst.GstObjector = (*AudioAggregatorConvertPad)(nil)
)

// AudioAggregatorConvertPadder describes types inherited from AudioAggregatorConvertPad.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type AudioAggregatorConvertPadder interface {
	AudioAggregatorPadder

	baseAudioAggregatorConvertPad() *AudioAggregatorConvertPad
}

var _ AudioAggregatorConvertPadder = (*AudioAggregatorConvertPad)(nil)

func init() {
	coreglib.RegisterClassInfo[*AudioAggregatorConvertPad, *AudioAggregatorConvertPadClass, AudioAggregatorConvertPadOverrides](
		GTypeAudioAggregatorConvertPad,
		initAudioAggregatorConvertPadClass,
		wrapAudioAggregatorConvertPad,
		defaultAudioAggregatorConvertPadOverrides,
	)
}

func initAudioAggregatorConvertPadClass(gclass unsafe.Pointer, overrides AudioAggregatorConvertPadOverrides, classInitFunc func(*AudioAggregatorConvertPadClass)) {
	if classInitFunc != nil {
		class := (*AudioAggregatorConvertPadClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapAudioAggregatorConvertPad(obj *coreglib.Object) *AudioAggregatorConvertPad {
	return &AudioAggregatorConvertPad{
		AudioAggregatorPad: AudioAggregatorPad{
			AggregatorPad: gstbase.AggregatorPad{
				Pad: gst.Pad{
					GstObject: gst.GstObject{
						InitiallyUnowned: coreglib.InitiallyUnowned{
							Object: obj,
						},
					},
				},
			},
		},
	}
}

func marshalAudioAggregatorConvertPad(p uintptr) (interface{}, error) {
	return wrapAudioAggregatorConvertPad(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (v *AudioAggregatorConvertPad) baseAudioAggregatorConvertPad() *AudioAggregatorConvertPad {
	return v
}

// BaseAudioAggregatorConvertPad returns the underlying base object.
func BaseAudioAggregatorConvertPad(obj AudioAggregatorConvertPadder) *AudioAggregatorConvertPad {
	return obj.baseAudioAggregatorConvertPad()
}

// AudioAggregatorPadOverrides contains methods that are overridable.
type AudioAggregatorPadOverrides struct {
	// ConvertBuffer: convert a buffer from one format to another.
	//
	// The function takes the following parameters:
	//
	//   - inInfo
	//   - outInfo
	//   - buffer
	ConvertBuffer func(inInfo, outInfo *AudioInfo, buffer *gst.Buffer) *gst.Buffer
	// UpdateConversionInfo: called when either the input or output formats have
	// changed.
	UpdateConversionInfo func()
}

func defaultAudioAggregatorPadOverrides(v *AudioAggregatorPad) AudioAggregatorPadOverrides {
	return AudioAggregatorPadOverrides{
		ConvertBuffer:        v.convertBuffer,
		UpdateConversionInfo: v.updateConversionInfo,
	}
}

// AudioAggregatorPad (GstAudioAggregatorPad): default implementation of GstPad
// used with AudioAggregator.
type AudioAggregatorPad struct {
	_ [0]func() // equal guard
	gstbase.AggregatorPad
}

var (
	_ gst.GstObjector = (*AudioAggregatorPad)(nil)
)

// AudioAggregatorPadder describes types inherited from AudioAggregatorPad.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type AudioAggregatorPadder interface {
	gstbase.AggregatorPadder

	baseAudioAggregatorPad() *AudioAggregatorPad
}

var _ AudioAggregatorPadder = (*AudioAggregatorPad)(nil)

func init() {
	coreglib.RegisterClassInfo[*AudioAggregatorPad, *AudioAggregatorPadClass, AudioAggregatorPadOverrides](
		GTypeAudioAggregatorPad,
		initAudioAggregatorPadClass,
		wrapAudioAggregatorPad,
		defaultAudioAggregatorPadOverrides,
	)
}

func initAudioAggregatorPadClass(gclass unsafe.Pointer, overrides AudioAggregatorPadOverrides, classInitFunc func(*AudioAggregatorPadClass)) {
	pclass := (*C.GstAudioAggregatorPadClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeAudioAggregatorPad))))

	if overrides.ConvertBuffer != nil {
		pclass.convert_buffer = (*[0]byte)(C._gotk4_gstaudio1_AudioAggregatorPadClass_convert_buffer)
	}

	if overrides.UpdateConversionInfo != nil {
		pclass.update_conversion_info = (*[0]byte)(C._gotk4_gstaudio1_AudioAggregatorPadClass_update_conversion_info)
	}

	if classInitFunc != nil {
		class := (*AudioAggregatorPadClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapAudioAggregatorPad(obj *coreglib.Object) *AudioAggregatorPad {
	return &AudioAggregatorPad{
		AggregatorPad: gstbase.AggregatorPad{
			Pad: gst.Pad{
				GstObject: gst.GstObject{
					InitiallyUnowned: coreglib.InitiallyUnowned{
						Object: obj,
					},
				},
			},
		},
	}
}

func marshalAudioAggregatorPad(p uintptr) (interface{}, error) {
	return wrapAudioAggregatorPad(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (v *AudioAggregatorPad) baseAudioAggregatorPad() *AudioAggregatorPad {
	return v
}

// BaseAudioAggregatorPad returns the underlying base object.
func BaseAudioAggregatorPad(obj AudioAggregatorPadder) *AudioAggregatorPad {
	return obj.baseAudioAggregatorPad()
}

// convertBuffer: convert a buffer from one format to another.
//
// The function takes the following parameters:
//
//   - inInfo
//   - outInfo
//   - buffer
func (pad *AudioAggregatorPad) convertBuffer(inInfo, outInfo *AudioInfo, buffer *gst.Buffer) *gst.Buffer {
	gclass := (*C.GstAudioAggregatorPadClass)(coreglib.PeekParentClass(pad))
	fnarg := gclass.convert_buffer

	var _arg0 *C.GstAudioAggregatorPad // out
	var _arg1 *C.GstAudioInfo          // out
	var _arg2 *C.GstAudioInfo          // out
	var _arg3 *C.GstBuffer             // out
	var _cret *C.GstBuffer             // in

	_arg0 = (*C.GstAudioAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))
	_arg1 = (*C.GstAudioInfo)(gextras.StructNative(unsafe.Pointer(inInfo)))
	_arg2 = (*C.GstAudioInfo)(gextras.StructNative(unsafe.Pointer(outInfo)))
	_arg3 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))

	_cret = C._gotk4_gstaudio1_AudioAggregatorPad_virtual_convert_buffer(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(pad)
	runtime.KeepAlive(inInfo)
	runtime.KeepAlive(outInfo)
	runtime.KeepAlive(buffer)

	var _ret *gst.Buffer // out

	_ret = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_ret)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _ret
}

// updateConversionInfo: called when either the input or output formats have
// changed.
func (pad *AudioAggregatorPad) updateConversionInfo() {
	gclass := (*C.GstAudioAggregatorPadClass)(coreglib.PeekParentClass(pad))
	fnarg := gclass.update_conversion_info

	var _arg0 *C.GstAudioAggregatorPad // out

	_arg0 = (*C.GstAudioAggregatorPad)(unsafe.Pointer(coreglib.BaseObject(pad).Native()))

	C._gotk4_gstaudio1_AudioAggregatorPad_virtual_update_conversion_info(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(pad)
}

// AudioBaseSinkOverrides contains methods that are overridable.
type AudioBaseSinkOverrides struct {
	// CreateRingbuffer: create and return the AudioRingBuffer for sink.
	// This function will call the ::create_ringbuffer vmethod and will set sink
	// as the parent of the returned buffer (see gst_object_set_parent()).
	//
	// The function returns the following values:
	//
	//   - audioRingBuffer (optional): new ringbuffer of sink.
	CreateRingbuffer func() AudioRingBufferer
	// Payload: payload data in a format suitable to write to the sink. If no
	// payloading is required, returns a reffed copy of the original buffer,
	// else returns the payloaded buffer with all other metadata copied.
	Payload func(buffer *gst.Buffer) *gst.Buffer
}

func defaultAudioBaseSinkOverrides(v *AudioBaseSink) AudioBaseSinkOverrides {
	return AudioBaseSinkOverrides{
		CreateRingbuffer: v.createRingbuffer,
		Payload:          v.payload,
	}
}

// AudioBaseSink (GstAudioBaseSink): this is the base class for audio sinks.
// Subclasses need to implement the ::create_ringbuffer vmethod. This base class
// will then take care of writing samples to the ringbuffer, synchronisation,
// clipping and flushing.
type AudioBaseSink struct {
	_ [0]func() // equal guard
	gstbase.BaseSink
}

var (
	_ gstbase.BaseSinker = (*AudioBaseSink)(nil)
)

// AudioBaseSinker describes types inherited from AudioBaseSink.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type AudioBaseSinker interface {
	gstbase.BaseSinker

	// CreateRingbuffer (gst_audio_base_sink_create_ringbuffer): create and
	// return the AudioRingBuffer for sink.
	CreateRingbuffer() AudioRingBufferer
	// AlignmentThreshold (gst_audio_base_sink_get_alignment_threshold):
	// get the current alignment threshold, in nanoseconds, used by sink.
	AlignmentThreshold() gst.ClockTime
	// DiscontWait (gst_audio_base_sink_get_discont_wait): get the current
	// discont wait, in nanoseconds, used by sink.
	DiscontWait() gst.ClockTime
	// DriftTolerance (gst_audio_base_sink_get_drift_tolerance): get the current
	// drift tolerance, in microseconds, used by sink.
	DriftTolerance() int64
	// ProvideClock (gst_audio_base_sink_get_provide_clock) queries whether sink
	// will provide a clock or not.
	ProvideClock() bool
	// SlaveMethod (gst_audio_base_sink_get_slave_method): get the current slave
	// method used by sink.
	SlaveMethod() AudioBaseSinkSlaveMethod
	// ReportDeviceFailure (gst_audio_base_sink_report_device_failure) informs
	// this base class that the audio output device has failed for some reason,
	// causing a discontinuity (for example, because the device recovered from
	// the error, but lost all contents of its ring buffer).
	ReportDeviceFailure()
	// SetAlignmentThreshold (gst_audio_base_sink_set_alignment_threshold)
	// controls the sink's alignment threshold.
	SetAlignmentThreshold(alignmentThreshold gst.ClockTime)
	// SetCustomSlavingCallback
	// (gst_audio_base_sink_set_custom_slaving_callback) sets the custom slaving
	// callback.
	SetCustomSlavingCallback(callback AudioBaseSinkCustomSlavingCallback)
	// SetDiscontWait (gst_audio_base_sink_set_discont_wait) controls how long
	// the sink will wait before creating a discontinuity.
	SetDiscontWait(discontWait gst.ClockTime)
	// SetDriftTolerance (gst_audio_base_sink_set_drift_tolerance) controls the
	// sink's drift tolerance.
	SetDriftTolerance(driftTolerance int64)
	// SetProvideClock (gst_audio_base_sink_set_provide_clock) controls whether
	// sink will provide a clock or not.
	SetProvideClock(provide bool)
	// SetSlaveMethod (gst_audio_base_sink_set_slave_method) controls how clock
	// slaving will be performed in sink.
	SetSlaveMethod(method AudioBaseSinkSlaveMethod)

	baseAudioBaseSink() *AudioBaseSink
}

var _ AudioBaseSinker = (*AudioBaseSink)(nil)

func init() {
	coreglib.RegisterClassInfo[*AudioBaseSink, *AudioBaseSinkClass, AudioBaseSinkOverrides](
		GTypeAudioBaseSink,
		initAudioBaseSinkClass,
		wrapAudioBaseSink,
		defaultAudioBaseSinkOverrides,
	)
}

func initAudioBaseSinkClass(gclass unsafe.Pointer, overrides AudioBaseSinkOverrides, classInitFunc func(*AudioBaseSinkClass)) {
	pclass := (*C.GstAudioBaseSinkClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeAudioBaseSink))))

	if overrides.CreateRingbuffer != nil {
		pclass.create_ringbuffer = (*[0]byte)(C._gotk4_gstaudio1_AudioBaseSinkClass_create_ringbuffer)
	}

	if overrides.Payload != nil {
		pclass.payload = (*[0]byte)(C._gotk4_gstaudio1_AudioBaseSinkClass_payload)
	}

	if classInitFunc != nil {
		class := (*AudioBaseSinkClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapAudioBaseSink(obj *coreglib.Object) *AudioBaseSink {
	return &AudioBaseSink{
		BaseSink: gstbase.BaseSink{
			Element: gst.Element{
				GstObject: gst.GstObject{
					InitiallyUnowned: coreglib.InitiallyUnowned{
						Object: obj,
					},
				},
			},
		},
	}
}

func marshalAudioBaseSink(p uintptr) (interface{}, error) {
	return wrapAudioBaseSink(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (sink *AudioBaseSink) baseAudioBaseSink() *AudioBaseSink {
	return sink
}

// BaseAudioBaseSink returns the underlying base object.
func BaseAudioBaseSink(obj AudioBaseSinker) *AudioBaseSink {
	return obj.baseAudioBaseSink()
}

// CreateRingbuffer (gst_audio_base_sink_create_ringbuffer): create and return
// the AudioRingBuffer for sink. This function will call the ::create_ringbuffer
// vmethod and will set sink as the parent of the returned buffer (see
// gst_object_set_parent()).
//
// The function returns the following values:
//
//   - audioRingBuffer (optional): new ringbuffer of sink.
func (sink *AudioBaseSink) CreateRingbuffer() AudioRingBufferer {
	var _arg0 *C.GstAudioBaseSink   // out
	var _cret *C.GstAudioRingBuffer // in

	_arg0 = (*C.GstAudioBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_audio_base_sink_create_ringbuffer(_arg0)
	runtime.KeepAlive(sink)

	var _audioRingBuffer AudioRingBufferer // out

	if _cret != nil {
		{
			objptr := unsafe.Pointer(_cret)

			object := coreglib.Take(objptr)
			casted := object.WalkCast(func(obj coreglib.Objector) bool {
				_, ok := obj.(AudioRingBufferer)
				return ok
			})
			rv, ok := casted.(AudioRingBufferer)
			if !ok {
				panic("no marshaler for " + object.TypeFromInstance().String() + " matching gstaudio.AudioRingBufferer")
			}
			_audioRingBuffer = rv
		}
	}

	return _audioRingBuffer
}

// AlignmentThreshold (gst_audio_base_sink_get_alignment_threshold): get the
// current alignment threshold, in nanoseconds, used by sink.
//
// The function returns the following values:
//
//   - clockTime: current alignment threshold used by sink.
func (sink *AudioBaseSink) AlignmentThreshold() gst.ClockTime {
	var _arg0 *C.GstAudioBaseSink // out
	var _cret C.GstClockTime      // in

	_arg0 = (*C.GstAudioBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_audio_base_sink_get_alignment_threshold(_arg0)
	runtime.KeepAlive(sink)

	var _clockTime gst.ClockTime // out

	_clockTime = gst.ClockTime(_cret)

	return _clockTime
}

// DiscontWait (gst_audio_base_sink_get_discont_wait): get the current discont
// wait, in nanoseconds, used by sink.
//
// The function returns the following values:
//
//   - clockTime: current discont wait used by sink.
func (sink *AudioBaseSink) DiscontWait() gst.ClockTime {
	var _arg0 *C.GstAudioBaseSink // out
	var _cret C.GstClockTime      // in

	_arg0 = (*C.GstAudioBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_audio_base_sink_get_discont_wait(_arg0)
	runtime.KeepAlive(sink)

	var _clockTime gst.ClockTime // out

	_clockTime = gst.ClockTime(_cret)

	return _clockTime
}

// DriftTolerance (gst_audio_base_sink_get_drift_tolerance): get the current
// drift tolerance, in microseconds, used by sink.
//
// The function returns the following values:
//
//   - gint64: current drift tolerance used by sink.
func (sink *AudioBaseSink) DriftTolerance() int64 {
	var _arg0 *C.GstAudioBaseSink // out
	var _cret C.gint64            // in

	_arg0 = (*C.GstAudioBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_audio_base_sink_get_drift_tolerance(_arg0)
	runtime.KeepAlive(sink)

	var _gint64 int64 // out

	_gint64 = int64(_cret)

	return _gint64
}

// ProvideClock (gst_audio_base_sink_get_provide_clock) queries whether sink
// will provide a clock or not. See also gst_audio_base_sink_set_provide_clock.
//
// The function returns the following values:
//
//   - ok: TRUE if sink will provide a clock.
func (sink *AudioBaseSink) ProvideClock() bool {
	var _arg0 *C.GstAudioBaseSink // out
	var _cret C.gboolean          // in

	_arg0 = (*C.GstAudioBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_audio_base_sink_get_provide_clock(_arg0)
	runtime.KeepAlive(sink)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SlaveMethod (gst_audio_base_sink_get_slave_method): get the current slave
// method used by sink.
//
// The function returns the following values:
//
//   - audioBaseSinkSlaveMethod: current slave method used by sink.
func (sink *AudioBaseSink) SlaveMethod() AudioBaseSinkSlaveMethod {
	var _arg0 *C.GstAudioBaseSink           // out
	var _cret C.GstAudioBaseSinkSlaveMethod // in

	_arg0 = (*C.GstAudioBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C.gst_audio_base_sink_get_slave_method(_arg0)
	runtime.KeepAlive(sink)

	var _audioBaseSinkSlaveMethod AudioBaseSinkSlaveMethod // out

	_audioBaseSinkSlaveMethod = AudioBaseSinkSlaveMethod(_cret)

	return _audioBaseSinkSlaveMethod
}

// ReportDeviceFailure (gst_audio_base_sink_report_device_failure) informs this
// base class that the audio output device has failed for some reason, causing
// a discontinuity (for example, because the device recovered from the error,
// but lost all contents of its ring buffer). This function is typically called
// by derived classes, and is useful for the custom slave method.
func (sink *AudioBaseSink) ReportDeviceFailure() {
	var _arg0 *C.GstAudioBaseSink // out

	_arg0 = (*C.GstAudioBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	C.gst_audio_base_sink_report_device_failure(_arg0)
	runtime.KeepAlive(sink)
}

// SetAlignmentThreshold (gst_audio_base_sink_set_alignment_threshold) controls
// the sink's alignment threshold.
//
// The function takes the following parameters:
//
//   - alignmentThreshold: new alignment threshold in nanoseconds.
func (sink *AudioBaseSink) SetAlignmentThreshold(alignmentThreshold gst.ClockTime) {
	var _arg0 *C.GstAudioBaseSink // out
	var _arg1 C.GstClockTime      // out

	_arg0 = (*C.GstAudioBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = C.GstClockTime(alignmentThreshold)

	C.gst_audio_base_sink_set_alignment_threshold(_arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(alignmentThreshold)
}

// SetCustomSlavingCallback (gst_audio_base_sink_set_custom_slaving_callback)
// sets the custom slaving callback. This callback will be invoked if the
// slave-method property is set to GST_AUDIO_BASE_SINK_SLAVE_CUSTOM and the
// audio sink receives and plays samples.
//
// Setting the callback to NULL causes the sink to behave as if the
// GST_AUDIO_BASE_SINK_SLAVE_NONE method were used.
//
// The function takes the following parameters:
//
//   - callback: AudioBaseSinkCustomSlavingCallback.
func (sink *AudioBaseSink) SetCustomSlavingCallback(callback AudioBaseSinkCustomSlavingCallback) {
	var _arg0 *C.GstAudioBaseSink                     // out
	var _arg1 C.GstAudioBaseSinkCustomSlavingCallback // out
	var _arg2 C.gpointer
	var _arg3 C.GDestroyNotify

	_arg0 = (*C.GstAudioBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = (*[0]byte)(C._gotk4_gstaudio1_AudioBaseSinkCustomSlavingCallback)
	_arg2 = C.gpointer(gbox.Assign(callback))
	_arg3 = (C.GDestroyNotify)((*[0]byte)(C.callbackDelete))

	C.gst_audio_base_sink_set_custom_slaving_callback(_arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(callback)
}

// SetDiscontWait (gst_audio_base_sink_set_discont_wait) controls how long the
// sink will wait before creating a discontinuity.
//
// The function takes the following parameters:
//
//   - discontWait: new discont wait in nanoseconds.
func (sink *AudioBaseSink) SetDiscontWait(discontWait gst.ClockTime) {
	var _arg0 *C.GstAudioBaseSink // out
	var _arg1 C.GstClockTime      // out

	_arg0 = (*C.GstAudioBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = C.GstClockTime(discontWait)

	C.gst_audio_base_sink_set_discont_wait(_arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(discontWait)
}

// SetDriftTolerance (gst_audio_base_sink_set_drift_tolerance) controls the
// sink's drift tolerance.
//
// The function takes the following parameters:
//
//   - driftTolerance: new drift tolerance in microseconds.
func (sink *AudioBaseSink) SetDriftTolerance(driftTolerance int64) {
	var _arg0 *C.GstAudioBaseSink // out
	var _arg1 C.gint64            // out

	_arg0 = (*C.GstAudioBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = C.gint64(driftTolerance)

	C.gst_audio_base_sink_set_drift_tolerance(_arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(driftTolerance)
}

// SetProvideClock (gst_audio_base_sink_set_provide_clock) controls whether sink
// will provide a clock or not. If provide is TRUE, gst_element_provide_clock()
// will return a clock that reflects the datarate of sink. If provide is FALSE,
// gst_element_provide_clock() will return NULL.
//
// The function takes the following parameters:
//
//   - provide: new state.
func (sink *AudioBaseSink) SetProvideClock(provide bool) {
	var _arg0 *C.GstAudioBaseSink // out
	var _arg1 C.gboolean          // out

	_arg0 = (*C.GstAudioBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	if provide {
		_arg1 = C.TRUE
	}

	C.gst_audio_base_sink_set_provide_clock(_arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(provide)
}

// SetSlaveMethod (gst_audio_base_sink_set_slave_method) controls how clock
// slaving will be performed in sink.
//
// The function takes the following parameters:
//
//   - method: new slave method.
func (sink *AudioBaseSink) SetSlaveMethod(method AudioBaseSinkSlaveMethod) {
	var _arg0 *C.GstAudioBaseSink           // out
	var _arg1 C.GstAudioBaseSinkSlaveMethod // out

	_arg0 = (*C.GstAudioBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = C.GstAudioBaseSinkSlaveMethod(method)

	C.gst_audio_base_sink_set_slave_method(_arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(method)
}

// createRingbuffer: create and return the AudioRingBuffer for sink. This
// function will call the ::create_ringbuffer vmethod and will set sink as the
// parent of the returned buffer (see gst_object_set_parent()).
//
// The function returns the following values:
//
//   - audioRingBuffer (optional): new ringbuffer of sink.
func (sink *AudioBaseSink) createRingbuffer() AudioRingBufferer {
	gclass := (*C.GstAudioBaseSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.create_ringbuffer

	var _arg0 *C.GstAudioBaseSink   // out
	var _cret *C.GstAudioRingBuffer // in

	_arg0 = (*C.GstAudioBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C._gotk4_gstaudio1_AudioBaseSink_virtual_create_ringbuffer(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(sink)

	var _audioRingBuffer AudioRingBufferer // out

	if _cret != nil {
		{
			objptr := unsafe.Pointer(_cret)

			object := coreglib.Take(objptr)
			casted := object.WalkCast(func(obj coreglib.Objector) bool {
				_, ok := obj.(AudioRingBufferer)
				return ok
			})
			rv, ok := casted.(AudioRingBufferer)
			if !ok {
				panic("no marshaler for " + object.TypeFromInstance().String() + " matching gstaudio.AudioRingBufferer")
			}
			_audioRingBuffer = rv
		}
	}

	return _audioRingBuffer
}

// Payload data in a format suitable to write to the sink. If no payloading
// is required, returns a reffed copy of the original buffer, else returns the
// payloaded buffer with all other metadata copied.
func (sink *AudioBaseSink) payload(buffer *gst.Buffer) *gst.Buffer {
	gclass := (*C.GstAudioBaseSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.payload

	var _arg0 *C.GstAudioBaseSink // out
	var _arg1 *C.GstBuffer        // out
	var _cret *C.GstBuffer        // in

	_arg0 = (*C.GstAudioBaseSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))

	_cret = C._gotk4_gstaudio1_AudioBaseSink_virtual_payload(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(buffer)

	var _ret *gst.Buffer // out

	_ret = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_ret)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _ret
}

// AudioBaseSrcOverrides contains methods that are overridable.
type AudioBaseSrcOverrides struct {
	// CreateRingbuffer: create and return the AudioRingBuffer for src.
	// This function will call the ::create_ringbuffer vmethod and will set src
	// as the parent of the returned buffer (see gst_object_set_parent()).
	//
	// The function returns the following values:
	//
	//   - audioRingBuffer (optional): new ringbuffer of src.
	CreateRingbuffer func() AudioRingBufferer
}

func defaultAudioBaseSrcOverrides(v *AudioBaseSrc) AudioBaseSrcOverrides {
	return AudioBaseSrcOverrides{
		CreateRingbuffer: v.createRingbuffer,
	}
}

// AudioBaseSrc (GstAudioBaseSrc): this is the base class for audio sources.
// Subclasses need to implement the ::create_ringbuffer vmethod. This base class
// will then take care of reading samples from the ringbuffer, synchronisation
// and flushing.
type AudioBaseSrc struct {
	_ [0]func() // equal guard
	gstbase.PushSrc
}

var (
	_ gstbase.BaseSrcer = (*AudioBaseSrc)(nil)
)

// AudioBaseSrcer describes types inherited from AudioBaseSrc.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type AudioBaseSrcer interface {
	gstbase.PushSrcer

	// CreateRingbuffer (gst_audio_base_src_create_ringbuffer): create and
	// return the AudioRingBuffer for src.
	CreateRingbuffer() AudioRingBufferer
	// ProvideClock (gst_audio_base_src_get_provide_clock) queries whether src
	// will provide a clock or not.
	ProvideClock() bool
	// SlaveMethod (gst_audio_base_src_get_slave_method): get the current slave
	// method used by src.
	SlaveMethod() AudioBaseSrcSlaveMethod
	// SetProvideClock (gst_audio_base_src_set_provide_clock) controls whether
	// src will provide a clock or not.
	SetProvideClock(provide bool)
	// SetSlaveMethod (gst_audio_base_src_set_slave_method) controls how clock
	// slaving will be performed in src.
	SetSlaveMethod(method AudioBaseSrcSlaveMethod)

	baseAudioBaseSrc() *AudioBaseSrc
}

var _ AudioBaseSrcer = (*AudioBaseSrc)(nil)

func init() {
	coreglib.RegisterClassInfo[*AudioBaseSrc, *AudioBaseSrcClass, AudioBaseSrcOverrides](
		GTypeAudioBaseSrc,
		initAudioBaseSrcClass,
		wrapAudioBaseSrc,
		defaultAudioBaseSrcOverrides,
	)
}

func initAudioBaseSrcClass(gclass unsafe.Pointer, overrides AudioBaseSrcOverrides, classInitFunc func(*AudioBaseSrcClass)) {
	pclass := (*C.GstAudioBaseSrcClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeAudioBaseSrc))))

	if overrides.CreateRingbuffer != nil {
		pclass.create_ringbuffer = (*[0]byte)(C._gotk4_gstaudio1_AudioBaseSrcClass_create_ringbuffer)
	}

	if classInitFunc != nil {
		class := (*AudioBaseSrcClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapAudioBaseSrc(obj *coreglib.Object) *AudioBaseSrc {
	return &AudioBaseSrc{
		PushSrc: gstbase.PushSrc{
			BaseSrc: gstbase.BaseSrc{
				Element: gst.Element{
					GstObject: gst.GstObject{
						InitiallyUnowned: coreglib.InitiallyUnowned{
							Object: obj,
						},
					},
				},
			},
		},
	}
}

func marshalAudioBaseSrc(p uintptr) (interface{}, error) {
	return wrapAudioBaseSrc(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (src *AudioBaseSrc) baseAudioBaseSrc() *AudioBaseSrc {
	return src
}

// BaseAudioBaseSrc returns the underlying base object.
func BaseAudioBaseSrc(obj AudioBaseSrcer) *AudioBaseSrc {
	return obj.baseAudioBaseSrc()
}

// CreateRingbuffer (gst_audio_base_src_create_ringbuffer): create and return
// the AudioRingBuffer for src. This function will call the ::create_ringbuffer
// vmethod and will set src as the parent of the returned buffer (see
// gst_object_set_parent()).
//
// The function returns the following values:
//
//   - audioRingBuffer (optional): new ringbuffer of src.
func (src *AudioBaseSrc) CreateRingbuffer() AudioRingBufferer {
	var _arg0 *C.GstAudioBaseSrc    // out
	var _cret *C.GstAudioRingBuffer // in

	_arg0 = (*C.GstAudioBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C.gst_audio_base_src_create_ringbuffer(_arg0)
	runtime.KeepAlive(src)

	var _audioRingBuffer AudioRingBufferer // out

	if _cret != nil {
		{
			objptr := unsafe.Pointer(_cret)

			object := coreglib.Take(objptr)
			casted := object.WalkCast(func(obj coreglib.Objector) bool {
				_, ok := obj.(AudioRingBufferer)
				return ok
			})
			rv, ok := casted.(AudioRingBufferer)
			if !ok {
				panic("no marshaler for " + object.TypeFromInstance().String() + " matching gstaudio.AudioRingBufferer")
			}
			_audioRingBuffer = rv
		}
	}

	return _audioRingBuffer
}

// ProvideClock (gst_audio_base_src_get_provide_clock) queries whether src will
// provide a clock or not. See also gst_audio_base_src_set_provide_clock.
//
// The function returns the following values:
//
//   - ok: TRUE if src will provide a clock.
func (src *AudioBaseSrc) ProvideClock() bool {
	var _arg0 *C.GstAudioBaseSrc // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C.gst_audio_base_src_get_provide_clock(_arg0)
	runtime.KeepAlive(src)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SlaveMethod (gst_audio_base_src_get_slave_method): get the current slave
// method used by src.
//
// The function returns the following values:
//
//   - audioBaseSrcSlaveMethod: current slave method used by src.
func (src *AudioBaseSrc) SlaveMethod() AudioBaseSrcSlaveMethod {
	var _arg0 *C.GstAudioBaseSrc           // out
	var _cret C.GstAudioBaseSrcSlaveMethod // in

	_arg0 = (*C.GstAudioBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C.gst_audio_base_src_get_slave_method(_arg0)
	runtime.KeepAlive(src)

	var _audioBaseSrcSlaveMethod AudioBaseSrcSlaveMethod // out

	_audioBaseSrcSlaveMethod = AudioBaseSrcSlaveMethod(_cret)

	return _audioBaseSrcSlaveMethod
}

// SetProvideClock (gst_audio_base_src_set_provide_clock) controls whether src
// will provide a clock or not. If provide is TRUE, gst_element_provide_clock()
// will return a clock that reflects the datarate of src. If provide is FALSE,
// gst_element_provide_clock() will return NULL.
//
// The function takes the following parameters:
//
//   - provide: new state.
func (src *AudioBaseSrc) SetProvideClock(provide bool) {
	var _arg0 *C.GstAudioBaseSrc // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstAudioBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	if provide {
		_arg1 = C.TRUE
	}

	C.gst_audio_base_src_set_provide_clock(_arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(provide)
}

// SetSlaveMethod (gst_audio_base_src_set_slave_method) controls how clock
// slaving will be performed in src.
//
// The function takes the following parameters:
//
//   - method: new slave method.
func (src *AudioBaseSrc) SetSlaveMethod(method AudioBaseSrcSlaveMethod) {
	var _arg0 *C.GstAudioBaseSrc           // out
	var _arg1 C.GstAudioBaseSrcSlaveMethod // out

	_arg0 = (*C.GstAudioBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = C.GstAudioBaseSrcSlaveMethod(method)

	C.gst_audio_base_src_set_slave_method(_arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(method)
}

// createRingbuffer: create and return the AudioRingBuffer for src. This
// function will call the ::create_ringbuffer vmethod and will set src as the
// parent of the returned buffer (see gst_object_set_parent()).
//
// The function returns the following values:
//
//   - audioRingBuffer (optional): new ringbuffer of src.
func (src *AudioBaseSrc) createRingbuffer() AudioRingBufferer {
	gclass := (*C.GstAudioBaseSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.create_ringbuffer

	var _arg0 *C.GstAudioBaseSrc    // out
	var _cret *C.GstAudioRingBuffer // in

	_arg0 = (*C.GstAudioBaseSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C._gotk4_gstaudio1_AudioBaseSrc_virtual_create_ringbuffer(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(src)

	var _audioRingBuffer AudioRingBufferer // out

	if _cret != nil {
		{
			objptr := unsafe.Pointer(_cret)

			object := coreglib.Take(objptr)
			casted := object.WalkCast(func(obj coreglib.Objector) bool {
				_, ok := obj.(AudioRingBufferer)
				return ok
			})
			rv, ok := casted.(AudioRingBufferer)
			if !ok {
				panic("no marshaler for " + object.TypeFromInstance().String() + " matching gstaudio.AudioRingBufferer")
			}
			_audioRingBuffer = rv
		}
	}

	return _audioRingBuffer
}

// AudioCdSrcOverrides contains methods that are overridable.
type AudioCdSrcOverrides struct {
	// Close: closing the device.
	Close func()
	// Open: opening the device.
	Open func(device string) bool
	// ReadSector: reading a sector.
	ReadSector func(sector int) *gst.Buffer
}

func defaultAudioCdSrcOverrides(v *AudioCdSrc) AudioCdSrcOverrides {
	return AudioCdSrcOverrides{
		Close:      v.close,
		Open:       v.open,
		ReadSector: v.readSector,
	}
}

// AudioCdSrc (GstAudioCdSrc) provides a base class for CD digital audio (CDDA)
// sources, which handles things like seeking, querying, discid calculation,
// tags, and buffer timestamping.
//
// # Using GstAudioCdSrc-based elements in applications
//
// GstAudioCdSrc registers two Format<!-- -->s of its own, namely the "track"
// format and the "sector" format. Applications will usually only find the
// "track" format interesting. You can retrieve that Format for use in seek
// events or queries with gst_format_get_by_nick("track").
//
// In order to query the number of tracks, for example, an application would
// set the CDDA source element to READY or PAUSED state and then query the the
// number of tracks via gst_element_query_duration() using the track format
// acquired above. Applications can query the currently playing track in the
// same way.
//
// Alternatively, applications may retrieve the currently playing track and the
// total number of tracks from the taglist that will posted on the bus whenever
// the CD is opened or the currently playing track changes. The taglist will
// contain GST_TAG_TRACK_NUMBER and GST_TAG_TRACK_COUNT tags.
//
// Applications playing back CD audio using playbin and cdda://n URIs should
// issue a seek command in track format to change between tracks, rather than
// setting a new cdda://n+1 URI on playbin (as setting a new URI on playbin
// involves closing and re-opening the CD device, which is much much slower).
//
// # Tags and meta-information
//
// CDDA sources will automatically emit a number of tags,
// details about which can be found in the libgsttag documentation.
// Those tags are: T_TAG_CDDA_CDDB_DISCID, T_TAG_CDDA_CDDB_DISCID_FULL,
// T_TAG_CDDA_MUSICBRAINZ_DISCID, T_TAG_CDDA_MUSICBRAINZ_DISCID_FULL, among
// others.
//
// Tracks and Table of Contents (TOC)
//
// Applications will be informed of the available tracks via a TOC message on
// the pipeline's Bus. The Toc will contain a TocEntry for each track, with
// information about each track. The duration for each track can be retrieved
// via the T_TAG_DURATION tag from each entry's tag list, or calculated via
// gst_toc_entry_get_start_stop_times(). The track entries in the TOC will be
// sorted by track number.
type AudioCdSrc struct {
	_ [0]func() // equal guard
	gstbase.PushSrc

	gst.URIHandler
}

var (
	_ gstbase.BaseSrcer = (*AudioCdSrc)(nil)
)

// AudioCdSrcer describes types inherited from AudioCdSrc.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type AudioCdSrcer interface {
	gstbase.PushSrcer
	gst.URIHandlerer

	// AddTrack (gst_audio_cd_src_add_track): CDDA sources use this function
	// from their start vfunc to announce the available data and audio tracks to
	// the base source class.
	AddTrack(track *AudioCdSrcTrack) bool

	baseAudioCdSrc() *AudioCdSrc
}

var _ AudioCdSrcer = (*AudioCdSrc)(nil)

func init() {
	coreglib.RegisterClassInfo[*AudioCdSrc, *AudioCdSrcClass, AudioCdSrcOverrides](
		GTypeAudioCdSrc,
		initAudioCdSrcClass,
		wrapAudioCdSrc,
		defaultAudioCdSrcOverrides,
	)
}

func initAudioCdSrcClass(gclass unsafe.Pointer, overrides AudioCdSrcOverrides, classInitFunc func(*AudioCdSrcClass)) {
	pclass := (*C.GstAudioCdSrcClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeAudioCdSrc))))

	if overrides.Close != nil {
		pclass.close = (*[0]byte)(C._gotk4_gstaudio1_AudioCdSrcClass_close)
	}

	if overrides.Open != nil {
		pclass.open = (*[0]byte)(C._gotk4_gstaudio1_AudioCdSrcClass_open)
	}

	if overrides.ReadSector != nil {
		pclass.read_sector = (*[0]byte)(C._gotk4_gstaudio1_AudioCdSrcClass_read_sector)
	}

	if classInitFunc != nil {
		class := (*AudioCdSrcClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapAudioCdSrc(obj *coreglib.Object) *AudioCdSrc {
	return &AudioCdSrc{
		PushSrc: gstbase.PushSrc{
			BaseSrc: gstbase.BaseSrc{
				Element: gst.Element{
					GstObject: gst.GstObject{
						InitiallyUnowned: coreglib.InitiallyUnowned{
							Object: obj,
						},
					},
				},
			},
		},
		URIHandler: gst.URIHandler{
			Object: obj,
		},
	}
}

func marshalAudioCdSrc(p uintptr) (interface{}, error) {
	return wrapAudioCdSrc(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (src *AudioCdSrc) baseAudioCdSrc() *AudioCdSrc {
	return src
}

// BaseAudioCdSrc returns the underlying base object.
func BaseAudioCdSrc(obj AudioCdSrcer) *AudioCdSrc {
	return obj.baseAudioCdSrc()
}

// AddTrack (gst_audio_cd_src_add_track): CDDA sources use this function from
// their start vfunc to announce the available data and audio tracks to the base
// source class. The caller should allocate track on the stack, the base source
// will do a shallow copy of the structure (and take ownership of the taglist if
// there is one).
//
// The function takes the following parameters:
//
//   - track address of AudioCdSrcTrack to add.
//
// The function returns the following values:
//
//   - ok: FALSE on error, otherwise TRUE.
func (src *AudioCdSrc) AddTrack(track *AudioCdSrcTrack) bool {
	var _arg0 *C.GstAudioCdSrc      // out
	var _arg1 *C.GstAudioCdSrcTrack // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioCdSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = (*C.GstAudioCdSrcTrack)(gextras.StructNative(unsafe.Pointer(track)))

	_cret = C.gst_audio_cd_src_add_track(_arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(track)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Close: closing the device.
func (src *AudioCdSrc) close() {
	gclass := (*C.GstAudioCdSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.close

	var _arg0 *C.GstAudioCdSrc // out

	_arg0 = (*C.GstAudioCdSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	C._gotk4_gstaudio1_AudioCdSrc_virtual_close(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(src)
}

// Open: opening the device.
func (src *AudioCdSrc) open(device string) bool {
	gclass := (*C.GstAudioCdSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.open

	var _arg0 *C.GstAudioCdSrc // out
	var _arg1 *C.gchar         // out
	var _cret C.gboolean       // in

	_arg0 = (*C.GstAudioCdSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = (*C.gchar)(unsafe.Pointer(C.CString(device)))
	defer C.free(unsafe.Pointer(_arg1))

	_cret = C._gotk4_gstaudio1_AudioCdSrc_virtual_open(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(device)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// readSector: reading a sector.
func (src *AudioCdSrc) readSector(sector int) *gst.Buffer {
	gclass := (*C.GstAudioCdSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.read_sector

	var _arg0 *C.GstAudioCdSrc // out
	var _arg1 C.gint           // out
	var _cret *C.GstBuffer     // in

	_arg0 = (*C.GstAudioCdSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = C.gint(sector)

	_cret = C._gotk4_gstaudio1_AudioCdSrc_virtual_read_sector(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(sector)

	var _buffer *gst.Buffer // out

	_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_buffer)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _buffer
}

// AudioClockOverrides contains methods that are overridable.
type AudioClockOverrides struct {
}

func defaultAudioClockOverrides(v *AudioClock) AudioClockOverrides {
	return AudioClockOverrides{}
}

// AudioClock (GstAudioClock) makes it easy for elements to implement a Clock,
// they simply need to provide a function that returns the current clock time.
//
// This object is internally used to implement the clock in AudioBaseSink.
type AudioClock struct {
	_ [0]func() // equal guard
	gst.SystemClock
}

var (
	_ gst.Clocker = (*AudioClock)(nil)
)

// AudioClocker describes types inherited from AudioClock.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type AudioClocker interface {
	gst.SystemClocker

	// Adjust (gst_audio_clock_adjust) time with the internal offset of the
	// audio clock.
	Adjust(time gst.ClockTime) gst.ClockTime
	// Time (gst_audio_clock_get_time): report the time as returned by the
	// AudioClockGetTimeFunc without applying any offsets.
	Time() gst.ClockTime
	// Invalidate (gst_audio_clock_invalidate) the clock function.
	Invalidate()
	// Reset (gst_audio_clock_reset): inform clock that future calls to
	// AudioClockGetTimeFunc will return values starting from time.
	Reset(time gst.ClockTime)

	baseAudioClock() *AudioClock
}

var _ AudioClocker = (*AudioClock)(nil)

func init() {
	coreglib.RegisterClassInfo[*AudioClock, *AudioClockClass, AudioClockOverrides](
		GTypeAudioClock,
		initAudioClockClass,
		wrapAudioClock,
		defaultAudioClockOverrides,
	)
}

func initAudioClockClass(gclass unsafe.Pointer, overrides AudioClockOverrides, classInitFunc func(*AudioClockClass)) {
	if classInitFunc != nil {
		class := (*AudioClockClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapAudioClock(obj *coreglib.Object) *AudioClock {
	return &AudioClock{
		SystemClock: gst.SystemClock{
			Clock: gst.Clock{
				GstObject: gst.GstObject{
					InitiallyUnowned: coreglib.InitiallyUnowned{
						Object: obj,
					},
				},
			},
		},
	}
}

func marshalAudioClock(p uintptr) (interface{}, error) {
	return wrapAudioClock(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (clock *AudioClock) baseAudioClock() *AudioClock {
	return clock
}

// BaseAudioClock returns the underlying base object.
func BaseAudioClock(obj AudioClocker) *AudioClock {
	return obj.baseAudioClock()
}

// NewAudioClock (gst_audio_clock_new): create a new AudioClock instance.
// Whenever the clock time should be calculated it will call func with
// user_data. When func returns T_CLOCK_TIME_NONE, the clock will return the
// last reported time.
//
// The function takes the following parameters:
//
//   - name of the clock.
//   - fn: function.
//
// The function returns the following values:
//
//   - audioClock: new AudioClock casted to a Clock.
func NewAudioClock(name string, fn AudioClockGetTimeFunc) *AudioClock {
	var _arg1 *C.gchar                   // out
	var _arg2 C.GstAudioClockGetTimeFunc // out
	var _arg3 C.gpointer
	var _arg4 C.GDestroyNotify
	var _cret *C.GstClock // in

	_arg1 = (*C.gchar)(unsafe.Pointer(C.CString(name)))
	defer C.free(unsafe.Pointer(_arg1))
	_arg2 = (*[0]byte)(C._gotk4_gstaudio1_AudioClockGetTimeFunc)
	_arg3 = C.gpointer(gbox.Assign(fn))
	_arg4 = (C.GDestroyNotify)((*[0]byte)(C.callbackDelete))

	_cret = C.gst_audio_clock_new(_arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(name)
	runtime.KeepAlive(fn)

	var _audioClock *AudioClock // out

	_audioClock = wrapAudioClock(coreglib.AssumeOwnership(unsafe.Pointer(_cret)))

	return _audioClock
}

// Adjust (gst_audio_clock_adjust) time with the internal offset of the audio
// clock.
//
// The function takes the following parameters:
//
//   - time: ClockTime.
//
// The function returns the following values:
//
//   - clockTime: time adjusted with the internal offset.
func (clock *AudioClock) Adjust(time gst.ClockTime) gst.ClockTime {
	var _arg0 *C.GstAudioClock // out
	var _arg1 C.GstClockTime   // out
	var _cret C.GstClockTime   // in

	_arg0 = (*C.GstAudioClock)(unsafe.Pointer(coreglib.BaseObject(clock).Native()))
	_arg1 = C.GstClockTime(time)

	_cret = C.gst_audio_clock_adjust(_arg0, _arg1)
	runtime.KeepAlive(clock)
	runtime.KeepAlive(time)

	var _clockTime gst.ClockTime // out

	_clockTime = gst.ClockTime(_cret)

	return _clockTime
}

// Time (gst_audio_clock_get_time): report the time as returned by the
// AudioClockGetTimeFunc without applying any offsets.
//
// The function returns the following values:
//
//   - clockTime: time as reported by the time function of the audio clock.
func (clock *AudioClock) Time() gst.ClockTime {
	var _arg0 *C.GstAudioClock // out
	var _cret C.GstClockTime   // in

	_arg0 = (*C.GstAudioClock)(unsafe.Pointer(coreglib.BaseObject(clock).Native()))

	_cret = C.gst_audio_clock_get_time(_arg0)
	runtime.KeepAlive(clock)

	var _clockTime gst.ClockTime // out

	_clockTime = gst.ClockTime(_cret)

	return _clockTime
}

// Invalidate (gst_audio_clock_invalidate) the clock function. Call this
// function when the provided AudioClockGetTimeFunc cannot be called anymore,
// for example, when the user_data becomes invalid.
//
// After calling this function, clock will return the last returned time for the
// rest of its lifetime.
func (clock *AudioClock) Invalidate() {
	var _arg0 *C.GstAudioClock // out

	_arg0 = (*C.GstAudioClock)(unsafe.Pointer(coreglib.BaseObject(clock).Native()))

	C.gst_audio_clock_invalidate(_arg0)
	runtime.KeepAlive(clock)
}

// Reset (gst_audio_clock_reset): inform clock that future calls to
// AudioClockGetTimeFunc will return values starting from time. The clock will
// update an internal offset to make sure that future calls to internal_time
// will return an increasing result as required by the Clock object.
//
// The function takes the following parameters:
//
//   - time: ClockTime.
func (clock *AudioClock) Reset(time gst.ClockTime) {
	var _arg0 *C.GstAudioClock // out
	var _arg1 C.GstClockTime   // out

	_arg0 = (*C.GstAudioClock)(unsafe.Pointer(coreglib.BaseObject(clock).Native()))
	_arg1 = C.GstClockTime(time)

	C.gst_audio_clock_reset(_arg0, _arg1)
	runtime.KeepAlive(clock)
	runtime.KeepAlive(time)
}

// AudioDecoderOverrides contains methods that are overridable.
type AudioDecoderOverrides struct {
	// Close: optional. Called when the element changes to GST_STATE_NULL.
	// Allows closing external resources.
	Close func() bool
	// DecideAllocation: optional. Setup the allocation parameters for
	// allocating output buffers. The passed in query contains the result of the
	// downstream allocation query. Subclasses should chain up to the parent
	// implementation to invoke the default handler.
	DecideAllocation func(query *gst.Query) bool
	// Flush: optional. Instructs subclass to clear any codec caches and
	// discard any pending samples and not yet returned decoded data. hard
	// indicates whether a FLUSH is being processed, or otherwise a DISCONT (or
	// conceptually similar).
	Flush func(hard bool)
	// Caps: optional. Allows for a custom sink getcaps implementation. If not
	// implemented, default returns gst_audio_decoder_proxy_getcaps applied to
	// sink template caps.
	caps func(filter *gst.Caps) *gst.Caps
	// HandleFrame provides input data (or NULL to clear any remaining data)
	// to subclass. Input data ref management is performed by base class,
	// subclass should not care or intervene, and input data is only
	// valid until next call to base class, most notably a call to
	// gst_audio_decoder_finish_frame().
	HandleFrame func(buffer *gst.Buffer) gst.FlowReturn
	// Negotiate with downstream elements to currently configured AudioInfo.
	// Unmark GST_PAD_FLAG_NEED_RECONFIGURE in any case. But mark it again if
	// negotiate fails.
	//
	// The function returns the following values:
	//
	//   - ok: TRUE if the negotiation succeeded, else FALSE.
	Negotiate func() bool
	// Open: optional. Called when the element changes to GST_STATE_READY.
	// Allows opening external resources.
	Open func() bool
	// The function returns the following values:
	//
	//   - offset
	//   - length
	//   - flowReturn
	Parse func(adapter *gstbase.Adapter) (offset, length int, flowReturn gst.FlowReturn)
	// ProposeAllocation: optional. Propose buffer allocation parameters
	// for upstream elements. Subclasses should chain up to the parent
	// implementation to invoke the default handler.
	ProposeAllocation func(query *gst.Query) bool
	// SetFormat notifies subclass of incoming data format (caps).
	SetFormat func(caps *gst.Caps) bool
	// SinkEvent: optional. Event handler on the sink pad. Subclasses should
	// chain up to the parent implementation to invoke the default handler.
	SinkEvent func(event *gst.Event) bool
	// SinkQuery: optional. Query handler on the sink pad. This function should
	// return TRUE if the query could be performed. Subclasses should chain up
	// to the parent implementation to invoke the default handler. Since: 1.6.
	SinkQuery func(query *gst.Query) bool
	// SrcEvent: optional. Event handler on the src pad. Subclasses should chain
	// up to the parent implementation to invoke the default handler.
	SrcEvent func(event *gst.Event) bool
	// SrcQuery: optional. Query handler on the source pad. This function should
	// return TRUE if the query could be performed. Subclasses should chain up
	// to the parent implementation to invoke the default handler. Since: 1.6.
	SrcQuery func(query *gst.Query) bool
	// Start: optional. Called when the element starts processing. Allows
	// opening external resources.
	Start func() bool
	// Stop: optional. Called when the element stops processing. Allows closing
	// external resources.
	Stop func() bool
	// TransformMeta: optional. Transform the metadata on the input buffer to
	// the output buffer. By default this method copies all meta without tags
	// and meta with only the "audio" tag. subclasses can implement this method
	// and return TRUE if the metadata is to be copied. Since: 1.6.
	//
	// The function takes the following parameters:
	//
	//   - outbuf
	//   - meta
	//   - inbuf
	TransformMeta func(outbuf *gst.Buffer, meta *gst.Meta, inbuf *gst.Buffer) bool
}

func defaultAudioDecoderOverrides(v *AudioDecoder) AudioDecoderOverrides {
	return AudioDecoderOverrides{
		Close:             v.close,
		DecideAllocation:  v.decideAllocation,
		Flush:             v.flush,
		caps:              v.caps,
		HandleFrame:       v.handleFrame,
		Negotiate:         v.negotiate,
		Open:              v.open,
		Parse:             v.parse,
		ProposeAllocation: v.proposeAllocation,
		SetFormat:         v.setFormat,
		SinkEvent:         v.sinkEvent,
		SinkQuery:         v.sinkQuery,
		SrcEvent:          v.srcEvent,
		SrcQuery:          v.srcQuery,
		Start:             v.start,
		Stop:              v.stop,
		TransformMeta:     v.transformMeta,
	}
}

// AudioDecoder (GstAudioDecoder): this base class is for audio decoders turning
// encoded data into raw audio samples.
//
// GstAudioDecoder and subclass should cooperate as follows.
//
// Configuration
//
//   - Initially, GstAudioDecoder calls start when the decoder element
//     is activated, which allows subclass to perform any global setup.
//     Base class (context) parameters can already be set according to subclass
//     capabilities (or possibly upon receive more information in subsequent
//     set_format).
//   - GstAudioDecoder calls set_format to inform subclass of the format
//     of input audio data that it is about to receive. While unlikely,
//     it might be called more than once, if changing input parameters require
//     reconfiguration.
//   - GstAudioDecoder calls stop at end of all processing.
//
// As of configuration stage, and throughout processing, GstAudioDecoder
// provides various (context) parameters, e.g. describing the format of output
// audio data (valid when output caps have been set) or current parsing state.
// Conversely, subclass can and should configure context to inform base class of
// its expectation w.r.t. buffer handling.
//
// Data processing
//
//   - Base class gathers input data, and optionally allows subclass to parse
//     this into subsequently manageable (as defined by subclass) chunks.
//     Such chunks are subsequently referred to as 'frames', though they may or
//     may not correspond to 1 (or more) audio format frame.
//   - Input frame is provided to subclass' handle_frame.
//   - If codec processing results in decoded data, subclass should call
//     gst_audio_decoder_finish_frame to have decoded data pushed downstream.
//   - Just prior to actually pushing a buffer downstream, it is passed to
//     pre_push. Subclass should either use this callback to arrange for
//     additional downstream pushing or otherwise ensure such custom pushing
//     occurs after at least a method call has finished since setting src pad
//     caps.
//   - During the parsing process GstAudioDecoderClass will handle both srcpad
//     and sinkpad events. Sink events will be passed to subclass if event
//     callback has been provided.
//
// Shutdown phase
//
//   - GstAudioDecoder class calls stop to inform the subclass that data parsing
//     will be stopped.
//
// Subclass is responsible for providing pad template caps for source and sink
// pads. The pads need to be named "sink" and "src". It also needs to set the
// fixed caps on srcpad, when the format is ensured. This is typically when base
// class calls subclass' set_format function, though it might be delayed until
// calling gst_audio_decoder_finish_frame.
//
// In summary, above process should have subclass concentrating on codec data
// processing while leaving other matters to base class, such as most notably
// timestamp handling. While it may exert more control in this area (see e.g.
// pre_push), it is very much not recommended.
//
// In particular, base class will try to arrange for perfect output timestamps
// as much as possible while tracking upstream timestamps. To this end,
// if deviation between the next ideal expected perfect timestamp and upstream
// exceeds AudioDecoder:tolerance, then resync to upstream occurs (which would
// happen always if the tolerance mechanism is disabled).
//
// In non-live pipelines, baseclass can also (configurably) arrange for output
// buffer aggregation which may help to redue large(r) numbers of small(er)
// buffers being pushed and processed downstream. Note that this feature is
// only available if the buffer layout is interleaved. For planar buffers,
// the decoder implementation is fully responsible for the output buffer size.
//
// On the other hand, it should be noted that baseclass only provides limited
// seeking support (upon explicit subclass request), as full-fledged support
// should rather be left to upstream demuxer, parser or alike. This simple
// approach caters for seeking and duration reporting using estimated input
// bitrates.
//
// Things that subclass need to take care of:
//
//   - Provide pad templates
//
//   - Set source pad caps when appropriate
//
//   - Set user-configurable properties to sane defaults for format and
//     implementing codec at hand, and convey some subclass capabilities and
//     expectations in context.
//
//   - Accept data in handle_frame and provide encoded results to
//     gst_audio_decoder_finish_frame. If it is prepared to perform PLC,
//     it should also accept NULL data in handle_frame and provide for data for
//     indicated duration.
type AudioDecoder struct {
	_ [0]func() // equal guard
	gst.Element
}

var (
	_ gst.Elementer = (*AudioDecoder)(nil)
)

// AudioDecoderer describes types inherited from AudioDecoder.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type AudioDecoderer interface {
	gst.Elementer

	// AllocateOutputBuffer (gst_audio_decoder_allocate_output_buffer): helper
	// function that allocates a buffer to hold an audio frame for dec's current
	// output format.
	AllocateOutputBuffer(size uint) *gst.Buffer
	// FinishFrame (gst_audio_decoder_finish_frame) collects decoded data and
	// pushes it downstream.
	FinishFrame(buf *gst.Buffer, frames int) gst.FlowReturn
	// FinishSubframe (gst_audio_decoder_finish_subframe) collects decoded data
	// and pushes it downstream.
	FinishSubframe(buf *gst.Buffer) gst.FlowReturn
	// Allocator (gst_audio_decoder_get_allocator) lets AudioDecoder sub-classes
	// to know the memory allocator used by the base class and its params.
	Allocator() (gst.Allocatorrer, *gst.AllocationParams)
	AudioInfo() *AudioInfo
	Delay() int
	// Drainable (gst_audio_decoder_get_drainable) queries decoder drain
	// handling.
	Drainable() bool
	EstimateRate() int
	// Latency (gst_audio_decoder_get_latency) sets the variables pointed to by
	// min and max to the currently configured latency.
	Latency() (min, max gst.ClockTime)
	MaxErrors() int
	// MinLatency (gst_audio_decoder_get_min_latency) queries decoder's latency
	// aggregation.
	MinLatency() gst.ClockTime
	// NeedsFormat (gst_audio_decoder_get_needs_format) queries decoder required
	// format handling.
	NeedsFormat() bool
	// ParseState (gst_audio_decoder_get_parse_state): return current parsing
	// (sync and eos) state.
	ParseState() (sync, eos bool)
	// Plc (gst_audio_decoder_get_plc) queries decoder packet loss concealment
	// handling.
	Plc() bool
	PlcAware() int
	// Tolerance (gst_audio_decoder_get_tolerance) queries current audio jitter
	// tolerance threshold.
	Tolerance() gst.ClockTime
	// MergeTags (gst_audio_decoder_merge_tags) sets the audio decoder tags and
	// how they should be merged with any upstream stream tags.
	MergeTags(tags *gst.TagList, mode gst.TagMergeMode)
	// Negotiate (gst_audio_decoder_negotiate) with downstream elements to
	// currently configured AudioInfo.
	Negotiate() bool
	// ProxyGetcaps (gst_audio_decoder_proxy_getcaps) returns caps that
	// express caps (or sink template caps if caps == NULL) restricted to
	// rate/channels/...
	ProxyGetcaps(caps, filter *gst.Caps) *gst.Caps
	// SetAllocationCaps (gst_audio_decoder_set_allocation_caps) sets a caps in
	// allocation query which are different from the set pad's caps.
	SetAllocationCaps(allocationCaps *gst.Caps)
	// SetDrainable (gst_audio_decoder_set_drainable) configures decoder drain
	// handling.
	SetDrainable(enabled bool)
	// SetEstimateRate (gst_audio_decoder_set_estimate_rate) allows baseclass to
	// perform byte to time estimated conversion.
	SetEstimateRate(enabled bool)
	// SetLatency (gst_audio_decoder_set_latency) sets decoder latency.
	SetLatency(min, max gst.ClockTime)
	// SetMaxErrors (gst_audio_decoder_set_max_errors) sets numbers of tolerated
	// decoder errors, where a tolerated one is then only warned about, but more
	// than tolerated will lead to fatal error.
	SetMaxErrors(num int)
	// SetMinLatency (gst_audio_decoder_set_min_latency) sets decoder minimum
	// aggregation latency.
	SetMinLatency(num gst.ClockTime)
	// SetNeedsFormat (gst_audio_decoder_set_needs_format) configures decoder
	// format needs.
	SetNeedsFormat(enabled bool)
	// SetOutputCaps (gst_audio_decoder_set_output_caps): configure output caps
	// on the srcpad of dec.
	SetOutputCaps(caps *gst.Caps) bool
	// SetOutputFormat (gst_audio_decoder_set_output_format): configure output
	// info on the srcpad of dec.
	SetOutputFormat(info *AudioInfo) bool
	// SetPlc (gst_audio_decoder_set_plc): enable or disable decoder packet loss
	// concealment, provided subclass and codec are capable and allow handling
	// plc.
	SetPlc(enabled bool)
	// SetPlcAware (gst_audio_decoder_set_plc_aware) indicates whether or not
	// subclass handles packet loss concealment (plc).
	SetPlcAware(plc bool)
	// SetTolerance (gst_audio_decoder_set_tolerance) configures decoder audio
	// jitter tolerance threshold.
	SetTolerance(tolerance gst.ClockTime)
	// SetUseDefaultPadAcceptcaps
	// (gst_audio_decoder_set_use_default_pad_acceptcaps) lets AudioDecoder
	// sub-classes decide if they want the sink pad to use the default pad query
	// handler to reply to accept-caps queries.
	SetUseDefaultPadAcceptcaps(use bool)

	baseAudioDecoder() *AudioDecoder
}

var _ AudioDecoderer = (*AudioDecoder)(nil)

func init() {
	coreglib.RegisterClassInfo[*AudioDecoder, *AudioDecoderClass, AudioDecoderOverrides](
		GTypeAudioDecoder,
		initAudioDecoderClass,
		wrapAudioDecoder,
		defaultAudioDecoderOverrides,
	)
}

func initAudioDecoderClass(gclass unsafe.Pointer, overrides AudioDecoderOverrides, classInitFunc func(*AudioDecoderClass)) {
	pclass := (*C.GstAudioDecoderClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeAudioDecoder))))

	if overrides.Close != nil {
		pclass.close = (*[0]byte)(C._gotk4_gstaudio1_AudioDecoderClass_close)
	}

	if overrides.DecideAllocation != nil {
		pclass.decide_allocation = (*[0]byte)(C._gotk4_gstaudio1_AudioDecoderClass_decide_allocation)
	}

	if overrides.Flush != nil {
		pclass.flush = (*[0]byte)(C._gotk4_gstaudio1_AudioDecoderClass_flush)
	}

	if overrides.caps != nil {
		pclass.getcaps = (*[0]byte)(C._gotk4_gstaudio1_AudioDecoderClass_getcaps)
	}

	if overrides.HandleFrame != nil {
		pclass.handle_frame = (*[0]byte)(C._gotk4_gstaudio1_AudioDecoderClass_handle_frame)
	}

	if overrides.Negotiate != nil {
		pclass.negotiate = (*[0]byte)(C._gotk4_gstaudio1_AudioDecoderClass_negotiate)
	}

	if overrides.Open != nil {
		pclass.open = (*[0]byte)(C._gotk4_gstaudio1_AudioDecoderClass_open)
	}

	if overrides.Parse != nil {
		pclass.parse = (*[0]byte)(C._gotk4_gstaudio1_AudioDecoderClass_parse)
	}

	if overrides.ProposeAllocation != nil {
		pclass.propose_allocation = (*[0]byte)(C._gotk4_gstaudio1_AudioDecoderClass_propose_allocation)
	}

	if overrides.SetFormat != nil {
		pclass.set_format = (*[0]byte)(C._gotk4_gstaudio1_AudioDecoderClass_set_format)
	}

	if overrides.SinkEvent != nil {
		pclass.sink_event = (*[0]byte)(C._gotk4_gstaudio1_AudioDecoderClass_sink_event)
	}

	if overrides.SinkQuery != nil {
		pclass.sink_query = (*[0]byte)(C._gotk4_gstaudio1_AudioDecoderClass_sink_query)
	}

	if overrides.SrcEvent != nil {
		pclass.src_event = (*[0]byte)(C._gotk4_gstaudio1_AudioDecoderClass_src_event)
	}

	if overrides.SrcQuery != nil {
		pclass.src_query = (*[0]byte)(C._gotk4_gstaudio1_AudioDecoderClass_src_query)
	}

	if overrides.Start != nil {
		pclass.start = (*[0]byte)(C._gotk4_gstaudio1_AudioDecoderClass_start)
	}

	if overrides.Stop != nil {
		pclass.stop = (*[0]byte)(C._gotk4_gstaudio1_AudioDecoderClass_stop)
	}

	if overrides.TransformMeta != nil {
		pclass.transform_meta = (*[0]byte)(C._gotk4_gstaudio1_AudioDecoderClass_transform_meta)
	}

	if classInitFunc != nil {
		class := (*AudioDecoderClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapAudioDecoder(obj *coreglib.Object) *AudioDecoder {
	return &AudioDecoder{
		Element: gst.Element{
			GstObject: gst.GstObject{
				InitiallyUnowned: coreglib.InitiallyUnowned{
					Object: obj,
				},
			},
		},
	}
}

func marshalAudioDecoder(p uintptr) (interface{}, error) {
	return wrapAudioDecoder(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (dec *AudioDecoder) baseAudioDecoder() *AudioDecoder {
	return dec
}

// BaseAudioDecoder returns the underlying base object.
func BaseAudioDecoder(obj AudioDecoderer) *AudioDecoder {
	return obj.baseAudioDecoder()
}

// AllocateOutputBuffer (gst_audio_decoder_allocate_output_buffer): helper
// function that allocates a buffer to hold an audio frame for dec's current
// output format.
//
// The function takes the following parameters:
//
//   - size of the buffer.
//
// The function returns the following values:
//
//   - buffer: allocated buffer.
func (dec *AudioDecoder) AllocateOutputBuffer(size uint) *gst.Buffer {
	var _arg0 *C.GstAudioDecoder // out
	var _arg1 C.gsize            // out
	var _cret *C.GstBuffer       // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = C.gsize(size)

	_cret = C.gst_audio_decoder_allocate_output_buffer(_arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(size)

	var _buffer *gst.Buffer // out

	_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_buffer)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _buffer
}

// FinishFrame (gst_audio_decoder_finish_frame) collects decoded data and pushes
// it downstream.
//
// buf may be NULL in which case the indicated number of frames are discarded
// and considered to have produced no output (e.g. lead-in or setup frames).
// Otherwise, source pad caps must be set when it is called with valid data in
// buf.
//
// Note that a frame received in AudioDecoderClass.handle_frame() may be
// invalidated by a call to this function.
//
// The function takes the following parameters:
//
//   - buf (optional): decoded data.
//   - frames: number of decoded frames represented by decoded data.
//
// The function returns the following values:
//
//   - flowReturn that should be escalated to caller (of caller).
func (dec *AudioDecoder) FinishFrame(buf *gst.Buffer, frames int) gst.FlowReturn {
	var _arg0 *C.GstAudioDecoder // out
	var _arg1 *C.GstBuffer       // out
	var _arg2 C.gint             // out
	var _cret C.GstFlowReturn    // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	if buf != nil {
		_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buf)))
		runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(buf)), nil)
	}
	_arg2 = C.gint(frames)

	_cret = C.gst_audio_decoder_finish_frame(_arg0, _arg1, _arg2)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(buf)
	runtime.KeepAlive(frames)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// FinishSubframe (gst_audio_decoder_finish_subframe) collects decoded data and
// pushes it downstream. This function may be called multiple times for a given
// input frame.
//
// buf may be NULL in which case it is assumed that the current input frame is
// finished. This is equivalent to calling gst_audio_decoder_finish_subframe()
// with a NULL buffer and frames=1 after having pushed out all decoded audio
// subframes using this function.
//
// When called with valid data in buf the source pad caps must have been set
// already.
//
// Note that a frame received in AudioDecoderClass.handle_frame() may be
// invalidated by a call to this function.
//
// The function takes the following parameters:
//
//   - buf (optional): decoded data.
//
// The function returns the following values:
//
//   - flowReturn that should be escalated to caller (of caller).
func (dec *AudioDecoder) FinishSubframe(buf *gst.Buffer) gst.FlowReturn {
	var _arg0 *C.GstAudioDecoder // out
	var _arg1 *C.GstBuffer       // out
	var _cret C.GstFlowReturn    // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	if buf != nil {
		_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buf)))
		runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(buf)), nil)
	}

	_cret = C.gst_audio_decoder_finish_subframe(_arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(buf)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// Allocator (gst_audio_decoder_get_allocator) lets AudioDecoder sub-classes to
// know the memory allocator used by the base class and its params.
//
// Unref the allocator after use it.
//
// The function returns the following values:
//
//   - allocator (optional): Allocator used.
//   - params (optional) the AllocationParams of allocator.
func (dec *AudioDecoder) Allocator() (gst.Allocatorrer, *gst.AllocationParams) {
	var _arg0 *C.GstAudioDecoder    // out
	var _arg1 *C.GstAllocator       // in
	var _arg2 C.GstAllocationParams // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	C.gst_audio_decoder_get_allocator(_arg0, &_arg1, &_arg2)
	runtime.KeepAlive(dec)

	var _allocator gst.Allocatorrer   // out
	var _params *gst.AllocationParams // out

	if _arg1 != nil {
		{
			objptr := unsafe.Pointer(_arg1)

			object := coreglib.AssumeOwnership(objptr)
			casted := object.WalkCast(func(obj coreglib.Objector) bool {
				_, ok := obj.(gst.Allocatorrer)
				return ok
			})
			rv, ok := casted.(gst.Allocatorrer)
			if !ok {
				panic("no marshaler for " + object.TypeFromInstance().String() + " matching gst.Allocatorrer")
			}
			_allocator = rv
		}
	}
	_params = (*gst.AllocationParams)(gextras.NewStructNative(unsafe.Pointer((&_arg2))))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_params)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_allocation_params_free((*C.GstAllocationParams)(intern.C))
		},
	)

	return _allocator, _params
}

// The function returns the following values:
//
//   - audioInfo describing the input audio format.
func (dec *AudioDecoder) AudioInfo() *AudioInfo {
	var _arg0 *C.GstAudioDecoder // out
	var _cret *C.GstAudioInfo    // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	_cret = C.gst_audio_decoder_get_audio_info(_arg0)
	runtime.KeepAlive(dec)

	var _audioInfo *AudioInfo // out

	_audioInfo = (*AudioInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _audioInfo
}

// The function returns the following values:
//
//   - gint: currently configured decoder delay.
func (dec *AudioDecoder) Delay() int {
	var _arg0 *C.GstAudioDecoder // out
	var _cret C.gint             // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	_cret = C.gst_audio_decoder_get_delay(_arg0)
	runtime.KeepAlive(dec)

	var _gint int // out

	_gint = int(_cret)

	return _gint
}

// Drainable (gst_audio_decoder_get_drainable) queries decoder drain handling.
//
// The function returns the following values:
//
//   - ok: TRUE if drainable handling is enabled.
//
//     MT safe.
func (dec *AudioDecoder) Drainable() bool {
	var _arg0 *C.GstAudioDecoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	_cret = C.gst_audio_decoder_get_drainable(_arg0)
	runtime.KeepAlive(dec)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function returns the following values:
//
//   - gint: currently configured byte to time conversion setting.
func (dec *AudioDecoder) EstimateRate() int {
	var _arg0 *C.GstAudioDecoder // out
	var _cret C.gint             // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	_cret = C.gst_audio_decoder_get_estimate_rate(_arg0)
	runtime.KeepAlive(dec)

	var _gint int // out

	_gint = int(_cret)

	return _gint
}

// Latency (gst_audio_decoder_get_latency) sets the variables pointed to by min
// and max to the currently configured latency.
//
// The function returns the following values:
//
//   - min (optional): pointer to storage to hold minimum latency.
//   - max (optional): pointer to storage to hold maximum latency.
func (dec *AudioDecoder) Latency() (min, max gst.ClockTime) {
	var _arg0 *C.GstAudioDecoder // out
	var _arg1 C.GstClockTime     // in
	var _arg2 C.GstClockTime     // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	C.gst_audio_decoder_get_latency(_arg0, &_arg1, &_arg2)
	runtime.KeepAlive(dec)

	var _min gst.ClockTime // out
	var _max gst.ClockTime // out

	_min = gst.ClockTime(_arg1)
	_max = gst.ClockTime(_arg2)

	return _min, _max
}

// The function returns the following values:
//
//   - gint: currently configured decoder tolerated error count.
func (dec *AudioDecoder) MaxErrors() int {
	var _arg0 *C.GstAudioDecoder // out
	var _cret C.gint             // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	_cret = C.gst_audio_decoder_get_max_errors(_arg0)
	runtime.KeepAlive(dec)

	var _gint int // out

	_gint = int(_cret)

	return _gint
}

// MinLatency (gst_audio_decoder_get_min_latency) queries decoder's latency
// aggregation.
//
// The function returns the following values:
//
//   - clockTime: aggregation latency.
//
//     MT safe.
func (dec *AudioDecoder) MinLatency() gst.ClockTime {
	var _arg0 *C.GstAudioDecoder // out
	var _cret C.GstClockTime     // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	_cret = C.gst_audio_decoder_get_min_latency(_arg0)
	runtime.KeepAlive(dec)

	var _clockTime gst.ClockTime // out

	_clockTime = gst.ClockTime(_cret)

	return _clockTime
}

// NeedsFormat (gst_audio_decoder_get_needs_format) queries decoder required
// format handling.
//
// The function returns the following values:
//
//   - ok: TRUE if required format handling is enabled.
//
//     MT safe.
func (dec *AudioDecoder) NeedsFormat() bool {
	var _arg0 *C.GstAudioDecoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	_cret = C.gst_audio_decoder_get_needs_format(_arg0)
	runtime.KeepAlive(dec)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// ParseState (gst_audio_decoder_get_parse_state): return current parsing (sync
// and eos) state.
//
// The function returns the following values:
//
//   - sync (optional): pointer to a variable to hold the current sync state.
//   - eos (optional): pointer to a variable to hold the current eos state.
func (dec *AudioDecoder) ParseState() (sync, eos bool) {
	var _arg0 *C.GstAudioDecoder // out
	var _arg1 C.gboolean         // in
	var _arg2 C.gboolean         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	C.gst_audio_decoder_get_parse_state(_arg0, &_arg1, &_arg2)
	runtime.KeepAlive(dec)

	var _sync bool // out
	var _eos bool  // out

	if _arg1 != 0 {
		_sync = true
	}
	if _arg2 != 0 {
		_eos = true
	}

	return _sync, _eos
}

// Plc (gst_audio_decoder_get_plc) queries decoder packet loss concealment
// handling.
//
// The function returns the following values:
//
//   - ok: TRUE if packet loss concealment is enabled.
//
//     MT safe.
func (dec *AudioDecoder) Plc() bool {
	var _arg0 *C.GstAudioDecoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	_cret = C.gst_audio_decoder_get_plc(_arg0)
	runtime.KeepAlive(dec)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function returns the following values:
//
//   - gint: currently configured plc handling.
func (dec *AudioDecoder) PlcAware() int {
	var _arg0 *C.GstAudioDecoder // out
	var _cret C.gint             // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	_cret = C.gst_audio_decoder_get_plc_aware(_arg0)
	runtime.KeepAlive(dec)

	var _gint int // out

	_gint = int(_cret)

	return _gint
}

// Tolerance (gst_audio_decoder_get_tolerance) queries current audio jitter
// tolerance threshold.
//
// The function returns the following values:
//
//   - clockTime: decoder audio jitter tolerance threshold.
//
//     MT safe.
func (dec *AudioDecoder) Tolerance() gst.ClockTime {
	var _arg0 *C.GstAudioDecoder // out
	var _cret C.GstClockTime     // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	_cret = C.gst_audio_decoder_get_tolerance(_arg0)
	runtime.KeepAlive(dec)

	var _clockTime gst.ClockTime // out

	_clockTime = gst.ClockTime(_cret)

	return _clockTime
}

// MergeTags (gst_audio_decoder_merge_tags) sets the audio decoder tags and how
// they should be merged with any upstream stream tags. This will override any
// tags previously-set with gst_audio_decoder_merge_tags().
//
// Note that this is provided for convenience, and the subclass is not required
// to use this and can still do tag handling on its own.
//
// The function takes the following parameters:
//
//   - tags (optional) to merge, or NULL.
//   - mode to use, usually T_TAG_MERGE_REPLACE.
func (dec *AudioDecoder) MergeTags(tags *gst.TagList, mode gst.TagMergeMode) {
	var _arg0 *C.GstAudioDecoder // out
	var _arg1 *C.GstTagList      // out
	var _arg2 C.GstTagMergeMode  // out

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	if tags != nil {
		_arg1 = (*C.GstTagList)(gextras.StructNative(unsafe.Pointer(tags)))
	}
	_arg2 = C.GstTagMergeMode(mode)

	C.gst_audio_decoder_merge_tags(_arg0, _arg1, _arg2)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(tags)
	runtime.KeepAlive(mode)
}

// Negotiate (gst_audio_decoder_negotiate) with downstream elements to currently
// configured AudioInfo. Unmark GST_PAD_FLAG_NEED_RECONFIGURE in any case.
// But mark it again if negotiate fails.
//
// The function returns the following values:
//
//   - ok: TRUE if the negotiation succeeded, else FALSE.
func (dec *AudioDecoder) Negotiate() bool {
	var _arg0 *C.GstAudioDecoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	_cret = C.gst_audio_decoder_negotiate(_arg0)
	runtime.KeepAlive(dec)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// ProxyGetcaps (gst_audio_decoder_proxy_getcaps) returns caps that express
// caps (or sink template caps if caps == NULL) restricted to rate/channels/...
// combinations supported by downstream elements.
//
// The function takes the following parameters:
//
//   - caps (optional): initial caps.
//   - filter (optional) caps.
//
// The function returns the following values:
//
//   - ret owned by caller.
func (decoder *AudioDecoder) ProxyGetcaps(caps, filter *gst.Caps) *gst.Caps {
	var _arg0 *C.GstAudioDecoder // out
	var _arg1 *C.GstCaps         // out
	var _arg2 *C.GstCaps         // out
	var _cret *C.GstCaps         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	if caps != nil {
		_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))
	}
	if filter != nil {
		_arg2 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(filter)))
	}

	_cret = C.gst_audio_decoder_proxy_getcaps(_arg0, _arg1, _arg2)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(caps)
	runtime.KeepAlive(filter)

	var _ret *gst.Caps // out

	_ret = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_ret)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _ret
}

// SetAllocationCaps (gst_audio_decoder_set_allocation_caps) sets a caps in
// allocation query which are different from the set pad's caps. Use this
// function before calling gst_audio_decoder_negotiate(). Setting to NULL the
// allocation query will use the caps from the pad.
//
// The function takes the following parameters:
//
//   - allocationCaps (optional) or NULL.
func (dec *AudioDecoder) SetAllocationCaps(allocationCaps *gst.Caps) {
	var _arg0 *C.GstAudioDecoder // out
	var _arg1 *C.GstCaps         // out

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	if allocationCaps != nil {
		_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(allocationCaps)))
	}

	C.gst_audio_decoder_set_allocation_caps(_arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(allocationCaps)
}

// SetDrainable (gst_audio_decoder_set_drainable) configures decoder drain
// handling. If drainable, subclass might be handed a NULL buffer to have it
// return any leftover decoded data. Otherwise, it is not considered so capable
// and will only ever be passed real data.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - enabled: new state.
func (dec *AudioDecoder) SetDrainable(enabled bool) {
	var _arg0 *C.GstAudioDecoder // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	if enabled {
		_arg1 = C.TRUE
	}

	C.gst_audio_decoder_set_drainable(_arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(enabled)
}

// SetEstimateRate (gst_audio_decoder_set_estimate_rate) allows baseclass to
// perform byte to time estimated conversion.
//
// The function takes the following parameters:
//
//   - enabled: whether to enable byte to time conversion.
func (dec *AudioDecoder) SetEstimateRate(enabled bool) {
	var _arg0 *C.GstAudioDecoder // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	if enabled {
		_arg1 = C.TRUE
	}

	C.gst_audio_decoder_set_estimate_rate(_arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(enabled)
}

// SetLatency (gst_audio_decoder_set_latency) sets decoder latency. If the
// provided values changed from previously provided ones, this will also post
// a LATENCY message on the bus so the pipeline can reconfigure its global
// latency.
//
// The function takes the following parameters:
//
//   - min: minimum latency.
//   - max: maximum latency.
func (dec *AudioDecoder) SetLatency(min, max gst.ClockTime) {
	var _arg0 *C.GstAudioDecoder // out
	var _arg1 C.GstClockTime     // out
	var _arg2 C.GstClockTime     // out

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = C.GstClockTime(min)
	_arg2 = C.GstClockTime(max)

	C.gst_audio_decoder_set_latency(_arg0, _arg1, _arg2)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(min)
	runtime.KeepAlive(max)
}

// SetMaxErrors (gst_audio_decoder_set_max_errors) sets numbers of tolerated
// decoder errors, where a tolerated one is then only warned about, but more
// than tolerated will lead to fatal error. You can set -1 for never returning
// fatal errors. Default is set to GST_AUDIO_DECODER_MAX_ERRORS.
//
// The function takes the following parameters:
//
//   - num: max tolerated errors.
func (dec *AudioDecoder) SetMaxErrors(num int) {
	var _arg0 *C.GstAudioDecoder // out
	var _arg1 C.gint             // out

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = C.gint(num)

	C.gst_audio_decoder_set_max_errors(_arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(num)
}

// SetMinLatency (gst_audio_decoder_set_min_latency) sets decoder minimum
// aggregation latency.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - num: new minimum latency.
func (dec *AudioDecoder) SetMinLatency(num gst.ClockTime) {
	var _arg0 *C.GstAudioDecoder // out
	var _arg1 C.GstClockTime     // out

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = C.GstClockTime(num)

	C.gst_audio_decoder_set_min_latency(_arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(num)
}

// SetNeedsFormat (gst_audio_decoder_set_needs_format) configures decoder format
// needs. If enabled, subclass needs to be negotiated with format caps before
// it can process any data. It will then never be handed any data before it
// has been configured. Otherwise, it might be handed data without having been
// configured and is then expected being able to do so either by default or
// based on the input data.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - enabled: new state.
func (dec *AudioDecoder) SetNeedsFormat(enabled bool) {
	var _arg0 *C.GstAudioDecoder // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	if enabled {
		_arg1 = C.TRUE
	}

	C.gst_audio_decoder_set_needs_format(_arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(enabled)
}

// SetOutputCaps (gst_audio_decoder_set_output_caps): configure output caps
// on the srcpad of dec. Similar to gst_audio_decoder_set_output_format(),
// but allows subclasses to specify output caps that can't be expressed via
// AudioInfo e.g. caps that have caps features.
//
// The function takes the following parameters:
//
//   - caps: (fixed) Caps.
//
// The function returns the following values:
//
//   - ok: TRUE on success.
func (dec *AudioDecoder) SetOutputCaps(caps *gst.Caps) bool {
	var _arg0 *C.GstAudioDecoder // out
	var _arg1 *C.GstCaps         // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C.gst_audio_decoder_set_output_caps(_arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(caps)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SetOutputFormat (gst_audio_decoder_set_output_format): configure output info
// on the srcpad of dec.
//
// The function takes the following parameters:
//
//   - info: AudioInfo.
//
// The function returns the following values:
//
//   - ok: TRUE on success.
func (dec *AudioDecoder) SetOutputFormat(info *AudioInfo) bool {
	var _arg0 *C.GstAudioDecoder // out
	var _arg1 *C.GstAudioInfo    // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = (*C.GstAudioInfo)(gextras.StructNative(unsafe.Pointer(info)))

	_cret = C.gst_audio_decoder_set_output_format(_arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(info)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SetPlc (gst_audio_decoder_set_plc): enable or disable decoder packet loss
// concealment, provided subclass and codec are capable and allow handling plc.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - enabled: new state.
func (dec *AudioDecoder) SetPlc(enabled bool) {
	var _arg0 *C.GstAudioDecoder // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	if enabled {
		_arg1 = C.TRUE
	}

	C.gst_audio_decoder_set_plc(_arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(enabled)
}

// SetPlcAware (gst_audio_decoder_set_plc_aware) indicates whether or not
// subclass handles packet loss concealment (plc).
//
// The function takes the following parameters:
//
//   - plc: new plc state.
func (dec *AudioDecoder) SetPlcAware(plc bool) {
	var _arg0 *C.GstAudioDecoder // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	if plc {
		_arg1 = C.TRUE
	}

	C.gst_audio_decoder_set_plc_aware(_arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(plc)
}

// SetTolerance (gst_audio_decoder_set_tolerance) configures decoder audio
// jitter tolerance threshold.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - tolerance: new tolerance.
func (dec *AudioDecoder) SetTolerance(tolerance gst.ClockTime) {
	var _arg0 *C.GstAudioDecoder // out
	var _arg1 C.GstClockTime     // out

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = C.GstClockTime(tolerance)

	C.gst_audio_decoder_set_tolerance(_arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(tolerance)
}

// SetUseDefaultPadAcceptcaps (gst_audio_decoder_set_use_default_pad_acceptcaps)
// lets AudioDecoder sub-classes decide if they want the sink pad to use the
// default pad query handler to reply to accept-caps queries.
//
// By setting this to true it is possible to further customize the default
// handler with GST_PAD_SET_ACCEPT_INTERSECT and GST_PAD_SET_ACCEPT_TEMPLATE.
//
// The function takes the following parameters:
//
//   - use: if the default pad accept-caps query handling should be used.
func (decoder *AudioDecoder) SetUseDefaultPadAcceptcaps(use bool) {
	var _arg0 *C.GstAudioDecoder // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(decoder).Native()))
	if use {
		_arg1 = C.TRUE
	}

	C.gst_audio_decoder_set_use_default_pad_acceptcaps(_arg0, _arg1)
	runtime.KeepAlive(decoder)
	runtime.KeepAlive(use)
}

// Close: optional. Called when the element changes to GST_STATE_NULL. Allows
// closing external resources.
func (dec *AudioDecoder) close() bool {
	gclass := (*C.GstAudioDecoderClass)(coreglib.PeekParentClass(dec))
	fnarg := gclass.close

	var _arg0 *C.GstAudioDecoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	_cret = C._gotk4_gstaudio1_AudioDecoder_virtual_close(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(dec)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// decideAllocation: optional. Setup the allocation parameters for allocating
// output buffers. The passed in query contains the result of the downstream
// allocation query. Subclasses should chain up to the parent implementation to
// invoke the default handler.
func (dec *AudioDecoder) decideAllocation(query *gst.Query) bool {
	gclass := (*C.GstAudioDecoderClass)(coreglib.PeekParentClass(dec))
	fnarg := gclass.decide_allocation

	var _arg0 *C.GstAudioDecoder // out
	var _arg1 *C.GstQuery        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstaudio1_AudioDecoder_virtual_decide_allocation(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Flush: optional. Instructs subclass to clear any codec caches and discard any
// pending samples and not yet returned decoded data. hard indicates whether a
// FLUSH is being processed, or otherwise a DISCONT (or conceptually similar).
func (dec *AudioDecoder) flush(hard bool) {
	gclass := (*C.GstAudioDecoderClass)(coreglib.PeekParentClass(dec))
	fnarg := gclass.flush

	var _arg0 *C.GstAudioDecoder // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	if hard {
		_arg1 = C.TRUE
	}

	C._gotk4_gstaudio1_AudioDecoder_virtual_flush(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(hard)
}

// Caps: optional. Allows for a custom sink getcaps implementation. If not
// implemented, default returns gst_audio_decoder_proxy_getcaps applied to sink
// template caps.
func (dec *AudioDecoder) caps(filter *gst.Caps) *gst.Caps {
	gclass := (*C.GstAudioDecoderClass)(coreglib.PeekParentClass(dec))
	fnarg := gclass.getcaps

	var _arg0 *C.GstAudioDecoder // out
	var _arg1 *C.GstCaps         // out
	var _cret *C.GstCaps         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(filter)))

	_cret = C._gotk4_gstaudio1_AudioDecoder_virtual_getcaps(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(filter)

	var _caps *gst.Caps // out

	_caps = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_caps)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _caps
}

// handleFrame provides input data (or NULL to clear any remaining data) to
// subclass. Input data ref management is performed by base class, subclass
// should not care or intervene, and input data is only valid until next call to
// base class, most notably a call to gst_audio_decoder_finish_frame().
func (dec *AudioDecoder) handleFrame(buffer *gst.Buffer) gst.FlowReturn {
	gclass := (*C.GstAudioDecoderClass)(coreglib.PeekParentClass(dec))
	fnarg := gclass.handle_frame

	var _arg0 *C.GstAudioDecoder // out
	var _arg1 *C.GstBuffer       // out
	var _cret C.GstFlowReturn    // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))

	_cret = C._gotk4_gstaudio1_AudioDecoder_virtual_handle_frame(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(buffer)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// Negotiate: negotiate with downstream elements to currently configured
// AudioInfo. Unmark GST_PAD_FLAG_NEED_RECONFIGURE in any case. But mark it
// again if negotiate fails.
//
// The function returns the following values:
//
//   - ok: TRUE if the negotiation succeeded, else FALSE.
func (dec *AudioDecoder) negotiate() bool {
	gclass := (*C.GstAudioDecoderClass)(coreglib.PeekParentClass(dec))
	fnarg := gclass.negotiate

	var _arg0 *C.GstAudioDecoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	_cret = C._gotk4_gstaudio1_AudioDecoder_virtual_negotiate(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(dec)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Open: optional. Called when the element changes to GST_STATE_READY. Allows
// opening external resources.
func (dec *AudioDecoder) open() bool {
	gclass := (*C.GstAudioDecoderClass)(coreglib.PeekParentClass(dec))
	fnarg := gclass.open

	var _arg0 *C.GstAudioDecoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	_cret = C._gotk4_gstaudio1_AudioDecoder_virtual_open(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(dec)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function returns the following values:
//
//   - offset
//   - length
//   - flowReturn
func (dec *AudioDecoder) parse(adapter *gstbase.Adapter) (offset, length int, flowReturn gst.FlowReturn) {
	gclass := (*C.GstAudioDecoderClass)(coreglib.PeekParentClass(dec))
	fnarg := gclass.parse

	var _arg0 *C.GstAudioDecoder // out
	var _arg1 *C.GstAdapter      // out
	var _arg2 C.gint             // in
	var _arg3 C.gint             // in
	var _cret C.GstFlowReturn    // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = (*C.GstAdapter)(unsafe.Pointer(coreglib.BaseObject(adapter).Native()))

	_cret = C._gotk4_gstaudio1_AudioDecoder_virtual_parse(unsafe.Pointer(fnarg), _arg0, _arg1, &_arg2, &_arg3)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(adapter)

	var _offset int                // out
	var _length int                // out
	var _flowReturn gst.FlowReturn // out

	_offset = int(_arg2)
	_length = int(_arg3)
	_flowReturn = gst.FlowReturn(_cret)

	return _offset, _length, _flowReturn
}

// proposeAllocation: optional. Propose buffer allocation parameters for
// upstream elements. Subclasses should chain up to the parent implementation to
// invoke the default handler.
func (dec *AudioDecoder) proposeAllocation(query *gst.Query) bool {
	gclass := (*C.GstAudioDecoderClass)(coreglib.PeekParentClass(dec))
	fnarg := gclass.propose_allocation

	var _arg0 *C.GstAudioDecoder // out
	var _arg1 *C.GstQuery        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstaudio1_AudioDecoder_virtual_propose_allocation(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// setFormat notifies subclass of incoming data format (caps).
func (dec *AudioDecoder) setFormat(caps *gst.Caps) bool {
	gclass := (*C.GstAudioDecoderClass)(coreglib.PeekParentClass(dec))
	fnarg := gclass.set_format

	var _arg0 *C.GstAudioDecoder // out
	var _arg1 *C.GstCaps         // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C._gotk4_gstaudio1_AudioDecoder_virtual_set_format(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(caps)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// sinkEvent: optional. Event handler on the sink pad. Subclasses should chain
// up to the parent implementation to invoke the default handler.
func (dec *AudioDecoder) sinkEvent(event *gst.Event) bool {
	gclass := (*C.GstAudioDecoderClass)(coreglib.PeekParentClass(dec))
	fnarg := gclass.sink_event

	var _arg0 *C.GstAudioDecoder // out
	var _arg1 *C.GstEvent        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C._gotk4_gstaudio1_AudioDecoder_virtual_sink_event(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(event)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// sinkQuery: optional. Query handler on the sink pad. This function should
// return TRUE if the query could be performed. Subclasses should chain up to
// the parent implementation to invoke the default handler. Since: 1.6.
func (dec *AudioDecoder) sinkQuery(query *gst.Query) bool {
	gclass := (*C.GstAudioDecoderClass)(coreglib.PeekParentClass(dec))
	fnarg := gclass.sink_query

	var _arg0 *C.GstAudioDecoder // out
	var _arg1 *C.GstQuery        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstaudio1_AudioDecoder_virtual_sink_query(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// srcEvent: optional. Event handler on the src pad. Subclasses should chain up
// to the parent implementation to invoke the default handler.
func (dec *AudioDecoder) srcEvent(event *gst.Event) bool {
	gclass := (*C.GstAudioDecoderClass)(coreglib.PeekParentClass(dec))
	fnarg := gclass.src_event

	var _arg0 *C.GstAudioDecoder // out
	var _arg1 *C.GstEvent        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C._gotk4_gstaudio1_AudioDecoder_virtual_src_event(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(event)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// srcQuery: optional. Query handler on the source pad. This function should
// return TRUE if the query could be performed. Subclasses should chain up to
// the parent implementation to invoke the default handler. Since: 1.6.
func (dec *AudioDecoder) srcQuery(query *gst.Query) bool {
	gclass := (*C.GstAudioDecoderClass)(coreglib.PeekParentClass(dec))
	fnarg := gclass.src_query

	var _arg0 *C.GstAudioDecoder // out
	var _arg1 *C.GstQuery        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstaudio1_AudioDecoder_virtual_src_query(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(dec)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Start: optional. Called when the element starts processing. Allows opening
// external resources.
func (dec *AudioDecoder) start() bool {
	gclass := (*C.GstAudioDecoderClass)(coreglib.PeekParentClass(dec))
	fnarg := gclass.start

	var _arg0 *C.GstAudioDecoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	_cret = C._gotk4_gstaudio1_AudioDecoder_virtual_start(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(dec)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Stop: optional. Called when the element stops processing. Allows closing
// external resources.
func (dec *AudioDecoder) stop() bool {
	gclass := (*C.GstAudioDecoderClass)(coreglib.PeekParentClass(dec))
	fnarg := gclass.stop

	var _arg0 *C.GstAudioDecoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(dec).Native()))

	_cret = C._gotk4_gstaudio1_AudioDecoder_virtual_stop(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(dec)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// transformMeta: optional. Transform the metadata on the input buffer to the
// output buffer. By default this method copies all meta without tags and meta
// with only the "audio" tag. subclasses can implement this method and return
// TRUE if the metadata is to be copied. Since: 1.6.
//
// The function takes the following parameters:
//
//   - outbuf
//   - meta
//   - inbuf
func (enc *AudioDecoder) transformMeta(outbuf *gst.Buffer, meta *gst.Meta, inbuf *gst.Buffer) bool {
	gclass := (*C.GstAudioDecoderClass)(coreglib.PeekParentClass(enc))
	fnarg := gclass.transform_meta

	var _arg0 *C.GstAudioDecoder // out
	var _arg1 *C.GstBuffer       // out
	var _arg2 *C.GstMeta         // out
	var _arg3 *C.GstBuffer       // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioDecoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(outbuf)))
	_arg2 = (*C.GstMeta)(gextras.StructNative(unsafe.Pointer(meta)))
	_arg3 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(inbuf)))

	_cret = C._gotk4_gstaudio1_AudioDecoder_virtual_transform_meta(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(outbuf)
	runtime.KeepAlive(meta)
	runtime.KeepAlive(inbuf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// AudioEncoderOverrides contains methods that are overridable.
type AudioEncoderOverrides struct {
	// Close: optional. Called when the element changes to GST_STATE_NULL.
	// Allows closing external resources.
	Close func() bool
	// DecideAllocation: optional. Setup the allocation parameters for
	// allocating output buffers. The passed in query contains the result of the
	// downstream allocation query. Subclasses should chain up to the parent
	// implementation to invoke the default handler.
	DecideAllocation func(query *gst.Query) bool
	// Flush: optional. Instructs subclass to clear any codec caches and discard
	// any pending samples and not yet returned encoded data.
	Flush func()
	// Caps: optional. Allows for a custom sink getcaps implementation (e.g.
	// for multichannel input specification). If not implemented, default
	// returns gst_audio_encoder_proxy_getcaps applied to sink template caps.
	caps func(filter *gst.Caps) *gst.Caps
	// HandleFrame provides input samples (or NULL to clear any remaining data)
	// according to directions as configured by the subclass using the API.
	// Input data ref management is performed by base class, subclass should not
	// care or intervene, and input data is only valid until next call to base
	// class, most notably a call to gst_audio_encoder_finish_frame().
	HandleFrame func(buffer *gst.Buffer) gst.FlowReturn
	// Negotiate with downstream elements to currently configured Caps. Unmark
	// GST_PAD_FLAG_NEED_RECONFIGURE in any case. But mark it again if negotiate
	// fails.
	//
	// The function returns the following values:
	//
	//   - ok: TRUE if the negotiation succeeded, else FALSE.
	Negotiate func() bool
	// Open: optional. Called when the element changes to GST_STATE_READY.
	// Allows opening external resources.
	Open func() bool
	// ProposeAllocation: optional. Propose buffer allocation parameters
	// for upstream elements. Subclasses should chain up to the parent
	// implementation to invoke the default handler.
	ProposeAllocation func(query *gst.Query) bool
	// SetFormat notifies subclass of incoming data format. GstAudioInfo
	// contains the format according to provided caps.
	SetFormat func(info *AudioInfo) bool
	// SinkEvent: optional. Event handler on the sink pad. Subclasses should
	// chain up to the parent implementation to invoke the default handler.
	SinkEvent func(event *gst.Event) bool
	// SinkQuery: optional. Query handler on the sink pad. This function should
	// return TRUE if the query could be performed. Subclasses should chain up
	// to the parent implementation to invoke the default handler. Since: 1.6.
	SinkQuery func(query *gst.Query) bool
	// SrcEvent: optional. Event handler on the src pad. Subclasses should chain
	// up to the parent implementation to invoke the default handler.
	SrcEvent func(event *gst.Event) bool
	// SrcQuery: optional. Query handler on the source pad. This function should
	// return TRUE if the query could be performed. Subclasses should chain up
	// to the parent implementation to invoke the default handler. Since: 1.6.
	SrcQuery func(query *gst.Query) bool
	// Start: optional. Called when the element starts processing. Allows
	// opening external resources.
	Start func() bool
	// Stop: optional. Called when the element stops processing. Allows closing
	// external resources.
	Stop func() bool
	// TransformMeta: optional. Transform the metadata on the input buffer to
	// the output buffer. By default this method copies all meta without tags
	// and meta with only the "audio" tag. subclasses can implement this method
	// and return TRUE if the metadata is to be copied. Since: 1.6.
	//
	// The function takes the following parameters:
	//
	//   - outbuf
	//   - meta
	//   - inbuf
	TransformMeta func(outbuf *gst.Buffer, meta *gst.Meta, inbuf *gst.Buffer) bool
}

func defaultAudioEncoderOverrides(v *AudioEncoder) AudioEncoderOverrides {
	return AudioEncoderOverrides{
		Close:             v.close,
		DecideAllocation:  v.decideAllocation,
		Flush:             v.flush,
		caps:              v.caps,
		HandleFrame:       v.handleFrame,
		Negotiate:         v.negotiate,
		Open:              v.open,
		ProposeAllocation: v.proposeAllocation,
		SetFormat:         v.setFormat,
		SinkEvent:         v.sinkEvent,
		SinkQuery:         v.sinkQuery,
		SrcEvent:          v.srcEvent,
		SrcQuery:          v.srcQuery,
		Start:             v.start,
		Stop:              v.stop,
		TransformMeta:     v.transformMeta,
	}
}

// AudioEncoder (GstAudioEncoder): this base class is for audio encoders turning
// raw audio samples into encoded audio data.
//
// GstAudioEncoder and subclass should cooperate as follows.
//
// Configuration
//
//   - Initially, GstAudioEncoder calls start when the encoder element is
//     activated, which allows subclass to perform any global setup.
//
//   - GstAudioEncoder calls set_format to inform subclass of the format of
//     input audio data that it is about to receive. Subclass should setup for
//     encoding and configure various base class parameters appropriately,
//     notably those directing desired input data handling. While unlikely,
//     it might be called more than once, if changing input parameters require
//     reconfiguration.
//
//   - GstAudioEncoder calls stop at end of all processing.
//
// As of configuration stage, and throughout processing, GstAudioEncoder
// maintains various parameters that provide required context, e.g. describing
// the format of input audio data. Conversely, subclass can and should configure
// these context parameters to inform base class of its expectation w.r.t.
// buffer handling.
//
// Data processing
//
//   - Base class gathers input sample data (as directed by the context's
//     frame_samples and frame_max) and provides this to subclass' handle_frame.
//   - If codec processing results in encoded data, subclass should call
//     gst_audio_encoder_finish_frame() to have encoded data pushed downstream.
//     Alternatively, it might also call gst_audio_encoder_finish_frame() (with
//     a NULL buffer and some number of dropped samples) to indicate dropped
//     (non-encoded) samples.
//   - Just prior to actually pushing a buffer downstream, it is passed to
//     pre_push.
//   - During the parsing process GstAudioEncoderClass will handle both srcpad
//     and sinkpad events. Sink events will be passed to subclass if event
//     callback has been provided.
//
// Shutdown phase
//
//   - GstAudioEncoder class calls stop to inform the subclass that data parsing
//     will be stopped.
//
// Subclass is responsible for providing pad template caps for source and sink
// pads. The pads need to be named "sink" and "src". It also needs to set the
// fixed caps on srcpad, when the format is ensured. This is typically when base
// class calls subclass' set_format function, though it might be delayed until
// calling gst_audio_encoder_finish_frame.
//
// In summary, above process should have subclass concentrating on codec data
// processing while leaving other matters to base class, such as most notably
// timestamp handling. While it may exert more control in this area (see e.g.
// pre_push), it is very much not recommended.
//
// In particular, base class will either favor tracking upstream timestamps
// (at the possible expense of jitter) or aim to arrange for a perfect
// stream of output timestamps, depending on AudioEncoder:perfect-timestamp.
// However, in the latter case, the input may not be so perfect or ideal,
// which is handled as follows. An input timestamp is compared with the
// expected timestamp as dictated by input sample stream and if the deviation
// is less than AudioEncoder:tolerance, the deviation is discarded. Otherwise,
// it is considered a discontuinity and subsequent output timestamp is resynced
// to the new position after performing configured discontinuity processing.
// In the non-perfect-timestamp case, an upstream variation exceeding
// tolerance only leads to marking DISCONT on subsequent outgoing (while
// timestamps are adjusted to upstream regardless of variation). While DISCONT
// is also marked in the perfect-timestamp case, this one optionally (see
// AudioEncoder:hard-resync) performs some additional steps, such as clipping
// of (early) input samples or draining all currently remaining input data,
// depending on the direction of the discontuinity.
//
// If perfect timestamps are arranged, it is also possible to request baseclass
// (usually set by subclass) to provide additional buffer metadata (in OFFSET
// and OFFSET_END) fields according to granule defined semantics currently
// needed by oggmux. Specifically, OFFSET is set to granulepos (= sample count
// including buffer) and OFFSET_END to corresponding timestamp (as determined by
// same sample count and sample rate).
//
// Things that subclass need to take care of:
//
//   - Provide pad templates
//   - Set source pad caps when appropriate
//   - Inform base class of buffer processing needs using context's
//     frame_samples and frame_bytes.
//   - Set user-configurable properties to sane defaults for format and
//     implementing codec at hand, e.g. those controlling timestamp behaviour
//     and discontinuity processing.
//   - Accept data in handle_frame and provide encoded results to
//     gst_audio_encoder_finish_frame().
type AudioEncoder struct {
	_ [0]func() // equal guard
	gst.Element

	gst.Preset
}

var (
	_ gst.Elementer = (*AudioEncoder)(nil)
)

// AudioEncoderer describes types inherited from AudioEncoder.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type AudioEncoderer interface {
	gst.Elementer
	gst.Presetter

	// AllocateOutputBuffer (gst_audio_encoder_allocate_output_buffer): helper
	// function that allocates a buffer to hold an encoded audio frame for enc's
	// current output format.
	AllocateOutputBuffer(size uint) *gst.Buffer
	// FinishFrame (gst_audio_encoder_finish_frame) collects encoded data and
	// pushes encoded data downstream.
	FinishFrame(buffer *gst.Buffer, samples int) gst.FlowReturn
	// Allocator (gst_audio_encoder_get_allocator) lets AudioEncoder sub-classes
	// to know the memory allocator used by the base class and its params.
	Allocator() (gst.Allocatorrer, *gst.AllocationParams)
	AudioInfo() *AudioInfo
	// Drainable (gst_audio_encoder_get_drainable) queries encoder drain
	// handling.
	Drainable() bool
	FrameMax() int
	FrameSamplesMax() int
	FrameSamplesMin() int
	// HardMin (gst_audio_encoder_get_hard_min) queries encoder hard minimum
	// handling.
	HardMin() bool
	HardResync() bool
	// Latency (gst_audio_encoder_get_latency) sets the variables pointed to by
	// min and max to the currently configured latency.
	Latency() (min, max gst.ClockTime)
	Lookahead() int
	// MarkGranule (gst_audio_encoder_get_mark_granule) queries if the encoder
	// will handle granule marking.
	MarkGranule() bool
	// PerfectTimestamp (gst_audio_encoder_get_perfect_timestamp) queries
	// encoder perfect timestamp behaviour.
	PerfectTimestamp() bool
	// Tolerance (gst_audio_encoder_get_tolerance) queries current audio jitter
	// tolerance threshold.
	Tolerance() gst.ClockTime
	// MergeTags (gst_audio_encoder_merge_tags) sets the audio encoder tags and
	// how they should be merged with any upstream stream tags.
	MergeTags(tags *gst.TagList, mode gst.TagMergeMode)
	// Negotiate (gst_audio_encoder_negotiate) with downstream elements to
	// currently configured Caps.
	Negotiate() bool
	// ProxyGetcaps (gst_audio_encoder_proxy_getcaps) returns caps that express
	// caps (or sink template caps if caps == NULL) restricted to channel/rate
	// combinations supported by downstream elements (e.g.
	ProxyGetcaps(caps, filter *gst.Caps) *gst.Caps
	// SetAllocationCaps (gst_audio_encoder_set_allocation_caps) sets a caps in
	// allocation query which are different from the set pad's caps.
	SetAllocationCaps(allocationCaps *gst.Caps)
	// SetDrainable (gst_audio_encoder_set_drainable) configures encoder drain
	// handling.
	SetDrainable(enabled bool)
	// SetFrameMax (gst_audio_encoder_set_frame_max) sets max number of frames
	// accepted at once (assumed minimally 1).
	SetFrameMax(num int)
	// SetFrameSamplesMax (gst_audio_encoder_set_frame_samples_max) sets number
	// of samples (per channel) subclass needs to be handed, at most or will be
	// handed all available if 0.
	SetFrameSamplesMax(num int)
	// SetFrameSamplesMin (gst_audio_encoder_set_frame_samples_min) sets number
	// of samples (per channel) subclass needs to be handed, at least or will be
	// handed all available if 0.
	SetFrameSamplesMin(num int)
	// SetHardMin (gst_audio_encoder_set_hard_min) configures encoder hard
	// minimum handling.
	SetHardMin(enabled bool)
	SetHardResync(enabled bool)
	// SetHeaders (gst_audio_encoder_set_headers): set the codec headers to be
	// sent downstream whenever requested.
	SetHeaders(headers []*gst.Buffer)
	// SetLatency (gst_audio_encoder_set_latency) sets encoder latency.
	SetLatency(min, max gst.ClockTime)
	// SetLookahead (gst_audio_encoder_set_lookahead) sets encoder lookahead (in
	// units of input rate samples).
	SetLookahead(num int)
	// SetMarkGranule (gst_audio_encoder_set_mark_granule): enable or disable
	// encoder granule handling.
	SetMarkGranule(enabled bool)
	// SetOutputFormat (gst_audio_encoder_set_output_format): configure output
	// caps on the srcpad of enc.
	SetOutputFormat(caps *gst.Caps) bool
	// SetPerfectTimestamp (gst_audio_encoder_set_perfect_timestamp): enable or
	// disable encoder perfect output timestamp preference.
	SetPerfectTimestamp(enabled bool)
	// SetTolerance (gst_audio_encoder_set_tolerance) configures encoder audio
	// jitter tolerance threshold.
	SetTolerance(tolerance gst.ClockTime)

	baseAudioEncoder() *AudioEncoder
}

var _ AudioEncoderer = (*AudioEncoder)(nil)

func init() {
	coreglib.RegisterClassInfo[*AudioEncoder, *AudioEncoderClass, AudioEncoderOverrides](
		GTypeAudioEncoder,
		initAudioEncoderClass,
		wrapAudioEncoder,
		defaultAudioEncoderOverrides,
	)
}

func initAudioEncoderClass(gclass unsafe.Pointer, overrides AudioEncoderOverrides, classInitFunc func(*AudioEncoderClass)) {
	pclass := (*C.GstAudioEncoderClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeAudioEncoder))))

	if overrides.Close != nil {
		pclass.close = (*[0]byte)(C._gotk4_gstaudio1_AudioEncoderClass_close)
	}

	if overrides.DecideAllocation != nil {
		pclass.decide_allocation = (*[0]byte)(C._gotk4_gstaudio1_AudioEncoderClass_decide_allocation)
	}

	if overrides.Flush != nil {
		pclass.flush = (*[0]byte)(C._gotk4_gstaudio1_AudioEncoderClass_flush)
	}

	if overrides.caps != nil {
		pclass.getcaps = (*[0]byte)(C._gotk4_gstaudio1_AudioEncoderClass_getcaps)
	}

	if overrides.HandleFrame != nil {
		pclass.handle_frame = (*[0]byte)(C._gotk4_gstaudio1_AudioEncoderClass_handle_frame)
	}

	if overrides.Negotiate != nil {
		pclass.negotiate = (*[0]byte)(C._gotk4_gstaudio1_AudioEncoderClass_negotiate)
	}

	if overrides.Open != nil {
		pclass.open = (*[0]byte)(C._gotk4_gstaudio1_AudioEncoderClass_open)
	}

	if overrides.ProposeAllocation != nil {
		pclass.propose_allocation = (*[0]byte)(C._gotk4_gstaudio1_AudioEncoderClass_propose_allocation)
	}

	if overrides.SetFormat != nil {
		pclass.set_format = (*[0]byte)(C._gotk4_gstaudio1_AudioEncoderClass_set_format)
	}

	if overrides.SinkEvent != nil {
		pclass.sink_event = (*[0]byte)(C._gotk4_gstaudio1_AudioEncoderClass_sink_event)
	}

	if overrides.SinkQuery != nil {
		pclass.sink_query = (*[0]byte)(C._gotk4_gstaudio1_AudioEncoderClass_sink_query)
	}

	if overrides.SrcEvent != nil {
		pclass.src_event = (*[0]byte)(C._gotk4_gstaudio1_AudioEncoderClass_src_event)
	}

	if overrides.SrcQuery != nil {
		pclass.src_query = (*[0]byte)(C._gotk4_gstaudio1_AudioEncoderClass_src_query)
	}

	if overrides.Start != nil {
		pclass.start = (*[0]byte)(C._gotk4_gstaudio1_AudioEncoderClass_start)
	}

	if overrides.Stop != nil {
		pclass.stop = (*[0]byte)(C._gotk4_gstaudio1_AudioEncoderClass_stop)
	}

	if overrides.TransformMeta != nil {
		pclass.transform_meta = (*[0]byte)(C._gotk4_gstaudio1_AudioEncoderClass_transform_meta)
	}

	if classInitFunc != nil {
		class := (*AudioEncoderClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapAudioEncoder(obj *coreglib.Object) *AudioEncoder {
	return &AudioEncoder{
		Element: gst.Element{
			GstObject: gst.GstObject{
				InitiallyUnowned: coreglib.InitiallyUnowned{
					Object: obj,
				},
			},
		},
		Preset: gst.Preset{
			Object: obj,
		},
	}
}

func marshalAudioEncoder(p uintptr) (interface{}, error) {
	return wrapAudioEncoder(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (enc *AudioEncoder) baseAudioEncoder() *AudioEncoder {
	return enc
}

// BaseAudioEncoder returns the underlying base object.
func BaseAudioEncoder(obj AudioEncoderer) *AudioEncoder {
	return obj.baseAudioEncoder()
}

// AllocateOutputBuffer (gst_audio_encoder_allocate_output_buffer): helper
// function that allocates a buffer to hold an encoded audio frame for enc's
// current output format.
//
// The function takes the following parameters:
//
//   - size of the buffer.
//
// The function returns the following values:
//
//   - buffer: allocated buffer.
func (enc *AudioEncoder) AllocateOutputBuffer(size uint) *gst.Buffer {
	var _arg0 *C.GstAudioEncoder // out
	var _arg1 C.gsize            // out
	var _cret *C.GstBuffer       // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	_arg1 = C.gsize(size)

	_cret = C.gst_audio_encoder_allocate_output_buffer(_arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(size)

	var _buffer *gst.Buffer // out

	_buffer = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_buffer)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _buffer
}

// FinishFrame (gst_audio_encoder_finish_frame) collects encoded data and pushes
// encoded data downstream. Source pad caps must be set when this is called.
//
// If samples < 0, then best estimate is all samples provided to encoder
// (subclass) so far. buf may be NULL, in which case next number of samples
// are considered discarded, e.g. as a result of discontinuous transmission,
// and a discontinuity is marked.
//
// Note that samples received in AudioEncoderClass.handle_frame() may be
// invalidated by a call to this function.
//
// The function takes the following parameters:
//
//   - buffer (optional): encoded data.
//   - samples: number of samples (per channel) represented by encoded data.
//
// The function returns the following values:
//
//   - flowReturn that should be escalated to caller (of caller).
func (enc *AudioEncoder) FinishFrame(buffer *gst.Buffer, samples int) gst.FlowReturn {
	var _arg0 *C.GstAudioEncoder // out
	var _arg1 *C.GstBuffer       // out
	var _arg2 C.gint             // out
	var _cret C.GstFlowReturn    // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	if buffer != nil {
		_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
		runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(buffer)), nil)
	}
	_arg2 = C.gint(samples)

	_cret = C.gst_audio_encoder_finish_frame(_arg0, _arg1, _arg2)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(samples)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// Allocator (gst_audio_encoder_get_allocator) lets AudioEncoder sub-classes to
// know the memory allocator used by the base class and its params.
//
// Unref the allocator after use it.
//
// The function returns the following values:
//
//   - allocator (optional): Allocator used.
//   - params (optional) the AllocationParams of allocator.
func (enc *AudioEncoder) Allocator() (gst.Allocatorrer, *gst.AllocationParams) {
	var _arg0 *C.GstAudioEncoder    // out
	var _arg1 *C.GstAllocator       // in
	var _arg2 C.GstAllocationParams // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))

	C.gst_audio_encoder_get_allocator(_arg0, &_arg1, &_arg2)
	runtime.KeepAlive(enc)

	var _allocator gst.Allocatorrer   // out
	var _params *gst.AllocationParams // out

	if _arg1 != nil {
		{
			objptr := unsafe.Pointer(_arg1)

			object := coreglib.AssumeOwnership(objptr)
			casted := object.WalkCast(func(obj coreglib.Objector) bool {
				_, ok := obj.(gst.Allocatorrer)
				return ok
			})
			rv, ok := casted.(gst.Allocatorrer)
			if !ok {
				panic("no marshaler for " + object.TypeFromInstance().String() + " matching gst.Allocatorrer")
			}
			_allocator = rv
		}
	}
	_params = (*gst.AllocationParams)(gextras.NewStructNative(unsafe.Pointer((&_arg2))))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_params)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_allocation_params_free((*C.GstAllocationParams)(intern.C))
		},
	)

	return _allocator, _params
}

// The function returns the following values:
//
//   - audioInfo describing the input audio format.
func (enc *AudioEncoder) AudioInfo() *AudioInfo {
	var _arg0 *C.GstAudioEncoder // out
	var _cret *C.GstAudioInfo    // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))

	_cret = C.gst_audio_encoder_get_audio_info(_arg0)
	runtime.KeepAlive(enc)

	var _audioInfo *AudioInfo // out

	_audioInfo = (*AudioInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _audioInfo
}

// Drainable (gst_audio_encoder_get_drainable) queries encoder drain handling.
//
// The function returns the following values:
//
//   - ok: TRUE if drainable handling is enabled.
//
//     MT safe.
func (enc *AudioEncoder) Drainable() bool {
	var _arg0 *C.GstAudioEncoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))

	_cret = C.gst_audio_encoder_get_drainable(_arg0)
	runtime.KeepAlive(enc)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// The function returns the following values:
//
//   - gint: currently configured maximum handled frames.
func (enc *AudioEncoder) FrameMax() int {
	var _arg0 *C.GstAudioEncoder // out
	var _cret C.gint             // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))

	_cret = C.gst_audio_encoder_get_frame_max(_arg0)
	runtime.KeepAlive(enc)

	var _gint int // out

	_gint = int(_cret)

	return _gint
}

// The function returns the following values:
//
//   - gint: currently maximum requested samples per frame.
func (enc *AudioEncoder) FrameSamplesMax() int {
	var _arg0 *C.GstAudioEncoder // out
	var _cret C.gint             // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))

	_cret = C.gst_audio_encoder_get_frame_samples_max(_arg0)
	runtime.KeepAlive(enc)

	var _gint int // out

	_gint = int(_cret)

	return _gint
}

// The function returns the following values:
//
//   - gint: currently minimum requested samples per frame.
func (enc *AudioEncoder) FrameSamplesMin() int {
	var _arg0 *C.GstAudioEncoder // out
	var _cret C.gint             // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))

	_cret = C.gst_audio_encoder_get_frame_samples_min(_arg0)
	runtime.KeepAlive(enc)

	var _gint int // out

	_gint = int(_cret)

	return _gint
}

// HardMin (gst_audio_encoder_get_hard_min) queries encoder hard minimum
// handling.
//
// The function returns the following values:
//
//   - ok: TRUE if hard minimum handling is enabled.
//
//     MT safe.
func (enc *AudioEncoder) HardMin() bool {
	var _arg0 *C.GstAudioEncoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))

	_cret = C.gst_audio_encoder_get_hard_min(_arg0)
	runtime.KeepAlive(enc)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

func (enc *AudioEncoder) HardResync() bool {
	var _arg0 *C.GstAudioEncoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))

	_cret = C.gst_audio_encoder_get_hard_resync(_arg0)
	runtime.KeepAlive(enc)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Latency (gst_audio_encoder_get_latency) sets the variables pointed to by min
// and max to the currently configured latency.
//
// The function returns the following values:
//
//   - min (optional): pointer to storage to hold minimum latency.
//   - max (optional): pointer to storage to hold maximum latency.
func (enc *AudioEncoder) Latency() (min, max gst.ClockTime) {
	var _arg0 *C.GstAudioEncoder // out
	var _arg1 C.GstClockTime     // in
	var _arg2 C.GstClockTime     // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))

	C.gst_audio_encoder_get_latency(_arg0, &_arg1, &_arg2)
	runtime.KeepAlive(enc)

	var _min gst.ClockTime // out
	var _max gst.ClockTime // out

	_min = gst.ClockTime(_arg1)
	_max = gst.ClockTime(_arg2)

	return _min, _max
}

// The function returns the following values:
//
//   - gint: currently configured encoder lookahead.
func (enc *AudioEncoder) Lookahead() int {
	var _arg0 *C.GstAudioEncoder // out
	var _cret C.gint             // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))

	_cret = C.gst_audio_encoder_get_lookahead(_arg0)
	runtime.KeepAlive(enc)

	var _gint int // out

	_gint = int(_cret)

	return _gint
}

// MarkGranule (gst_audio_encoder_get_mark_granule) queries if the encoder will
// handle granule marking.
//
// The function returns the following values:
//
//   - ok: TRUE if granule marking is enabled.
//
//     MT safe.
func (enc *AudioEncoder) MarkGranule() bool {
	var _arg0 *C.GstAudioEncoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))

	_cret = C.gst_audio_encoder_get_mark_granule(_arg0)
	runtime.KeepAlive(enc)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PerfectTimestamp (gst_audio_encoder_get_perfect_timestamp) queries encoder
// perfect timestamp behaviour.
//
// The function returns the following values:
//
//   - ok: TRUE if perfect timestamp setting enabled.
//
//     MT safe.
func (enc *AudioEncoder) PerfectTimestamp() bool {
	var _arg0 *C.GstAudioEncoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))

	_cret = C.gst_audio_encoder_get_perfect_timestamp(_arg0)
	runtime.KeepAlive(enc)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Tolerance (gst_audio_encoder_get_tolerance) queries current audio jitter
// tolerance threshold.
//
// The function returns the following values:
//
//   - clockTime: encoder audio jitter tolerance threshold.
//
//     MT safe.
func (enc *AudioEncoder) Tolerance() gst.ClockTime {
	var _arg0 *C.GstAudioEncoder // out
	var _cret C.GstClockTime     // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))

	_cret = C.gst_audio_encoder_get_tolerance(_arg0)
	runtime.KeepAlive(enc)

	var _clockTime gst.ClockTime // out

	_clockTime = gst.ClockTime(_cret)

	return _clockTime
}

// MergeTags (gst_audio_encoder_merge_tags) sets the audio encoder tags and how
// they should be merged with any upstream stream tags. This will override any
// tags previously-set with gst_audio_encoder_merge_tags().
//
// Note that this is provided for convenience, and the subclass is not required
// to use this and can still do tag handling on its own.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - tags (optional) to merge, or NULL to unset previously-set tags.
//   - mode to use, usually T_TAG_MERGE_REPLACE.
func (enc *AudioEncoder) MergeTags(tags *gst.TagList, mode gst.TagMergeMode) {
	var _arg0 *C.GstAudioEncoder // out
	var _arg1 *C.GstTagList      // out
	var _arg2 C.GstTagMergeMode  // out

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	if tags != nil {
		_arg1 = (*C.GstTagList)(gextras.StructNative(unsafe.Pointer(tags)))
	}
	_arg2 = C.GstTagMergeMode(mode)

	C.gst_audio_encoder_merge_tags(_arg0, _arg1, _arg2)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(tags)
	runtime.KeepAlive(mode)
}

// Negotiate (gst_audio_encoder_negotiate) with downstream elements to currently
// configured Caps. Unmark GST_PAD_FLAG_NEED_RECONFIGURE in any case. But mark
// it again if negotiate fails.
//
// The function returns the following values:
//
//   - ok: TRUE if the negotiation succeeded, else FALSE.
func (enc *AudioEncoder) Negotiate() bool {
	var _arg0 *C.GstAudioEncoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))

	_cret = C.gst_audio_encoder_negotiate(_arg0)
	runtime.KeepAlive(enc)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// ProxyGetcaps (gst_audio_encoder_proxy_getcaps) returns caps that express
// caps (or sink template caps if caps == NULL) restricted to channel/rate
// combinations supported by downstream elements (e.g. muxers).
//
// The function takes the following parameters:
//
//   - caps (optional): initial caps.
//   - filter (optional) caps.
//
// The function returns the following values:
//
//   - ret owned by caller.
func (enc *AudioEncoder) ProxyGetcaps(caps, filter *gst.Caps) *gst.Caps {
	var _arg0 *C.GstAudioEncoder // out
	var _arg1 *C.GstCaps         // out
	var _arg2 *C.GstCaps         // out
	var _cret *C.GstCaps         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	if caps != nil {
		_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))
	}
	if filter != nil {
		_arg2 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(filter)))
	}

	_cret = C.gst_audio_encoder_proxy_getcaps(_arg0, _arg1, _arg2)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(caps)
	runtime.KeepAlive(filter)

	var _ret *gst.Caps // out

	_ret = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_ret)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _ret
}

// SetAllocationCaps (gst_audio_encoder_set_allocation_caps) sets a caps in
// allocation query which are different from the set pad's caps. Use this
// function before calling gst_audio_encoder_negotiate(). Setting to NULL the
// allocation query will use the caps from the pad.
//
// The function takes the following parameters:
//
//   - allocationCaps (optional) or NULL.
func (enc *AudioEncoder) SetAllocationCaps(allocationCaps *gst.Caps) {
	var _arg0 *C.GstAudioEncoder // out
	var _arg1 *C.GstCaps         // out

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	if allocationCaps != nil {
		_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(allocationCaps)))
	}

	C.gst_audio_encoder_set_allocation_caps(_arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(allocationCaps)
}

// SetDrainable (gst_audio_encoder_set_drainable) configures encoder drain
// handling. If drainable, subclass might be handed a NULL buffer to have it
// return any leftover encoded data. Otherwise, it is not considered so capable
// and will only ever be passed real data.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - enabled: new state.
func (enc *AudioEncoder) SetDrainable(enabled bool) {
	var _arg0 *C.GstAudioEncoder // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	if enabled {
		_arg1 = C.TRUE
	}

	C.gst_audio_encoder_set_drainable(_arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(enabled)
}

// SetFrameMax (gst_audio_encoder_set_frame_max) sets max number of frames
// accepted at once (assumed minimally 1). Requires frame_samples_min and
// frame_samples_max to be the equal.
//
// Note: This value will be reset to 0 every time before
// AudioEncoderClass.set_format() is called.
//
// The function takes the following parameters:
//
//   - num: number of frames.
func (enc *AudioEncoder) SetFrameMax(num int) {
	var _arg0 *C.GstAudioEncoder // out
	var _arg1 C.gint             // out

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	_arg1 = C.gint(num)

	C.gst_audio_encoder_set_frame_max(_arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(num)
}

// SetFrameSamplesMax (gst_audio_encoder_set_frame_samples_max) sets number of
// samples (per channel) subclass needs to be handed, at most or will be handed
// all available if 0.
//
// If an exact number of samples is required,
// gst_audio_encoder_set_frame_samples_min() must be called with the same
// number.
//
// Note: This value will be reset to 0 every time before
// AudioEncoderClass.set_format() is called.
//
// The function takes the following parameters:
//
//   - num: number of samples per frame.
func (enc *AudioEncoder) SetFrameSamplesMax(num int) {
	var _arg0 *C.GstAudioEncoder // out
	var _arg1 C.gint             // out

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	_arg1 = C.gint(num)

	C.gst_audio_encoder_set_frame_samples_max(_arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(num)
}

// SetFrameSamplesMin (gst_audio_encoder_set_frame_samples_min) sets number of
// samples (per channel) subclass needs to be handed, at least or will be handed
// all available if 0.
//
// If an exact number of samples is required,
// gst_audio_encoder_set_frame_samples_max() must be called with the same
// number.
//
// Note: This value will be reset to 0 every time before
// AudioEncoderClass.set_format() is called.
//
// The function takes the following parameters:
//
//   - num: number of samples per frame.
func (enc *AudioEncoder) SetFrameSamplesMin(num int) {
	var _arg0 *C.GstAudioEncoder // out
	var _arg1 C.gint             // out

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	_arg1 = C.gint(num)

	C.gst_audio_encoder_set_frame_samples_min(_arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(num)
}

// SetHardMin (gst_audio_encoder_set_hard_min) configures encoder hard minimum
// handling. If enabled, subclass will never be handed less samples than it
// configured, which otherwise might occur near end-of-data handling. Instead,
// the leftover samples will simply be discarded.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - enabled: new state.
func (enc *AudioEncoder) SetHardMin(enabled bool) {
	var _arg0 *C.GstAudioEncoder // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	if enabled {
		_arg1 = C.TRUE
	}

	C.gst_audio_encoder_set_hard_min(_arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(enabled)
}

func (enc *AudioEncoder) SetHardResync(enabled bool) {
	var _arg0 *C.GstAudioEncoder // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	if enabled {
		_arg1 = C.TRUE
	}

	C.gst_audio_encoder_set_hard_resync(_arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(enabled)
}

// SetHeaders (gst_audio_encoder_set_headers): set the codec headers to be sent
// downstream whenever requested.
//
// The function takes the following parameters:
//
//   - headers: list of Buffer containing the codec header.
func (enc *AudioEncoder) SetHeaders(headers []*gst.Buffer) {
	var _arg0 *C.GstAudioEncoder // out
	var _arg1 *C.GList           // out

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	for i := len(headers) - 1; i >= 0; i-- {
		src := headers[i]
		var dst *C.GstBuffer // out
		dst = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(src)))
		runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(src)), nil)
		_arg1 = C.g_list_prepend(_arg1, C.gpointer(unsafe.Pointer(dst)))
	}

	C.gst_audio_encoder_set_headers(_arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(headers)
}

// SetLatency (gst_audio_encoder_set_latency) sets encoder latency. If the
// provided values changed from previously provided ones, this will also post
// a LATENCY message on the bus so the pipeline can reconfigure its global
// latency.
//
// The function takes the following parameters:
//
//   - min: minimum latency.
//   - max: maximum latency.
func (enc *AudioEncoder) SetLatency(min, max gst.ClockTime) {
	var _arg0 *C.GstAudioEncoder // out
	var _arg1 C.GstClockTime     // out
	var _arg2 C.GstClockTime     // out

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	_arg1 = C.GstClockTime(min)
	_arg2 = C.GstClockTime(max)

	C.gst_audio_encoder_set_latency(_arg0, _arg1, _arg2)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(min)
	runtime.KeepAlive(max)
}

// SetLookahead (gst_audio_encoder_set_lookahead) sets encoder lookahead (in
// units of input rate samples)
//
// Note: This value will be reset to 0 every time before
// AudioEncoderClass.set_format() is called.
//
// The function takes the following parameters:
//
//   - num: lookahead.
func (enc *AudioEncoder) SetLookahead(num int) {
	var _arg0 *C.GstAudioEncoder // out
	var _arg1 C.gint             // out

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	_arg1 = C.gint(num)

	C.gst_audio_encoder_set_lookahead(_arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(num)
}

// SetMarkGranule (gst_audio_encoder_set_mark_granule): enable or disable
// encoder granule handling.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - enabled: new state.
func (enc *AudioEncoder) SetMarkGranule(enabled bool) {
	var _arg0 *C.GstAudioEncoder // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	if enabled {
		_arg1 = C.TRUE
	}

	C.gst_audio_encoder_set_mark_granule(_arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(enabled)
}

// SetOutputFormat (gst_audio_encoder_set_output_format): configure output caps
// on the srcpad of enc.
//
// The function takes the following parameters:
//
//   - caps: Caps.
//
// The function returns the following values:
//
//   - ok: TRUE on success.
func (enc *AudioEncoder) SetOutputFormat(caps *gst.Caps) bool {
	var _arg0 *C.GstAudioEncoder // out
	var _arg1 *C.GstCaps         // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C.gst_audio_encoder_set_output_format(_arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(caps)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SetPerfectTimestamp (gst_audio_encoder_set_perfect_timestamp): enable or
// disable encoder perfect output timestamp preference.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - enabled: new state.
func (enc *AudioEncoder) SetPerfectTimestamp(enabled bool) {
	var _arg0 *C.GstAudioEncoder // out
	var _arg1 C.gboolean         // out

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	if enabled {
		_arg1 = C.TRUE
	}

	C.gst_audio_encoder_set_perfect_timestamp(_arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(enabled)
}

// SetTolerance (gst_audio_encoder_set_tolerance) configures encoder audio
// jitter tolerance threshold.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - tolerance: new tolerance.
func (enc *AudioEncoder) SetTolerance(tolerance gst.ClockTime) {
	var _arg0 *C.GstAudioEncoder // out
	var _arg1 C.GstClockTime     // out

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	_arg1 = C.GstClockTime(tolerance)

	C.gst_audio_encoder_set_tolerance(_arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(tolerance)
}

// Close: optional. Called when the element changes to GST_STATE_NULL. Allows
// closing external resources.
func (enc *AudioEncoder) close() bool {
	gclass := (*C.GstAudioEncoderClass)(coreglib.PeekParentClass(enc))
	fnarg := gclass.close

	var _arg0 *C.GstAudioEncoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))

	_cret = C._gotk4_gstaudio1_AudioEncoder_virtual_close(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(enc)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// decideAllocation: optional. Setup the allocation parameters for allocating
// output buffers. The passed in query contains the result of the downstream
// allocation query. Subclasses should chain up to the parent implementation to
// invoke the default handler.
func (enc *AudioEncoder) decideAllocation(query *gst.Query) bool {
	gclass := (*C.GstAudioEncoderClass)(coreglib.PeekParentClass(enc))
	fnarg := gclass.decide_allocation

	var _arg0 *C.GstAudioEncoder // out
	var _arg1 *C.GstQuery        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstaudio1_AudioEncoder_virtual_decide_allocation(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Flush: optional. Instructs subclass to clear any codec caches and discard any
// pending samples and not yet returned encoded data.
func (enc *AudioEncoder) flush() {
	gclass := (*C.GstAudioEncoderClass)(coreglib.PeekParentClass(enc))
	fnarg := gclass.flush

	var _arg0 *C.GstAudioEncoder // out

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))

	C._gotk4_gstaudio1_AudioEncoder_virtual_flush(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(enc)
}

// Caps: optional. Allows for a custom sink getcaps implementation (e.g.
// for multichannel input specification). If not implemented, default returns
// gst_audio_encoder_proxy_getcaps applied to sink template caps.
func (enc *AudioEncoder) caps(filter *gst.Caps) *gst.Caps {
	gclass := (*C.GstAudioEncoderClass)(coreglib.PeekParentClass(enc))
	fnarg := gclass.getcaps

	var _arg0 *C.GstAudioEncoder // out
	var _arg1 *C.GstCaps         // out
	var _cret *C.GstCaps         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(filter)))

	_cret = C._gotk4_gstaudio1_AudioEncoder_virtual_getcaps(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(filter)

	var _caps *gst.Caps // out

	_caps = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_caps)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _caps
}

// handleFrame provides input samples (or NULL to clear any remaining data)
// according to directions as configured by the subclass using the API. Input
// data ref management is performed by base class, subclass should not care
// or intervene, and input data is only valid until next call to base class,
// most notably a call to gst_audio_encoder_finish_frame().
func (enc *AudioEncoder) handleFrame(buffer *gst.Buffer) gst.FlowReturn {
	gclass := (*C.GstAudioEncoderClass)(coreglib.PeekParentClass(enc))
	fnarg := gclass.handle_frame

	var _arg0 *C.GstAudioEncoder // out
	var _arg1 *C.GstBuffer       // out
	var _cret C.GstFlowReturn    // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))

	_cret = C._gotk4_gstaudio1_AudioEncoder_virtual_handle_frame(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(buffer)

	var _flowReturn gst.FlowReturn // out

	_flowReturn = gst.FlowReturn(_cret)

	return _flowReturn
}

// Negotiate: negotiate with downstream elements to currently configured Caps.
// Unmark GST_PAD_FLAG_NEED_RECONFIGURE in any case. But mark it again if
// negotiate fails.
//
// The function returns the following values:
//
//   - ok: TRUE if the negotiation succeeded, else FALSE.
func (enc *AudioEncoder) negotiate() bool {
	gclass := (*C.GstAudioEncoderClass)(coreglib.PeekParentClass(enc))
	fnarg := gclass.negotiate

	var _arg0 *C.GstAudioEncoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))

	_cret = C._gotk4_gstaudio1_AudioEncoder_virtual_negotiate(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(enc)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Open: optional. Called when the element changes to GST_STATE_READY. Allows
// opening external resources.
func (enc *AudioEncoder) open() bool {
	gclass := (*C.GstAudioEncoderClass)(coreglib.PeekParentClass(enc))
	fnarg := gclass.open

	var _arg0 *C.GstAudioEncoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))

	_cret = C._gotk4_gstaudio1_AudioEncoder_virtual_open(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(enc)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// proposeAllocation: optional. Propose buffer allocation parameters for
// upstream elements. Subclasses should chain up to the parent implementation to
// invoke the default handler.
func (enc *AudioEncoder) proposeAllocation(query *gst.Query) bool {
	gclass := (*C.GstAudioEncoderClass)(coreglib.PeekParentClass(enc))
	fnarg := gclass.propose_allocation

	var _arg0 *C.GstAudioEncoder // out
	var _arg1 *C.GstQuery        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstaudio1_AudioEncoder_virtual_propose_allocation(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// setFormat notifies subclass of incoming data format. GstAudioInfo contains
// the format according to provided caps.
func (enc *AudioEncoder) setFormat(info *AudioInfo) bool {
	gclass := (*C.GstAudioEncoderClass)(coreglib.PeekParentClass(enc))
	fnarg := gclass.set_format

	var _arg0 *C.GstAudioEncoder // out
	var _arg1 *C.GstAudioInfo    // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	_arg1 = (*C.GstAudioInfo)(gextras.StructNative(unsafe.Pointer(info)))

	_cret = C._gotk4_gstaudio1_AudioEncoder_virtual_set_format(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(info)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// sinkEvent: optional. Event handler on the sink pad. Subclasses should chain
// up to the parent implementation to invoke the default handler.
func (enc *AudioEncoder) sinkEvent(event *gst.Event) bool {
	gclass := (*C.GstAudioEncoderClass)(coreglib.PeekParentClass(enc))
	fnarg := gclass.sink_event

	var _arg0 *C.GstAudioEncoder // out
	var _arg1 *C.GstEvent        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C._gotk4_gstaudio1_AudioEncoder_virtual_sink_event(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(event)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// sinkQuery: optional. Query handler on the sink pad. This function should
// return TRUE if the query could be performed. Subclasses should chain up to
// the parent implementation to invoke the default handler. Since: 1.6.
func (encoder *AudioEncoder) sinkQuery(query *gst.Query) bool {
	gclass := (*C.GstAudioEncoderClass)(coreglib.PeekParentClass(encoder))
	fnarg := gclass.sink_query

	var _arg0 *C.GstAudioEncoder // out
	var _arg1 *C.GstQuery        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstaudio1_AudioEncoder_virtual_sink_query(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// srcEvent: optional. Event handler on the src pad. Subclasses should chain up
// to the parent implementation to invoke the default handler.
func (enc *AudioEncoder) srcEvent(event *gst.Event) bool {
	gclass := (*C.GstAudioEncoderClass)(coreglib.PeekParentClass(enc))
	fnarg := gclass.src_event

	var _arg0 *C.GstAudioEncoder // out
	var _arg1 *C.GstEvent        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	_arg1 = (*C.GstEvent)(gextras.StructNative(unsafe.Pointer(event)))

	_cret = C._gotk4_gstaudio1_AudioEncoder_virtual_src_event(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(event)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// srcQuery: optional. Query handler on the source pad. This function should
// return TRUE if the query could be performed. Subclasses should chain up to
// the parent implementation to invoke the default handler. Since: 1.6.
func (encoder *AudioEncoder) srcQuery(query *gst.Query) bool {
	gclass := (*C.GstAudioEncoderClass)(coreglib.PeekParentClass(encoder))
	fnarg := gclass.src_query

	var _arg0 *C.GstAudioEncoder // out
	var _arg1 *C.GstQuery        // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(encoder).Native()))
	_arg1 = (*C.GstQuery)(gextras.StructNative(unsafe.Pointer(query)))

	_cret = C._gotk4_gstaudio1_AudioEncoder_virtual_src_query(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(encoder)
	runtime.KeepAlive(query)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Start: optional. Called when the element starts processing. Allows opening
// external resources.
func (enc *AudioEncoder) start() bool {
	gclass := (*C.GstAudioEncoderClass)(coreglib.PeekParentClass(enc))
	fnarg := gclass.start

	var _arg0 *C.GstAudioEncoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))

	_cret = C._gotk4_gstaudio1_AudioEncoder_virtual_start(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(enc)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Stop: optional. Called when the element stops processing. Allows closing
// external resources.
func (enc *AudioEncoder) stop() bool {
	gclass := (*C.GstAudioEncoderClass)(coreglib.PeekParentClass(enc))
	fnarg := gclass.stop

	var _arg0 *C.GstAudioEncoder // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))

	_cret = C._gotk4_gstaudio1_AudioEncoder_virtual_stop(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(enc)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// transformMeta: optional. Transform the metadata on the input buffer to the
// output buffer. By default this method copies all meta without tags and meta
// with only the "audio" tag. subclasses can implement this method and return
// TRUE if the metadata is to be copied. Since: 1.6.
//
// The function takes the following parameters:
//
//   - outbuf
//   - meta
//   - inbuf
func (enc *AudioEncoder) transformMeta(outbuf *gst.Buffer, meta *gst.Meta, inbuf *gst.Buffer) bool {
	gclass := (*C.GstAudioEncoderClass)(coreglib.PeekParentClass(enc))
	fnarg := gclass.transform_meta

	var _arg0 *C.GstAudioEncoder // out
	var _arg1 *C.GstBuffer       // out
	var _arg2 *C.GstMeta         // out
	var _arg3 *C.GstBuffer       // out
	var _cret C.gboolean         // in

	_arg0 = (*C.GstAudioEncoder)(unsafe.Pointer(coreglib.BaseObject(enc).Native()))
	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(outbuf)))
	_arg2 = (*C.GstMeta)(gextras.StructNative(unsafe.Pointer(meta)))
	_arg3 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(inbuf)))

	_cret = C._gotk4_gstaudio1_AudioEncoder_virtual_transform_meta(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(enc)
	runtime.KeepAlive(outbuf)
	runtime.KeepAlive(meta)
	runtime.KeepAlive(inbuf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// AudioFilterOverrides contains methods that are overridable.
type AudioFilterOverrides struct {
	// Setup: virtual function called whenever the format changes.
	Setup func(info *AudioInfo) bool
}

func defaultAudioFilterOverrides(v *AudioFilter) AudioFilterOverrides {
	return AudioFilterOverrides{
		Setup: v.setup,
	}
}

// AudioFilter (GstAudioFilter) is a BaseTransform<!-- -->-derived base class
// for simple audio filters, ie. those that output the same format that they get
// as input.
//
// AudioFilter will parse the input format for you (with error checking) before
// calling your setup function. Also, elements deriving from AudioFilter may use
// gst_audio_filter_class_add_pad_templates() from their class_init function to
// easily configure the set of caps/formats that the element is able to handle.
//
// Derived classes should override the AudioFilterClass.setup() and
// BaseTransformClass.transform_ip() and/or BaseTransformClass.transform()
// virtual functions in their class_init function.
type AudioFilter struct {
	_ [0]func() // equal guard
	gstbase.BaseTransform
}

var (
	_ gstbase.BaseTransformer = (*AudioFilter)(nil)
)

// AudioFilterer describes types inherited from AudioFilter.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type AudioFilterer interface {
	gstbase.BaseTransformer

	baseAudioFilter() *AudioFilter
}

var _ AudioFilterer = (*AudioFilter)(nil)

func init() {
	coreglib.RegisterClassInfo[*AudioFilter, *AudioFilterClass, AudioFilterOverrides](
		GTypeAudioFilter,
		initAudioFilterClass,
		wrapAudioFilter,
		defaultAudioFilterOverrides,
	)
}

func initAudioFilterClass(gclass unsafe.Pointer, overrides AudioFilterOverrides, classInitFunc func(*AudioFilterClass)) {
	pclass := (*C.GstAudioFilterClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeAudioFilter))))

	if overrides.Setup != nil {
		pclass.setup = (*[0]byte)(C._gotk4_gstaudio1_AudioFilterClass_setup)
	}

	if classInitFunc != nil {
		class := (*AudioFilterClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapAudioFilter(obj *coreglib.Object) *AudioFilter {
	return &AudioFilter{
		BaseTransform: gstbase.BaseTransform{
			Element: gst.Element{
				GstObject: gst.GstObject{
					InitiallyUnowned: coreglib.InitiallyUnowned{
						Object: obj,
					},
				},
			},
		},
	}
}

func marshalAudioFilter(p uintptr) (interface{}, error) {
	return wrapAudioFilter(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (v *AudioFilter) baseAudioFilter() *AudioFilter {
	return v
}

// BaseAudioFilter returns the underlying base object.
func BaseAudioFilter(obj AudioFilterer) *AudioFilter {
	return obj.baseAudioFilter()
}

// Setup: virtual function called whenever the format changes.
func (filter *AudioFilter) setup(info *AudioInfo) bool {
	gclass := (*C.GstAudioFilterClass)(coreglib.PeekParentClass(filter))
	fnarg := gclass.setup

	var _arg0 *C.GstAudioFilter // out
	var _arg1 *C.GstAudioInfo   // out
	var _cret C.gboolean        // in

	_arg0 = (*C.GstAudioFilter)(unsafe.Pointer(coreglib.BaseObject(filter).Native()))
	_arg1 = (*C.GstAudioInfo)(gextras.StructNative(unsafe.Pointer(info)))

	_cret = C._gotk4_gstaudio1_AudioFilter_virtual_setup(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(filter)
	runtime.KeepAlive(info)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// AudioRingBufferOverrides contains methods that are overridable.
type AudioRingBufferOverrides struct {
	// Acquire: allocate the resources for the ringbuffer. This function fills
	// in the data pointer of the ring buffer with a valid Buffer to which
	// samples can be written.
	//
	// The function takes the following parameters:
	//
	//   - spec specs of the buffer.
	//
	// The function returns the following values:
	//
	//   - ok: TRUE if the device could be acquired, FALSE on error.
	//
	//     MT safe.
	Acquire func(spec *AudioRingBufferSpec) bool
	// Activate buf to start or stop pulling data.
	//
	// MT safe.
	//
	// The function takes the following parameters:
	//
	//   - active: new mode.
	//
	// The function returns the following values:
	//
	//   - ok: TRUE if the device could be activated in the requested mode,
	//     FALSE on error.
	Activate func(active bool) bool
	// ClearAll: clear all samples from the ringbuffer.
	//
	// MT safe.
	ClearAll func()
	// CloseDevice: close the audio device associated with the ring
	// buffer. The ring buffer should already have been released via
	// gst_audio_ring_buffer_release().
	//
	// The function returns the following values:
	//
	//   - ok: TRUE if the device could be closed, FALSE on error.
	//
	//     MT safe.
	CloseDevice func() bool
	// Delay: get the number of samples queued in the audio device.
	// This is usually less than the segment size but can be bigger when the
	// implementation uses another internal buffer between the audio device.
	//
	// For playback ringbuffers this is the amount of samples transferred from
	// the ringbuffer to the device but still not played.
	//
	// For capture ringbuffers this is the amount of samples in the device that
	// are not yet transferred to the ringbuffer.
	//
	// The function returns the following values:
	//
	//   - guint: number of samples queued in the audio device.
	//
	//     MT safe.
	Delay func() uint
	// OpenDevice: open the audio device associated with the ring buffer.
	// Does not perform any setup on the device. You must open the device before
	// acquiring the ring buffer.
	//
	// The function returns the following values:
	//
	//   - ok: TRUE if the device could be opened, FALSE on error.
	//
	//     MT safe.
	OpenDevice func() bool
	// Pause processing samples from the ringbuffer.
	//
	// The function returns the following values:
	//
	//   - ok: TRUE if the device could be paused, FALSE on error.
	//
	//     MT safe.
	Pause func() bool
	// Release: free the resources of the ringbuffer.
	//
	// The function returns the following values:
	//
	//   - ok: TRUE if the device could be released, FALSE on error.
	//
	//     MT safe.
	Release func() bool
	// Resume: resume processing of samples after pause.
	Resume func() bool
	// Start processing samples from the ringbuffer.
	//
	// The function returns the following values:
	//
	//   - ok: TRUE if the device could be started, FALSE on error.
	//
	//     MT safe.
	Start func() bool
	// Stop processing samples from the ringbuffer.
	//
	// The function returns the following values:
	//
	//   - ok: TRUE if the device could be stopped, FALSE on error.
	//
	//     MT safe.
	Stop func() bool
}

func defaultAudioRingBufferOverrides(v *AudioRingBuffer) AudioRingBufferOverrides {
	return AudioRingBufferOverrides{
		Acquire:     v.acquire,
		Activate:    v.activate,
		ClearAll:    v.clearAll,
		CloseDevice: v.closeDevice,
		Delay:       v.delay,
		OpenDevice:  v.openDevice,
		Pause:       v.pause,
		Release:     v.release,
		Resume:      v.resume,
		Start:       v.start,
		Stop:        v.stop,
	}
}

// AudioRingBuffer (GstAudioRingBuffer): this object is the base class for audio
// ringbuffers used by the base audio source and sink classes.
//
// The ringbuffer abstracts a circular buffer of data. One reader and one
// writer can operate on the data from different threads in a lockfree manner.
// The base class is sufficiently flexible to be used as an abstraction for DMA
// based ringbuffers as well as a pure software implementations.
type AudioRingBuffer struct {
	_ [0]func() // equal guard
	gst.GstObject
}

var (
	_ gst.GstObjector = (*AudioRingBuffer)(nil)
)

// AudioRingBufferer describes types inherited from AudioRingBuffer.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type AudioRingBufferer interface {
	gst.GstObjector

	// Acquire (gst_audio_ring_buffer_acquire): allocate the resources for the
	// ringbuffer.
	Acquire(spec *AudioRingBufferSpec) bool
	// Activate (gst_audio_ring_buffer_activate) buf to start or stop pulling
	// data.
	Activate(active bool) bool
	// Advance (gst_audio_ring_buffer_advance) subclasses should call this
	// function to notify the fact that advance segments are now processed by
	// the device.
	Advance(advance uint)
	// Clear (gst_audio_ring_buffer_clear) the given segment of the buffer with
	// silence samples.
	Clear(segment int)
	// ClearAll (gst_audio_ring_buffer_clear_all): clear all samples from the
	// ringbuffer.
	ClearAll()
	// CloseDevice (gst_audio_ring_buffer_close_device): close the audio device
	// associated with the ring buffer.
	CloseDevice() bool
	// Convert (gst_audio_ring_buffer_convert) src_val in src_fmt to the
	// equivalent value in dest_fmt.
	Convert(srcFmt gst.Format, srcVal int64, destFmt gst.Format) (int64, bool)
	// Delay (gst_audio_ring_buffer_delay): get the number of samples queued in
	// the audio device.
	Delay() uint
	// DeviceIsOpen (gst_audio_ring_buffer_device_is_open) checks the status of
	// the device associated with the ring buffer.
	DeviceIsOpen() bool
	// IsAcquired (gst_audio_ring_buffer_is_acquired): check if the ringbuffer
	// is acquired and ready to use.
	IsAcquired() bool
	// IsActive (gst_audio_ring_buffer_is_active): check if buf is activated.
	IsActive() bool
	// IsFlushing (gst_audio_ring_buffer_is_flushing): check if buf is flushing.
	IsFlushing() bool
	// MayStart (gst_audio_ring_buffer_may_start): tell the ringbuffer that it
	// is allowed to start playback when the ringbuffer is filled with samples.
	MayStart(allowed bool)
	// OpenDevice (gst_audio_ring_buffer_open_device): open the audio device
	// associated with the ring buffer.
	OpenDevice() bool
	// Pause (gst_audio_ring_buffer_pause) processing samples from the
	// ringbuffer.
	Pause() bool
	// PrepareRead (gst_audio_ring_buffer_prepare_read) returns a pointer to
	// memory where the data from segment segment can be found.
	PrepareRead() (int, []byte, bool)
	// Read (gst_audio_ring_buffer_read) len samples from the ringbuffer into
	// the memory pointed to by data.
	Read(sample uint64, data []byte) (gst.ClockTime, uint)
	// Release (gst_audio_ring_buffer_release): free the resources of the
	// ringbuffer.
	Release() bool
	// SamplesDone (gst_audio_ring_buffer_samples_done): get the number of
	// samples that were processed by the ringbuffer since it was last started.
	SamplesDone() uint64
	// SetCallback (gst_audio_ring_buffer_set_callback_full) sets the given
	// callback function on the buffer.
	SetCallback(cb AudioRingBufferCallback)
	// SetErrored (gst_audio_ring_buffer_set_errored): mark the ringbuffer as
	// errored after it has started.
	SetErrored()
	// SetFlushing (gst_audio_ring_buffer_set_flushing): set the ringbuffer to
	// flushing mode or normal mode.
	SetFlushing(flushing bool)
	// SetSample (gst_audio_ring_buffer_set_sample): make sure that the next
	// sample written to the device is accounted for as being the sample sample
	// written to the device.
	SetSample(sample uint64)
	SetTimestamp(readseg int, timestamp gst.ClockTime)
	// Start (gst_audio_ring_buffer_start) processing samples from the
	// ringbuffer.
	Start() bool
	// Stop (gst_audio_ring_buffer_stop) processing samples from the ringbuffer.
	Stop() bool

	baseAudioRingBuffer() *AudioRingBuffer
}

var _ AudioRingBufferer = (*AudioRingBuffer)(nil)

func init() {
	coreglib.RegisterClassInfo[*AudioRingBuffer, *AudioRingBufferClass, AudioRingBufferOverrides](
		GTypeAudioRingBuffer,
		initAudioRingBufferClass,
		wrapAudioRingBuffer,
		defaultAudioRingBufferOverrides,
	)
}

func initAudioRingBufferClass(gclass unsafe.Pointer, overrides AudioRingBufferOverrides, classInitFunc func(*AudioRingBufferClass)) {
	pclass := (*C.GstAudioRingBufferClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeAudioRingBuffer))))

	if overrides.Acquire != nil {
		pclass.acquire = (*[0]byte)(C._gotk4_gstaudio1_AudioRingBufferClass_acquire)
	}

	if overrides.Activate != nil {
		pclass.activate = (*[0]byte)(C._gotk4_gstaudio1_AudioRingBufferClass_activate)
	}

	if overrides.ClearAll != nil {
		pclass.clear_all = (*[0]byte)(C._gotk4_gstaudio1_AudioRingBufferClass_clear_all)
	}

	if overrides.CloseDevice != nil {
		pclass.close_device = (*[0]byte)(C._gotk4_gstaudio1_AudioRingBufferClass_close_device)
	}

	if overrides.Delay != nil {
		pclass.delay = (*[0]byte)(C._gotk4_gstaudio1_AudioRingBufferClass_delay)
	}

	if overrides.OpenDevice != nil {
		pclass.open_device = (*[0]byte)(C._gotk4_gstaudio1_AudioRingBufferClass_open_device)
	}

	if overrides.Pause != nil {
		pclass.pause = (*[0]byte)(C._gotk4_gstaudio1_AudioRingBufferClass_pause)
	}

	if overrides.Release != nil {
		pclass.release = (*[0]byte)(C._gotk4_gstaudio1_AudioRingBufferClass_release)
	}

	if overrides.Resume != nil {
		pclass.resume = (*[0]byte)(C._gotk4_gstaudio1_AudioRingBufferClass_resume)
	}

	if overrides.Start != nil {
		pclass.start = (*[0]byte)(C._gotk4_gstaudio1_AudioRingBufferClass_start)
	}

	if overrides.Stop != nil {
		pclass.stop = (*[0]byte)(C._gotk4_gstaudio1_AudioRingBufferClass_stop)
	}

	if classInitFunc != nil {
		class := (*AudioRingBufferClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapAudioRingBuffer(obj *coreglib.Object) *AudioRingBuffer {
	return &AudioRingBuffer{
		GstObject: gst.GstObject{
			InitiallyUnowned: coreglib.InitiallyUnowned{
				Object: obj,
			},
		},
	}
}

func marshalAudioRingBuffer(p uintptr) (interface{}, error) {
	return wrapAudioRingBuffer(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (buf *AudioRingBuffer) baseAudioRingBuffer() *AudioRingBuffer {
	return buf
}

// BaseAudioRingBuffer returns the underlying base object.
func BaseAudioRingBuffer(obj AudioRingBufferer) *AudioRingBuffer {
	return obj.baseAudioRingBuffer()
}

// Acquire (gst_audio_ring_buffer_acquire): allocate the resources for the
// ringbuffer. This function fills in the data pointer of the ring buffer with a
// valid Buffer to which samples can be written.
//
// The function takes the following parameters:
//
//   - spec specs of the buffer.
//
// The function returns the following values:
//
//   - ok: TRUE if the device could be acquired, FALSE on error.
//
//     MT safe.
func (buf *AudioRingBuffer) Acquire(spec *AudioRingBufferSpec) bool {
	var _arg0 *C.GstAudioRingBuffer     // out
	var _arg1 *C.GstAudioRingBufferSpec // out
	var _cret C.gboolean                // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))
	_arg1 = (*C.GstAudioRingBufferSpec)(gextras.StructNative(unsafe.Pointer(spec)))

	_cret = C.gst_audio_ring_buffer_acquire(_arg0, _arg1)
	runtime.KeepAlive(buf)
	runtime.KeepAlive(spec)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Activate (gst_audio_ring_buffer_activate) buf to start or stop pulling data.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - active: new mode.
//
// The function returns the following values:
//
//   - ok: TRUE if the device could be activated in the requested mode, FALSE on
//     error.
func (buf *AudioRingBuffer) Activate(active bool) bool {
	var _arg0 *C.GstAudioRingBuffer // out
	var _arg1 C.gboolean            // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))
	if active {
		_arg1 = C.TRUE
	}

	_cret = C.gst_audio_ring_buffer_activate(_arg0, _arg1)
	runtime.KeepAlive(buf)
	runtime.KeepAlive(active)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Advance (gst_audio_ring_buffer_advance) subclasses should call this function
// to notify the fact that advance segments are now processed by the device.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - advance: number of segments written.
func (buf *AudioRingBuffer) Advance(advance uint) {
	var _arg0 *C.GstAudioRingBuffer // out
	var _arg1 C.guint               // out

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))
	_arg1 = C.guint(advance)

	C.gst_audio_ring_buffer_advance(_arg0, _arg1)
	runtime.KeepAlive(buf)
	runtime.KeepAlive(advance)
}

// Clear (gst_audio_ring_buffer_clear) the given segment of the buffer with
// silence samples. This function is used by subclasses.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - segment to clear.
func (buf *AudioRingBuffer) Clear(segment int) {
	var _arg0 *C.GstAudioRingBuffer // out
	var _arg1 C.gint                // out

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))
	_arg1 = C.gint(segment)

	C.gst_audio_ring_buffer_clear(_arg0, _arg1)
	runtime.KeepAlive(buf)
	runtime.KeepAlive(segment)
}

// ClearAll (gst_audio_ring_buffer_clear_all): clear all samples from the
// ringbuffer.
//
// MT safe.
func (buf *AudioRingBuffer) ClearAll() {
	var _arg0 *C.GstAudioRingBuffer // out

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	C.gst_audio_ring_buffer_clear_all(_arg0)
	runtime.KeepAlive(buf)
}

// CloseDevice (gst_audio_ring_buffer_close_device): close the audio device
// associated with the ring buffer. The ring buffer should already have been
// released via gst_audio_ring_buffer_release().
//
// The function returns the following values:
//
//   - ok: TRUE if the device could be closed, FALSE on error.
//
//     MT safe.
func (buf *AudioRingBuffer) CloseDevice() bool {
	var _arg0 *C.GstAudioRingBuffer // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	_cret = C.gst_audio_ring_buffer_close_device(_arg0)
	runtime.KeepAlive(buf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Convert (gst_audio_ring_buffer_convert) src_val in src_fmt to the equivalent
// value in dest_fmt. The result will be put in dest_val.
//
// The function takes the following parameters:
//
//   - srcFmt: source format.
//   - srcVal: source value.
//   - destFmt: destination format.
//
// The function returns the following values:
//
//   - destVal: location to store the converted value.
//   - ok: TRUE if the conversion succeeded.
func (buf *AudioRingBuffer) Convert(srcFmt gst.Format, srcVal int64, destFmt gst.Format) (int64, bool) {
	var _arg0 *C.GstAudioRingBuffer // out
	var _arg1 C.GstFormat           // out
	var _arg2 C.gint64              // out
	var _arg3 C.GstFormat           // out
	var _arg4 C.gint64              // in
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))
	_arg1 = C.GstFormat(srcFmt)
	_arg2 = C.gint64(srcVal)
	_arg3 = C.GstFormat(destFmt)

	_cret = C.gst_audio_ring_buffer_convert(_arg0, _arg1, _arg2, _arg3, &_arg4)
	runtime.KeepAlive(buf)
	runtime.KeepAlive(srcFmt)
	runtime.KeepAlive(srcVal)
	runtime.KeepAlive(destFmt)

	var _destVal int64 // out
	var _ok bool       // out

	_destVal = int64(_arg4)
	if _cret != 0 {
		_ok = true
	}

	return _destVal, _ok
}

// Delay (gst_audio_ring_buffer_delay): get the number of samples queued in the
// audio device. This is usually less than the segment size but can be bigger
// when the implementation uses another internal buffer between the audio
// device.
//
// For playback ringbuffers this is the amount of samples transferred from the
// ringbuffer to the device but still not played.
//
// For capture ringbuffers this is the amount of samples in the device that are
// not yet transferred to the ringbuffer.
//
// The function returns the following values:
//
//   - guint: number of samples queued in the audio device.
//
//     MT safe.
func (buf *AudioRingBuffer) Delay() uint {
	var _arg0 *C.GstAudioRingBuffer // out
	var _cret C.guint               // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	_cret = C.gst_audio_ring_buffer_delay(_arg0)
	runtime.KeepAlive(buf)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// DeviceIsOpen (gst_audio_ring_buffer_device_is_open) checks the status of the
// device associated with the ring buffer.
//
// The function returns the following values:
//
//   - ok: TRUE if the device was open, FALSE if it was closed.
//
//     MT safe.
func (buf *AudioRingBuffer) DeviceIsOpen() bool {
	var _arg0 *C.GstAudioRingBuffer // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	_cret = C.gst_audio_ring_buffer_device_is_open(_arg0)
	runtime.KeepAlive(buf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// IsAcquired (gst_audio_ring_buffer_is_acquired): check if the ringbuffer is
// acquired and ready to use.
//
// The function returns the following values:
//
//   - ok: TRUE if the ringbuffer is acquired, FALSE on error.
//
//     MT safe.
func (buf *AudioRingBuffer) IsAcquired() bool {
	var _arg0 *C.GstAudioRingBuffer // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	_cret = C.gst_audio_ring_buffer_is_acquired(_arg0)
	runtime.KeepAlive(buf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// IsActive (gst_audio_ring_buffer_is_active): check if buf is activated.
//
// MT safe.
//
// The function returns the following values:
//
//   - ok: TRUE if the device is active.
func (buf *AudioRingBuffer) IsActive() bool {
	var _arg0 *C.GstAudioRingBuffer // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	_cret = C.gst_audio_ring_buffer_is_active(_arg0)
	runtime.KeepAlive(buf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// IsFlushing (gst_audio_ring_buffer_is_flushing): check if buf is flushing.
//
// MT safe.
//
// The function returns the following values:
//
//   - ok: TRUE if the device is flushing.
func (buf *AudioRingBuffer) IsFlushing() bool {
	var _arg0 *C.GstAudioRingBuffer // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	_cret = C.gst_audio_ring_buffer_is_flushing(_arg0)
	runtime.KeepAlive(buf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// MayStart (gst_audio_ring_buffer_may_start): tell the ringbuffer that it is
// allowed to start playback when the ringbuffer is filled with samples.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - allowed: new value.
func (buf *AudioRingBuffer) MayStart(allowed bool) {
	var _arg0 *C.GstAudioRingBuffer // out
	var _arg1 C.gboolean            // out

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))
	if allowed {
		_arg1 = C.TRUE
	}

	C.gst_audio_ring_buffer_may_start(_arg0, _arg1)
	runtime.KeepAlive(buf)
	runtime.KeepAlive(allowed)
}

// OpenDevice (gst_audio_ring_buffer_open_device): open the audio device
// associated with the ring buffer. Does not perform any setup on the device.
// You must open the device before acquiring the ring buffer.
//
// The function returns the following values:
//
//   - ok: TRUE if the device could be opened, FALSE on error.
//
//     MT safe.
func (buf *AudioRingBuffer) OpenDevice() bool {
	var _arg0 *C.GstAudioRingBuffer // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	_cret = C.gst_audio_ring_buffer_open_device(_arg0)
	runtime.KeepAlive(buf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Pause (gst_audio_ring_buffer_pause) processing samples from the ringbuffer.
//
// The function returns the following values:
//
//   - ok: TRUE if the device could be paused, FALSE on error.
//
//     MT safe.
func (buf *AudioRingBuffer) Pause() bool {
	var _arg0 *C.GstAudioRingBuffer // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	_cret = C.gst_audio_ring_buffer_pause(_arg0)
	runtime.KeepAlive(buf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// PrepareRead (gst_audio_ring_buffer_prepare_read) returns a pointer to memory
// where the data from segment segment can be found. This function is mostly
// used by subclasses.
//
// The function returns the following values:
//
//   - segment to read.
//
//   - readptr: the pointer to the memory where samples can be read.
//
//   - ok: FALSE if the buffer is not started.
//
//     MT safe.
func (buf *AudioRingBuffer) PrepareRead() (int, []byte, bool) {
	var _arg0 *C.GstAudioRingBuffer // out
	var _arg1 C.gint                // in
	var _arg2 *C.guint8             // in
	var _arg3 C.gint                // in
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	_cret = C.gst_audio_ring_buffer_prepare_read(_arg0, &_arg1, &_arg2, &_arg3)
	runtime.KeepAlive(buf)

	var _segment int    // out
	var _readptr []byte // out
	var _ok bool        // out

	_segment = int(_arg1)
	defer C.free(unsafe.Pointer(_arg2))
	_readptr = make([]byte, _arg3)
	copy(_readptr, unsafe.Slice((*byte)(unsafe.Pointer(_arg2)), _arg3))
	if _cret != 0 {
		_ok = true
	}

	return _segment, _readptr, _ok
}

// Read (gst_audio_ring_buffer_read) len samples from the ringbuffer into the
// memory pointed to by data. The first sample should be read from position
// sample in the ringbuffer.
//
// len should not be a multiple of the segment size of the ringbuffer although
// it is recommended.
//
// timestamp will return the timestamp associated with the data returned.
//
// The function takes the following parameters:
//
//   - sample position of the data.
//   - data: where the data should be read.
//
// The function returns the following values:
//
//   - timestamp: where the timestamp is returned.
//
//   - guint: number of samples read from the ringbuffer or -1 on error.
//
//     MT safe.
func (buf *AudioRingBuffer) Read(sample uint64, data []byte) (gst.ClockTime, uint) {
	var _arg0 *C.GstAudioRingBuffer // out
	var _arg1 C.guint64             // out
	var _arg2 *C.guint8             // out
	var _arg3 C.guint
	var _arg4 C.GstClockTime // in
	var _cret C.guint        // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))
	_arg1 = C.guint64(sample)
	_arg3 = (C.guint)(len(data))
	if len(data) > 0 {
		_arg2 = (*C.guint8)(unsafe.Pointer(&data[0]))
	}

	_cret = C.gst_audio_ring_buffer_read(_arg0, _arg1, _arg2, _arg3, &_arg4)
	runtime.KeepAlive(buf)
	runtime.KeepAlive(sample)
	runtime.KeepAlive(data)

	var _timestamp gst.ClockTime // out
	var _guint uint              // out

	_timestamp = gst.ClockTime(_arg4)
	_guint = uint(_cret)

	return _timestamp, _guint
}

// Release (gst_audio_ring_buffer_release): free the resources of the
// ringbuffer.
//
// The function returns the following values:
//
//   - ok: TRUE if the device could be released, FALSE on error.
//
//     MT safe.
func (buf *AudioRingBuffer) Release() bool {
	var _arg0 *C.GstAudioRingBuffer // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	_cret = C.gst_audio_ring_buffer_release(_arg0)
	runtime.KeepAlive(buf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SamplesDone (gst_audio_ring_buffer_samples_done): get the number of
// samples that were processed by the ringbuffer since it was last started.
// This does not include the number of samples not yet processed (see
// gst_audio_ring_buffer_delay()).
//
// The function returns the following values:
//
//   - guint64: number of samples processed by the ringbuffer.
//
//     MT safe.
func (buf *AudioRingBuffer) SamplesDone() uint64 {
	var _arg0 *C.GstAudioRingBuffer // out
	var _cret C.guint64             // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	_cret = C.gst_audio_ring_buffer_samples_done(_arg0)
	runtime.KeepAlive(buf)

	var _guint64 uint64 // out

	_guint64 = uint64(_cret)

	return _guint64
}

// SetCallback (gst_audio_ring_buffer_set_callback_full) sets the given callback
// function on the buffer. This function will be called every time a segment has
// been written to a device.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - cb (optional): callback to set.
func (buf *AudioRingBuffer) SetCallback(cb AudioRingBufferCallback) {
	var _arg0 *C.GstAudioRingBuffer        // out
	var _arg1 C.GstAudioRingBufferCallback // out
	var _arg2 C.gpointer
	var _arg3 C.GDestroyNotify

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))
	if cb != nil {
		_arg1 = (*[0]byte)(C._gotk4_gstaudio1_AudioRingBufferCallback)
		_arg2 = C.gpointer(gbox.Assign(cb))
		_arg3 = (C.GDestroyNotify)((*[0]byte)(C.callbackDelete))
	}

	C.gst_audio_ring_buffer_set_callback_full(_arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(buf)
	runtime.KeepAlive(cb)
}

// SetErrored (gst_audio_ring_buffer_set_errored): mark the ringbuffer as
// errored after it has started.
//
// MT safe.
func (buf *AudioRingBuffer) SetErrored() {
	var _arg0 *C.GstAudioRingBuffer // out

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	C.gst_audio_ring_buffer_set_errored(_arg0)
	runtime.KeepAlive(buf)
}

// SetFlushing (gst_audio_ring_buffer_set_flushing): set the ringbuffer to
// flushing mode or normal mode.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - flushing: new mode.
func (buf *AudioRingBuffer) SetFlushing(flushing bool) {
	var _arg0 *C.GstAudioRingBuffer // out
	var _arg1 C.gboolean            // out

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))
	if flushing {
		_arg1 = C.TRUE
	}

	C.gst_audio_ring_buffer_set_flushing(_arg0, _arg1)
	runtime.KeepAlive(buf)
	runtime.KeepAlive(flushing)
}

// SetSample (gst_audio_ring_buffer_set_sample): make sure that the next sample
// written to the device is accounted for as being the sample sample written to
// the device. This value will be used in reporting the current sample position
// of the ringbuffer.
//
// This function will also clear the buffer with silence.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - sample number to set.
func (buf *AudioRingBuffer) SetSample(sample uint64) {
	var _arg0 *C.GstAudioRingBuffer // out
	var _arg1 C.guint64             // out

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))
	_arg1 = C.guint64(sample)

	C.gst_audio_ring_buffer_set_sample(_arg0, _arg1)
	runtime.KeepAlive(buf)
	runtime.KeepAlive(sample)
}

// The function takes the following parameters:
//
//   - readseg
//   - timestamp
func (buf *AudioRingBuffer) SetTimestamp(readseg int, timestamp gst.ClockTime) {
	var _arg0 *C.GstAudioRingBuffer // out
	var _arg1 C.gint                // out
	var _arg2 C.GstClockTime        // out

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))
	_arg1 = C.gint(readseg)
	_arg2 = C.GstClockTime(timestamp)

	C.gst_audio_ring_buffer_set_timestamp(_arg0, _arg1, _arg2)
	runtime.KeepAlive(buf)
	runtime.KeepAlive(readseg)
	runtime.KeepAlive(timestamp)
}

// Start (gst_audio_ring_buffer_start) processing samples from the ringbuffer.
//
// The function returns the following values:
//
//   - ok: TRUE if the device could be started, FALSE on error.
//
//     MT safe.
func (buf *AudioRingBuffer) Start() bool {
	var _arg0 *C.GstAudioRingBuffer // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	_cret = C.gst_audio_ring_buffer_start(_arg0)
	runtime.KeepAlive(buf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Stop (gst_audio_ring_buffer_stop) processing samples from the ringbuffer.
//
// The function returns the following values:
//
//   - ok: TRUE if the device could be stopped, FALSE on error.
//
//     MT safe.
func (buf *AudioRingBuffer) Stop() bool {
	var _arg0 *C.GstAudioRingBuffer // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	_cret = C.gst_audio_ring_buffer_stop(_arg0)
	runtime.KeepAlive(buf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Acquire: allocate the resources for the ringbuffer. This function fills in
// the data pointer of the ring buffer with a valid Buffer to which samples can
// be written.
//
// The function takes the following parameters:
//
//   - spec specs of the buffer.
//
// The function returns the following values:
//
//   - ok: TRUE if the device could be acquired, FALSE on error.
//
//     MT safe.
func (buf *AudioRingBuffer) acquire(spec *AudioRingBufferSpec) bool {
	gclass := (*C.GstAudioRingBufferClass)(coreglib.PeekParentClass(buf))
	fnarg := gclass.acquire

	var _arg0 *C.GstAudioRingBuffer     // out
	var _arg1 *C.GstAudioRingBufferSpec // out
	var _cret C.gboolean                // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))
	_arg1 = (*C.GstAudioRingBufferSpec)(gextras.StructNative(unsafe.Pointer(spec)))

	_cret = C._gotk4_gstaudio1_AudioRingBuffer_virtual_acquire(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(buf)
	runtime.KeepAlive(spec)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Activate: activate buf to start or stop pulling data.
//
// MT safe.
//
// The function takes the following parameters:
//
//   - active: new mode.
//
// The function returns the following values:
//
//   - ok: TRUE if the device could be activated in the requested mode, FALSE on
//     error.
func (buf *AudioRingBuffer) activate(active bool) bool {
	gclass := (*C.GstAudioRingBufferClass)(coreglib.PeekParentClass(buf))
	fnarg := gclass.activate

	var _arg0 *C.GstAudioRingBuffer // out
	var _arg1 C.gboolean            // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))
	if active {
		_arg1 = C.TRUE
	}

	_cret = C._gotk4_gstaudio1_AudioRingBuffer_virtual_activate(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(buf)
	runtime.KeepAlive(active)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// clearAll: clear all samples from the ringbuffer.
//
// MT safe.
func (buf *AudioRingBuffer) clearAll() {
	gclass := (*C.GstAudioRingBufferClass)(coreglib.PeekParentClass(buf))
	fnarg := gclass.clear_all

	var _arg0 *C.GstAudioRingBuffer // out

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	C._gotk4_gstaudio1_AudioRingBuffer_virtual_clear_all(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(buf)
}

// closeDevice: close the audio device associated with the ring buffer. The ring
// buffer should already have been released via gst_audio_ring_buffer_release().
//
// The function returns the following values:
//
//   - ok: TRUE if the device could be closed, FALSE on error.
//
//     MT safe.
func (buf *AudioRingBuffer) closeDevice() bool {
	gclass := (*C.GstAudioRingBufferClass)(coreglib.PeekParentClass(buf))
	fnarg := gclass.close_device

	var _arg0 *C.GstAudioRingBuffer // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	_cret = C._gotk4_gstaudio1_AudioRingBuffer_virtual_close_device(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(buf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Delay: get the number of samples queued in the audio device. This is usually
// less than the segment size but can be bigger when the implementation uses
// another internal buffer between the audio device.
//
// For playback ringbuffers this is the amount of samples transferred from the
// ringbuffer to the device but still not played.
//
// For capture ringbuffers this is the amount of samples in the device that are
// not yet transferred to the ringbuffer.
//
// The function returns the following values:
//
//   - guint: number of samples queued in the audio device.
//
//     MT safe.
func (buf *AudioRingBuffer) delay() uint {
	gclass := (*C.GstAudioRingBufferClass)(coreglib.PeekParentClass(buf))
	fnarg := gclass.delay

	var _arg0 *C.GstAudioRingBuffer // out
	var _cret C.guint               // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	_cret = C._gotk4_gstaudio1_AudioRingBuffer_virtual_delay(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(buf)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// openDevice: open the audio device associated with the ring buffer. Does not
// perform any setup on the device. You must open the device before acquiring
// the ring buffer.
//
// The function returns the following values:
//
//   - ok: TRUE if the device could be opened, FALSE on error.
//
//     MT safe.
func (buf *AudioRingBuffer) openDevice() bool {
	gclass := (*C.GstAudioRingBufferClass)(coreglib.PeekParentClass(buf))
	fnarg := gclass.open_device

	var _arg0 *C.GstAudioRingBuffer // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	_cret = C._gotk4_gstaudio1_AudioRingBuffer_virtual_open_device(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(buf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Pause: pause processing samples from the ringbuffer.
//
// The function returns the following values:
//
//   - ok: TRUE if the device could be paused, FALSE on error.
//
//     MT safe.
func (buf *AudioRingBuffer) pause() bool {
	gclass := (*C.GstAudioRingBufferClass)(coreglib.PeekParentClass(buf))
	fnarg := gclass.pause

	var _arg0 *C.GstAudioRingBuffer // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	_cret = C._gotk4_gstaudio1_AudioRingBuffer_virtual_pause(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(buf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Release: free the resources of the ringbuffer.
//
// The function returns the following values:
//
//   - ok: TRUE if the device could be released, FALSE on error.
//
//     MT safe.
func (buf *AudioRingBuffer) release() bool {
	gclass := (*C.GstAudioRingBufferClass)(coreglib.PeekParentClass(buf))
	fnarg := gclass.release

	var _arg0 *C.GstAudioRingBuffer // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	_cret = C._gotk4_gstaudio1_AudioRingBuffer_virtual_release(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(buf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Resume processing of samples after pause.
func (buf *AudioRingBuffer) resume() bool {
	gclass := (*C.GstAudioRingBufferClass)(coreglib.PeekParentClass(buf))
	fnarg := gclass.resume

	var _arg0 *C.GstAudioRingBuffer // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	_cret = C._gotk4_gstaudio1_AudioRingBuffer_virtual_resume(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(buf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Start: start processing samples from the ringbuffer.
//
// The function returns the following values:
//
//   - ok: TRUE if the device could be started, FALSE on error.
//
//     MT safe.
func (buf *AudioRingBuffer) start() bool {
	gclass := (*C.GstAudioRingBufferClass)(coreglib.PeekParentClass(buf))
	fnarg := gclass.start

	var _arg0 *C.GstAudioRingBuffer // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	_cret = C._gotk4_gstaudio1_AudioRingBuffer_virtual_start(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(buf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Stop: stop processing samples from the ringbuffer.
//
// The function returns the following values:
//
//   - ok: TRUE if the device could be stopped, FALSE on error.
//
//     MT safe.
func (buf *AudioRingBuffer) stop() bool {
	gclass := (*C.GstAudioRingBufferClass)(coreglib.PeekParentClass(buf))
	fnarg := gclass.stop

	var _arg0 *C.GstAudioRingBuffer // out
	var _cret C.gboolean            // in

	_arg0 = (*C.GstAudioRingBuffer)(unsafe.Pointer(coreglib.BaseObject(buf).Native()))

	_cret = C._gotk4_gstaudio1_AudioRingBuffer_virtual_stop(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(buf)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// AudioRingBufferDebugSpecBuff (gst_audio_ring_buffer_debug_spec_buff):
// print debug info about the buffer sized in spec to the debug log.
//
// The function takes the following parameters:
//
//   - spec to debug.
func AudioRingBufferDebugSpecBuff(spec *AudioRingBufferSpec) {
	var _arg1 *C.GstAudioRingBufferSpec // out

	_arg1 = (*C.GstAudioRingBufferSpec)(gextras.StructNative(unsafe.Pointer(spec)))

	C.gst_audio_ring_buffer_debug_spec_buff(_arg1)
	runtime.KeepAlive(spec)
}

// AudioRingBufferDebugSpecCaps (gst_audio_ring_buffer_debug_spec_caps):
// print debug info about the parsed caps in spec to the debug log.
//
// The function takes the following parameters:
//
//   - spec to debug.
func AudioRingBufferDebugSpecCaps(spec *AudioRingBufferSpec) {
	var _arg1 *C.GstAudioRingBufferSpec // out

	_arg1 = (*C.GstAudioRingBufferSpec)(gextras.StructNative(unsafe.Pointer(spec)))

	C.gst_audio_ring_buffer_debug_spec_caps(_arg1)
	runtime.KeepAlive(spec)
}

// AudioRingBufferParseCaps (gst_audio_ring_buffer_parse_caps): parse caps into
// spec.
//
// The function takes the following parameters:
//
//   - spec: spec.
//   - caps: Caps.
//
// The function returns the following values:
//
//   - ok: TRUE if the caps could be parsed.
func AudioRingBufferParseCaps(spec *AudioRingBufferSpec, caps *gst.Caps) bool {
	var _arg1 *C.GstAudioRingBufferSpec // out
	var _arg2 *C.GstCaps                // out
	var _cret C.gboolean                // in

	_arg1 = (*C.GstAudioRingBufferSpec)(gextras.StructNative(unsafe.Pointer(spec)))
	_arg2 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C.gst_audio_ring_buffer_parse_caps(_arg1, _arg2)
	runtime.KeepAlive(spec)
	runtime.KeepAlive(caps)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// AudioSinkOverrides contains methods that are overridable.
type AudioSinkOverrides struct {
	// Close the device.
	Close func() bool
	// Delay: return how many frames are still in the device. Participates in
	// computing the time for audio clocks and drives the synchronisation.
	Delay func() uint
	// Open the device. No configuration needs to be done at this point.
	// This function is also used to check if the device is available.
	Open func() bool
	// Pause the device and unblock write as fast as possible. For retro
	// compatibility, the audio sink will fallback to calling reset if this
	// vmethod is not provided. Since: 1.18.
	Pause func()
	// Prepare the device to operate with the specified parameters.
	Prepare func(spec *AudioRingBufferSpec) bool
	// Reset returns as quickly as possible from a write and flush any pending
	// samples from the device. This vmethod is deprecated. Please provide pause
	// and stop instead.
	Reset func()
	// Resume the device. Since: 1.18.
	Resume func()
	// Stop the device and unblock write as fast as possible. Pending samples
	// are flushed from the device. For retro compatibility, the audio sink will
	// fallback to calling reset if this vmethod is not provided. Since: 1.18.
	Stop func()
	// Unprepare: undo operations done in prepare.
	Unprepare func() bool
	// Write samples to the device.
	//
	// The function takes the following parameters:
	//
	//   - data: sample data.
	Write func(data []byte) int
}

func defaultAudioSinkOverrides(v *AudioSink) AudioSinkOverrides {
	return AudioSinkOverrides{
		Close:     v.close,
		Delay:     v.delay,
		Open:      v.open,
		Pause:     v.pause,
		Prepare:   v.prepare,
		Reset:     v.reset,
		Resume:    v.resume,
		Stop:      v.stop,
		Unprepare: v.unprepare,
		Write:     v.write,
	}
}

// AudioSink (GstAudioSink): this is the most simple base class for audio sinks
// that only requires subclasses to implement a set of simple functions:
//
// * open() :Open the device.
//
// * prepare() :Configure the device with the specified format.
//
// * write() :Write samples to the device.
//
// * reset() :Unblock writes and flush the device.
//
// * delay() :Get the number of samples written but not yet played by the
// device.
//
// * unprepare() :Undo operations done by prepare.
//
// * close() :Close the device.
//
// All scheduling of samples and timestamps is done in this base class together
// with AudioBaseSink using a default implementation of a AudioRingBuffer that
// uses threads.
type AudioSink struct {
	_ [0]func() // equal guard
	AudioBaseSink
}

var (
	_ gstbase.BaseSinker = (*AudioSink)(nil)
)

// AudioSinker describes types inherited from AudioSink.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type AudioSinker interface {
	AudioBaseSinker

	baseAudioSink() *AudioSink
}

var _ AudioSinker = (*AudioSink)(nil)

func init() {
	coreglib.RegisterClassInfo[*AudioSink, *AudioSinkClass, AudioSinkOverrides](
		GTypeAudioSink,
		initAudioSinkClass,
		wrapAudioSink,
		defaultAudioSinkOverrides,
	)
}

func initAudioSinkClass(gclass unsafe.Pointer, overrides AudioSinkOverrides, classInitFunc func(*AudioSinkClass)) {
	pclass := (*C.GstAudioSinkClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeAudioSink))))

	if overrides.Close != nil {
		pclass.close = (*[0]byte)(C._gotk4_gstaudio1_AudioSinkClass_close)
	}

	if overrides.Delay != nil {
		pclass.delay = (*[0]byte)(C._gotk4_gstaudio1_AudioSinkClass_delay)
	}

	if overrides.Open != nil {
		pclass.open = (*[0]byte)(C._gotk4_gstaudio1_AudioSinkClass_open)
	}

	if overrides.Pause != nil {
		pclass.pause = (*[0]byte)(C._gotk4_gstaudio1_AudioSinkClass_pause)
	}

	if overrides.Prepare != nil {
		pclass.prepare = (*[0]byte)(C._gotk4_gstaudio1_AudioSinkClass_prepare)
	}

	if overrides.Reset != nil {
		pclass.reset = (*[0]byte)(C._gotk4_gstaudio1_AudioSinkClass_reset)
	}

	if overrides.Resume != nil {
		pclass.resume = (*[0]byte)(C._gotk4_gstaudio1_AudioSinkClass_resume)
	}

	if overrides.Stop != nil {
		pclass.stop = (*[0]byte)(C._gotk4_gstaudio1_AudioSinkClass_stop)
	}

	if overrides.Unprepare != nil {
		pclass.unprepare = (*[0]byte)(C._gotk4_gstaudio1_AudioSinkClass_unprepare)
	}

	if overrides.Write != nil {
		pclass.write = (*[0]byte)(C._gotk4_gstaudio1_AudioSinkClass_write)
	}

	if classInitFunc != nil {
		class := (*AudioSinkClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapAudioSink(obj *coreglib.Object) *AudioSink {
	return &AudioSink{
		AudioBaseSink: AudioBaseSink{
			BaseSink: gstbase.BaseSink{
				Element: gst.Element{
					GstObject: gst.GstObject{
						InitiallyUnowned: coreglib.InitiallyUnowned{
							Object: obj,
						},
					},
				},
			},
		},
	}
}

func marshalAudioSink(p uintptr) (interface{}, error) {
	return wrapAudioSink(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (v *AudioSink) baseAudioSink() *AudioSink {
	return v
}

// BaseAudioSink returns the underlying base object.
func BaseAudioSink(obj AudioSinker) *AudioSink {
	return obj.baseAudioSink()
}

// Close: close the device.
func (sink *AudioSink) close() bool {
	gclass := (*C.GstAudioSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.close

	var _arg0 *C.GstAudioSink // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstAudioSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C._gotk4_gstaudio1_AudioSink_virtual_close(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(sink)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Delay: return how many frames are still in the device. Participates in
// computing the time for audio clocks and drives the synchronisation.
func (sink *AudioSink) delay() uint {
	gclass := (*C.GstAudioSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.delay

	var _arg0 *C.GstAudioSink // out
	var _cret C.guint         // in

	_arg0 = (*C.GstAudioSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C._gotk4_gstaudio1_AudioSink_virtual_delay(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(sink)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// Open: open the device. No configuration needs to be done at this point.
// This function is also used to check if the device is available.
func (sink *AudioSink) open() bool {
	gclass := (*C.GstAudioSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.open

	var _arg0 *C.GstAudioSink // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstAudioSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C._gotk4_gstaudio1_AudioSink_virtual_open(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(sink)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Pause: pause the device and unblock write as fast as possible. For retro
// compatibility, the audio sink will fallback to calling reset if this vmethod
// is not provided. Since: 1.18.
func (sink *AudioSink) pause() {
	gclass := (*C.GstAudioSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.pause

	var _arg0 *C.GstAudioSink // out

	_arg0 = (*C.GstAudioSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	C._gotk4_gstaudio1_AudioSink_virtual_pause(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(sink)
}

// Prepare: prepare the device to operate with the specified parameters.
func (sink *AudioSink) prepare(spec *AudioRingBufferSpec) bool {
	gclass := (*C.GstAudioSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.prepare

	var _arg0 *C.GstAudioSink           // out
	var _arg1 *C.GstAudioRingBufferSpec // out
	var _cret C.gboolean                // in

	_arg0 = (*C.GstAudioSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg1 = (*C.GstAudioRingBufferSpec)(gextras.StructNative(unsafe.Pointer(spec)))

	_cret = C._gotk4_gstaudio1_AudioSink_virtual_prepare(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(spec)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Reset returns as quickly as possible from a write and flush any pending
// samples from the device. This vmethod is deprecated. Please provide pause and
// stop instead.
func (sink *AudioSink) reset() {
	gclass := (*C.GstAudioSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.reset

	var _arg0 *C.GstAudioSink // out

	_arg0 = (*C.GstAudioSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	C._gotk4_gstaudio1_AudioSink_virtual_reset(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(sink)
}

// Resume: resume the device. Since: 1.18.
func (sink *AudioSink) resume() {
	gclass := (*C.GstAudioSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.resume

	var _arg0 *C.GstAudioSink // out

	_arg0 = (*C.GstAudioSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	C._gotk4_gstaudio1_AudioSink_virtual_resume(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(sink)
}

// Stop: stop the device and unblock write as fast as possible. Pending samples
// are flushed from the device. For retro compatibility, the audio sink will
// fallback to calling reset if this vmethod is not provided. Since: 1.18.
func (sink *AudioSink) stop() {
	gclass := (*C.GstAudioSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.stop

	var _arg0 *C.GstAudioSink // out

	_arg0 = (*C.GstAudioSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	C._gotk4_gstaudio1_AudioSink_virtual_stop(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(sink)
}

// Unprepare: undo operations done in prepare.
func (sink *AudioSink) unprepare() bool {
	gclass := (*C.GstAudioSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.unprepare

	var _arg0 *C.GstAudioSink // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstAudioSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))

	_cret = C._gotk4_gstaudio1_AudioSink_virtual_unprepare(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(sink)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Write: write samples to the device.
//
// The function takes the following parameters:
//
//   - data: sample data.
func (sink *AudioSink) write(data []byte) int {
	gclass := (*C.GstAudioSinkClass)(coreglib.PeekParentClass(sink))
	fnarg := gclass.write

	var _arg0 *C.GstAudioSink // out
	var _arg1 C.gpointer      // out
	var _arg2 C.guint
	var _cret C.gint // in

	_arg0 = (*C.GstAudioSink)(unsafe.Pointer(coreglib.BaseObject(sink).Native()))
	_arg2 = (C.guint)(len(data))
	if len(data) > 0 {
		_arg1 = (C.gpointer)(unsafe.Pointer(&data[0]))
	}

	_cret = C._gotk4_gstaudio1_AudioSink_virtual_write(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2)
	runtime.KeepAlive(sink)
	runtime.KeepAlive(data)

	var _gint int // out

	_gint = int(_cret)

	return _gint
}

// AudioSrcOverrides contains methods that are overridable.
type AudioSrcOverrides struct {
	// Close: close the device.
	Close func() bool
	// Delay: number of frames queued in the device.
	Delay func() uint
	// Open: open the device with the specified caps.
	Open func() bool
	// Prepare: configure device with format.
	Prepare func(spec *AudioRingBufferSpec) bool
	// Read samples from the device.
	//
	// The function takes the following parameters:
	//
	//   - data: sample data.
	//
	// The function returns the following values:
	//
	//   - timestamp: ClockTime.
	//   - guint
	Read func(data []byte) (gst.ClockTime, uint)
	// Reset: unblock a read to the device and reset.
	Reset func()
	// Unprepare: undo the configuration.
	Unprepare func() bool
}

func defaultAudioSrcOverrides(v *AudioSrc) AudioSrcOverrides {
	return AudioSrcOverrides{
		Close:     v.close,
		Delay:     v.delay,
		Open:      v.open,
		Prepare:   v.prepare,
		Read:      v.read,
		Reset:     v.reset,
		Unprepare: v.unprepare,
	}
}

// AudioSrc (GstAudioSrc): this is the most simple base class for audio sources
// that only requires subclasses to implement a set of simple functions:
//
// * open() :Open the device. * prepare() :Configure the device with the
// specified format. * read() :Read samples from the device. * reset() :Unblock
// reads and flush the device. * delay() :Get the number of samples in the
// device but not yet read. * unprepare() :Undo operations done by prepare.
// * close() :Close the device.
//
// All scheduling of samples and timestamps is done in this base class together
// with AudioBaseSrc using a default implementation of a AudioRingBuffer that
// uses threads.
type AudioSrc struct {
	_ [0]func() // equal guard
	AudioBaseSrc
}

var (
	_ gstbase.BaseSrcer = (*AudioSrc)(nil)
)

// AudioSrcer describes types inherited from AudioSrc.
//
// To get the original type, the caller must assert this to an interface or
// another type.
type AudioSrcer interface {
	AudioBaseSrcer

	baseAudioSrc() *AudioSrc
}

var _ AudioSrcer = (*AudioSrc)(nil)

func init() {
	coreglib.RegisterClassInfo[*AudioSrc, *AudioSrcClass, AudioSrcOverrides](
		GTypeAudioSrc,
		initAudioSrcClass,
		wrapAudioSrc,
		defaultAudioSrcOverrides,
	)
}

func initAudioSrcClass(gclass unsafe.Pointer, overrides AudioSrcOverrides, classInitFunc func(*AudioSrcClass)) {
	pclass := (*C.GstAudioSrcClass)(unsafe.Pointer(C.g_type_check_class_cast((*C.GTypeClass)(gclass), C.GType(GTypeAudioSrc))))

	if overrides.Close != nil {
		pclass.close = (*[0]byte)(C._gotk4_gstaudio1_AudioSrcClass_close)
	}

	if overrides.Delay != nil {
		pclass.delay = (*[0]byte)(C._gotk4_gstaudio1_AudioSrcClass_delay)
	}

	if overrides.Open != nil {
		pclass.open = (*[0]byte)(C._gotk4_gstaudio1_AudioSrcClass_open)
	}

	if overrides.Prepare != nil {
		pclass.prepare = (*[0]byte)(C._gotk4_gstaudio1_AudioSrcClass_prepare)
	}

	if overrides.Read != nil {
		pclass.read = (*[0]byte)(C._gotk4_gstaudio1_AudioSrcClass_read)
	}

	if overrides.Reset != nil {
		pclass.reset = (*[0]byte)(C._gotk4_gstaudio1_AudioSrcClass_reset)
	}

	if overrides.Unprepare != nil {
		pclass.unprepare = (*[0]byte)(C._gotk4_gstaudio1_AudioSrcClass_unprepare)
	}

	if classInitFunc != nil {
		class := (*AudioSrcClass)(gextras.NewStructNative(gclass))
		classInitFunc(class)
	}
}

func wrapAudioSrc(obj *coreglib.Object) *AudioSrc {
	return &AudioSrc{
		AudioBaseSrc: AudioBaseSrc{
			PushSrc: gstbase.PushSrc{
				BaseSrc: gstbase.BaseSrc{
					Element: gst.Element{
						GstObject: gst.GstObject{
							InitiallyUnowned: coreglib.InitiallyUnowned{
								Object: obj,
							},
						},
					},
				},
			},
		},
	}
}

func marshalAudioSrc(p uintptr) (interface{}, error) {
	return wrapAudioSrc(coreglib.ValueFromNative(unsafe.Pointer(p)).Object()), nil
}

func (v *AudioSrc) baseAudioSrc() *AudioSrc {
	return v
}

// BaseAudioSrc returns the underlying base object.
func BaseAudioSrc(obj AudioSrcer) *AudioSrc {
	return obj.baseAudioSrc()
}

// Close the device.
func (src *AudioSrc) close() bool {
	gclass := (*C.GstAudioSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.close

	var _arg0 *C.GstAudioSrc // out
	var _cret C.gboolean     // in

	_arg0 = (*C.GstAudioSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C._gotk4_gstaudio1_AudioSrc_virtual_close(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(src)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Delay: number of frames queued in the device.
func (src *AudioSrc) delay() uint {
	gclass := (*C.GstAudioSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.delay

	var _arg0 *C.GstAudioSrc // out
	var _cret C.guint        // in

	_arg0 = (*C.GstAudioSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C._gotk4_gstaudio1_AudioSrc_virtual_delay(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(src)

	var _guint uint // out

	_guint = uint(_cret)

	return _guint
}

// Open the device with the specified caps.
func (src *AudioSrc) open() bool {
	gclass := (*C.GstAudioSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.open

	var _arg0 *C.GstAudioSrc // out
	var _cret C.gboolean     // in

	_arg0 = (*C.GstAudioSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C._gotk4_gstaudio1_AudioSrc_virtual_open(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(src)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Prepare: configure device with format.
func (src *AudioSrc) prepare(spec *AudioRingBufferSpec) bool {
	gclass := (*C.GstAudioSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.prepare

	var _arg0 *C.GstAudioSrc            // out
	var _arg1 *C.GstAudioRingBufferSpec // out
	var _cret C.gboolean                // in

	_arg0 = (*C.GstAudioSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg1 = (*C.GstAudioRingBufferSpec)(gextras.StructNative(unsafe.Pointer(spec)))

	_cret = C._gotk4_gstaudio1_AudioSrc_virtual_prepare(unsafe.Pointer(fnarg), _arg0, _arg1)
	runtime.KeepAlive(src)
	runtime.KeepAlive(spec)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Read: read samples from the device.
//
// The function takes the following parameters:
//
//   - data: sample data.
//
// The function returns the following values:
//
//   - timestamp: ClockTime.
//   - guint
func (src *AudioSrc) read(data []byte) (gst.ClockTime, uint) {
	gclass := (*C.GstAudioSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.read

	var _arg0 *C.GstAudioSrc // out
	var _arg1 C.gpointer     // out
	var _arg2 C.guint
	var _arg3 C.GstClockTime // in
	var _cret C.guint        // in

	_arg0 = (*C.GstAudioSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))
	_arg2 = (C.guint)(len(data))
	if len(data) > 0 {
		_arg1 = (C.gpointer)(unsafe.Pointer(&data[0]))
	}

	_cret = C._gotk4_gstaudio1_AudioSrc_virtual_read(unsafe.Pointer(fnarg), _arg0, _arg1, _arg2, &_arg3)
	runtime.KeepAlive(src)
	runtime.KeepAlive(data)

	var _timestamp gst.ClockTime // out
	var _guint uint              // out

	_timestamp = gst.ClockTime(_arg3)
	_guint = uint(_cret)

	return _timestamp, _guint
}

// Reset: unblock a read to the device and reset.
func (src *AudioSrc) reset() {
	gclass := (*C.GstAudioSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.reset

	var _arg0 *C.GstAudioSrc // out

	_arg0 = (*C.GstAudioSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	C._gotk4_gstaudio1_AudioSrc_virtual_reset(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(src)
}

// Unprepare: undo the configuration.
func (src *AudioSrc) unprepare() bool {
	gclass := (*C.GstAudioSrcClass)(coreglib.PeekParentClass(src))
	fnarg := gclass.unprepare

	var _arg0 *C.GstAudioSrc // out
	var _cret C.gboolean     // in

	_arg0 = (*C.GstAudioSrc)(unsafe.Pointer(coreglib.BaseObject(src).Native()))

	_cret = C._gotk4_gstaudio1_AudioSrc_virtual_unprepare(unsafe.Pointer(fnarg), _arg0)
	runtime.KeepAlive(src)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// AudioAggregatorClass (GstAudioAggregatorClass): instance of this type is
// always passed by reference.
type AudioAggregatorClass struct {
	*audioAggregatorClass
}

// audioAggregatorClass is the struct that's finalized.
type audioAggregatorClass struct {
	native *C.GstAudioAggregatorClass
}

func (a *AudioAggregatorClass) ParentClass() *gstbase.AggregatorClass {
	valptr := &a.native.parent_class
	var _v *gstbase.AggregatorClass // out
	_v = (*gstbase.AggregatorClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// AudioAggregatorConvertPadClass (GstAudioAggregatorConvertPadClass): instance
// of this type is always passed by reference.
type AudioAggregatorConvertPadClass struct {
	*audioAggregatorConvertPadClass
}

// audioAggregatorConvertPadClass is the struct that's finalized.
type audioAggregatorConvertPadClass struct {
	native *C.GstAudioAggregatorConvertPadClass
}

func (a *AudioAggregatorConvertPadClass) ParentClass() *AudioAggregatorPadClass {
	valptr := &a.native.parent_class
	var _v *AudioAggregatorPadClass // out
	_v = (*AudioAggregatorPadClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// AudioAggregatorPadClass (GstAudioAggregatorPadClass): instance of this type
// is always passed by reference.
type AudioAggregatorPadClass struct {
	*audioAggregatorPadClass
}

// audioAggregatorPadClass is the struct that's finalized.
type audioAggregatorPadClass struct {
	native *C.GstAudioAggregatorPadClass
}

func (a *AudioAggregatorPadClass) ParentClass() *gstbase.AggregatorPadClass {
	valptr := &a.native.parent_class
	var _v *gstbase.AggregatorPadClass // out
	_v = (*gstbase.AggregatorPadClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// AudioBaseSinkClass (GstAudioBaseSinkClass) class. Override the vmethod to
// implement functionality.
//
// An instance of this type is always passed by reference.
type AudioBaseSinkClass struct {
	*audioBaseSinkClass
}

// audioBaseSinkClass is the struct that's finalized.
type audioBaseSinkClass struct {
	native *C.GstAudioBaseSinkClass
}

// ParentClass: parent class.
func (a *AudioBaseSinkClass) ParentClass() *gstbase.BaseSinkClass {
	valptr := &a.native.parent_class
	var _v *gstbase.BaseSinkClass // out
	_v = (*gstbase.BaseSinkClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// AudioBaseSrcClass (GstAudioBaseSrcClass) class. Override the vmethod to
// implement functionality.
//
// An instance of this type is always passed by reference.
type AudioBaseSrcClass struct {
	*audioBaseSrcClass
}

// audioBaseSrcClass is the struct that's finalized.
type audioBaseSrcClass struct {
	native *C.GstAudioBaseSrcClass
}

// ParentClass: parent class.
func (a *AudioBaseSrcClass) ParentClass() *gstbase.PushSrcClass {
	valptr := &a.native.parent_class
	var _v *gstbase.PushSrcClass // out
	_v = (*gstbase.PushSrcClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// AudioBuffer (GstAudioBuffer): structure containing the result of an audio
// buffer map operation, which is executed with gst_audio_buffer_map().
// For non-interleaved (planar) buffers, the beginning of each channel in the
// buffer has its own pointer in the planes array. For interleaved buffers, the
// planes array only contains one item, which is the pointer to the beginning of
// the buffer, and n_planes equals 1.
//
// The different channels in planes are always in the GStreamer channel order.
//
// An instance of this type is always passed by reference.
type AudioBuffer struct {
	*audioBuffer
}

// audioBuffer is the struct that's finalized.
type audioBuffer struct {
	native *C.GstAudioBuffer
}

// Info describing the audio properties of this buffer.
func (a *AudioBuffer) Info() *AudioInfo {
	valptr := &a.native.info
	var _v *AudioInfo // out
	_v = (*AudioInfo)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// NSamples: size of the buffer in samples.
func (a *AudioBuffer) NSamples() uint {
	valptr := &a.native.n_samples
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// NPlanes: number of planes available.
func (a *AudioBuffer) NPlanes() int {
	valptr := &a.native.n_planes
	var _v int // out
	_v = int(*valptr)
	return _v
}

// Planes: array of n_planes pointers pointing to the start of each plane in the
// mapped buffer.
func (a *AudioBuffer) Planes() *unsafe.Pointer {
	valptr := &a.native.planes
	var _v *unsafe.Pointer // out
	_v = (*unsafe.Pointer)(unsafe.Pointer(*valptr))
	return _v
}

// Buffer: mapped buffer.
func (a *AudioBuffer) Buffer() *gst.Buffer {
	valptr := &a.native.buffer
	var _v *gst.Buffer // out
	_v = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_v)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})
	return _v
}

// NSamples: size of the buffer in samples.
func (a *AudioBuffer) SetNSamples(nSamples uint) {
	valptr := &a.native.n_samples
	*valptr = C.gsize(nSamples)
}

// NPlanes: number of planes available.
func (a *AudioBuffer) SetNPlanes(nPlanes int) {
	valptr := &a.native.n_planes
	*valptr = C.gint(nPlanes)
}

// Unmap (gst_audio_buffer_unmap) unmaps an audio buffer that was previously
// mapped with gst_audio_buffer_map().
func (buffer *AudioBuffer) Unmap() {
	var _arg0 *C.GstAudioBuffer // out

	_arg0 = (*C.GstAudioBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))

	C.gst_audio_buffer_unmap(_arg0)
	runtime.KeepAlive(buffer)
}

// AudioBufferClip (gst_audio_buffer_clip): clip the buffer to the given
// GstSegment.
//
// After calling this function the caller does not own a reference to buffer
// anymore.
//
// The function takes the following parameters:
//
//   - buffer to clip.
//   - segment: segment in GST_FORMAT_TIME or GST_FORMAT_DEFAULT to which the
//     buffer should be clipped.
//   - rate: sample rate.
//   - bpf: size of one audio frame in bytes. This is the size of one sample *
//     number of channels.
//
// The function returns the following values:
//
//   - ret (optional): NULL if the buffer is completely outside the configured
//     segment, otherwise the clipped buffer is returned.
//
//     If the buffer has no timestamp, it is assumed to be inside the segment
//     and is not clipped.
func AudioBufferClip(buffer *gst.Buffer, segment *gst.Segment, rate, bpf int) *gst.Buffer {
	var _arg1 *C.GstBuffer  // out
	var _arg2 *C.GstSegment // out
	var _arg3 C.gint        // out
	var _arg4 C.gint        // out
	var _cret *C.GstBuffer  // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(buffer)), nil)
	_arg2 = (*C.GstSegment)(gextras.StructNative(unsafe.Pointer(segment)))
	_arg3 = C.gint(rate)
	_arg4 = C.gint(bpf)

	_cret = C.gst_audio_buffer_clip(_arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(segment)
	runtime.KeepAlive(rate)
	runtime.KeepAlive(bpf)

	var _ret *gst.Buffer // out

	if _cret != nil {
		_ret = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_ret)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
			})
	}

	return _ret
}

// AudioBufferMap (gst_audio_buffer_map) maps an audio gstbuffer so that it can
// be read or written and stores the result of the map operation in buffer.
//
// This is especially useful when the gstbuffer is in non-interleaved (planar)
// layout, in which case this function will use the information in the
// gstbuffer's attached AudioMeta in order to map each channel in a separate
// "plane" in AudioBuffer. If a AudioMeta is not attached on the gstbuffer,
// then it must be in interleaved layout.
//
// If a AudioMeta is attached, then the AudioInfo on the meta is checked against
// info. Normally, they should be equal, but in case they are not, a g_critical
// will be printed and the AudioInfo from the meta will be used.
//
// In non-interleaved buffers, it is possible to have each channel on a separate
// Memory. In this case, each memory will be mapped separately to avoid
// copying their contents in a larger memory area. Do note though that it is
// not supported to have a single channel spanning over two or more different
// Memory objects. Although the map operation will likely succeed in this case,
// it will be highly sub-optimal and it is recommended to merge all the memories
// in the buffer before calling this function.
//
// Note: The actual Buffer is not ref'ed, but it is required to stay valid as
// long as it's mapped.
//
// The function takes the following parameters:
//
//   - info: audio properties of the buffer.
//   - gstbuffer to be mapped.
//   - flags access mode for the memory.
//
// The function returns the following values:
//
//   - buffer: pointer to a AudioBuffer.
//   - ok: TRUE if the map operation succeeded or FALSE on failure.
func AudioBufferMap(info *AudioInfo, gstbuffer *gst.Buffer, flags gst.MapFlags) (*AudioBuffer, bool) {
	var _arg1 C.GstAudioBuffer // in
	var _arg2 *C.GstAudioInfo  // out
	var _arg3 *C.GstBuffer     // out
	var _arg4 C.GstMapFlags    // out
	var _cret C.gboolean       // in

	_arg2 = (*C.GstAudioInfo)(gextras.StructNative(unsafe.Pointer(info)))
	_arg3 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(gstbuffer)))
	_arg4 = C.GstMapFlags(flags)

	_cret = C.gst_audio_buffer_map(&_arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(info)
	runtime.KeepAlive(gstbuffer)
	runtime.KeepAlive(flags)

	var _buffer *AudioBuffer // out
	var _ok bool             // out

	_buffer = (*AudioBuffer)(gextras.NewStructNative(unsafe.Pointer((&_arg1))))
	if _cret != 0 {
		_ok = true
	}

	return _buffer, _ok
}

// AudioBufferReorderChannels (gst_audio_buffer_reorder_channels) reorders
// buffer from the channel positions from to the channel positions to.
// from and to must contain the same number of positions and the same positions,
// only in a different order. buffer must be writable.
//
// The function takes the following parameters:
//
//   - buffer to reorder.
//   - format: GstAudioFormat of the buffer.
//   - from: channel positions in the buffer.
//   - to: channel positions to convert to.
//
// The function returns the following values:
//
//   - ok: TRUE if the reordering was possible.
func AudioBufferReorderChannels(buffer *gst.Buffer, format AudioFormat, from, to []AudioChannelPosition) bool {
	var _arg1 *C.GstBuffer               // out
	var _arg2 C.GstAudioFormat           // out
	var _arg4 *C.GstAudioChannelPosition // out
	var _arg3 C.gint
	var _arg5 *C.GstAudioChannelPosition // out
	var _cret C.gboolean                 // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	_arg2 = C.GstAudioFormat(format)
	_arg3 = (C.gint)(len(from))
	if len(from) > 0 {
		_arg4 = (*C.GstAudioChannelPosition)(unsafe.Pointer(&from[0]))
	}
	_arg3 = (C.gint)(len(to))
	if len(to) > 0 {
		_arg5 = (*C.GstAudioChannelPosition)(unsafe.Pointer(&to[0]))
	}

	_cret = C.gst_audio_buffer_reorder_channels(_arg1, _arg2, _arg3, _arg4, _arg5)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(format)
	runtime.KeepAlive(from)
	runtime.KeepAlive(to)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// AudioBufferTruncate (gst_audio_buffer_truncate): truncate the buffer to
// finally have samples number of samples, removing the necessary amount of
// samples from the end and trim number of samples from the beginning.
//
// This function does not know the audio rate, therefore the caller is
// responsible for re-setting the correct timestamp and duration to the buffer.
// However, timestamp will be preserved if trim == 0, and duration will also be
// preserved if there is no trimming to be done. Offset and offset end will be
// preserved / updated.
//
// After calling this function the caller does not own a reference to buffer
// anymore.
//
// The function takes the following parameters:
//
//   - buffer to truncate.
//   - bpf: size of one audio frame in bytes. This is the size of one sample *
//     number of channels.
//   - trim: number of samples to remove from the beginning of the buffer.
//   - samples: final number of samples that should exist in this buffer or -1
//     to use all the remaining samples if you are only removing samples from
//     the beginning.
//
// The function returns the following values:
//
//   - ret: truncated buffer.
func AudioBufferTruncate(buffer *gst.Buffer, bpf int, trim, samples uint) *gst.Buffer {
	var _arg1 *C.GstBuffer // out
	var _arg2 C.gint       // out
	var _arg3 C.gsize      // out
	var _arg4 C.gsize      // out
	var _cret *C.GstBuffer // in

	_arg1 = (*C.GstBuffer)(gextras.StructNative(unsafe.Pointer(buffer)))
	runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(buffer)), nil)
	_arg2 = C.gint(bpf)
	_arg3 = C.gsize(trim)
	_arg4 = C.gsize(samples)

	_cret = C.gst_audio_buffer_truncate(_arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(buffer)
	runtime.KeepAlive(bpf)
	runtime.KeepAlive(trim)
	runtime.KeepAlive(samples)

	var _ret *gst.Buffer // out

	_ret = (*gst.Buffer)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_ret)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _ret
}

// AudioCdSrcClass (GstAudioCdSrcClass): audio CD source base class.
//
// An instance of this type is always passed by reference.
type AudioCdSrcClass struct {
	*audioCdSrcClass
}

// audioCdSrcClass is the struct that's finalized.
type audioCdSrcClass struct {
	native *C.GstAudioCdSrcClass
}

// PushsrcClass: parent class.
func (a *AudioCdSrcClass) PushsrcClass() *gstbase.PushSrcClass {
	valptr := &a.native.pushsrc_class
	var _v *gstbase.PushSrcClass // out
	_v = (*gstbase.PushSrcClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// AudioCdSrcTrack (GstAudioCdSrcTrack): CD track abstraction to communicate TOC
// entries to the base class.
//
// This structure is only for use by sub-classed in connection with
// gst_audio_cd_src_add_track().
//
// Applications will be informed of the available tracks via a TOC message on
// the pipeline's Bus instead.
//
// An instance of this type is always passed by reference.
type AudioCdSrcTrack struct {
	*audioCdSrcTrack
}

// audioCdSrcTrack is the struct that's finalized.
type audioCdSrcTrack struct {
	native *C.GstAudioCdSrcTrack
}

// IsAudio: whether this is an audio track.
func (a *AudioCdSrcTrack) IsAudio() bool {
	valptr := &a.native.is_audio
	var _v bool // out
	if *valptr != 0 {
		_v = true
	}
	return _v
}

// Num: track number in TOC (usually starts from 1, but not always).
func (a *AudioCdSrcTrack) Num() uint {
	valptr := &a.native.num
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Start: first sector of this track (LBA).
func (a *AudioCdSrcTrack) Start() uint {
	valptr := &a.native.start
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// End: last sector of this track (LBA).
func (a *AudioCdSrcTrack) End() uint {
	valptr := &a.native.end
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Tags: track-specific tags (e.g. from cd-text information), or NULL.
func (a *AudioCdSrcTrack) Tags() *gst.TagList {
	valptr := &a.native.tags
	var _v *gst.TagList // out
	_v = (*gst.TagList)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	return _v
}

// IsAudio: whether this is an audio track.
func (a *AudioCdSrcTrack) SetIsAudio(isAudio bool) {
	valptr := &a.native.is_audio
	if isAudio {
		*valptr = C.TRUE
	}
}

// Num: track number in TOC (usually starts from 1, but not always).
func (a *AudioCdSrcTrack) SetNum(num uint) {
	valptr := &a.native.num
	*valptr = C.guint(num)
}

// Start: first sector of this track (LBA).
func (a *AudioCdSrcTrack) SetStart(start uint) {
	valptr := &a.native.start
	*valptr = C.guint(start)
}

// End: last sector of this track (LBA).
func (a *AudioCdSrcTrack) SetEnd(end uint) {
	valptr := &a.native.end
	*valptr = C.guint(end)
}

// AudioClippingMeta (GstAudioClippingMeta): extra buffer metadata describing
// how much audio has to be clipped from the start or end of a buffer.
// This is used for compressed formats, where the first frame usually has some
// additional samples due to encoder and decoder delays, and the last frame
// usually has some additional samples to be able to fill the complete last
// frame.
//
// This is used to ensure that decoded data in the end has the same amount of
// samples, and multiply decoded streams can be gaplessly concatenated.
//
// Note: If clipping of the start is done by adjusting the segment, this meta
// has to be dropped from buffers as otherwise clipping could happen twice.
//
// An instance of this type is always passed by reference.
type AudioClippingMeta struct {
	*audioClippingMeta
}

// audioClippingMeta is the struct that's finalized.
type audioClippingMeta struct {
	native *C.GstAudioClippingMeta
}

// Meta: parent Meta.
func (a *AudioClippingMeta) Meta() *gst.Meta {
	valptr := &a.native.meta
	var _v *gst.Meta // out
	_v = (*gst.Meta)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// Format of start and stop, GST_FORMAT_DEFAULT is samples.
func (a *AudioClippingMeta) Format() gst.Format {
	valptr := &a.native.format
	var _v gst.Format // out
	_v = gst.Format(*valptr)
	return _v
}

// Start: amount of audio to clip from start of buffer.
func (a *AudioClippingMeta) Start() uint64 {
	valptr := &a.native.start
	var _v uint64 // out
	_v = uint64(*valptr)
	return _v
}

// End: amount of to clip from end of buffer.
func (a *AudioClippingMeta) End() uint64 {
	valptr := &a.native.end
	var _v uint64 // out
	_v = uint64(*valptr)
	return _v
}

// Start: amount of audio to clip from start of buffer.
func (a *AudioClippingMeta) SetStart(start uint64) {
	valptr := &a.native.start
	*valptr = C.guint64(start)
}

// End: amount of to clip from end of buffer.
func (a *AudioClippingMeta) SetEnd(end uint64) {
	valptr := &a.native.end
	*valptr = C.guint64(end)
}

func AudioClippingMetaGetInfo() *gst.MetaInfo {
	var _cret *C.GstMetaInfo // in

	_cret = C.gst_audio_clipping_meta_get_info()

	var _metaInfo *gst.MetaInfo // out

	_metaInfo = (*gst.MetaInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _metaInfo
}

// AudioClockClass (GstAudioClockClass): instance of this type is always passed
// by reference.
type AudioClockClass struct {
	*audioClockClass
}

// audioClockClass is the struct that's finalized.
type audioClockClass struct {
	native *C.GstAudioClockClass
}

func (a *AudioClockClass) ParentClass() *gst.SystemClockClass {
	valptr := &a.native.parent_class
	var _v *gst.SystemClockClass // out
	_v = (*gst.SystemClockClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// AudioConverter (GstAudioConverter): this object is used to convert audio
// samples from one format to another. The object can perform conversion of:
//
//   - audio format with optional dithering and noise shaping
//
//   - audio samplerate
//
//   - audio channels and channel layout
//
// An instance of this type is always passed by reference.
type AudioConverter struct {
	*audioConverter
}

// audioConverter is the struct that's finalized.
type audioConverter struct {
	native *C.GstAudioConverter
}

func marshalAudioConverter(p uintptr) (interface{}, error) {
	b := coreglib.ValueFromNative(unsafe.Pointer(p)).Boxed()
	return &AudioConverter{&audioConverter{(*C.GstAudioConverter)(b)}}, nil
}

// NewAudioConverter constructs a struct AudioConverter.
func NewAudioConverter(flags AudioConverterFlags, inInfo *AudioInfo, outInfo *AudioInfo, config *gst.Structure) *AudioConverter {
	var _arg1 C.GstAudioConverterFlags // out
	var _arg2 *C.GstAudioInfo          // out
	var _arg3 *C.GstAudioInfo          // out
	var _arg4 *C.GstStructure          // out
	var _cret *C.GstAudioConverter     // in

	_arg1 = C.GstAudioConverterFlags(flags)
	_arg2 = (*C.GstAudioInfo)(gextras.StructNative(unsafe.Pointer(inInfo)))
	_arg3 = (*C.GstAudioInfo)(gextras.StructNative(unsafe.Pointer(outInfo)))
	if config != nil {
		_arg4 = (*C.GstStructure)(gextras.StructNative(unsafe.Pointer(config)))
		runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(config)), nil)
	}

	_cret = C.gst_audio_converter_new(_arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(flags)
	runtime.KeepAlive(inInfo)
	runtime.KeepAlive(outInfo)
	runtime.KeepAlive(config)

	var _audioConverter *AudioConverter // out

	if _cret != nil {
		_audioConverter = (*AudioConverter)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_audioConverter)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_audio_converter_free((*C.GstAudioConverter)(intern.C))
			},
		)
	}

	return _audioConverter
}

// Convert (gst_audio_converter_convert): convenience wrapper around
// gst_audio_converter_samples(), which will perform allocation of the output
// buffer based on the result from gst_audio_converter_get_out_frames().
//
// The function takes the following parameters:
//
//   - flags: extra AudioConverterFlags.
//   - in: input data.
//
// The function returns the following values:
//
//   - out: pointer where the output data will be written.
//   - ok: TRUE is the conversion could be performed.
func (convert *AudioConverter) Convert(flags AudioConverterFlags, in []byte) ([]byte, bool) {
	var _arg0 *C.GstAudioConverter     // out
	var _arg1 C.GstAudioConverterFlags // out
	var _arg2 C.gpointer               // out
	var _arg3 C.gsize
	var _arg4 C.gpointer // in
	var _arg5 C.gsize    // in
	var _cret C.gboolean // in

	_arg0 = (*C.GstAudioConverter)(gextras.StructNative(unsafe.Pointer(convert)))
	_arg1 = C.GstAudioConverterFlags(flags)
	_arg3 = (C.gsize)(len(in))
	if len(in) > 0 {
		_arg2 = (C.gpointer)(unsafe.Pointer(&in[0]))
	}

	_cret = C.gst_audio_converter_convert(_arg0, _arg1, _arg2, _arg3, &_arg4, &_arg5)
	runtime.KeepAlive(convert)
	runtime.KeepAlive(flags)
	runtime.KeepAlive(in)

	var _out []byte // out
	var _ok bool    // out

	defer C.free(unsafe.Pointer(_arg4))
	_out = make([]byte, _arg5)
	copy(_out, unsafe.Slice((*byte)(unsafe.Pointer(_arg4)), _arg5))
	if _cret != 0 {
		_ok = true
	}

	return _out, _ok
}

// Config (gst_audio_converter_get_config): get the current configuration of
// convert.
//
// The function returns the following values:
//
//   - inRate (optional): result input rate.
//   - outRate (optional): result output rate.
//   - structure: a Structure that remains valid for as long as convert is valid
//     or until gst_audio_converter_update_config() is called.
func (convert *AudioConverter) Config() (inRate int, outRate int, structure *gst.Structure) {
	var _arg0 *C.GstAudioConverter // out
	var _arg1 C.gint               // in
	var _arg2 C.gint               // in
	var _cret *C.GstStructure      // in

	_arg0 = (*C.GstAudioConverter)(gextras.StructNative(unsafe.Pointer(convert)))

	_cret = C.gst_audio_converter_get_config(_arg0, &_arg1, &_arg2)
	runtime.KeepAlive(convert)

	var _inRate int               // out
	var _outRate int              // out
	var _structure *gst.Structure // out

	_inRate = int(_arg1)
	_outRate = int(_arg2)
	_structure = (*gst.Structure)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	C.gst_mini_object_ref((*C.GstMiniObject)(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_structure)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _inRate, _outRate, _structure
}

// InFrames (gst_audio_converter_get_in_frames): calculate how many input frames
// are currently needed by convert to produce out_frames of output frames.
//
// The function takes the following parameters:
//
//   - outFrames: number of output frames.
//
// The function returns the following values:
//
//   - gsize: number of input frames.
func (convert *AudioConverter) InFrames(outFrames uint) uint {
	var _arg0 *C.GstAudioConverter // out
	var _arg1 C.gsize              // out
	var _cret C.gsize              // in

	_arg0 = (*C.GstAudioConverter)(gextras.StructNative(unsafe.Pointer(convert)))
	_arg1 = C.gsize(outFrames)

	_cret = C.gst_audio_converter_get_in_frames(_arg0, _arg1)
	runtime.KeepAlive(convert)
	runtime.KeepAlive(outFrames)

	var _gsize uint // out

	_gsize = uint(_cret)

	return _gsize
}

// MaxLatency (gst_audio_converter_get_max_latency): get the maximum number of
// input frames that the converter would need before producing output.
//
// The function returns the following values:
//
//   - gsize: latency of convert as expressed in the number of frames.
func (convert *AudioConverter) MaxLatency() uint {
	var _arg0 *C.GstAudioConverter // out
	var _cret C.gsize              // in

	_arg0 = (*C.GstAudioConverter)(gextras.StructNative(unsafe.Pointer(convert)))

	_cret = C.gst_audio_converter_get_max_latency(_arg0)
	runtime.KeepAlive(convert)

	var _gsize uint // out

	_gsize = uint(_cret)

	return _gsize
}

// OutFrames (gst_audio_converter_get_out_frames): calculate how many output
// frames can be produced when in_frames input frames are given to convert.
//
// The function takes the following parameters:
//
//   - inFrames: number of input frames.
//
// The function returns the following values:
//
//   - gsize: number of output frames.
func (convert *AudioConverter) OutFrames(inFrames uint) uint {
	var _arg0 *C.GstAudioConverter // out
	var _arg1 C.gsize              // out
	var _cret C.gsize              // in

	_arg0 = (*C.GstAudioConverter)(gextras.StructNative(unsafe.Pointer(convert)))
	_arg1 = C.gsize(inFrames)

	_cret = C.gst_audio_converter_get_out_frames(_arg0, _arg1)
	runtime.KeepAlive(convert)
	runtime.KeepAlive(inFrames)

	var _gsize uint // out

	_gsize = uint(_cret)

	return _gsize
}

// IsPassthrough (gst_audio_converter_is_passthrough) returns whether the
// audio converter will operate in passthrough mode. The return value would be
// typically input to gst_base_transform_set_passthrough().
//
// The function returns the following values:
//
//   - ok: TRUE when no conversion will actually occur.
func (convert *AudioConverter) IsPassthrough() bool {
	var _arg0 *C.GstAudioConverter // out
	var _cret C.gboolean           // in

	_arg0 = (*C.GstAudioConverter)(gextras.StructNative(unsafe.Pointer(convert)))

	_cret = C.gst_audio_converter_is_passthrough(_arg0)
	runtime.KeepAlive(convert)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// Reset (gst_audio_converter_reset) convert to the state it was when it was
// first created, clearing any history it might currently have.
func (convert *AudioConverter) Reset() {
	var _arg0 *C.GstAudioConverter // out

	_arg0 = (*C.GstAudioConverter)(gextras.StructNative(unsafe.Pointer(convert)))

	C.gst_audio_converter_reset(_arg0)
	runtime.KeepAlive(convert)
}

// Samples (gst_audio_converter_samples): perform the conversion with in_frames
// in in to out_frames in out using convert.
//
// In case the samples are interleaved, in and out must point to an array with a
// single element pointing to a block of interleaved samples.
//
// If non-interleaved samples are used, in and out must point to an array with
// pointers to memory blocks, one for each channel.
//
// in may be NULL, in which case in_frames of silence samples are processed by
// the converter.
//
// This function always produces out_frames of output and consumes
// in_frames of input. Use gst_audio_converter_get_out_frames() and
// gst_audio_converter_get_in_frames() to make sure in_frames and out_frames are
// matching and in and out point to enough memory.
//
// The function takes the following parameters:
//
//   - flags: extra AudioConverterFlags.
//   - in (optional): input frames.
//   - inFrames: number of input frames.
//   - out (optional): output frames.
//   - outFrames: number of output frames.
//
// The function returns the following values:
//
//   - ok: TRUE is the conversion could be performed.
func (convert *AudioConverter) Samples(flags AudioConverterFlags, in *unsafe.Pointer, inFrames uint, out *unsafe.Pointer, outFrames uint) bool {
	var _arg0 *C.GstAudioConverter     // out
	var _arg1 C.GstAudioConverterFlags // out
	var _arg2 *C.gpointer              // out
	var _arg3 C.gsize                  // out
	var _arg4 *C.gpointer              // out
	var _arg5 C.gsize                  // out
	var _cret C.gboolean               // in

	_arg0 = (*C.GstAudioConverter)(gextras.StructNative(unsafe.Pointer(convert)))
	_arg1 = C.GstAudioConverterFlags(flags)
	if in != nil {
		_arg2 = (*C.gpointer)(unsafe.Pointer(in))
	}
	_arg3 = C.gsize(inFrames)
	if out != nil {
		_arg4 = (*C.gpointer)(unsafe.Pointer(out))
	}
	_arg5 = C.gsize(outFrames)

	_cret = C.gst_audio_converter_samples(_arg0, _arg1, _arg2, _arg3, _arg4, _arg5)
	runtime.KeepAlive(convert)
	runtime.KeepAlive(flags)
	runtime.KeepAlive(in)
	runtime.KeepAlive(inFrames)
	runtime.KeepAlive(out)
	runtime.KeepAlive(outFrames)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SupportsInplace (gst_audio_converter_supports_inplace) returns whether the
// audio converter can perform the conversion in-place. The return value would
// be typically input to gst_base_transform_set_in_place().
//
// The function returns the following values:
//
//   - ok: TRUE when the conversion can be done in place.
func (convert *AudioConverter) SupportsInplace() bool {
	var _arg0 *C.GstAudioConverter // out
	var _cret C.gboolean           // in

	_arg0 = (*C.GstAudioConverter)(gextras.StructNative(unsafe.Pointer(convert)))

	_cret = C.gst_audio_converter_supports_inplace(_arg0)
	runtime.KeepAlive(convert)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// UpdateConfig (gst_audio_converter_update_config): set in_rate, out_rate and
// config as extra configuration for convert.
//
// in_rate and out_rate specify the new sample rates of input and output
// formats. A value of 0 leaves the sample rate unchanged.
//
// config can be NULL, in which case, the current configuration is not changed.
//
// If the parameters in config can not be set exactly, this function returns
// FALSE and will try to update as much state as possible. The new state can
// then be retrieved and refined with gst_audio_converter_get_config().
//
// Look at the GST_AUDIO_CONVERTER_OPT_* fields to check valid configuration
// option and values.
//
// The function takes the following parameters:
//
//   - inRate: input rate.
//   - outRate: output rate.
//   - config (optional) or NULL.
//
// The function returns the following values:
//
//   - ok: TRUE when the new parameters could be set.
func (convert *AudioConverter) UpdateConfig(inRate int, outRate int, config *gst.Structure) bool {
	var _arg0 *C.GstAudioConverter // out
	var _arg1 C.gint               // out
	var _arg2 C.gint               // out
	var _arg3 *C.GstStructure      // out
	var _cret C.gboolean           // in

	_arg0 = (*C.GstAudioConverter)(gextras.StructNative(unsafe.Pointer(convert)))
	_arg1 = C.gint(inRate)
	_arg2 = C.gint(outRate)
	if config != nil {
		_arg3 = (*C.GstStructure)(gextras.StructNative(unsafe.Pointer(config)))
		runtime.SetFinalizer(gextras.StructIntern(unsafe.Pointer(config)), nil)
	}

	_cret = C.gst_audio_converter_update_config(_arg0, _arg1, _arg2, _arg3)
	runtime.KeepAlive(convert)
	runtime.KeepAlive(inRate)
	runtime.KeepAlive(outRate)
	runtime.KeepAlive(config)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// AudioDecoderClass (GstAudioDecoderClass) subclasses can override any of the
// available virtual methods or not, as needed. At minimum handle_frame (and
// likely set_format) needs to be overridden.
//
// An instance of this type is always passed by reference.
type AudioDecoderClass struct {
	*audioDecoderClass
}

// audioDecoderClass is the struct that's finalized.
type audioDecoderClass struct {
	native *C.GstAudioDecoderClass
}

// ElementClass: parent class structure.
func (a *AudioDecoderClass) ElementClass() *gst.ElementClass {
	valptr := &a.native.element_class
	var _v *gst.ElementClass // out
	_v = (*gst.ElementClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// AudioDownmixMeta (GstAudioDownmixMeta): extra buffer metadata describing
// audio downmixing matrix. This metadata is attached to audio buffers and
// contains a matrix to downmix the buffer number of channels to channels.
//
// matrix is an two-dimensional array of to_channels times from_channels
// coefficients, i.e. the i-th output channels is constructed by multiplicating
// the input channels with the coefficients in matrix[i] and taking the sum of
// the results.
//
// An instance of this type is always passed by reference.
type AudioDownmixMeta struct {
	*audioDownmixMeta
}

// audioDownmixMeta is the struct that's finalized.
type audioDownmixMeta struct {
	native *C.GstAudioDownmixMeta
}

// Meta: parent Meta.
func (a *AudioDownmixMeta) Meta() *gst.Meta {
	valptr := &a.native.meta
	var _v *gst.Meta // out
	_v = (*gst.Meta)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// FromPosition: channel positions of the source.
func (a *AudioDownmixMeta) FromPosition() *AudioChannelPosition {
	valptr := &a.native.from_position
	var _v *AudioChannelPosition // out
	_v = (*AudioChannelPosition)(unsafe.Pointer(*valptr))
	return _v
}

// ToPosition: channel positions of the destination.
func (a *AudioDownmixMeta) ToPosition() *AudioChannelPosition {
	valptr := &a.native.to_position
	var _v *AudioChannelPosition // out
	_v = (*AudioChannelPosition)(unsafe.Pointer(*valptr))
	return _v
}

// FromChannels: number of channels of the source.
func (a *AudioDownmixMeta) FromChannels() int {
	valptr := &a.native.from_channels
	var _v int // out
	_v = int(*valptr)
	return _v
}

// ToChannels: number of channels of the destination.
func (a *AudioDownmixMeta) ToChannels() int {
	valptr := &a.native.to_channels
	var _v int // out
	_v = int(*valptr)
	return _v
}

// Matrix: matrix coefficients.
func (a *AudioDownmixMeta) Matrix() **float32 {
	valptr := &a.native.matrix
	var _v **float32 // out
	_v = (**float32)(unsafe.Pointer(*valptr))
	return _v
}

// FromChannels: number of channels of the source.
func (a *AudioDownmixMeta) SetFromChannels(fromChannels int) {
	valptr := &a.native.from_channels
	*valptr = C.gint(fromChannels)
}

// ToChannels: number of channels of the destination.
func (a *AudioDownmixMeta) SetToChannels(toChannels int) {
	valptr := &a.native.to_channels
	*valptr = C.gint(toChannels)
}

func AudioDownmixMetaGetInfo() *gst.MetaInfo {
	var _cret *C.GstMetaInfo // in

	_cret = C.gst_audio_downmix_meta_get_info()

	var _metaInfo *gst.MetaInfo // out

	_metaInfo = (*gst.MetaInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _metaInfo
}

// AudioEncoderClass (GstAudioEncoderClass) subclasses can override any of
// the available virtual methods or not, as needed. At minimum set_format and
// handle_frame needs to be overridden.
//
// An instance of this type is always passed by reference.
type AudioEncoderClass struct {
	*audioEncoderClass
}

// audioEncoderClass is the struct that's finalized.
type audioEncoderClass struct {
	native *C.GstAudioEncoderClass
}

// ElementClass: parent class structure.
func (a *AudioEncoderClass) ElementClass() *gst.ElementClass {
	valptr := &a.native.element_class
	var _v *gst.ElementClass // out
	_v = (*gst.ElementClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// AudioFilterClass (GstAudioFilterClass): in addition to the setup virtual
// function, you should also override the GstBaseTransform::transform and/or
// GstBaseTransform::transform_ip virtual function.
//
// An instance of this type is always passed by reference.
type AudioFilterClass struct {
	*audioFilterClass
}

// audioFilterClass is the struct that's finalized.
type audioFilterClass struct {
	native *C.GstAudioFilterClass
}

// Basetransformclass: parent class.
func (a *AudioFilterClass) Basetransformclass() *gstbase.BaseTransformClass {
	valptr := &a.native.basetransformclass
	var _v *gstbase.BaseTransformClass // out
	_v = (*gstbase.BaseTransformClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// AddPadTemplates (gst_audio_filter_class_add_pad_templates): convenience
// function to add pad templates to this element class, with allowed_caps as the
// caps that can be handled.
//
// This function is usually used from within a GObject class_init function.
//
// The function takes the following parameters:
//
//   - allowedCaps: what formats the filter can handle, as Caps.
func (klass *AudioFilterClass) AddPadTemplates(allowedCaps *gst.Caps) {
	var _arg0 *C.GstAudioFilterClass // out
	var _arg1 *C.GstCaps             // out

	_arg0 = (*C.GstAudioFilterClass)(gextras.StructNative(unsafe.Pointer(klass)))
	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(allowedCaps)))

	C.gst_audio_filter_class_add_pad_templates(_arg0, _arg1)
	runtime.KeepAlive(klass)
	runtime.KeepAlive(allowedCaps)
}

// AudioFormatInfo (GstAudioFormatInfo): information for an audio format.
//
// An instance of this type is always passed by reference.
type AudioFormatInfo struct {
	*audioFormatInfo
}

// audioFormatInfo is the struct that's finalized.
type audioFormatInfo struct {
	native *C.GstAudioFormatInfo
}

func marshalAudioFormatInfo(p uintptr) (interface{}, error) {
	b := coreglib.ValueFromNative(unsafe.Pointer(p)).Boxed()
	return &AudioFormatInfo{&audioFormatInfo{(*C.GstAudioFormatInfo)(b)}}, nil
}

// FillSilence (gst_audio_format_info_fill_silence): fill length bytes in dest
// with silence samples for info.
//
// The function takes the following parameters:
//
//   - dest: destination to fill.
func (info *AudioFormatInfo) FillSilence(dest []byte) {
	var _arg0 *C.GstAudioFormatInfo // out
	var _arg1 C.gpointer            // out
	var _arg2 C.gsize

	_arg0 = (*C.GstAudioFormatInfo)(gextras.StructNative(unsafe.Pointer(info)))
	_arg2 = (C.gsize)(len(dest))
	if len(dest) > 0 {
		_arg1 = (C.gpointer)(unsafe.Pointer(&dest[0]))
	}

	C.gst_audio_format_info_fill_silence(_arg0, _arg1, _arg2)
	runtime.KeepAlive(info)
	runtime.KeepAlive(dest)
}

// AudioInfo (GstAudioInfo): information describing audio properties. This
// information can be filled in from GstCaps with gst_audio_info_from_caps().
//
// Use the provided macros to access the info in this structure.
//
// An instance of this type is always passed by reference.
type AudioInfo struct {
	*audioInfo
}

// audioInfo is the struct that's finalized.
type audioInfo struct {
	native *C.GstAudioInfo
}

func marshalAudioInfo(p uintptr) (interface{}, error) {
	b := coreglib.ValueFromNative(unsafe.Pointer(p)).Boxed()
	return &AudioInfo{&audioInfo{(*C.GstAudioInfo)(b)}}, nil
}

// NewAudioInfo constructs a struct AudioInfo.
func NewAudioInfo() *AudioInfo {
	var _cret *C.GstAudioInfo // in

	_cret = C.gst_audio_info_new()

	var _audioInfo *AudioInfo // out

	_audioInfo = (*AudioInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_audioInfo)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_audio_info_free((*C.GstAudioInfo)(intern.C))
		},
	)

	return _audioInfo
}

// NewAudioInfoFromCaps constructs a struct AudioInfo.
func NewAudioInfoFromCaps(caps *gst.Caps) *AudioInfo {
	var _arg1 *C.GstCaps      // out
	var _cret *C.GstAudioInfo // in

	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C.gst_audio_info_new_from_caps(_arg1)
	runtime.KeepAlive(caps)

	var _audioInfo *AudioInfo // out

	if _cret != nil {
		_audioInfo = (*AudioInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))
		runtime.SetFinalizer(
			gextras.StructIntern(unsafe.Pointer(_audioInfo)),
			func(intern *struct{ C unsafe.Pointer }) {
				C.gst_audio_info_free((*C.GstAudioInfo)(intern.C))
			},
		)
	}

	return _audioInfo
}

// Finfo: format info of the audio.
func (a *AudioInfo) Finfo() *AudioFormatInfo {
	valptr := &a.native.finfo
	var _v *AudioFormatInfo // out
	_v = (*AudioFormatInfo)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	return _v
}

// Flags: additional audio flags.
func (a *AudioInfo) Flags() AudioFlags {
	valptr := &a.native.flags
	var _v AudioFlags // out
	_v = AudioFlags(*valptr)
	return _v
}

// Layout: audio layout.
func (a *AudioInfo) Layout() AudioLayout {
	valptr := &a.native.layout
	var _v AudioLayout // out
	_v = AudioLayout(*valptr)
	return _v
}

// Rate: audio sample rate.
func (a *AudioInfo) Rate() int {
	valptr := &a.native.rate
	var _v int // out
	_v = int(*valptr)
	return _v
}

// Channels: number of channels.
func (a *AudioInfo) Channels() int {
	valptr := &a.native.channels
	var _v int // out
	_v = int(*valptr)
	return _v
}

// Bpf: number of bytes for one frame, this is the size of one sample *
// channels.
func (a *AudioInfo) Bpf() int {
	valptr := &a.native.bpf
	var _v int // out
	_v = int(*valptr)
	return _v
}

// Position positions for each channel.
func (a *AudioInfo) Position() [64]AudioChannelPosition {
	valptr := &a.native.position
	var _v [64]AudioChannelPosition // out
	_v = *(*[64]AudioChannelPosition)(unsafe.Pointer(&*valptr))
	return _v
}

// Rate: audio sample rate.
func (a *AudioInfo) SetRate(rate int) {
	valptr := &a.native.rate
	*valptr = C.gint(rate)
}

// Channels: number of channels.
func (a *AudioInfo) SetChannels(channels int) {
	valptr := &a.native.channels
	*valptr = C.gint(channels)
}

// Bpf: number of bytes for one frame, this is the size of one sample *
// channels.
func (a *AudioInfo) SetBpf(bpf int) {
	valptr := &a.native.bpf
	*valptr = C.gint(bpf)
}

// Convert (gst_audio_info_convert) converts among various Format types. This
// function handles GST_FORMAT_BYTES, GST_FORMAT_TIME, and GST_FORMAT_DEFAULT.
// For raw audio, GST_FORMAT_DEFAULT corresponds to audio frames. This function
// can be used to handle pad queries of the type GST_QUERY_CONVERT.
//
// The function takes the following parameters:
//
//   - srcFmt of the src_val.
//   - srcVal: value to convert.
//   - destFmt of the dest_val.
//
// The function returns the following values:
//
//   - destVal: pointer to destination value.
//   - ok: TRUE if the conversion was successful.
func (info *AudioInfo) Convert(srcFmt gst.Format, srcVal int64, destFmt gst.Format) (int64, bool) {
	var _arg0 *C.GstAudioInfo // out
	var _arg1 C.GstFormat     // out
	var _arg2 C.gint64        // out
	var _arg3 C.GstFormat     // out
	var _arg4 C.gint64        // in
	var _cret C.gboolean      // in

	_arg0 = (*C.GstAudioInfo)(gextras.StructNative(unsafe.Pointer(info)))
	_arg1 = C.GstFormat(srcFmt)
	_arg2 = C.gint64(srcVal)
	_arg3 = C.GstFormat(destFmt)

	_cret = C.gst_audio_info_convert(_arg0, _arg1, _arg2, _arg3, &_arg4)
	runtime.KeepAlive(info)
	runtime.KeepAlive(srcFmt)
	runtime.KeepAlive(srcVal)
	runtime.KeepAlive(destFmt)

	var _destVal int64 // out
	var _ok bool       // out

	_destVal = int64(_arg4)
	if _cret != 0 {
		_ok = true
	}

	return _destVal, _ok
}

// Copy (gst_audio_info_copy) a GstAudioInfo structure.
//
// The function returns the following values:
//
//   - audioInfo: new AudioInfo. free with gst_audio_info_free.
func (info *AudioInfo) Copy() *AudioInfo {
	var _arg0 *C.GstAudioInfo // out
	var _cret *C.GstAudioInfo // in

	_arg0 = (*C.GstAudioInfo)(gextras.StructNative(unsafe.Pointer(info)))

	_cret = C.gst_audio_info_copy(_arg0)
	runtime.KeepAlive(info)

	var _audioInfo *AudioInfo // out

	_audioInfo = (*AudioInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_audioInfo)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_audio_info_free((*C.GstAudioInfo)(intern.C))
		},
	)

	return _audioInfo
}

// IsEqual (gst_audio_info_is_equal) compares two AudioInfo and returns whether
// they are equal or not.
//
// The function takes the following parameters:
//
//   - other: AudioInfo.
//
// The function returns the following values:
//
//   - ok: TRUE if info and other are equal, else FALSE.
func (info *AudioInfo) IsEqual(other *AudioInfo) bool {
	var _arg0 *C.GstAudioInfo // out
	var _arg1 *C.GstAudioInfo // out
	var _cret C.gboolean      // in

	_arg0 = (*C.GstAudioInfo)(gextras.StructNative(unsafe.Pointer(info)))
	_arg1 = (*C.GstAudioInfo)(gextras.StructNative(unsafe.Pointer(other)))

	_cret = C.gst_audio_info_is_equal(_arg0, _arg1)
	runtime.KeepAlive(info)
	runtime.KeepAlive(other)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SetFormat (gst_audio_info_set_format): set the default info for the audio
// info of format and rate and channels.
//
// Note: This initializes info first, no values are preserved.
//
// The function takes the following parameters:
//
//   - format: format.
//   - rate: samplerate.
//   - channels: number of channels.
//   - position (optional): channel positions.
func (info *AudioInfo) SetFormat(format AudioFormat, rate int, channels int, position [64]AudioChannelPosition) {
	var _arg0 *C.GstAudioInfo            // out
	var _arg1 C.GstAudioFormat           // out
	var _arg2 C.gint                     // out
	var _arg3 C.gint                     // out
	var _arg4 *C.GstAudioChannelPosition // out

	_arg0 = (*C.GstAudioInfo)(gextras.StructNative(unsafe.Pointer(info)))
	_arg1 = C.GstAudioFormat(format)
	_arg2 = C.gint(rate)
	_arg3 = C.gint(channels)
	_arg4 = (*C.GstAudioChannelPosition)(unsafe.Pointer(&position))

	C.gst_audio_info_set_format(_arg0, _arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(info)
	runtime.KeepAlive(format)
	runtime.KeepAlive(rate)
	runtime.KeepAlive(channels)
	runtime.KeepAlive(position)
}

// ToCaps (gst_audio_info_to_caps): convert the values of info into a Caps.
//
// The function returns the following values:
//
//   - caps: new Caps containing the info of info.
func (info *AudioInfo) ToCaps() *gst.Caps {
	var _arg0 *C.GstAudioInfo // out
	var _cret *C.GstCaps      // in

	_arg0 = (*C.GstAudioInfo)(gextras.StructNative(unsafe.Pointer(info)))

	_cret = C.gst_audio_info_to_caps(_arg0)
	runtime.KeepAlive(info)

	var _caps *gst.Caps // out

	_caps = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_caps)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _caps
}

// AudioInfoFromCaps (gst_audio_info_from_caps): parse caps and update info.
//
// The function takes the following parameters:
//
//   - caps: Caps.
//
// The function returns the following values:
//
//   - info: AudioInfo.
//   - ok: TRUE if caps could be parsed.
func AudioInfoFromCaps(caps *gst.Caps) (*AudioInfo, bool) {
	var _arg1 C.GstAudioInfo // in
	var _arg2 *C.GstCaps     // out
	var _cret C.gboolean     // in

	_arg2 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C.gst_audio_info_from_caps(&_arg1, _arg2)
	runtime.KeepAlive(caps)

	var _info *AudioInfo // out
	var _ok bool         // out

	_info = (*AudioInfo)(gextras.NewStructNative(unsafe.Pointer((&_arg1))))
	if _cret != 0 {
		_ok = true
	}

	return _info, _ok
}

// AudioInfoInit (gst_audio_info_init): initialize info with default values.
//
// The function returns the following values:
//
//   - info: AudioInfo.
func AudioInfoInit() *AudioInfo {
	var _arg1 C.GstAudioInfo // in

	C.gst_audio_info_init(&_arg1)

	var _info *AudioInfo // out

	_info = (*AudioInfo)(gextras.NewStructNative(unsafe.Pointer((&_arg1))))

	return _info
}

// AudioLevelMeta (GstAudioLevelMeta): meta containing Audio Level Indication:
// https://tools.ietf.org/html/rfc6464
//
// An instance of this type is always passed by reference.
type AudioLevelMeta struct {
	*audioLevelMeta
}

// audioLevelMeta is the struct that's finalized.
type audioLevelMeta struct {
	native *C.GstAudioLevelMeta
}

// Meta: parent Meta.
func (a *AudioLevelMeta) Meta() *gst.Meta {
	valptr := &a.native.meta
	var _v *gst.Meta // out
	_v = (*gst.Meta)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// Level: -dBov from 0-127 (127 is silence).
func (a *AudioLevelMeta) Level() byte {
	valptr := &a.native.level
	var _v byte // out
	_v = byte(*valptr)
	return _v
}

// VoiceActivity: whether the buffer contains voice activity.
func (a *AudioLevelMeta) VoiceActivity() bool {
	valptr := &a.native.voice_activity
	var _v bool // out
	if *valptr != 0 {
		_v = true
	}
	return _v
}

// Level: -dBov from 0-127 (127 is silence).
func (a *AudioLevelMeta) SetLevel(level byte) {
	valptr := &a.native.level
	*valptr = C.guint8(level)
}

// VoiceActivity: whether the buffer contains voice activity.
func (a *AudioLevelMeta) SetVoiceActivity(voiceActivity bool) {
	valptr := &a.native.voice_activity
	if voiceActivity {
		*valptr = C.TRUE
	}
}

// AudioLevelMetaGetInfo (gst_audio_level_meta_get_info): return the MetaInfo
// associated with AudioLevelMeta.
//
// The function returns the following values:
//
//   - metaInfo: MetaInfo.
func AudioLevelMetaGetInfo() *gst.MetaInfo {
	var _cret *C.GstMetaInfo // in

	_cret = C.gst_audio_level_meta_get_info()

	var _metaInfo *gst.MetaInfo // out

	_metaInfo = (*gst.MetaInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _metaInfo
}

// AudioMeta (GstAudioMeta) defines an audio downmix matrix to be send along
// with audio buffers. These functions in this module help to create and attach
// the meta as well as extracting it.
//
// An instance of this type is always passed by reference.
type AudioMeta struct {
	*audioMeta
}

// audioMeta is the struct that's finalized.
type audioMeta struct {
	native *C.GstAudioMeta
}

// Meta: parent Meta.
func (a *AudioMeta) Meta() *gst.Meta {
	valptr := &a.native.meta
	var _v *gst.Meta // out
	_v = (*gst.Meta)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// Info: audio properties of the buffer.
func (a *AudioMeta) Info() *AudioInfo {
	valptr := &a.native.info
	var _v *AudioInfo // out
	_v = (*AudioInfo)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// Samples: number of valid samples in the buffer.
func (a *AudioMeta) Samples() uint {
	valptr := &a.native.samples
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Offsets offsets (in bytes) where each channel plane starts in the buffer or
// NULL if the buffer has interleaved layout; if not NULL, this is guaranteed to
// be an array of info.channels elements.
func (a *AudioMeta) Offsets() *uint {
	valptr := &a.native.offsets
	var _v *uint // out
	_v = (*uint)(unsafe.Pointer(*valptr))
	return _v
}

// Samples: number of valid samples in the buffer.
func (a *AudioMeta) SetSamples(samples uint) {
	valptr := &a.native.samples
	*valptr = C.gsize(samples)
}

func AudioMetaGetInfo() *gst.MetaInfo {
	var _cret *C.GstMetaInfo // in

	_cret = C.gst_audio_meta_get_info()

	var _metaInfo *gst.MetaInfo // out

	_metaInfo = (*gst.MetaInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _metaInfo
}

// AudioRingBufferClass (GstAudioRingBufferClass) vmethods that subclasses can
// override to implement the ringbuffer.
//
// An instance of this type is always passed by reference.
type AudioRingBufferClass struct {
	*audioRingBufferClass
}

// audioRingBufferClass is the struct that's finalized.
type audioRingBufferClass struct {
	native *C.GstAudioRingBufferClass
}

// ParentClass: parent class.
func (a *AudioRingBufferClass) ParentClass() *gst.ObjectClass {
	valptr := &a.native.parent_class
	var _v *gst.ObjectClass // out
	_v = (*gst.ObjectClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// AudioRingBufferSpec (GstAudioRingBufferSpec): structure containing the format
// specification of the ringbuffer.
//
// When type is GST_AUDIO_RING_BUFFER_FORMAT_TYPE_DSD, the dsd_format is valid
// (otherwise it is unused). Also, when DSD is the sample type, only the rate,
// channels, position, and bpf fields in info are populated.
//
// An instance of this type is always passed by reference.
type AudioRingBufferSpec struct {
	*audioRingBufferSpec
}

// audioRingBufferSpec is the struct that's finalized.
type audioRingBufferSpec struct {
	native *C.GstAudioRingBufferSpec
}

// Caps caps that generated the Spec.
func (a *AudioRingBufferSpec) Caps() *gst.Caps {
	valptr := &a.native.caps
	var _v *gst.Caps // out
	_v = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_v)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})
	return _v
}

// Type: sample type.
func (a *AudioRingBufferSpec) Type() AudioRingBufferFormatType {
	valptr := &a.native._type
	var _v AudioRingBufferFormatType // out
	_v = AudioRingBufferFormatType(*valptr)
	return _v
}

// Info: AudioInfo.
func (a *AudioRingBufferSpec) Info() *AudioInfo {
	valptr := &a.native.info
	var _v *AudioInfo // out
	_v = (*AudioInfo)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// LatencyTime: latency in microseconds.
func (a *AudioRingBufferSpec) LatencyTime() uint64 {
	valptr := &a.native.latency_time
	var _v uint64 // out
	_v = uint64(*valptr)
	return _v
}

// BufferTime: total buffer size in microseconds.
func (a *AudioRingBufferSpec) BufferTime() uint64 {
	valptr := &a.native.buffer_time
	var _v uint64 // out
	_v = uint64(*valptr)
	return _v
}

// Segsize: size of one segment in bytes.
func (a *AudioRingBufferSpec) Segsize() int {
	valptr := &a.native.segsize
	var _v int // out
	_v = int(*valptr)
	return _v
}

// Segtotal: total number of segments.
func (a *AudioRingBufferSpec) Segtotal() int {
	valptr := &a.native.segtotal
	var _v int // out
	_v = int(*valptr)
	return _v
}

// Seglatency: number of segments queued in the lower level device, defaults to
// segtotal.
func (a *AudioRingBufferSpec) Seglatency() int {
	valptr := &a.native.seglatency
	var _v int // out
	_v = int(*valptr)
	return _v
}

// LatencyTime: latency in microseconds.
func (a *AudioRingBufferSpec) SetLatencyTime(latencyTime uint64) {
	valptr := &a.native.latency_time
	*valptr = C.guint64(latencyTime)
}

// BufferTime: total buffer size in microseconds.
func (a *AudioRingBufferSpec) SetBufferTime(bufferTime uint64) {
	valptr := &a.native.buffer_time
	*valptr = C.guint64(bufferTime)
}

// Segsize: size of one segment in bytes.
func (a *AudioRingBufferSpec) SetSegsize(segsize int) {
	valptr := &a.native.segsize
	*valptr = C.gint(segsize)
}

// Segtotal: total number of segments.
func (a *AudioRingBufferSpec) SetSegtotal(segtotal int) {
	valptr := &a.native.segtotal
	*valptr = C.gint(segtotal)
}

// Seglatency: number of segments queued in the lower level device, defaults to
// segtotal.
func (a *AudioRingBufferSpec) SetSeglatency(seglatency int) {
	valptr := &a.native.seglatency
	*valptr = C.gint(seglatency)
}

// AudioSinkClass (GstAudioSinkClass): instance of this type is always passed by
// reference.
type AudioSinkClass struct {
	*audioSinkClass
}

// audioSinkClass is the struct that's finalized.
type audioSinkClass struct {
	native *C.GstAudioSinkClass
}

// ParentClass: parent class structure.
func (a *AudioSinkClass) ParentClass() *AudioBaseSinkClass {
	valptr := &a.native.parent_class
	var _v *AudioBaseSinkClass // out
	_v = (*AudioBaseSinkClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// Extension class extension structure. Since: 1.18.
func (a *AudioSinkClass) Extension() *AudioSinkClassExtension {
	valptr := &a.native.extension
	var _v *AudioSinkClassExtension // out
	_v = (*AudioSinkClassExtension)(gextras.NewStructNative(unsafe.Pointer(*valptr)))
	return _v
}

// AudioSinkClassExtension (GstAudioSinkClassExtension): instance of this type
// is always passed by reference.
type AudioSinkClassExtension struct {
	*audioSinkClassExtension
}

// audioSinkClassExtension is the struct that's finalized.
type audioSinkClassExtension struct {
	native *C.GstAudioSinkClassExtension
}

// AudioSrcClass (GstAudioSrcClass) class. Override the vmethod to implement
// functionality.
//
// An instance of this type is always passed by reference.
type AudioSrcClass struct {
	*audioSrcClass
}

// audioSrcClass is the struct that's finalized.
type audioSrcClass struct {
	native *C.GstAudioSrcClass
}

// ParentClass: parent class.
func (a *AudioSrcClass) ParentClass() *AudioBaseSrcClass {
	valptr := &a.native.parent_class
	var _v *AudioBaseSrcClass // out
	_v = (*AudioBaseSrcClass)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// AudioStreamAlign (GstAudioStreamAlign) provides a helper object that
// helps tracking audio stream alignment and discontinuities, and detects
// discontinuities if possible.
//
// See gst_audio_stream_align_new() for a description of its parameters and
// gst_audio_stream_align_process() for the details of the processing.
//
// An instance of this type is always passed by reference.
type AudioStreamAlign struct {
	*audioStreamAlign
}

// audioStreamAlign is the struct that's finalized.
type audioStreamAlign struct {
	native *C.GstAudioStreamAlign
}

func marshalAudioStreamAlign(p uintptr) (interface{}, error) {
	b := coreglib.ValueFromNative(unsafe.Pointer(p)).Boxed()
	return &AudioStreamAlign{&audioStreamAlign{(*C.GstAudioStreamAlign)(b)}}, nil
}

// NewAudioStreamAlign constructs a struct AudioStreamAlign.
func NewAudioStreamAlign(rate int, alignmentThreshold gst.ClockTime, discontWait gst.ClockTime) *AudioStreamAlign {
	var _arg1 C.gint                 // out
	var _arg2 C.GstClockTime         // out
	var _arg3 C.GstClockTime         // out
	var _cret *C.GstAudioStreamAlign // in

	_arg1 = C.gint(rate)
	_arg2 = C.GstClockTime(alignmentThreshold)
	_arg3 = C.GstClockTime(discontWait)

	_cret = C.gst_audio_stream_align_new(_arg1, _arg2, _arg3)
	runtime.KeepAlive(rate)
	runtime.KeepAlive(alignmentThreshold)
	runtime.KeepAlive(discontWait)

	var _audioStreamAlign *AudioStreamAlign // out

	_audioStreamAlign = (*AudioStreamAlign)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_audioStreamAlign)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_audio_stream_align_free((*C.GstAudioStreamAlign)(intern.C))
		},
	)

	return _audioStreamAlign
}

// Copy (gst_audio_stream_align_copy) a GstAudioStreamAlign structure.
//
// The function returns the following values:
//
//   - audioStreamAlign: new AudioStreamAlign. free with
//     gst_audio_stream_align_free.
func (align *AudioStreamAlign) Copy() *AudioStreamAlign {
	var _arg0 *C.GstAudioStreamAlign // out
	var _cret *C.GstAudioStreamAlign // in

	_arg0 = (*C.GstAudioStreamAlign)(gextras.StructNative(unsafe.Pointer(align)))

	_cret = C.gst_audio_stream_align_copy(_arg0)
	runtime.KeepAlive(align)

	var _audioStreamAlign *AudioStreamAlign // out

	_audioStreamAlign = (*AudioStreamAlign)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_audioStreamAlign)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_audio_stream_align_free((*C.GstAudioStreamAlign)(intern.C))
		},
	)

	return _audioStreamAlign
}

// AlignmentThreshold (gst_audio_stream_align_get_alignment_threshold) gets the
// currently configured alignment threshold.
//
// The function returns the following values:
//
//   - clockTime: currently configured alignment threshold.
func (align *AudioStreamAlign) AlignmentThreshold() gst.ClockTime {
	var _arg0 *C.GstAudioStreamAlign // out
	var _cret C.GstClockTime         // in

	_arg0 = (*C.GstAudioStreamAlign)(gextras.StructNative(unsafe.Pointer(align)))

	_cret = C.gst_audio_stream_align_get_alignment_threshold(_arg0)
	runtime.KeepAlive(align)

	var _clockTime gst.ClockTime // out

	_clockTime = gst.ClockTime(_cret)

	return _clockTime
}

// DiscontWait (gst_audio_stream_align_get_discont_wait) gets the currently
// configured discont wait.
//
// The function returns the following values:
//
//   - clockTime: currently configured discont wait.
func (align *AudioStreamAlign) DiscontWait() gst.ClockTime {
	var _arg0 *C.GstAudioStreamAlign // out
	var _cret C.GstClockTime         // in

	_arg0 = (*C.GstAudioStreamAlign)(gextras.StructNative(unsafe.Pointer(align)))

	_cret = C.gst_audio_stream_align_get_discont_wait(_arg0)
	runtime.KeepAlive(align)

	var _clockTime gst.ClockTime // out

	_clockTime = gst.ClockTime(_cret)

	return _clockTime
}

// Rate (gst_audio_stream_align_get_rate) gets the currently configured sample
// rate.
//
// The function returns the following values:
//
//   - gint: currently configured sample rate.
func (align *AudioStreamAlign) Rate() int {
	var _arg0 *C.GstAudioStreamAlign // out
	var _cret C.gint                 // in

	_arg0 = (*C.GstAudioStreamAlign)(gextras.StructNative(unsafe.Pointer(align)))

	_cret = C.gst_audio_stream_align_get_rate(_arg0)
	runtime.KeepAlive(align)

	var _gint int // out

	_gint = int(_cret)

	return _gint
}

// SamplesSinceDiscont (gst_audio_stream_align_get_samples_since_discont)
// returns the number of samples that were processed since the last
// discontinuity was detected.
//
// The function returns the following values:
//
//   - guint64: number of samples processed since the last discontinuity.
func (align *AudioStreamAlign) SamplesSinceDiscont() uint64 {
	var _arg0 *C.GstAudioStreamAlign // out
	var _cret C.guint64              // in

	_arg0 = (*C.GstAudioStreamAlign)(gextras.StructNative(unsafe.Pointer(align)))

	_cret = C.gst_audio_stream_align_get_samples_since_discont(_arg0)
	runtime.KeepAlive(align)

	var _guint64 uint64 // out

	_guint64 = uint64(_cret)

	return _guint64
}

// TimestampAtDiscont (gst_audio_stream_align_get_timestamp_at_discont):
// timestamp that was passed when a discontinuity was detected, i.e. the first
// timestamp after the discontinuity.
//
// The function returns the following values:
//
//   - clockTime: last timestamp at when a discontinuity was detected.
func (align *AudioStreamAlign) TimestampAtDiscont() gst.ClockTime {
	var _arg0 *C.GstAudioStreamAlign // out
	var _cret C.GstClockTime         // in

	_arg0 = (*C.GstAudioStreamAlign)(gextras.StructNative(unsafe.Pointer(align)))

	_cret = C.gst_audio_stream_align_get_timestamp_at_discont(_arg0)
	runtime.KeepAlive(align)

	var _clockTime gst.ClockTime // out

	_clockTime = gst.ClockTime(_cret)

	return _clockTime
}

// MarkDiscont (gst_audio_stream_align_mark_discont) marks the next buffer as
// discontinuous and resets timestamp tracking.
func (align *AudioStreamAlign) MarkDiscont() {
	var _arg0 *C.GstAudioStreamAlign // out

	_arg0 = (*C.GstAudioStreamAlign)(gextras.StructNative(unsafe.Pointer(align)))

	C.gst_audio_stream_align_mark_discont(_arg0)
	runtime.KeepAlive(align)
}

// Process (gst_audio_stream_align_process) processes data with timestamp and
// n_samples, and returns the output timestamp, duration and sample position
// together with a boolean to signal whether a discontinuity was detected or
// not. All non-discontinuous data will have perfect timestamps and durations.
//
// A discontinuity is detected once the difference between the actual
// timestamp and the timestamp calculated from the sample count since the last
// discontinuity differs by more than the alignment threshold for a duration
// longer than discont wait.
//
// Note: In reverse playback, every buffer is considered discontinuous in the
// context of buffer flags because the last sample of the previous buffer is
// discontinuous with the first sample of the current one. However for this
// function they are only considered discontinuous in reverse playback if the
// first sample of the previous buffer is discontinuous with the last sample of
// the current one.
//
// The function takes the following parameters:
//
//   - discont: if this data is considered to be discontinuous.
//   - timestamp of the start of the data.
//   - nSamples: number of samples to process.
//
// The function returns the following values:
//
//   - outTimestamp: output timestamp of the data.
//   - outDuration: output duration of the data.
//   - outSamplePosition: output sample position of the start of the data.
//   - ok: TRUE if a discontinuity was detected, FALSE otherwise.
func (align *AudioStreamAlign) Process(discont bool, timestamp gst.ClockTime, nSamples uint) (outTimestamp gst.ClockTime, outDuration gst.ClockTime, outSamplePosition uint64, ok bool) {
	var _arg0 *C.GstAudioStreamAlign // out
	var _arg1 C.gboolean             // out
	var _arg2 C.GstClockTime         // out
	var _arg3 C.guint                // out
	var _arg4 C.GstClockTime         // in
	var _arg5 C.GstClockTime         // in
	var _arg6 C.guint64              // in
	var _cret C.gboolean             // in

	_arg0 = (*C.GstAudioStreamAlign)(gextras.StructNative(unsafe.Pointer(align)))
	if discont {
		_arg1 = C.TRUE
	}
	_arg2 = C.GstClockTime(timestamp)
	_arg3 = C.guint(nSamples)

	_cret = C.gst_audio_stream_align_process(_arg0, _arg1, _arg2, _arg3, &_arg4, &_arg5, &_arg6)
	runtime.KeepAlive(align)
	runtime.KeepAlive(discont)
	runtime.KeepAlive(timestamp)
	runtime.KeepAlive(nSamples)

	var _outTimestamp gst.ClockTime // out
	var _outDuration gst.ClockTime  // out
	var _outSamplePosition uint64   // out
	var _ok bool                    // out

	_outTimestamp = gst.ClockTime(_arg4)
	_outDuration = gst.ClockTime(_arg5)
	_outSamplePosition = uint64(_arg6)
	if _cret != 0 {
		_ok = true
	}

	return _outTimestamp, _outDuration, _outSamplePosition, _ok
}

// SetAlignmentThreshold (gst_audio_stream_align_set_alignment_threshold) sets
// alignment_treshold as new alignment threshold for the following processing.
//
// The function takes the following parameters:
//
//   - alignmentThreshold: new alignment threshold.
func (align *AudioStreamAlign) SetAlignmentThreshold(alignmentThreshold gst.ClockTime) {
	var _arg0 *C.GstAudioStreamAlign // out
	var _arg1 C.GstClockTime         // out

	_arg0 = (*C.GstAudioStreamAlign)(gextras.StructNative(unsafe.Pointer(align)))
	_arg1 = C.GstClockTime(alignmentThreshold)

	C.gst_audio_stream_align_set_alignment_threshold(_arg0, _arg1)
	runtime.KeepAlive(align)
	runtime.KeepAlive(alignmentThreshold)
}

// SetDiscontWait (gst_audio_stream_align_set_discont_wait) sets
// alignment_treshold as new discont wait for the following processing.
//
// The function takes the following parameters:
//
//   - discontWait: new discont wait.
func (align *AudioStreamAlign) SetDiscontWait(discontWait gst.ClockTime) {
	var _arg0 *C.GstAudioStreamAlign // out
	var _arg1 C.GstClockTime         // out

	_arg0 = (*C.GstAudioStreamAlign)(gextras.StructNative(unsafe.Pointer(align)))
	_arg1 = C.GstClockTime(discontWait)

	C.gst_audio_stream_align_set_discont_wait(_arg0, _arg1)
	runtime.KeepAlive(align)
	runtime.KeepAlive(discontWait)
}

// SetRate (gst_audio_stream_align_set_rate) sets rate as new sample rate for
// the following processing. If the sample rate differs this implicitly marks
// the next data as discontinuous.
//
// The function takes the following parameters:
//
//   - rate: new sample rate.
func (align *AudioStreamAlign) SetRate(rate int) {
	var _arg0 *C.GstAudioStreamAlign // out
	var _arg1 C.gint                 // out

	_arg0 = (*C.GstAudioStreamAlign)(gextras.StructNative(unsafe.Pointer(align)))
	_arg1 = C.gint(rate)

	C.gst_audio_stream_align_set_rate(_arg0, _arg1)
	runtime.KeepAlive(align)
	runtime.KeepAlive(rate)
}

// DsdInfo (GstDsdInfo): information describing DSD audio properties.
//
// In DSD, the "sample format" is the bit. Unlike PCM, there are no further
// "sample formats" in DSD. However, in software, DSD bits are grouped into
// bytes (since dealing with individual bits is impractical), and these bytes in
// turn are grouped into words. This becomes relevant when interleaving channels
// and transmitting DSD data through audio APIs. The different types of grouping
// DSD bytes are referred to as the "DSD grouping forma" or just "DSD format".
// DsdFormat has a list of valid ways of grouping DSD bytes into words.
//
// DSD rates are equivalent to PCM sample rates, except that they specify how
// many DSD bytes are consumed per second. This refers to the bytes per second
// _per channel_; the rate does not change when the number of channel changes.
// (Strictly speaking, it would be more correct to measure the *bits* per
// second, since the bit is the DSD "sample format", but it is more practical
// to use bytes.) In DSD, bit rates are always an integer multiple of the CD
// audio rate (44100) or the DAT rate (48000). DSD64-44x is 44100 * 64 = 2822400
// bits per second, or 352800 bytes per second (the latter would be used in this
// info structure). DSD64-48x is 48000 * 64 = 3072000 bits per second, or 384000
// bytes per second. T_DSD_MAKE_DSD_RATE_44x can be used for specifying DSD-44x
// rates, *and T_DSD_MAKE_DSD_RATE_48x can be used for specifying DSD-48x ones.
// Also, since DSD-48x is less well known, when the multiplier is given without
// the 44x/48x specifier, 44x is typically implied.
//
// It is important to know that in DSD, different format widths correspond to
// different playtimes. That is, a word with 32 DSD bits covers two times as
// much playtime as a word with 16 DSD bits. This is in contrast to PCM, where
// one word (= one PCM sample) always covers a time period of 1/samplerate,
// no matter how many bits a PCM sample is made of. For this reason, DSD and PCM
// widths and strides cannot be used the same way.
//
// Multiple channels are arranged in DSD data either interleaved or non-
// interleaved. This is similar to PCM. Interleaved layouts rotate between
// channels and words. First, word 0 of channel 0 is present. Then word 0 of
// channel 1 follows. Then word 0 of channel 2 etc. until all channels are
// through, then comes word 1 of channel 0 etc.
//
// Non-interleaved data is planar. First, all words of channel 0 are present,
// then all words of channel 1 etc. Unlike interleaved data, non-interleaved
// data can be sparse, that is, there can be space in between the planes.
// the positions array specifies the plane offsets.
//
// In uncommon cases, the DSD bits in the data bytes can be stored in reverse
// order. For example, normally, in DSDU8, the first byte contains DSD bits 0 to
// 7, and the most significant bit of that byte is DSD bit 0. If this order is
// reversed, then bit 7 is the first one instead. In that ase, reversed_bytes is
// set to TRUE.
//
// Use the provided macros to access the info in this structure.
//
// An instance of this type is always passed by reference.
type DsdInfo struct {
	*dsdInfo
}

// dsdInfo is the struct that's finalized.
type dsdInfo struct {
	native *C.GstDsdInfo
}

func marshalDsdInfo(p uintptr) (interface{}, error) {
	b := coreglib.ValueFromNative(unsafe.Pointer(p)).Boxed()
	return &DsdInfo{&dsdInfo{(*C.GstDsdInfo)(b)}}, nil
}

// NewDsdInfo constructs a struct DsdInfo.
func NewDsdInfo() *DsdInfo {
	var _cret *C.GstDsdInfo // in

	_cret = C.gst_dsd_info_new()

	var _dsdInfo *DsdInfo // out

	_dsdInfo = (*DsdInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_dsdInfo)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_dsd_info_free((*C.GstDsdInfo)(intern.C))
		},
	)

	return _dsdInfo
}

// NewDsdInfoFromCaps constructs a struct DsdInfo.
func NewDsdInfoFromCaps(caps *gst.Caps) *DsdInfo {
	var _arg1 *C.GstCaps    // out
	var _cret *C.GstDsdInfo // in

	_arg1 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C.gst_dsd_info_new_from_caps(_arg1)
	runtime.KeepAlive(caps)

	var _dsdInfo *DsdInfo // out

	_dsdInfo = (*DsdInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_dsdInfo)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_dsd_info_free((*C.GstDsdInfo)(intern.C))
		},
	)

	return _dsdInfo
}

// Format: DSD grouping format.
func (d *DsdInfo) Format() DsdFormat {
	valptr := &d.native.format
	var _v DsdFormat // out
	_v = DsdFormat(*valptr)
	return _v
}

// Rate: DSD rate.
func (d *DsdInfo) Rate() int {
	valptr := &d.native.rate
	var _v int // out
	_v = int(*valptr)
	return _v
}

// Channels: number of channels (must be at least 1).
func (d *DsdInfo) Channels() int {
	valptr := &d.native.channels
	var _v int // out
	_v = int(*valptr)
	return _v
}

// Layout: audio layout.
func (d *DsdInfo) Layout() AudioLayout {
	valptr := &d.native.layout
	var _v AudioLayout // out
	_v = AudioLayout(*valptr)
	return _v
}

// ReversedBytes: true if the DSD bits in the data bytes are reversed, that is,
// the least significant bit comes first.
func (d *DsdInfo) ReversedBytes() bool {
	valptr := &d.native.reversed_bytes
	var _v bool // out
	if *valptr != 0 {
		_v = true
	}
	return _v
}

// Positions positions for each channel.
func (d *DsdInfo) Positions() [64]AudioChannelPosition {
	valptr := &d.native.positions
	var _v [64]AudioChannelPosition // out
	_v = *(*[64]AudioChannelPosition)(unsafe.Pointer(&*valptr))
	return _v
}

func (d *DsdInfo) Flags() AudioFlags {
	valptr := &d.native.flags
	var _v AudioFlags // out
	_v = AudioFlags(*valptr)
	return _v
}

// Rate: DSD rate.
func (d *DsdInfo) SetRate(rate int) {
	valptr := &d.native.rate
	*valptr = C.gint(rate)
}

// Channels: number of channels (must be at least 1).
func (d *DsdInfo) SetChannels(channels int) {
	valptr := &d.native.channels
	*valptr = C.gint(channels)
}

// ReversedBytes: true if the DSD bits in the data bytes are reversed, that is,
// the least significant bit comes first.
func (d *DsdInfo) SetReversedBytes(reversedBytes bool) {
	valptr := &d.native.reversed_bytes
	if reversedBytes {
		*valptr = C.TRUE
	}
}

// Copy (gst_dsd_info_copy) a GstDsdInfo structure.
//
// The function returns the following values:
//
//   - dsdInfo: new DsdInfo. free with gst_dsd_info_free.
func (info *DsdInfo) Copy() *DsdInfo {
	var _arg0 *C.GstDsdInfo // out
	var _cret *C.GstDsdInfo // in

	_arg0 = (*C.GstDsdInfo)(gextras.StructNative(unsafe.Pointer(info)))

	_cret = C.gst_dsd_info_copy(_arg0)
	runtime.KeepAlive(info)

	var _dsdInfo *DsdInfo // out

	_dsdInfo = (*DsdInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_dsdInfo)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_dsd_info_free((*C.GstDsdInfo)(intern.C))
		},
	)

	return _dsdInfo
}

// IsEqual (gst_dsd_info_is_equal) compares two DsdInfo and returns whether they
// are equal or not.
//
// The function takes the following parameters:
//
//   - other: DsdInfo.
//
// The function returns the following values:
//
//   - ok: TRUE if info and other are equal, else FALSE.
func (info *DsdInfo) IsEqual(other *DsdInfo) bool {
	var _arg0 *C.GstDsdInfo // out
	var _arg1 *C.GstDsdInfo // out
	var _cret C.gboolean    // in

	_arg0 = (*C.GstDsdInfo)(gextras.StructNative(unsafe.Pointer(info)))
	_arg1 = (*C.GstDsdInfo)(gextras.StructNative(unsafe.Pointer(other)))

	_cret = C.gst_dsd_info_is_equal(_arg0, _arg1)
	runtime.KeepAlive(info)
	runtime.KeepAlive(other)

	var _ok bool // out

	if _cret != 0 {
		_ok = true
	}

	return _ok
}

// SetFormat (gst_dsd_info_set_format): set the default info for the DSD info of
// format and rate and channels.
//
// Note: This initializes info first, no values are preserved.
//
// The function takes the following parameters:
//
//   - format: format.
//   - rate: DSD rate.
//   - channels: number of channels.
//   - positions (optional): channel positions.
func (info *DsdInfo) SetFormat(format DsdFormat, rate int, channels int, positions [64]AudioChannelPosition) {
	var _arg0 *C.GstDsdInfo              // out
	var _arg1 C.GstDsdFormat             // out
	var _arg2 C.gint                     // out
	var _arg3 C.gint                     // out
	var _arg4 *C.GstAudioChannelPosition // out

	_arg0 = (*C.GstDsdInfo)(gextras.StructNative(unsafe.Pointer(info)))
	_arg1 = C.GstDsdFormat(format)
	_arg2 = C.gint(rate)
	_arg3 = C.gint(channels)
	_arg4 = (*C.GstAudioChannelPosition)(unsafe.Pointer(&positions))

	C.gst_dsd_info_set_format(_arg0, _arg1, _arg2, _arg3, _arg4)
	runtime.KeepAlive(info)
	runtime.KeepAlive(format)
	runtime.KeepAlive(rate)
	runtime.KeepAlive(channels)
	runtime.KeepAlive(positions)
}

// ToCaps (gst_dsd_info_to_caps): convert the values of info into a Caps.
//
// The function returns the following values:
//
//   - caps: new Caps containing the info of info.
func (info *DsdInfo) ToCaps() *gst.Caps {
	var _arg0 *C.GstDsdInfo // out
	var _cret *C.GstCaps    // in

	_arg0 = (*C.GstDsdInfo)(gextras.StructNative(unsafe.Pointer(info)))

	_cret = C.gst_dsd_info_to_caps(_arg0)
	runtime.KeepAlive(info)

	var _caps *gst.Caps // out

	_caps = (*gst.Caps)(gextras.NewStructNative(unsafe.Pointer(_cret)))
	runtime.SetFinalizer(
		gextras.StructIntern(unsafe.Pointer(_caps)),
		func(intern *struct{ C unsafe.Pointer }) {
			C.gst_mini_object_unref((*C.GstMiniObject)(intern.C))
		})

	return _caps
}

// DsdInfoFromCaps (gst_dsd_info_from_caps): parse caps and update info.
//
// The function takes the following parameters:
//
//   - caps: Caps.
//
// The function returns the following values:
//
//   - info: DsdInfo.
//   - ok: TRUE if caps could be parsed.
func DsdInfoFromCaps(caps *gst.Caps) (*DsdInfo, bool) {
	var _arg1 C.GstDsdInfo // in
	var _arg2 *C.GstCaps   // out
	var _cret C.gboolean   // in

	_arg2 = (*C.GstCaps)(gextras.StructNative(unsafe.Pointer(caps)))

	_cret = C.gst_dsd_info_from_caps(&_arg1, _arg2)
	runtime.KeepAlive(caps)

	var _info *DsdInfo // out
	var _ok bool       // out

	_info = (*DsdInfo)(gextras.NewStructNative(unsafe.Pointer((&_arg1))))
	if _cret != 0 {
		_ok = true
	}

	return _info, _ok
}

// DsdInfoInit (gst_dsd_info_init): initialize info with default values.
//
// The function returns the following values:
//
//   - info: DsdInfo.
func DsdInfoInit() *DsdInfo {
	var _arg1 C.GstDsdInfo // in

	C.gst_dsd_info_init(&_arg1)

	var _info *DsdInfo // out

	_info = (*DsdInfo)(gextras.NewStructNative(unsafe.Pointer((&_arg1))))

	return _info
}

// DsdPlaneOffsetMeta (GstDsdPlaneOffsetMeta): buffer metadata describing planar
// DSD contents in the buffer. This is not needed for interleaved DSD data,
// and is required for non-interleaved (= planar) data.
//
// The different channels in offsets are always in the GStreamer channel order.
// Zero-copy channel reordering can be implemented by swapping the values in
// offsets.
//
// It is not allowed for channels to overlap in memory, i.e. for each i in [0,
// channels), the range [offsets[i], offsets[i] + num_bytes_per_channel) must
// not overlap with any other such range.
//
// It is, however, allowed to have parts of the buffer memory unused, by using
// offsets and num_bytes_per_channel in such a way that leave gaps on it.
// This is used to implement zero-copy clipping in non-interleaved buffers.
//
// Obviously, due to the above, it is not safe to infer the number of
// valid bytes from the size of the buffer. You should always use the
// num_bytes_per_channel variable of this metadata.
//
// An instance of this type is always passed by reference.
type DsdPlaneOffsetMeta struct {
	*dsdPlaneOffsetMeta
}

// dsdPlaneOffsetMeta is the struct that's finalized.
type dsdPlaneOffsetMeta struct {
	native *C.GstDsdPlaneOffsetMeta
}

// Meta: parent Meta.
func (d *DsdPlaneOffsetMeta) Meta() *gst.Meta {
	valptr := &d.native.meta
	var _v *gst.Meta // out
	_v = (*gst.Meta)(gextras.NewStructNative(unsafe.Pointer(valptr)))
	return _v
}

// NumChannels: number of channels in the DSD data.
func (d *DsdPlaneOffsetMeta) NumChannels() int {
	valptr := &d.native.num_channels
	var _v int // out
	_v = int(*valptr)
	return _v
}

// NumBytesPerChannel: number of valid bytes per channel in the buffer.
func (d *DsdPlaneOffsetMeta) NumBytesPerChannel() uint {
	valptr := &d.native.num_bytes_per_channel
	var _v uint // out
	_v = uint(*valptr)
	return _v
}

// Offsets offsets (in bytes) where each channel plane starts in the buffer.
func (d *DsdPlaneOffsetMeta) Offsets() *uint {
	valptr := &d.native.offsets
	var _v *uint // out
	_v = (*uint)(unsafe.Pointer(*valptr))
	return _v
}

// NumChannels: number of channels in the DSD data.
func (d *DsdPlaneOffsetMeta) SetNumChannels(numChannels int) {
	valptr := &d.native.num_channels
	*valptr = C.gint(numChannels)
}

// NumBytesPerChannel: number of valid bytes per channel in the buffer.
func (d *DsdPlaneOffsetMeta) SetNumBytesPerChannel(numBytesPerChannel uint) {
	valptr := &d.native.num_bytes_per_channel
	*valptr = C.gsize(numBytesPerChannel)
}

func DsdPlaneOffsetMetaGetInfo() *gst.MetaInfo {
	var _cret *C.GstMetaInfo // in

	_cret = C.gst_dsd_plane_offset_meta_get_info()

	var _metaInfo *gst.MetaInfo // out

	_metaInfo = (*gst.MetaInfo)(gextras.NewStructNative(unsafe.Pointer(_cret)))

	return _metaInfo
}

// StreamVolumeInterface (GstStreamVolumeInterface): instance of this type is
// always passed by reference.
type StreamVolumeInterface struct {
	*streamVolumeInterface
}

// streamVolumeInterface is the struct that's finalized.
type streamVolumeInterface struct {
	native *C.GstStreamVolumeInterface
}
